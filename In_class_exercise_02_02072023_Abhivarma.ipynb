{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhivarma-Birru-Unt/Abhivarma_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023_Abhivarma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_IxAhYrwql5"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdii6UZwql7"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIpIcpqTwql8"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "E9UTlS0Dwql8",
        "outputId": "5fe163ff-870c-4e17-b648-573da215d8ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nHere we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\\nWe choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\\n\\nHere we scrape only the basic comment users have mentioned and the respective star rating they have given.\\nThese allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\\n\\nWe collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\\n\\nSTEPS:\\n1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\\n2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\\n3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\\n4. Iterate each page dynamically until we get atleast 1000 reviews of the product\\n5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \\n6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\\n7. Print or Display the dataframe to get the respective reviews.\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Here we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\n",
        "We choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\n",
        "\n",
        "Here we scrape only the basic comment users have mentioned and the respective star rating they have given.\n",
        "These allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\n",
        "\n",
        "We collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\n",
        "\n",
        "STEPS:\n",
        "1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\n",
        "2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\n",
        "3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\n",
        "4. Iterate each page dynamically until we get atleast 1000 reviews of the product\n",
        "5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \n",
        "6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\n",
        "7. Print or Display the dataframe to get the respective reviews.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGRL5c6wql9"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jjrDdfv-wql-",
        "outputId": "966a9293-82ca-46cc-ee61-66ee9830e22d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Comment Rating\n",
              "0               Fabulous!      5\n",
              "1     Best in the market!      5\n",
              "2                Terrific      5\n",
              "3               Fabulous!      5\n",
              "4             Really Nice      4\n",
              "...                   ...    ...\n",
              "1195               Super!      5\n",
              "1196              Awesome      5\n",
              "1197               Super!      5\n",
              "1198            Wonderful      4\n",
              "1199            Must buy!      5\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10843bc8-bc24-4a9f-90d3-c8d853e4c737\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terrific</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>Must buy!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10843bc8-bc24-4a9f-90d3-c8d853e4c737')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10843bc8-bc24-4a9f-90d3-c8d853e4c737 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10843bc8-bc24-4a9f-90d3-c8d853e4c737');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "reviewTextHeading = [] # This list stores the generic main heading of the review\n",
        "reviewRating =[] #List to comments of the reviews\n",
        "for page in range(120):\n",
        "  linkToAmazon = \"https://www.flipkart.com/apple-iphone-xr-product-red-64-gb-includes-earpods-power-adapter/product-reviews/itmf9z7zhydhtbn5?pid=MOBF9Z7ZRWGTX3FA&lid=LSTMOBF9Z7ZRWGTX3FAWC8NB0&marketplace=FLIPKART\"+ str(page) \n",
        "  specificPage = requests.get(linkToAmazon)\n",
        "  soup = BeautifulSoup(specificPage.text,'html.parser')\n",
        "  mainReviewOfProduct=soup.find_all(class_ = '_2-N8zT')\n",
        "  reviewCommentOfProduct = soup.find_all(class_='_3LWZlK _1BLPMq')\n",
        "  for mainReview, commentOfReview in zip(mainReviewOfProduct, reviewCommentOfProduct):\n",
        "      reviewTextHeading.append(mainReview.text) \n",
        "      reviewRating.append(commentOfReview.text)\n",
        "\n",
        "dataFrameOfRating = pd.DataFrame(list(zip(reviewTextHeading, reviewRating)),columns=[\"Comment\",\"Rating\"])\n",
        "dataFrameOfRating"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrameOfRating.sort_values(\"Rating\",ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "clNYst_MDr2Q",
        "outputId": "1c3f9e70-7906-4865-8d88-49f176b4a527"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Comment Rating\n",
              "0              Fabulous!      5\n",
              "761  Best in the market!      5\n",
              "743            Fabulous!      5\n",
              "745               Super!      5\n",
              "746              Awesome      5\n",
              "..                   ...    ...\n",
              "188            Wonderful      4\n",
              "964          Really Nice      4\n",
              "688            Wonderful      4\n",
              "958            Wonderful      4\n",
              "534          Really Nice      4\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db307a85-83ac-4d6b-bc05-1c0344ac2a59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db307a85-83ac-4d6b-bc05-1c0344ac2a59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db307a85-83ac-4d6b-bc05-1c0344ac2a59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db307a85-83ac-4d6b-bc05-1c0344ac2a59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyR97nQKwql-"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install semanticscholar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RVWUgbUpCu",
        "outputId": "a3d598a3-a83a-44f1-81ee-ad64b8982ce5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting semanticscholar\n",
            "  Downloading semanticscholar-0.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (2.25.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (8.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (1.24.3)\n",
            "Installing collected packages: semanticscholar\n",
            "Successfully installed semanticscholar-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPVluKOxwql_",
        "outputId": "16b7ba79-d24b-4d2a-a464-3e16a4297245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "------------------------------------\n",
            "Title :  A Primer in BERTology: What We Know About How BERT Works\n",
            "Author/s :  Anna Rogers, Olga Kovaleva, Anna Rumshisky\n",
            "Venue :  Transactions of the Association for Computational Linguistics\n",
            "year :  2020\n",
            "Abstract :  Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.\n",
            "------------------------------------\n",
            "Title :  Some Simple Economics of Crowdfunding\n",
            "Author/s :  A. Agrawal, Christian Catalini, Avi Goldfarb\n",
            "Venue :  Innovation Policy and the Economy\n",
            "year :  2013\n",
            "Abstract :  It is not surprising that the financing of early-stage creative projects and ventures is typically geographically localized since these types of funding decisions are usually predicated on personal relationships and due diligence requiring face-to-face interactions in response to high levels of risk, uncertainty, and information asymmetry. So, to economists, the recent rise of crowdfunding—raising capital from many people through an online platform—which offers little opportunity for careful due diligence and involves not only friends and family but also many strangers from near and far, is initially startling. On the eve of launching equity-based crowdfunding, a new market for early-stage finance in the United States, we provide a preliminary exploration of its underlying economics. We highlight the extent to which economic theory, in particular transaction costs, reputation, and market design, can explain the rise of nonequity crowdfunding and offer a framework for speculating on how equity-based crowdfunding may unfold. We conclude by articulating open questions related to how crowdfunding may affect social welfare and the rate and direction of innovation.\n",
            "------------------------------------\n",
            "Title :  Advances in Social Media Research: Past, Present and Future\n",
            "Author/s :  Kawal Kapoor, K. Tamilmani, N. Rana, Pushp P. Patil, Yogesh Kumar Dwivedi, S. Nerur\n",
            "Venue :  Inf. Syst. Frontiers\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Semantic Image Synthesis With Spatially-Adaptive Normalization\n",
            "Author/s :  Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.\n",
            "------------------------------------\n",
            "Title :  Science vs Conspiracy: Collective Narratives in the Age of Misinformation\n",
            "Author/s :  Alessandro Bessi, Mauro Coletto, G. Davidescu, A. Scala, G. Caldarelli, W. Quattrociocchi\n",
            "Venue :  PLoS ONE\n",
            "year :  2014\n",
            "Abstract :  The large availability of user provided contents on online social media facilitates people aggregation around shared beliefs, interests, worldviews and narratives. In spite of the enthusiastic rhetoric about the so called collective intelligence unsubstantiated rumors and conspiracy theories—e.g., chemtrails, reptilians or the Illuminati—are pervasive in online social networks (OSN). In this work we study, on a sample of 1.2 million of individuals, how information related to very distinct narratives—i.e. main stream scientific and conspiracy news—are consumed and shape communities on Facebook. Our results show that polarized communities emerge around distinct types of contents and usual consumers of conspiracy news result to be more focused and self-contained on their specific contents. To test potential biases induced by the continued exposure to unsubstantiated rumors on users’ content selection, we conclude our analysis measuring how users respond to 4,709 troll information—i.e. parodistic and sarcastic imitation of conspiracy theories. We find that 77.92% of likes and 80.86% of comments are from users usually interacting with conspiracy stories.\n",
            "------------------------------------\n",
            "Title :  COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author/s :  Cristina M. Pulido, Beatriz Villarejo-Carballido, Gisela Redondo-Sama, Aitor Gómez\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title :  Generalized Composite Kernel Framework for Hyperspectral Image Classification\n",
            "Author/s :  Jun Li, P. Marpu, A. Plaza, J. Bioucas-Dias, J. Benediktsson\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2013\n",
            "Abstract :  This paper presents a new framework for the development of generalized composite kernel machines for hyperspectral image classification. We construct a new family of generalized composite kernels which exhibit great flexibility when combining the spectral and the spatial information contained in the hyperspectral data, without any weight parameters. The classifier adopted in this work is the multinomial logistic regression, and the spatial information is modeled from extended multiattribute profiles. In order to illustrate the good performance of the proposed framework, support vector machines are also used for evaluation purposes. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible/Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the proposed framework leads to state-of-the-art classification performance in complex analysis scenarios.\n",
            "------------------------------------\n",
            "Title :  Entanglement wedge reconstruction and the information paradox\n",
            "Author/s :  Geoffrey Penington\n",
            "Venue :  Journal of High Energy Physics\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Sensor Mania! The Internet of Things, Wearable Computing, Objective Metrics, and the Quantified Self 2.0\n",
            "Author/s :  M. Swan\n",
            "Venue :  J. Sens. Actuator Networks\n",
            "year :  2012\n",
            "Abstract :  The number of devices on the Internet exceeded the number of people on the Internet in 2008, and is estimated to reach 50 billion in 2020. A wide-ranging Internet of Things (IOT) ecosystem is emerging to support the process of connecting real-world objects like buildings, roads, household appliances, and human bodies to the Internet via sensors and microprocessor chips that record and transmit data such as sound waves, temperature, movement, and other variables. The explosion in Internet-connected sensors means that new classes of technical capability and application are being created. More granular 24/7 quantified monitoring is leading to a deeper understanding of the internal and external worlds encountered by humans. New data literacy behaviors such as correlation assessment, anomaly detection, and high-frequency data processing are developing as humans adapt to the different kinds of data flows enabled by the IOT. The IOT ecosystem has four critical functional steps: data creation, information generation, meaning-making, and action-taking. This paper provides a comprehensive review of the current and rapidly emerging ecosystem of the Internet of Things (IOT).\n",
            "------------------------------------\n",
            "Title :  Predicting information credibility in time-sensitive social media\n",
            "Author/s :  Carlos Castillo, Marcelo Mendoza, Bárbara Poblete\n",
            "Venue :  Internet Research\n",
            "year :  2013\n",
            "Abstract :  Purpose – Twitter is a popular microblogging service which has proven, in recent years, its potential for propagating news and information about developing events. The purpose of this paper is to focus on the analysis of information credibility on Twitter. The purpose of our research is to establish if an automatic discovery process of relevant and credible news events can be achieved. Design/methodology/approach – The paper follows a supervised learning approach for the task of automatic classification of credible news events. A first classifier decides if an information cascade corresponds to a newsworthy event. Then a second classifier decides if this cascade can be considered credible or not. The paper undertakes this effort training over a significant amount of labeled data, obtained using crowdsourcing tools. The paper validates these classifiers under two settings: the first, a sample of automatically detected Twitter “trends” in English, and second, the paper tests how well this model transfers to...\n",
            "------------------------------------\n",
            "Title :  Deep supervised learning for hyperspectral data classification through convolutional neural networks\n",
            "Author/s :  K. Makantasis, K. Karantzalos, A. Doulamis, N. Doulamis\n",
            "Venue :  IEEE International Geoscience and Remote Sensing Symposium\n",
            "year :  2015\n",
            "Abstract :  Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs\n",
            "Author/s :  Vishwanath A. Sindagi, Vishal M. Patel\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  We present a novel method called Contextual Pyramid CNN (CP-CNN) for generating high-quality crowd density and count estimation by explicitly incorporating global and local contextual information of crowd images. The proposed CP-CNN consists of four modules: Global Context Estimator (GCE), Local Context Estimator (LCE), Density Map Estimator (DME) and a Fusion-CNN (F-CNN). GCE is a VGG-16 based CNN that encodes global context and it is trained to classify input images into different density classes, whereas LCE is another CNN that encodes local context information and it is trained to perform patch-wise classification of input images into different density classes. DME is a multi-column architecture-based CNN that aims to generate high-dimensional feature maps from the input image which are fused with the contextual information estimated by GCE and LCE using F-CNN. To generate high resolution and high-quality density maps, F-CNN uses a set of convolutional and fractionally-strided convolutional layers and it is trained along with the DME in an end-to-end fashion using a combination of adversarial loss and pixellevel Euclidean loss. Extensive experiments on highly challenging datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Mandatory IFRS Adoption and Financial Statement Comparability\n",
            "Author/s :  François Brochet, Alan D. Jagolinzer, Edward J. Riedl\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This study examines whether mandatory adoption of International Financial Reporting Standards (IFRS) leads to capital market benefits through enhanced financial statement comparability. UK domestic standards are considered very similar to IFRS (Bae et al. 2008), suggesting any capital market benefits observed for UK-domiciled firms are more likely attributable to improvements in comparability (i.e., better precision of across-firm information) than to changes in information quality specific to the firm (i.e., core information quality). If IFRS adoption improves financial statement comparability, we predict this should reduce insiders’ ability to benefit from private information. Consistent with these expectations, we find that abnormal returns to insider purchases ― used to proxy for private information ― are reduced following IFRS adoption. Similar results obtain across numerous subsamples and proxies used to isolate IFRS effects attributable to comparability. Together, the findings are consistent with mandatory IFRS adoption improving comparability and thus leading to capital market benefits by reducing insiders’ ability to exploit private information.\n",
            "------------------------------------\n",
            "Title :  Actionable Knowledge for Environmental Decision Making: Broadening the Usability of Climate Science\n",
            "Author/s :  C. Kirchhoff, M. Lemos, S. Dessai\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Despite the rapid evolution and growing complexity in models of science-society interaction, the rate and breadth of use of scientific knowledge in environmental decision making, especially related to climate variability and change, remain below expectations. This suggests a persistent gap between production and use that, to date, efforts to rethink and restructure science production have not been able to surmount. We review different models of science-policy interfaces to understand how they have influenced the organization of knowledge production and application. We then explore how new approaches to the creation of knowledge have emerged, involving both growing integration across disciplines and greater interaction with users. Finally, we review climate information use in the United States and United Kingdom to explore how the structure of knowledge production and the characteristics of users and their decision environments expose the challenges of broadening usable climate science.\n",
            "------------------------------------\n",
            "Title :  Social networks predict patch discovery in a wild population of songbirds\n",
            "Author/s :  L. Aplin, D. Farine, J. Morand‐Ferron, B. Sheldon\n",
            "Venue :  Proceedings of the Royal Society B: Biological Sciences\n",
            "year :  2012\n",
            "Abstract :  Animals use social information in a wide variety of contexts. Its extensive use by individuals to locate food patches has been documented in a number of species, and various mechanisms of discovery have been identified. However, less is known about whether individuals differ in their access to, and use of, social information to find food. We measured the social network of a wild population of three sympatric tit species (family Paridae) and then recorded individual discovery of novel food patches. By using recently developed methods for network-based diffusion analysis, we show that order of arrival at new food patches was predicted by social associations. Models based only on group searching did not explain this relationship. Furthermore, network position was correlated with likelihood of patch discovery, with central individuals more likely to locate and use novel foraging patches than those with limited social connections. These results demonstrate the utility of social network analysis as a method to investigate social information use, and suggest that the greater probability of receiving social information about new foraging patches confers a benefit on more socially connected individuals.\n",
            "------------------------------------\n",
            "Title :  Accounting Information Systems\n",
            "Author/s :  Tawfiq Abu-Raqabeh\n",
            "Venue :  Education and Linguistics Research\n",
            "year :  2018\n",
            "Abstract :  Today’s swiftly changing technology, globalization, and integration of corporations has created a need for the introduction of IAS to higher education institutes. This study explores and examines the introduction of IAS to the higher education institutes. The readiness of the institutes, the problems they face to incorporate the IAS to the curriculum. The criteria utilized by ABET focuses on content and delivery of curriculum within the IS discipline. The advantages of incorporating the IAS in the curriculum for students and faculty.\n",
            "------------------------------------\n",
            "Title :  Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\n",
            "Author/s :  Wenjie Luo, Yujia Li, R. Urtasun, R. Zemel\n",
            "Venue :  NIPS\n",
            "year :  2016\n",
            "Abstract :  We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field size, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field size. We analyze the effective receptive field in several architecture designs, and the effect of sub-sampling, skip connections, dropout and nonlinear activations on it. This leads to suggestions for ways to address its tendency to be too small.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Hyperspectral Image Segmentation Using Subspace Multinomial Logistic Regression and Markov Random Fields\n",
            "Author/s :  Jun Li, J. Bioucas-Dias, A. Plaza\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2012\n",
            "Abstract :  This paper introduces a new supervised segmentation algorithm for remotely sensed hyperspectral image data which integrates the spectral and spatial information in a Bayesian framework. A multinomial logistic regression (MLR) algorithm is first used to learn the posterior probability distributions from the spectral information, using a subspace projection method to better characterize noise and highly mixed pixels. Then, contextual information is included using a multilevel logistic Markov-Gibbs Markov random field prior. Finally, a maximum a posteriori segmentation is efficiently computed by the min-cut-based integer optimization algorithm. The proposed segmentation approach is experimentally evaluated using both simulated and real hyperspectral data sets, exhibiting state-of-the-art performance when compared with recently introduced hyperspectral image classification methods. The integration of subspace projection methods with the MLR algorithm, combined with the use of spatial-contextual information, represents an innovative contribution in the literature. This approach is shown to provide accurate characterization of hyperspectral imagery in both the spectral and the spatial domain.\n",
            "------------------------------------\n",
            "Title :  Image Super-Resolution Using Very Deep Residual Channel Attention Networks\n",
            "Author/s :  Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, Y. Fu\n",
            "Venue :  European Conference on Computer Vision\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Meta-analysis of the age-related positivity effect: age differences in preferences for positive over negative information.\n",
            "Author/s :  Andrew E. Reed, Larry Chan, J. Mikels\n",
            "Venue :  Psychology and Aging\n",
            "year :  2014\n",
            "Abstract :  In contrast to long-held axioms of old age as a time of \"doom and gloom,\" mounting evidence indicates an age-related positivity effect in attention and memory. However, several studies report inconsistent findings that raise critical questions about the effect's reliability, robustness, and potential moderators. To address these questions, we conducted a systematic meta-analysis of 100 empirical studies of the positivity effect (N = 7,129). Results indicate that the positivity effect is reliable and moderated by theoretically implicated methodological and sample characteristics. The positivity effect is larger in studies that do not constrain (vs. constrain) cognitive processing-reflecting older adults' natural information processing preferences-and in studies incorporating wider (vs. narrower) age comparisons. Analyses indicated that older adults show a significant information processing bias toward positive versus negative information, whereas younger adults show the opposite pattern. We discuss implications of these findings for theoretical perspectives on emotion-cognition interactions across the adult life span and suggest future research directions.\n",
            "------------------------------------\n",
            "Title :  Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author/s :  G. Schryen\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Intelligent Reflecting Surface Aided MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer\n",
            "Author/s :  Cunhua Pan, Hong Ren, Kezhi Wang, M. Elkashlan, A. Nallanathan, Jiangzhou Wang, L. Hanzo\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2019\n",
            "Abstract :  An intelligent reflecting surface (IRS) is invoked for enhancing the energy harvesting performance of a simultaneous wireless information and power transfer (SWIPT) aided system. Specifically, an IRS-assisted SWIPT system is considered, where a multi-antenna aided base station (BS) communicates with several multi-antenna assisted information receivers (IRs), while guaranteeing the energy harvesting requirement of the energy receivers (ERs). To maximize the weighted sum rate (WSR) of IRs, the transmit precoding (TPC) matrices of the BS and passive phase shift matrix of the IRS should be jointly optimized. To tackle this challenging optimization problem, we first adopt the classic block coordinate descent (BCD) algorithm for decoupling the original optimization problem into several subproblems and alternately optimize the TPC matrices and the phase shift matrix. For each subproblem, we provide a low-complexity iterative algorithm, which is guaranteed to converge to the Karush-Kuhn-Tucker (KKT) point of each subproblem. The BCD algorithm is rigorously proved to converge to the KKT point of the original problem. We also conceive a feasibility checking method to study its feasibility. Our extensive simulation results confirm that employing IRSs in SWIPT beneficially enhances the system performance and the proposed BCD algorithm converges rapidly, which is appealing for practical applications.\n",
            "------------------------------------\n",
            "Title :  Rapid assessment of disaster damage using social media activity\n",
            "Author/s :  Yury Kryvasheyeu, Haohui Chen, Nick Obradovich, E. Moro, P. Van Hentenryck, J. Fowler, Manuel Cebrian\n",
            "Venue :  Science Advances\n",
            "year :  2016\n",
            "Abstract :  Researchers show a correlation between per-capita social media activity and disaster damage, facilitating its rapid assessment. Could social media data aid in disaster response and damage assessment? Countries face both an increasing frequency and an increasing intensity of natural disasters resulting from climate change. During such events, citizens turn to social media platforms for disaster-related communication and information. Social media improves situational awareness, facilitates dissemination of emergency information, enables early warning systems, and helps coordinate relief efforts. In addition, the spatiotemporal distribution of disaster-related messages helps with the real-time monitoring and assessment of the disaster itself. We present a multiscale analysis of Twitter activity before, during, and after Hurricane Sandy. We examine the online response of 50 metropolitan areas of the United States and find a strong relationship between proximity to Sandy’s path and hurricane-related social media activity. We show that real and perceived threats, together with physical disaster effects, are directly observable through the intensity and composition of Twitter’s message stream. We demonstrate that per-capita Twitter activity strongly correlates with the per-capita economic damage inflicted by the hurricane. We verify our findings for a wide range of disasters and suggest that massive online social networks can be used for rapid assessment of damage caused by a large-scale disaster.\n",
            "------------------------------------\n",
            "Title :  Learning to Communicate with Deep Multi-Agent Reinforcement Learning\n",
            "Author/s :  Jakob N. Foerster, Yannis Assael, N. D. Freitas, Shimon Whiteson\n",
            "Venue :  NIPS\n",
            "year :  2016\n",
            "Abstract :  We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.\n",
            "------------------------------------\n",
            "Title :  Rethinking segregation and integration: contributions of whole-brain modelling\n",
            "Author/s :  G. Deco, G. Tononi, M. Boly, M. Kringelbach\n",
            "Venue :  Nature Reviews Neuroscience\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Fuzzy C-Means Clustering With Local Information and Kernel Metric for Image Segmentation\n",
            "Author/s :  Maoguo Gong, Yan Liang, Jiao Shi, Wenping Ma, Jingjing Ma\n",
            "Venue :  IEEE Transactions on Image Processing\n",
            "year :  2013\n",
            "Abstract :  In this paper, we present an improved fuzzy C-means (FCM) algorithm for image segmentation by introducing a tradeoff weighted fuzzy factor and a kernel metric. The tradeoff weighted fuzzy factor depends on the space distance of all neighboring pixels and their gray-level difference simultaneously. By using this factor, the new algorithm can accurately estimate the damping extent of neighboring pixels. In order to further enhance its robustness to noise and outliers, we introduce a kernel distance measure to its objective function. The new algorithm adaptively determines the kernel parameter by using a fast bandwidth selection rule based on the distance variance of all data points in the collection. Furthermore, the tradeoff weighted fuzzy factor and the kernel distance measure are both parameter free. Experimental results on synthetic and real images show that the new algorithm is effective and efficient, and is relatively independent of this type of noise.\n",
            "------------------------------------\n",
            "Title :  Localization algorithms of Wireless Sensor Networks: a survey\n",
            "Author/s :  Guangjie Han, Huihui Xu, T. Duong, Jinfang Jiang, T. Hara\n",
            "Venue :  Telecommunications Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Twisted photons: new quantum perspectives in high dimensions\n",
            "Author/s :  Manuel Erhard, R. Fickler, M. Krenn, A. Zeilinger\n",
            "Venue :  Light: Science & Applications\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Towards Actualizing the Value Potential of Korea Health Insurance Review and Assessment (HIRA) Data as a Resource for Health Research: Strengths, Limitations, Applications, and Strategies for Optimal Use of HIRA Data\n",
            "Author/s :  Jee-Ae Kim, Seokjun Yoon, L. Kim, Dong Sook Kim\n",
            "Venue :  Journal of Korean medical science\n",
            "year :  2017\n",
            "Abstract :  Health Insurance and Review Assessment (HIRA) in South Korea, also called National Health Insurance (NHI) data, is a repository of claims data collected in the process of reimbursing healthcare providers. Under the universal coverage system, having fee-for-services covering all citizens in South Korea, HIRA contains comprehensive and rich information pertaining to healthcare services such as treatments, pharmaceuticals, procedures, and diagnoses for almost 50 million beneficiaries. This corpus of HIRA data, which constitutes a large repository of data in the healthcare sector, has enormous potential to create value in several ways: enhancing the efficiency of the healthcare delivery system without compromising quality of care; adding supporting evidence for a given intervention; and providing the information needed to prevent (or monitor) adverse events. In order to actualize this potential, HIRA data need to actively be utilized for research. Thus understanding this data would greatly enhance this potential. We introduce HIRA data as an important source for health research and provide guidelines for researchers who are currently utilizing HIRA, or interested in doing so, to answer their research questions. We present the characteristics and structure of HIRA data. We discuss strengths and limitations that should be considered in conducting research with HIRA data and suggest strategies for optimal utilization of HIRA data by reviewing published research using HIRA data.\n",
            "------------------------------------\n",
            "Title :  Diversity is All You Need: Learning Skills without a Reward Function\n",
            "Author/s :  Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, S. Levine\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2018\n",
            "Abstract :  Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN (\"Diversity is All You Need\"), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. In these environments, some of the learned skills correspond to solving the task, and each skill that solves the task does so in a distinct manner. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning\n",
            "------------------------------------\n",
            "Title :  The effect of electronic word of mouth on brand image and purchase intention\n",
            "Author/s :  M. Jalilvand, Neda Samiei\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Purpose – Word‐of‐mouth (WOM) has been recognized as one of the most influential resources of information transmission. Advances in information technology and the emergence of online social network sites have changed the way information is transmitted. This phenomenon impacts consumers as this easily accessible information could greatly affect the consumption decision. The purpose of this paper is to examine the extent to which e‐WOM among consumers can influence brand image and purchase intention in the automobile industry.Design/methodology/approach – Measurement items are adapted from existing scales found in the marketing literature. Academic colleagues reviewed the items for face validity and readability. The scales are evaluated for reliability, convergent validity, and discriminant validity using data collected in a survey of Iran Khodro's prospective customers in Iran. A structural equation modeling procedure is applied to the examination of the influences of e‐WOM on brand image and purchase inte...\n",
            "------------------------------------\n",
            "Title :  FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack\n",
            "Author/s :  Y. Yarom, K. Falkner\n",
            "Venue :  USENIX Security Symposium\n",
            "year :  2014\n",
            "Abstract :  Sharing memory pages between non-trusting processes is a common method of reducing the memory footprint of multi-tenanted systems. In this paper we demonstrate that, due to a weakness in the Intel X86 processors, page sharing exposes processes to information leaks. We present FLUSH+RELOAD, a cache side-channel attack technique that exploits this weakness to monitor access to memory lines in shared pages. Unlike previous cache side-channel attacks, FLUSH+RELOAD targets the Last-Level Cache (i.e. L3 on processors with three cache levels). Consequently, the attack program and the victim do not need to share the execution core. \n",
            " \n",
            "We demonstrate the efficacy of the FLUSH+RELOAD attack by using it to extract the private encryption keys from a victim program running GnuPG 1.4.13. We tested the attack both between two unrelated processes in a single operating system and between processes running in separate virtual machines. On average, the attack is able to recover 96.7% of the bits of the secret key by observing a single signature or decryption round.\n",
            "------------------------------------\n",
            "Title :  ClinVar: public archive of relationships among sequence variation and human phenotype\n",
            "Author/s :  M. Landrum, Jennifer M. Lee, George R. Riley, W. Jang, W. Rubinstein, D. Church, D. Maglott\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  ClinVar (http://www.ncbi.nlm.nih.gov/clinvar/) provides a freely available archive of reports of relationships among medically important variants and phenotypes. ClinVar accessions submissions reporting human variation, interpretations of the relationship of that variation to human health and the evidence supporting each interpretation. The database is tightly coupled with dbSNP and dbVar, which maintain information about the location of variation on human assemblies. ClinVar is also based on the phenotypic descriptions maintained in MedGen (http://www.ncbi.nlm.nih.gov/medgen). Each ClinVar record represents the submitter, the variation and the phenotype, i.e. the unit that is assigned an accession of the format SCV000000000.0. The submitter can update the submission at any time, in which case a new version is assigned. To facilitate evaluation of the medical importance of each variant, ClinVar aggregates submissions with the same variation/phenotype combination, adds value from other NCBI databases, assigns a distinct accession of the format RCV000000000.0 and reports if there are conflicting clinical interpretations. Data in ClinVar are available in multiple formats, including html, download as XML, VCF or tab-delimited subsets. Data from ClinVar are provided as annotation tracks on genomic RefSeqs and are used in tools such as Variation Reporter (http://www.ncbi.nlm.nih.gov/variation/tools/reporter), which reports what is known about variation based on user-supplied locations.\n",
            "------------------------------------\n",
            "Title :  Climate services for society: origins, institutional arrangements, and design elements for an evaluation framework\n",
            "Author/s :  C. Vaughan, S. Dessai\n",
            "Venue :  Wiley Interdisciplinary Reviews: Climate Change\n",
            "year :  2014\n",
            "Abstract :  Climate services involve the generation, provision, and contextualization of information and knowledge derived from climate research for decision making at all levels of society. These services are mainly targeted at informing adaptation to climate variability and change, widely recognized as an important challenge for sustainable development. This paper reviews the development of climate services, beginning with a historical overview, a short summary of improvements in climate information, and a description of the recent surge of interest in climate service development including, for example, the Global Framework for Climate Services, implemented by the World Meteorological Organization in October 2012. It also reviews institutional arrangements of selected emerging climate services across local, national, regional, and international scales. By synthesizing existing literature, the paper proposes four design elements of a climate services evaluation framework. These design elements include: problem identification and the decision‐making context; the characteristics, tailoring, and dissemination of the climate information; the governance and structure of the service, including the process by which it is developed; and the socioeconomic value of the service. The design elements are intended to serve as a guide to organize future work regarding the evaluation of when and whether climate services are more or less successful. The paper concludes by identifying future research questions regarding the institutional arrangements that support climate services and nascent efforts to evaluate them. WIREs Clim Change 2014, 5:587–603. doi: 10.1002/wcc.290\n",
            "------------------------------------\n",
            "Title :  Preparing and conducting interviews to collect data.\n",
            "Author/s :  O. Doody, M. Noonan\n",
            "Venue :  Nurse Researcher\n",
            "year :  2013\n",
            "Abstract :  AIM\n",
            "To describe three styles of interviews and discuss issues regarding planning and conducting interviews.\n",
            "\n",
            "\n",
            "BACKGROUND\n",
            "Interviews are probably the approach most used to collect data in studies. They are particularly useful in uncovering the story behind a participant's experiences. Researchers can follow a line of questions to gain information about a topic, or further explore responses or findings. But the researcher needs to plan and decide the format of the interview before collecting data.\n",
            "\n",
            "\n",
            "REVIEW METHODS\n",
            "The authors included papers on structured, unstructured and semi-structured interviews published in a peer-reviewed joumrnal and in English.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Interviews are one of the most common metods of data collection in qualitative research. However they require the researcher to have a sound understanding of their use and appropriateness. The ability to conduct interviews is one that develops over time and to aid the researcher in developing their interview skills they should consult with other researchers, seeking comments and advice and, critically, to appraise audio recordings.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "This article aims to support students who are undertaking research modules as part of their academic studies, writing a research proposal or novice researchers who are about to use interviews as a means of data collection.\n",
            "\n",
            "\n",
            "IMPLICATIONS FOR RESEARCH/PRACTICE\n",
            "To conduct a successful interview, researchers need to develop their interview technique, choose the right method and carefully plan for all aspects of the process.\n",
            "------------------------------------\n",
            "Title :  Cortical information flow during flexible sensorimotor decisions\n",
            "Author/s :  M. Siegel, T. J. Buschman, E. Miller\n",
            "Venue :  Science\n",
            "year :  2015\n",
            "Abstract :  Signal flow during sensorimotor choices Little is known about the flow of task signals across the brain. Siegel et al. simultaneously recorded from multiple units in the sensory, parietal, prefrontal, and motor cortex while monkeys were cued to perform one among two possible simple tasks. The proportion of neurons coding for stimuli, cues, tasks, and choices, and their response latency, varied across regions. Parietal and prefrontal brain regions encoded task information and choices with the same latency. Interestingly, all brain areas encoded all types of information. However, they differed functionally according to the proportions of neurons and their response latency. Science, this issue p. 1352 A dynamic network of cortical areas processing similar information but to different degrees is explored. During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.\n",
            "------------------------------------\n",
            "Title :  DeViSE: A Deep Visual-Semantic Embedding Model\n",
            "Author/s :  Andrea Frome, G. Corrado, Jonathon Shlens, Samy Bengio, J. Dean, M. Ranzato, Tomas Mikolov\n",
            "Venue :  NIPS\n",
            "year :  2013\n",
            "Abstract :  Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.\n",
            "------------------------------------\n",
            "Title :  Context-Aware Recommender Systems for Learning: A Survey and Future Challenges\n",
            "Author/s :  K. Verbert, N. Manouselis, X. Ochoa, M. Wolpers, H. Drachsler, I. Bosnić, E. Duval\n",
            "Venue :  IEEE Transactions on Learning Technologies\n",
            "year :  2012\n",
            "Abstract :  Recommender systems have been researched extensively by the Technology Enhanced Learning (TEL) community during the last decade. By identifying suitable resources from a potentially overwhelming variety of choices, such systems offer a promising approach to facilitate both learning and teaching tasks. As learning is taking place in extremely diverse and rich environments, the incorporation of contextual information about the user in the recommendation process has attracted major interest. Such contextualization is researched as a paradigm for building intelligent systems that can better predict and anticipate the needs of users, and act more efficiently in response to their behavior. In this paper, we try to assess the degree to which current work in TEL recommender systems has achieved this, as well as outline areas in which further work is needed. First, we present a context framework that identifies relevant context dimensions for TEL applications. Then, we present an analysis of existing TEL recommender systems along these dimensions. Finally, based on our survey results, we outline topics on which further research is needed.\n",
            "------------------------------------\n",
            "Title :  The Structural Virality of Online Diffusion\n",
            "Author/s :  Sharad Goel, Ashton Anderson, J. Hofman, D. Watts\n",
            "Venue :  Management Sciences\n",
            "year :  2015\n",
            "Abstract :  Viral products and ideas are intuitively understood to grow through a person-to-person diffusion process analogous to the spread of an infectious disease; however, until recently it has been prohibitively difficult to directly observe purportedly viral events, and thus to rigorously quantify or characterize their structural properties. Here we propose a formal measure of what we label “structural virality” that interpolates between two conceptual extremes: content that gains its popularity through a single, large broadcast and that which grows through multiple generations with any one individual directly responsible for only a fraction of the total adoption. We use this notion of structural virality to analyze a unique data set of a billion diffusion events on Twitter, including the propagation of news stories, videos, images, and petitions. We find that across all domains and all sizes of events, online diffusion is characterized by surprising structural diversity; that is, popular events regularly grow via both broadcast and viral mechanisms, as well as essentially all conceivable combinations of the two. Nevertheless, we find that structural virality is typically low, and remains so independent of size, suggesting that popularity is largely driven by the size of the largest broadcast. Finally, we attempt to replicate these findings with a model of contagion characterized by a low infection rate spreading on a scale-free network. We find that although several of our empirical findings are consistent with such a model, it fails to replicate the observed diversity of structural virality, thereby suggesting new directions for future modeling efforts. This paper was accepted by Lorin Hitt, information systems.\n",
            "------------------------------------\n",
            "Title :  Routes for breaching and protecting genetic privacy\n",
            "Author/s :  Yaniv Erlich, A. Narayanan\n",
            "Venue :  Nature reviews genetics\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Cognitive Load Theory: Implications for medical education: AMEE Guide No. 86\n",
            "Author/s :  John Q. Young, J. V. van Merrienboer, S. Durning, O. ten Cate\n",
            "Venue :  Medical Teacher\n",
            "year :  2014\n",
            "Abstract :  Abstract Cognitive Load Theory (CLT) builds upon established models of human memory that include the subsystems of sensory, working and long-term memory. Working memory (WM) can only process a limited number of information elements at any given time. This constraint creates a “bottleneck” for learning. CLT identifies three types of cognitive load that impact WM: intrinsic load (associated with performing essential aspects of the task), extraneous load (associated with non-essential aspects of the task) and germane load (associated with the deliberate use of cognitive strategies that facilitate learning). When the cognitive load associated with a task exceeds the learner’s WM capacity, performance and learning is impaired. To facilitate learning, CLT researchers have developed instructional techniques that decrease extraneous load (e.g. worked examples), titrate intrinsic load to the developmental stage of the learner (e.g. simplify task without decontextualizing) and ensure that unused WM capacity is dedicated to germane load, i.e. cognitive learning strategies. A number of instructional techniques have been empirically tested. As learners’ progress, curricula must also attend to the expertise-reversal effect. Instructional techniques that facilitate learning among early learners may not help and may even interfere with learning among more advanced learners. CLT has particular relevance to medical education because many of the professional activities to be learned require the simultaneous integration of multiple and varied sets of knowledge, skills and behaviors at a specific time and place. These activities possess high “element interactivity” and therefore impose a cognitive load that may surpass the WM capacity of the learner. Applications to various medical education settings (classroom, workplace and self-directed learning) are explored.\n",
            "------------------------------------\n",
            "Title :  PEGASIS : Power-Efficient Gathering in Sensor Information Systems\n",
            "Author/s :  A. Sankaliya\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Sensor network consisting of nodes with limited battery power and wireless communications are deployed to collect useful information from the field. The main idea in PEGASIS is for each node to receive from and transmit to close neighbors and take turns being the leader for transmission to the BS. This approach distributes the energy load evenly among the sensor nodes in the network. Sensor nodes are randomly deployed in the sensor field, and therefore, the i th node is at a random location. The nodes will be organized to form a chain, which can either be accomplished by the sensor nodes themselves using a greedy algorithm. The algorithm to resolve the unbalanced energy consumption problem caused by long distance data transmission of some nodes in a chain formed by the greedy algorithm.\n",
            "------------------------------------\n",
            "Title :  Internet of Things for Enterprise Systems of Modern Manufacturing\n",
            "Author/s :  Z. Bi, Lida Xu, Chengen Wang\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2014\n",
            "Abstract :  Design and operation of a manufacturing enterprise involve numerous types of decision-making at various levels and domains. A complex system has a large number of design variables and decision-making requires real-time data collected from machines, processes, and business environments. Enterprise systems (ESs) are used to support data acquisition, communication, and all decision-making activities. Therefore, information technology (IT) infrastructure for data acquisition and sharing affects the performance of an ES greatly. Our objective is to investigate the impact of emerging Internet of Things (IoT) on ESs in modern manufacturing. To achieve this objective, the evolution of manufacturing system paradigms is discussed to identify the requirements of decision support systems in dynamic and distributed environments; recent advances in IT are overviewed and associated with next-generation manufacturing paradigms; and the relation of IT infrastructure and ESs is explored to identify the technological gaps in adopting IoT as an IT infrastructure of ESs. The future research directions in this area are discussed.\n",
            "------------------------------------\n",
            "Title :  Magnetic skyrmion logic gates: conversion, duplication and merging of skyrmions\n",
            "Author/s :  Xichao Zhang, M. Ezawa, Yan Zhou\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Machine Learning Models that Remember Too Much\n",
            "Author/s :  Congzheng Song, T. Ristenpart, Vitaly Shmatikov\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2017\n",
            "Abstract :  Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data. We consider a malicious ML provider who supplies model-training code to the data holder, does \\emph{not} observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that \"memorize\" information about the training dataset in the model\\textemdash yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data.\n",
            "------------------------------------\n",
            "Title :  Pyramid Attention Network for Semantic Segmentation\n",
            "Author/s :  Hanchao Li, Pengfei Xiong, Jie An, Lingxue Wang\n",
            "Venue :  British Machine Vision Conference\n",
            "year :  2018\n",
            "Abstract :  A Pyramid Attention Network(PAN) is proposed to exploit the impact of global contextual information in semantic segmentation. Different from most existing works, we combine attention mechanism and spatial pyramid to extract precise dense features for pixel labeling instead of complicated dilated convolution and artificially designed decoder networks. Specifically, we introduce a Feature Pyramid Attention module to perform spatial pyramid attention structure on high-level output and combining global pooling to learn a better feature representation, and a Global Attention Upsample module on each decoder layer to provide global context as a guidance of low-level features to select category localization details. The proposed approach achieves state-of-the-art performance on PASCAL VOC 2012 and Cityscapes benchmarks with a new record of mIoU accuracy 84.0% on PASCAL VOC 2012, while training without COCO dataset.\n",
            "------------------------------------\n",
            "Title :  What's skill got to do with it?: Information literacy skills and self-views of ability among first-year college students\n",
            "Author/s :  M. Gross, D. Latham\n",
            "Venue :  J. Assoc. Inf. Sci. Technol.\n",
            "year :  2012\n",
            "Abstract :  This study replicates a previous study based on work in psychology, which demonstrates that students who score as below proficient in information literacy (IL) skills have a miscalibrated self-view of their ability. Simply stated, these students tend to believe that they have above-average IL skills, when, in fact, an objective test of their ability indicates that they are below-proficient in terms of their actual skills. This investigation was part of an Institute of Museum and Library Services-funded project and includes demographic data about participants, their scores on an objective test of their information literacy skills, and self-estimates of their ability. Findings support previous research that indicates many students come to college without proficient IL skills, that students with below-proficient IL skills have inflated views of their ability, and that this miscalibration can also be expressed by students who test as proficient. Implications for research and practice are discussed. © 2012 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title :  Activities at the Universal Protein Resource (UniProt)\n",
            "Author/s :  R. Apweiler, A. Bateman, M. Martin, C. O’Donovan, M. Magrane, Y. Alam-Faruque, E. Alpi, R. Antunes, J. Arganiska, E. Casanova, B. Bely, M. Bingley, C. Bonilla, R. Britto, B. Bursteinas, W. Chan, G. Chavali, Elena Cibrián-Uhalte, A. D. Silva, M. D. Giorgi, Tunca Dogan, F. Fazzini, P. Gane, Lg Castro, P. Garmiri, E. Hatton-Ellis, R. Hieta, R. Huntley, D. Legge, W. Liu, J. Luo, Alistair MacDougall, P. Mutowo, Andrew Nightingale, S. Orchard, K. Pichler, D. Poggioli, S. Pundir, L. Pureza, G. Qi, S. Rosanoff, Rabie Saidi, T. Sawford, A. Shypitsyna, E. Turner, Volynkin, T. Wardell, X. Watkins, H. Zellner, M. Corbett, M. Donnelly, P. V. Rensburg, M. Goujon, H. McWilliam, R. Lopez, I. Xenarios, L. Bougueleret, A. Bridge, S. Poux, N. Redaschi, L. Aimo, A. Auchincloss, K. Axelsen, Parit Bansal, Delphine Baratin, P. Binz, M. Blatter, B. Boeckmann, Jerven T. Bolleman, E. Boutet, L. Breuza, C. Casal-Casas, E. D. Castro, L. Cerutti, E. Coudert, Béatrice A. Cuche, M. Doche, D. Dornevil, Severine Duvaud, A. Estreicher, L. Famiglietti, M. Feuermann, E. Gasteiger, S. Gehant, Gerritsen, A. Gos, N. Gruaz-Gumowski, U. Hinz, C. Hulo, J. James, F. Jungo, G. Keller, Lara, P. Lemercier, J. Lew, D. Lieberherr, T. Lombardot, X. Martin, P. Masson, A. Morgat, T. Neto, S. Paesano, I. Pedruzzi, S. Pilbout, Monica Pozzato, Manuela Pruess, C. Rivoire, B. Roechert, Michel Schneider, C. Sigrist, K. Sonesson, S. Staehli, A. Stutz, S. Sundaram, M. Tognolli, L. Verbregue, A. Veuthey, Cathy H. Wu, C. Arighi, L. Arminski, Chuming Chen, Youhai H. Chen, J. Garavelli, Hongzhan Huang, K. Laiho, P. McGarvey, D. Natale, Baris E. Suzek, C. R. Vinayaka, Q. Wang, Y. Wang, L. Yeh, Yerramalla, J. Zhang\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to provide the scientific community with a comprehensive, high-quality and freely accessible resource of protein sequences and functional annotation. It integrates, interprets and standardizes data from literature and numerous resources to achieve the most comprehensive catalog possible of protein information. The central activities are the biocuration of the UniProt Knowledgebase and the dissemination of these data through our Web site and web services. UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR). UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.\n",
            "------------------------------------\n",
            "Title :  Collaborative filtering recommender systems\n",
            "Author/s :  M. Nilashi, Karamollah Bagherifard, O. Ibrahim, H. Alizadeh, L. Nojeem, Nazanin Roozegar\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recommender Systems are software tools and techniques for suggesting items to users by considering their preferences in an automated fashion. The suggestions provided are aimed at support users in various decision- making processes. Technically, recommender system has their origins in different fields such as Information Retrieval (IR), text classification, machine learning and Decision Support Systems (DSS). Recommender systems are used to address the Information Overload (IO) problem by recommending potentially interesting or useful items to users. They have proven to be worthy tools for online users to deal with the IO and have become one of the most popular and powerful tools in E-commerce. Many existing recommender systems rely on the Collaborative Filtering (CF) and have been extensively used in E-commerce .They have proven to be very effective with powerful techniques in many famous E-commerce companies. This study presents an overview of the field of recommender systems with current generation of recommendation methods and examines comprehensively CF systems with its algorithms.\n",
            "------------------------------------\n",
            "Title :  Constrained Nonnegative Matrix Factorization for Image Representation\n",
            "Author/s :  Haifeng Liu, Zhaohui Wu, Xuelong Li, Deng Cai, Thomas S. Huang\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2012\n",
            "Abstract :  Nonnegative matrix factorization (NMF) is a popular technique for finding parts-based, linear representations of nonnegative data. It has been successfully applied in a wide range of applications such as pattern recognition, information retrieval, and computer vision. However, NMF is essentially an unsupervised method and cannot make use of label information. In this paper, we propose a novel semi-supervised matrix decomposition method, called Constrained Nonnegative Matrix Factorization (CNMF), which incorporates the label information as additional constraints. Specifically, we show how explicitly combining label information improves the discriminating power of the resulting matrix decomposition. We explore the proposed CNMF method with two cost function formulations and provide the corresponding update solutions for the optimization problems. Empirical experiments demonstrate the effectiveness of our novel algorithm in comparison to the state-of-the-art approaches through a set of evaluations based on real-world applications.\n",
            "------------------------------------\n",
            "Title :  Information Flow Analysis of Android Applications in DroidSafe\n",
            "Author/s :  Michael I. Gordon, Deokhwan Kim, J. Perkins, Limei Gilham, Nguyen Nguyen, M. Rinard\n",
            "Venue :  Network and Distributed System Security Symposium\n",
            "year :  2015\n",
            "Abstract :  We present DroidSafe, a static information flow analysis tool that reports potential leaks of sensitive information in Android applications. DroidSafe combines a comprehensive, accurate, and precise model of the Android runtime with static analysis design decisions that enable the DroidSafe analyses to scale to analyze this model. This combination is enabled by accurate analysis stubs, a technique that enables the effective analysis of code whose complete semantics lies outside the scope of Java, and by a combination of analyses that together can statically resolve communication targets identified by dynamically constructed values such as strings and class designators. Our experimental results demonstrate that 1) DroidSafe achieves unprecedented precision and accuracy for Android information flow analysis (as measured on a standard previously published set of benchmark applications) and 2) DroidSafe detects all malicious information flow leaks inserted into 24 real-world Android applications by three independent, hostile Red-Team organizations. The previous state-of-the art analysis, in contrast, detects less than 10% of these malicious flows.\n",
            "------------------------------------\n",
            "Title :  A Survey on Network Embedding\n",
            "Author/s :  Peng Cui, Xiao Wang, J. Pei, Wenwu Zhu\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2017\n",
            "Abstract :  Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.\n",
            "------------------------------------\n",
            "Title :  The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics\n",
            "Author/s :  D. Ivanov, A. Dolgui, B. Sokolov\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2018\n",
            "Abstract :  The impact of digitalisation and Industry 4.0 on the ripple effect and disruption risk control analytics in the supply chain (SC) is studied. The research framework combines the results from two isolated areas, i.e. the impact of digitalisation on SC management (SCM) and the impact of SCM on the ripple effect control. To the best of our knowledge, this is the first study that connects business, information, engineering and analytics perspectives on digitalisation and SC risks. This paper does not pretend to be encyclopedic, but rather analyses recent literature and case-studies seeking to bring the discussion further with the help of a conceptual framework for researching the relationships between digitalisation and SC disruptions risks. In addition, it emerges with an SC risk analytics framework. It analyses perspectives and future transformations that can be expected in transition towards cyber-physical SCs. With these two frameworks, this study contributes to the literature by answering the questions of (1) what relations exist between big data analytics, Industry 4.0, additive manufacturing, advanced trace & tracking systems and SC disruption risks; (2) how digitalisation can contribute to enhancing ripple effect control; and (3) what digital technology-based extensions can trigger the developments towards SC risk analytics.\n",
            "------------------------------------\n",
            "Title :  Framework for Managing the COVID-19 Infodemic: Methods and Results of an Online, Crowdsourced WHO Technical Consultation\n",
            "Author/s :  V. Tangcharoensathien, N. Calleja, Tim Nguyen, T. Purnat, Marcelo D'agostino, Sebastian Garcia-Saiso, M. Landry, A. Rashidian, Clayton Hamilton, Abdelhalim AbdAllah, I. Ghiga, Alexandra Hill, D. Hougendobler, J. van Andel, M. Nunn, Ian Brooks, P. Sacco, M. De Domenico, Philip Mai, A. Gruzd, Alexandre Alaphilippe, S. Briand\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background An infodemic is an overabundance of information—some accurate and some not—that occurs during an epidemic. In a similar manner to an epidemic, it spreads between humans via digital and physical information systems. It makes it hard for people to find trustworthy sources and reliable guidance when they need it. Objective A World Health Organization (WHO) technical consultation on responding to the infodemic related to the coronavirus disease (COVID-19) pandemic was held, entirely online, to crowdsource suggested actions for a framework for infodemic management. Methods A group of policy makers, public health professionals, researchers, students, and other concerned stakeholders was joined by representatives of the media, social media platforms, various private sector organizations, and civil society to suggest and discuss actions for all parts of society, and multiple related professional and scientific disciplines, methods, and technologies. A total of 594 ideas for actions were crowdsourced online during the discussions and consolidated into suggestions for an infodemic management framework. Results The analysis team distilled the suggestions into a set of 50 proposed actions for a framework for managing infodemics in health emergencies. The consultation revealed six policy implications to consider. First, interventions and messages must be based on science and evidence, and must reach citizens and enable them to make informed decisions on how to protect themselves and their communities in a health emergency. Second, knowledge should be translated into actionable behavior-change messages, presented in ways that are understood by and accessible to all individuals in all parts of all societies. Third, governments should reach out to key communities to ensure their concerns and information needs are understood, tailoring advice and messages to address the audiences they represent. Fourth, to strengthen the analysis and amplification of information impact, strategic partnerships should be formed across all sectors, including but not limited to the social media and technology sectors, academia, and civil society. Fifth, health authorities should ensure that these actions are informed by reliable information that helps them understand the circulating narratives and changes in the flow of information, questions, and misinformation in communities. Sixth, following experiences to date in responding to the COVID-19 infodemic and the lessons from other disease outbreaks, infodemic management approaches should be further developed to support preparedness and response, and to inform risk mitigation, and be enhanced through data science and sociobehavioral and other research. Conclusions The first version of this framework proposes five action areas in which WHO Member States and actors within society can apply, according to their mandate, an infodemic management approach adapted to national contexts and practices. Responses to the COVID-19 pandemic and the related infodemic require swift, regular, systematic, and coordinated action from multiple sectors of society and government. It remains crucial that we promote trusted information and fight misinformation, thereby helping save lives.\n",
            "------------------------------------\n",
            "Title :  Gene Regulatory Network Inference from Single-Cell Data Using Multivariate Information Measures\n",
            "Author/s :  Thalia E. Chan, M. Stumpf, A. Babtie\n",
            "Venue :  bioRxiv\n",
            "year :  2017\n",
            "Abstract :  While single-cell gene expression experiments present new challenges for data processing, the cell-to-cell variability observed also reveals statistical relationships that can be used by information theory. Here, we use multivariate information theory to explore the statistical dependencies between triplets of genes in single-cell gene expression datasets. We develop PIDC, a fast, efficient algorithm that uses partial information decomposition (PID) to identify regulatory relationships between genes. We thoroughly evaluate the performance of our algorithm and demonstrate that the higher order information captured by PIDC allows it to outperform pairwise mutual information-based algorithms when recovering true relationships present in simulated data. We also infer gene regulatory networks from three experimental single-cell data sets and illustrate how network context, choices made during analysis, and sources of variability affect network inference. PIDC tutorials and open-source software for estimating PID are available here: https://github.com/Tchanders/network_inference_tutorials. PIDC should facilitate the identification of putative functional relationships and mechanistic hypotheses from single-cell transcriptomic data.\n",
            "------------------------------------\n",
            "Title :  Recent Advances on Spectral–Spatial Hyperspectral Image Classification: An Overview and New Guidelines\n",
            "Author/s :  Lin He, Jun Yu Li, Chenying Liu, Shutao Li\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2018\n",
            "Abstract :  Imaging spectroscopy, also known as hyperspectral imaging, has been transformed in the last four decades from being a sparse research tool into a commodity product available to a broad user community. Specially, in the last 10 years, a large number of new techniques able to take into account the special properties of hyperspectral data have been introduced for hyperspectral data processing, where hyperspectral image classification, as one of the most active topics, has drawn massive attentions. Spectral–spatial hyperspectral image classification can achieve better classification performance than its pixel-wise counterpart, since the former utilizes not only the information of spectral signature but also that from spatial domain. In this paper, we provide a comprehensive overview on the methods belonging to the category of spectral–spatial classification in a relatively unified context. First, we develop a concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance. In terms of the way that the neighborhood information is used, the spatial dependency systems can be classified into fixed, adaptive, and global systems, which can accommodate various kinds of existing spectral–spatial methods. Based on such, the categorizations of single-dependency, bilayer-dependency, and multiple-dependency systems are further introduced. Second, we categorize the performings of existing spectral–spatial methods into four paradigms according to the different fusion stages wherein spatial information takes effect, i.e., preprocessing-based, integrated, postprocessing-based, and hybrid classifications. Then, typical methodologies are outlined. Finally, several representative spectral–spatial classification methods are applied on real-world hyperspectral data in our experiments.\n",
            "------------------------------------\n",
            "Title :  Silent Listeners: The Evolution of Privacy and Disclosure on Facebook\n",
            "Author/s :  F. Stutzman, R. Gross, A. Acquisti\n",
            "Venue :  Journal of Privacy and Confidentiality\n",
            "year :  2013\n",
            "Abstract :  Over the past decade, social network sites have experienced dramatic growth in popularity, reaching most demographics and providing new opportunities for interaction and socialization. Through this growth, users have been challenged to manage novel privacy concerns and balance nuanced trade-offs between disclosing and withholding personal information. To date, however, no study has documented how privacy and disclosure evolved on social network sites over an extended period of time. In this manuscript we use profile data from a longitudinal panel of 5,076 Facebook users to understand how their privacy and disclosure behavior changed between 2005---the early days of the network---and 2011. Our analysis highlights three contrasting trends. First, over time Facebook users in our dataset exhibited increasingly privacy-seeking behavior, progressively decreasing the amount of personal data shared publicly with unconnected profiles in the same network. However, and second, changes implemented by Facebook near the end of the period of time under our observation arrested or in some cases inverted that trend. Third, the amount and scope of personal information that Facebook users revealed privately to other connected profiles actually increased over time---and because of that, so did disclosures to ``silent listeners'' on the network: Facebook itself, third-party apps, and (indirectly) advertisers. These findings highlight the tension between privacy choices as expressions of individual subjective preferences, and the role of the environment in shaping those choices.\n",
            "------------------------------------\n",
            "Title :  What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author/s :  Alexis Conneau, Germán Kruszewski, Guillaume Lample, Loïc Barrault, Marco Baroni\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2018\n",
            "Abstract :  Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title :  Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts\n",
            "Author/s :  C. D. Santos, M. Gatti\n",
            "Venue :  International Conference on Computational Linguistics\n",
            "year :  2014\n",
            "Abstract :  Sentiment analysis of short texts such as single sentences and Twitter messages is challenging because of the limited contextual information that they normally contain. Effectively solving this task requires strategies that combine the small text content with prior knowledge and use more than just bag-of-words. In this work we propose a new deep convolutional neural network that exploits from characterto sentence-level information to perform sentiment analysis of short texts. We apply our approach for two corpora of two different domains: the Stanford Sentiment Treebank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentiment corpus (STS), which contains Twitter messages. For the SSTb corpus, our approach achieves state-of-the-art results for single sentence sentiment prediction in both binary positive/negative classification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy. For the STS corpus, our approach achieves a sentiment prediction accuracy of 86.4%.\n",
            "------------------------------------\n",
            "Title :  An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author/s :  Daniel Russo, Benjamin Van Roy\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2014\n",
            "Abstract :  We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title :  Recent Advances on Spectral–Spatial Hyperspectral Image Classification: An Overview and New Guidelines\n",
            "Author/s :  Lin He, Jun Yu Li, Chenying Liu, Shutao Li\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2018\n",
            "Abstract :  Imaging spectroscopy, also known as hyperspectral imaging, has been transformed in the last four decades from being a sparse research tool into a commodity product available to a broad user community. Specially, in the last 10 years, a large number of new techniques able to take into account the special properties of hyperspectral data have been introduced for hyperspectral data processing, where hyperspectral image classification, as one of the most active topics, has drawn massive attentions. Spectral–spatial hyperspectral image classification can achieve better classification performance than its pixel-wise counterpart, since the former utilizes not only the information of spectral signature but also that from spatial domain. In this paper, we provide a comprehensive overview on the methods belonging to the category of spectral–spatial classification in a relatively unified context. First, we develop a concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance. In terms of the way that the neighborhood information is used, the spatial dependency systems can be classified into fixed, adaptive, and global systems, which can accommodate various kinds of existing spectral–spatial methods. Based on such, the categorizations of single-dependency, bilayer-dependency, and multiple-dependency systems are further introduced. Second, we categorize the performings of existing spectral–spatial methods into four paradigms according to the different fusion stages wherein spatial information takes effect, i.e., preprocessing-based, integrated, postprocessing-based, and hybrid classifications. Then, typical methodologies are outlined. Finally, several representative spectral–spatial classification methods are applied on real-world hyperspectral data in our experiments.\n",
            "------------------------------------\n",
            "Title :  Partisan Perceptual Bias and the Information Environment\n",
            "Author/s :  Jennifer Jerit\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Perceptual bias occurs when beliefs deviate from reality. Democrats and Republicans are thought to be especially susceptible to this type of biased-information processing. And yet we know little about the pervasiveness of perceptual bias outside the domain of ‘‘performance issues’’ (e.g., unemployment, inflation) or how individuallevel partisan motivation interacts with the information environment. We investigate these issues in two studies that examine perceptual bias on a wide range of political topics spanning two decades. Using survey data as well as an experiment with diverse subjects, we demonstrate that people perceive the world in a manner consistent with their political views. The result is a selective pattern of learning in which partisans have higher levels of knowledge for facts that confirm their world view and lower levels of knowledge for facts that challenge them. This basic relationship is exaggerated on topics receiving high levels of media coverage.\n",
            "------------------------------------\n",
            "Title :  What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author/s :  Alexis Conneau, Germán Kruszewski, Guillaume Lample, Loïc Barrault, Marco Baroni\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2018\n",
            "Abstract :  Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title :  Variable selection with stepwise and best subset approaches.\n",
            "Author/s :  Wentao Bao\n",
            "Venue :  Annals of Translational Medicine\n",
            "year :  2016\n",
            "Abstract :  While purposeful selection is performed partly by software and partly by hand, the stepwise and best subset approaches are automatically performed by software. Two R functions stepAIC() and bestglm() are well designed for stepwise and best subset regression, respectively. The stepAIC() function begins with a full or null model, and methods for stepwise regression can be specified in the direction argument with character values \"forward\", \"backward\" and \"both\". The bestglm() function begins with a data frame containing explanatory variables and response variables. The response variable should be in the last column. Varieties of goodness-of-fit criteria can be specified in the IC argument. The Bayesian information criterion (BIC) usually results in more parsimonious model than the Akaike information criterion.\n",
            "------------------------------------\n",
            "Title :  The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics\n",
            "Author/s :  D. Ivanov, A. Dolgui, B. Sokolov\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2018\n",
            "Abstract :  The impact of digitalisation and Industry 4.0 on the ripple effect and disruption risk control analytics in the supply chain (SC) is studied. The research framework combines the results from two isolated areas, i.e. the impact of digitalisation on SC management (SCM) and the impact of SCM on the ripple effect control. To the best of our knowledge, this is the first study that connects business, information, engineering and analytics perspectives on digitalisation and SC risks. This paper does not pretend to be encyclopedic, but rather analyses recent literature and case-studies seeking to bring the discussion further with the help of a conceptual framework for researching the relationships between digitalisation and SC disruptions risks. In addition, it emerges with an SC risk analytics framework. It analyses perspectives and future transformations that can be expected in transition towards cyber-physical SCs. With these two frameworks, this study contributes to the literature by answering the questions of (1) what relations exist between big data analytics, Industry 4.0, additive manufacturing, advanced trace & tracking systems and SC disruption risks; (2) how digitalisation can contribute to enhancing ripple effect control; and (3) what digital technology-based extensions can trigger the developments towards SC risk analytics.\n",
            "------------------------------------\n",
            "Title :  An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author/s :  Daniel Russo, Benjamin Van Roy\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2014\n",
            "Abstract :  We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title :  Thermodynamics from Information\n",
            "Author/s :  M. N. Bera, A. Winter, M. Lewenstein\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author/s :  Christopher Courtney, Supradeep Dutta, Yong Li\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title :  Permutation Entropy and Its Main Biomedical and Econophysics Applications: A Review\n",
            "Author/s :  M. Zanin, L. Zunino, O. Rosso, D. Papo\n",
            "Venue :  Entropy\n",
            "year :  2012\n",
            "Abstract :  Entropy is a powerful tool for the analysis of time series, as it allows describing the probability distributions of the possible state of a system, and therefore the information encoded in it. Nevertheless, important information may be codified also in the temporal dynamics, an aspect which is not usually taken into account. The idea of calculating entropy based on permutation patterns (that is, permutations defined by the order relations among values of a time series) has received a lot of attention in the last years, especially for the understanding of complex and chaotic systems. Permutation entropy directly accounts for the temporal information contained in the time series; furthermore, it has the quality of simplicity, robustness and very low computational cost. To celebrate the tenth anniversary of the original work, here we analyze the theoretical foundations of the permutation entropy, as well as the main recent applications to the analysis of economical markets and to the understanding of biomedical systems.\n",
            "------------------------------------\n",
            "Title :  Sampling-based robotic information gathering algorithms\n",
            "Author/s :  G. Hollinger, G. Sukhatme\n",
            "Venue :  Int. J. Robotics Res.\n",
            "year :  2014\n",
            "Abstract :  We propose three sampling-based motion planning algorithms for generating informative mobile robot trajectories. The goal is to find a trajectory that maximizes an information quality metric (e.g. variance reduction, information gain, or mutual information) and also falls within a pre-specified budget constraint (e.g. fuel, energy, or time). Prior algorithms have employed combinatorial optimization techniques to solve these problems, but existing techniques are typically restricted to discrete domains and often scale poorly in the size of the problem. Our proposed rapidly exploring information gathering (RIG) algorithms combine ideas from sampling-based motion planning with branch and bound techniques to achieve efficient information gathering in continuous space with motion constraints. We provide analysis of the asymptotic optimality of our algorithms, and we present several conservative pruning strategies for modular, submodular, and time-varying information objectives. We demonstrate that our proposed techniques find optimal solutions more quickly than existing combinatorial solvers, and we provide a proof-of-concept field implementation on an autonomous surface vehicle performing a wireless signal strength monitoring task in a lake.\n",
            "------------------------------------\n",
            "Title :  Internet use by pregnant women seeking pregnancy-related information: a systematic review\n",
            "Author/s :  P. Sayakhot, M. Carolan-Olah\n",
            "Venue :  BMC Pregnancy and Childbirth\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Eliciting Expert Knowledge in Conservation Science\n",
            "Author/s :  T. Martin, M. Burgman, F. Fidler, P. Kuhnert, S. Low-Choy, M. McBride, K. Mengersen\n",
            "Venue :  Conservation Biology\n",
            "year :  2012\n",
            "Abstract :  Abstract:  Expert knowledge is used widely in the science and practice of conservation because of the complexity of problems, relative lack of data, and the imminent nature of many conservation decisions. Expert knowledge is substantive information on a particular topic that is not widely known by others. An expert is someone who holds this knowledge and who is often deferred to in its interpretation. We refer to predictions by experts of what may happen in a particular context as expert judgments. In general, an expert‐elicitation approach consists of five steps: deciding how information will be used, determining what to elicit, designing the elicitation process, performing the elicitation, and translating the elicited information into quantitative statements that can be used in a model or directly to make decisions. This last step is known as encoding. Some of the considerations in eliciting expert knowledge include determining how to work with multiple experts and how to combine multiple judgments, minimizing bias in the elicited information, and verifying the accuracy of expert information. We highlight structured elicitation techniques that, if adopted, will improve the accuracy and information content of expert judgment and ensure uncertainty is captured accurately. We suggest four aspects of an expert elicitation exercise be examined to determine its comprehensiveness and effectiveness: study design and context, elicitation design, elicitation method, and elicitation output. Just as the reliability of empirical data depends on the rigor with which it was acquired so too does that of expert knowledge.\n",
            "------------------------------------\n",
            "Title :  Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports\n",
            "Author/s :  Jian Zhou, Hongyu Zhang, D. Lo\n",
            "Venue :  International Conference on Software Engineering\n",
            "year :  2012\n",
            "Abstract :  For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.\n",
            "------------------------------------\n",
            "Title :  Trust-Aware Recommender Systems\n",
            "Author/s :  Mohammad Ali Abbasi, J. Tang\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Recommender systems are an effective solution to the information overload problem, specially in the online world where we are constantly faced with inordinately many choices. These systems try to find the items such as books or movies that match best with users’ preferences. Based on the different approaches to finding the items of interests to users, we can classify the recommender systems into three major groups. First, content based recommender systems use content information to make a recommendation. For example, such systems might recommend a romantic movie to a user that showed interest in romantic movies in her profile. Second, collaborative filtering recommender systems rely only on the past behavior of the users such as their previous transactions or ratings. By comparing this information, a collaborative filtering recommender system finds new items or users to users. In order to address the cold-start problem and fend off various types of attacks, the third class of recommender systems, namely trust-aware recommender systems, is proposed. These systems use social media and trust information to make a recommendation, which is shown to be promising in improving the accuracy of the recommendations. In this chapter, we give an overview of state-of-theart recommender systems with a focus on trust-aware recommender systems. In particular, we describe the ways that trust information can help to improve the quality of the recommendations. In the rest of the chapter, we introduce recommender systems, then trust in social media, and next trust-aware recommender systems. Trust-Aware Recommender Systems 3 1.1 Recommender Systems With the development of Web 2.0, information has increased at an unprecedented rate which aggravates the severity of the information overload problem for online users. For example, a search for “smartphone” returns 1,664,253 results in Amazon products or a search for “best movies to watch” in Google videos returns about 219,000,000 results. Due to the information overload problem, the decision-making process becomes perplexing when one is exposed to excessive information [58, 55, 19, 1]. Therefore, with the rapidly growing amount of available information and digital items on the web, it is necessary to use tools to filter this information in order to find items that are more likely to be of interest to the users. One can use search engines to overcome the information overload problem. In this case, the user has to refine the search terms or has to pick more specific query terms to narrow down the results. Another solution to overcome the information overload problem is to use top-k recommendations. In this approach, the system keeps a list of the most popular items and utilizes the list to recommend items to the user. For example, Ted is a website that uses this technique to recommend items to users. It can be seen in Figure 1.1, users can sort items bases on the different approaches such as overall popularity (most viewed), popularity in the past week (most emailed this week), or popularity in the past month (most popular this month) among others. Similar to search engines, top-k items are not usually customized based on users’ preferences and interest. In particulate, a top-k-item system returns the same list of items to people with different preferences. Therefore, customization is the major problem associated with these two approaches. Recommender systems are introduced to tackle the information overload, and the customization problem. Recommender systems are a subclass of information filtering systems that consider users’ preferences and recommended items that match with users’ preferences and interests [23]. These systems have become extremely common in recent years and are applied in a variety of applications including recommending products, social links, and digital items. The most popular ones are probably movies, music, news, books, and products in general [58, 70, 19, 26, 60]. Further, recommender systems are frequently used on recommending social links such as recommending people to follow on Twitter, befriend on social networks or dating sites [67, 37]. Furthermore, these systems are also used to accurately estimate the degree to which a particular user (from now on termed the target user) will like a particular item (the target item) [73]. Based on the type of data that recommender systems use, we can classify 1http://www.amazon.com 2https://www.google.com/#q=best+movies+to+watch&safe=active&tbm=vid 3http://www.ted.com/ 4 Trust-Aware Recommender Systems FIGURE 1.1: Ted.com uses a top-k item recommendation approach to rank items them into two major classes: content-based and collaborative filtering based recommender systems [76, 60]. Content-based recommendation systems use items’ features and characteristics to rank the items based on the user’s preferences. Collaborative filtering recommendation systems rely on the user’s past behavior e.g., purchases or ratings, to find similar users or items and utilize this information in order to find the items of interests to the user. In general, recommender systems are utility functions that predict the rating of item i from the item set I for user u from the user set U in the form of U × I → R, where rui is the rating of the item i for the given user u. The task of recommender systems is to predict user u’s rating for the given item i for which rui is unknown and use r̂ui to represent the predicted rating. The ratings, ru,i, can be any real number but often ratings are integers in the range [1, 5]. We use R to show all of the ratings. In real-world recommender systems, only a few users rate the items of interests (this number for many recommender system is less than 1%). Matrix 1.1 shows an example of a rating matrix with missing values. The goal of recommender systems is to predict these missing values. R =  5 2 3 4 3 4 2 2 5 3 5 5 3  (1.1) Trust-Aware Recommender Systems 5 Algorithm 1 Content-based recommendation 1: Describe the items that may be recommended. 2: Create a profile of the user that describes the types of items the user likes 3: Compare items to the user profile to determine what to recommend. The profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user. 1.1.1 Content-based Recommendation Content-based recommender systems uses items’ and users’ features to create a profile for each item or user. For example, movie profile might include attributes such as gender, participating actors, director, and office box popularity. User profile includes demographic information and users’s interests [28]. These systems use supervised machine learning to induce a classifier that can discriminate between items likely to be of interest to the user and those likely to be uninteresting [52, 5, 49]. The recommender recommends an item to a user based on a description of the item and a profile of the users’ interests. Algorithm 1 shows the main steps of a content-based recommendation. We usually use vector space model to represent users’ and items’ features. In this model, every item or user is represented as a vector. i = (t1, t2, ..., tn) (1.2) where tj is the frequency of term j in item i. To model users or items more accurately, instead of frequency we can use tf-idf which can be calculated as follows: tft,i = ft,i max{fz,i : z ∈ i} idft = log N nt (1.3) wt,i = tft,i × idft (1.4) where ft,i is the frequency of term t in item i, max{fz,i : z ∈ i} is the maximum term frequency in item i, N is the total number of items, nt is the number of items where term t appears. tft,i denotes the frequency of term t in item i, and idft denotes the inverse document frequency of term t, which inversely correlates with the number of items, that term t is appeared in their descriptions. The similarity between user u and item i can be calculated using Equation 1.5. sim(u, i) = ∑ t∈T wt,uwt,i √∑ t∈T w 2 t,u √∑ t∈T w 2 t,i (1.5) where T indicates the set of terms that appeared in item and user description. 6 Trust-Aware Recommender Systems 1.1.2 Collaborative Filtering (CF) Collaborative filtering is the process of filtering the information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc [69]. Collaborative filtering systems use the user’s past behavior, and recommend items that match their taste. Collaborative filtering recommender systems can be classified into memory-based and model-based collaborative filtering. In memory-based approach we predict the missing ratings based on similarity between users or items. In model-based approach, we use given user-item ratings to construct a model and use the model to predict missing ratings. We’ll give a detailed description of these two approaches in the following sections. The main advantage of this method is that the recommender system does not need to have any information about the users and content of the items to recommend. User-item ratings are the only information the system needs to operate. The following are assumptions for collaborative filtering systems [76]: • Users with similar ratings on some items are more likely to have similar ratings on future items, and • Items with similar ratings in the past are more likely to have similar ratings in the future. Figure 1.2 illustrates this approach for a small set of users and movies. The goal is recommending a new movie to Jack. In the first step, the system finds three other users that have similar movie taste as Jack’s. The next step it looks for other movies that these users liked. All three of them liked “Once Upon a Time in the West”, and two of them liked “Spider man”. Therefore, the top recommendation would be “Once Upon a Time in the West”. 1.1.2.1 Memory-based Collaborative Filtering In a memory-based approach, the recommender system aims to predict the missing ratings based on either similarity\n",
            "------------------------------------\n",
            "Title :  Electronic Health Records: Then, Now, and in the Future.\n",
            "Author/s :  R. Evans\n",
            "Venue :  Yearbook of medical informatics\n",
            "year :  2016\n",
            "Abstract :  OBJECTIVES\n",
            "Describe the state of Electronic Health Records (EHRs) in 1992 and their evolution by 2015 and where EHRs are expected to be in 25 years. Further to discuss the expectations for EHRs in 1992 and explore which of them were realized and what events accelerated or disrupted/derailed how EHRs evolved.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Literature search based on \"Electronic Health Record\", \"Medical Record\", and \"Medical Chart\" using Medline, Google, Wikipedia Medical, and Cochrane Libraries resulted in an initial review of 2,356 abstracts and other information in papers and books. Additional papers and books were identified through the review of references cited in the initial review.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "By 1992, hardware had become more affordable, powerful, and compact and the use of personal computers, local area networks, and the Internet provided faster and easier access to medical information. EHRs were initially developed and used at academic medical facilities but since most have been replaced by large vendor EHRs. While EHR use has increased and clinicians are being prepared to practice in an EHR-mediated world, technical issues have been overshadowed by procedural, professional, social, political, and especially ethical issues as well as the need for compliance with standards and information security. There have been enormous advancements that have taken place, but many of the early expectations for EHRs have not been realized and current EHRs still do not meet the needs of today's rapidly changing healthcare environment.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The current use of EHRs initiated by new technology would have been hard to foresee. Current and new EHR technology will help to provide international standards for interoperable applications that use health, social, economic, behavioral, and environmental data to communicate, interpret, and act intelligently upon complex healthcare information to foster precision medicine and a learning health system.\n",
            "------------------------------------\n",
            "Title :  You are facing the Mona Lisa: spot localization using PHY layer information\n",
            "Author/s :  Souvik Sen, B. Radunovic, Romit Roy Choudhury, T. Minka\n",
            "Venue :  ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services\n",
            "year :  2012\n",
            "Abstract :  This paper explores the viability of precise indoor localization using physical layer information in WiFi systems. We find evidence that channel responses from multiple OFDM subcarriers can be a promising location signature. While these signatures certainly vary over time and environmental mobility, we notice that their core structure preserves certain properties that are amenable to localization. We attempt to harness these opportunities through a functional system called PinLoc, implemented on off-the-shelf Intel 5300 cards. We evaluate the system in a busy engineering building, a crowded student center, a cafeteria, and at the Duke University museum, and demonstrate localization accuracies in the granularity of 1m x 1m boxes, called \"spots\". Results from 100 spots show that PinLoc is able to localize users to the correct spot with 89% mean accuracy, while incurring less than 6% false positives. We believe this is an important step forward, compared to the best indoor localization schemes of today, such as Horus.\n",
            "------------------------------------\n",
            "Title :  Deep Learning: Methods and Applications\n",
            "Author/s :  L. Deng, Dong Yu\n",
            "Venue :  Foundations and Trends® in Signal Processing\n",
            "year :  2014\n",
            "Abstract :  This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.\n",
            "------------------------------------\n",
            "Title :  Information Frictions in Trade\n",
            "Author/s :  Treb Allen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  It is costly to learn about market conditions elsewhere, especially in developing countries. This paper examines how such information frictions affect trade. Using data on regional agricultural trade in the Philippines, I first document a number of observed patterns in trade flows and prices that suggest the presence of information frictions. I then incorporate information frictions into a perfect competition trade model by embedding a process whereby heterogeneous producers engage in a costly sequential search process to determine where to sell their produce. I show that introducing information frictions reconciles the theory with the observed patterns in the data. Structural estimation of the model finds that information frictions are quantitatively important: roughly half the observed regional price dispersion is due to information frictions. Furthermore, incorporating information frictions improves the out‐of‐sample predictive power of the model.\n",
            "------------------------------------\n",
            "Title :  Quantum discord as resource for remote state preparation\n",
            "Author/s :  B. Dakić, Yannick Ole Lipp, Xiao-song Ma, M. Ringbauer, S. Kropatschek, S. Barz, T. Paterek, V. Vedral, A. Zeilinger, Č. Brukner, P. Walther\n",
            "Venue :  Nature Physics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Collateral Crises\n",
            "Author/s :  Gary B. Gorton, G. Ordonez\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Short-term collateralized debt, such as demand deposits and money market instruments - private money, is efficient if agents are willing to lend without producing costly information about the collateral backing the debt. When the economy relies on such informationally-insensitive debt, firms with low quality collateral can borrow, generating a credit boom and an increase in output and consumption. Financial fragility builds up over time as information about counter-parties decays. A crisis occurs when a small shock then causes a large change in the information environment. Agents suddenly have incentives to produce information, asymmetric information becomes a threat and there is a decline in output and consumption. A social planner would produce more information than private agents, but would not always want to eliminate fragility.\n",
            "------------------------------------\n",
            "Title :  High-Level Information Fusion Management and System Design\n",
            "Author/s :  Erik Blasch, É. Bossé, D. Lambert\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  High-level information fusion is the ability of a fusion system to capture awareness and complex relations, reason over past and future events, utilize direct sensing exploitations and tacit reports, and discern the usefulness and intention of results to meet system-level goals. This authoritative book serves a practical reference for developers, designers, and users of data fusion services that must relate the most recent theory to real-world applications. This unique volume provides alternative methods to represent and model various situations and describes design component implementations of fusion systems. Designers find expert guidance in applying current theories, selecting algorithms and software components, and measuring expected performance of high-level fusion systems.\n",
            "------------------------------------\n",
            "Title :  Distributed Event-Triggered Control for Multi-Agent Systems\n",
            "Author/s :  D. Dimarogonas, Emilio Frazzoli, K. Johansson\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2012\n",
            "Abstract :  Event-driven strategies for multi-agent systems are motivated by the future use of embedded microprocessors with limited resources that will gather information and actuate the individual agent controller updates. The controller updates considered here are event-driven, depending on the ratio of a certain measurement error with respect to the norm of a function of the state, and are applied to a first order agreement problem. A centralized formulation is considered first and then its distributed counterpart, in which agents require knowledge only of their neighbors' states for the controller implementation. The results are then extended to a self-triggered setup, where each agent computes its next update time at the previous one, without having to keep track of the state error that triggers the actuation between two consecutive update instants. The results are illustrated through simulation examples.\n",
            "------------------------------------\n",
            "Title :  Quantum resource theories\n",
            "Author/s :  E. Chitambar, G. Gour\n",
            "Venue :  Reviews of Modern Physics\n",
            "year :  2018\n",
            "Abstract :  Quantum resource theories (QRTs) offer a highly versatile and powerful framework for studying different phenomena in quantum physics. From quantum entanglement to quantum computation, resource theories can be used to quantify a desirable quantum effect, develop new protocols for its detection, and identify processes that optimize its use for a given application. Particularly, QRTs revolutionize the way we think about familiar properties of physical systems like entanglement, elevating them from just being interesting from a fundamental point of view to being useful in performing practical tasks. The basic methodology of a general QRT involves partitioning all quantum states into two groups, one consisting of free states and the other consisting of resource states. Accompanying the set of free states is a collection of free quantum operations arising from natural restrictions on physical systems, and that consists of all the physical processes allowed by the resource theory and which acts invariantly on the set of free states. The QRT then studies what information processing tasks become possible using the restricted operations. Despite the large degree of freedom in how one defines the free states and free operations, unexpected similarities emerge among different QRTs in terms of resource measures and resource convertibility. As a result, objects that appear quite distinct on the surface, such as entanglement and quantum reference frames, appear to have great similarity on a deeper structural level. In this article we review the general framework of a quantum resource theory, focusing on common structural features, operational tasks, and resource measures. To illustrate these concepts, an overview is provided on some of the more commonly studied QRTs in the literature.\n",
            "------------------------------------\n",
            "Title :  Information propagation in the Bitcoin network\n",
            "Author/s :  Christian Decker, Roger Wattenhofer\n",
            "Venue :  IEEE P2P 2013 Proceedings\n",
            "year :  2013\n",
            "Abstract :  Bitcoin is a digital currency that unlike traditional currencies does not rely on a centralized authority. Instead Bitcoin relies on a network of volunteers that collectively implement a replicated ledger and verify transactions. In this paper we analyze how Bitcoin uses a multi-hop broadcast to propagate transactions and blocks through the network to update the ledger replicas. We then use the gathered information to verify the conjecture that the propagation delay in the network is the primary cause for blockchain forks. Blockchain forks should be avoided as they are symptomatic for inconsistencies among the replicas in the network. We then show what can be achieved by pushing the current protocol to its limit with unilateral changes to the client's behavior.\n",
            "------------------------------------\n",
            "Title :  An Empirical Analysis of the Quality of Corporate Financial Disclosure\n",
            "Author/s :  S. Singhvi, H. Desai\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  IN A free enterprise system, variations in corporate disclosure practices are likely to result since corporations are managed by groups which have varying managerial philosophies and wide discretion in connection with disclosing information to the investing public. The quality of corporate disclosure influences to a great extent the quality of investment decisions made by investors. This study attempts to identify some of the characteristics of corporations in the United States which are associated with, and the probable implications of, the quality of corporate disclosure.\n",
            "------------------------------------\n",
            "Title :  Visualization and analysis of gene expression in tissue sections by spatial transcriptomics\n",
            "Author/s :  P. Ståhl, Fredrik Salmén, S. Vickovic, Anna Lundmark, J. F. Navarro, J. Magnusson, S. Giacomello, Michaela Asp, J. Westholm, M. Huss, A. Mollbrink, S. Linnarsson, S. Codeluppi, Å. Borg, F. Pontén, P. Costea, P. Sahlén, J. Mulder, O. Bergmann, J. Lundeberg, J. Frisén\n",
            "Venue :  Science\n",
            "year :  2016\n",
            "Abstract :  Spatial structure of RNA expression RNA-seq and similar methods can record gene expression within and among cells. Current methods typically lose positional information and many require arduous single-cell isolation and sequencing. Ståhl et al. have developed a way of measuring the spatial distribution of transcripts by annealing fixed brain or cancer tissue samples directly to bar-coded reverse transcriptase primers, performing reverse transcription followed by sequencing and computational reconstruction, and they can do so for multiple genes. Science, this issue p. 78 A new technique allows visualization and quantitative analysis of the spatially resolved transcriptome across individual tissue sections. Analysis of the pattern of proteins or messengerRNAs (mRNAs) in histological tissue sections is a cornerstone in biomedical research and diagnostics. This typically involves the visualization of a few proteins or expressed genes at a time. We have devised a strategy, which we call “spatial transcriptomics,” that allows visualization and quantitative analysis of the transcriptome with spatial resolution in individual tissue sections. By positioning histological sections on arrayed reverse transcription primers with unique positional barcodes, we demonstrate high-quality RNA-sequencing data with maintained two-dimensional positional information from the mouse brain and human breast cancer. Spatial transcriptomics provides quantitative gene expression data and visualization of the distribution of mRNAs within tissue sections and enables novel types of bioinformatics analyses, valuable in research and diagnostics.\n",
            "------------------------------------\n",
            "Title :  Information, Role Models and Perceived Returns to Education Experimental Evidence from Madagascar\n",
            "Author/s :  T. Nguyen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This brief summarizes the information, role models and perceived returns to education experimental evidence from Madagascar. This paper shows that increasing perceived returns to education strengthens incentives for schooling when agents underestimate the actual returns. The author conducted a field experiment in Madagascar to study alternative ways to provide additional information about the returns to education: simply providing statistics versus using a role model, an actual person sharing his and her success story. Some argue that role models may be more effective than providing statistics to a largely illiterate population. However, this proposition depends on how households update their beliefs based on the information the role model brings. Motivated by a model of belief formation, the author randomly assigns schools to the role model intervention, the statistics intervention, or a combination of both. The author fined that providing statistics reduced the large gap between perceived returns and the statistics provided. As a result, it improved average test scores by 0.2 standard deviations. For those whose initial perceived returns were below the statistics, test scores improved by 0.37 standard deviations. Student attendance in statistics schools is also 3.5 percentage points higher than attendance in schools without statistics. Consistent with the theory, seeing a role model of poor background has a larger impact on poor children's test scores than seeing someone of rich background. Combining a role model with statistics leads to smaller treatment effects than statistics alone, also consistent with the theory. The key implication of my results is that households lack information, but are able to process new information and change their decisions in a sophisticated manner.\n",
            "------------------------------------\n",
            "Title :  Context-Aware Recommender Systems for Learning: A Survey and Future Challenges\n",
            "Author/s :  K. Verbert, N. Manouselis, X. Ochoa, M. Wolpers, H. Drachsler, I. Bosnić, E. Duval\n",
            "Venue :  IEEE Transactions on Learning Technologies\n",
            "year :  2012\n",
            "Abstract :  Recommender systems have been researched extensively by the Technology Enhanced Learning (TEL) community during the last decade. By identifying suitable resources from a potentially overwhelming variety of choices, such systems offer a promising approach to facilitate both learning and teaching tasks. As learning is taking place in extremely diverse and rich environments, the incorporation of contextual information about the user in the recommendation process has attracted major interest. Such contextualization is researched as a paradigm for building intelligent systems that can better predict and anticipate the needs of users, and act more efficiently in response to their behavior. In this paper, we try to assess the degree to which current work in TEL recommender systems has achieved this, as well as outline areas in which further work is needed. First, we present a context framework that identifies relevant context dimensions for TEL applications. Then, we present an analysis of existing TEL recommender systems along these dimensions. Finally, based on our survey results, we outline topics on which further research is needed.\n",
            "------------------------------------\n",
            "Title :  Seeking and sharing health information online: comparing search engines and social media\n",
            "Author/s :  M. Choudhury, M. Morris, Ryen W. White\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2014\n",
            "Abstract :  Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
            "------------------------------------\n",
            "Title :  VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback\n",
            "Author/s :  Ruining He, Julian McAuley\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " Modern recommender systems model people and items by discovering or `teasing apart' the underlying dimensions that encode the properties of items and users' preferences toward them. Critically, such dimensions are uncovered based on user feedback, often in implicit form (such as purchase histories, browsing logs, etc.); in addition, some recommender systems make use of side information, such as product attributes, temporal information, or review text.However one important feature that is typically ignored by existing personalized recommendation and ranking methods is the visual appearance of the items being considered. In this paper we propose a scalable factorization model to incorporate visual signals into predictors of people's opinions, which we apply to a selection of large, real-world datasets. We make use of visual features extracted from product images using (pre-trained) deep networks, on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people's feedback. This not only leads to significantly more accurate personalized ranking methods, but also helps to alleviate cold start issues, and qualitatively to analyze the visual dimensions that influence people's opinions.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Some Hesitant Fuzzy Aggregation Operators with Their Application in Group Decision Making\n",
            "Author/s :  M. Xia, Zeshui Xu, Na Chen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Automatic detection of rumor on Sina Weibo\n",
            "Author/s :  Fan Yang, Yang Liu, Xiaohui Yu, Min Yang\n",
            "Venue :  MDS '12\n",
            "year :  2012\n",
            "Abstract :  The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter, the world's largest micro-blogging platform, as the premise of research. In this work, we shift the premise and study the problem of information credibility on Sina Weibo, China's leading micro-blogging service provider. With eight times more users than Twitter, Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone, and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments, the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs, and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification, and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge, this is the first study on rumor analysis and detection on Sina Weibo.\n",
            "------------------------------------\n",
            "Title :  Crowdsourcing, Citizen Science or Volunteered Geographic Information? The Current State of Crowdsourced Geographic Information\n",
            "Author/s :  L. See, P. Mooney, G. Foody, L. Bastin, A. Comber, J. Estima, S. Fritz, N. Kerle, B. Jiang, Mari Laakso, Hai-Ying Liu, G. Milcinski, Matej Niksic, M. Painho, Andrea Pődör, A. Raimond, M. Rutzinger\n",
            "Venue :  ISPRS Int. J. Geo Inf.\n",
            "year :  2016\n",
            "Abstract :  Citizens are increasingly becoming an important source of geographic information, sometimes entering domains that had until recently been the exclusive realm of authoritative agencies. This activity has a very diverse character as it can, amongst other things, be active or passive, involve spatial or aspatial data and the data provided can be variable in terms of key attributes such as format, description and quality. Unsurprisingly, therefore, there are a variety of terms used to describe data arising from citizens. In this article, the expressions used to describe citizen sensing of geographic information are reviewed and their use over time explored, prior to categorizing them and highlighting key issues in the current state of the subject. The latter involved a review of ~100 Internet sites with particular focus on their thematic topic, the nature of the data and issues such as incentives for contributors. This review suggests that most sites involve active rather than passive contribution, with citizens typically motivated by the desire to aid a worthy cause, often receiving little training. As such, this article provides a snapshot of the role of citizens in crowdsourcing geographic information and a guide to the current status of this rapidly emerging and evolving subject.\n",
            "------------------------------------\n",
            "Title :  Adapting to Artificial Intelligence: Radiologists and Pathologists as Information Specialists.\n",
            "Author/s :  S. Jha, E. Topol\n",
            "Venue :  JAMA\n",
            "year :  2016\n",
            "Abstract :  Artificial intelligence—the mimicking of human cognition by computers—was once a fable in science fiction but is becoming reality in medicine. The combination of big data and artificial intelligence, referred to by some as the fourth industrial revolution,1 will change radiology and pathology along with other medical specialties. Although reports of radiologists and pathologists being replaced by computers seem exaggerated,2 these specialties must plan strategically for a future in which artificial intelligence is part of the health care workforce. Radiologists have always revered machines and technology. In 1960, Lusted predicted “an electronic scannercomputer to examine chest photofluorograms, to separate the clearly normal chest films from the abnormal chest films.”3 Lusted further suggested that “the abnormal chest films would be marked for later study by the radiologists.”3 Lusted’s intuitions were prescient: interpreting radiographs is pattern recognition; computers can recognize patterns and may be helpful because some roentgenographic analyses can be automated. Nearly 60 years after Lusted’s prediction, Enlitic, a technology company in Silicon Valley, inputted images of normal radiographs and radiographs with fractures into a computerized database.4 Using deep learning, a refined version of artificial neural networks, the\n",
            "------------------------------------\n",
            "Title :  FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\n",
            "Author/s :  Caner Hazirbas, Lingni Ma, Csaba Domokos, D. Cremers\n",
            "Venue :  Asian Conference on Computer Vision\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Database resources of the National Center for Biotechnology Information\n",
            "Author/s :  Huang Gao\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Additional NCBI resources focus on literature (PubMed Central (PMC), Bookshelf and PubReader), health (ClinVar, dbGaP, dbMHC, the Genetic Testing Registry, HIV-1/Human Protein Interaction Database and MedGen), genomes (BioProject, Assembly, Genome, BioSample, dbSNP, dbVar, Epigenomics, the Map Viewer, Nucleotide, Probe, RefSeq, Sequence Read Archive, the Taxonomy Browser and the Trace Archive), genes (Gene, Gene Expression Omnibus (GEO), HomoloGene, PopSet and UniGene), proteins (Protein, the Conserved Domain Database (CDD), COBALT, Conserved Domain Architecture Retrieval Tool (CDART), the Molecular Modeling Database (MMDB) and Protein Clusters) and chemicals (Biosystems and the PubChem suite of small molecule databases). The Entrez system provides search and retrieval operations for most of these databases. Augmenting many of the web applications are custom implementations of the BLAST program optimized to search specialized datasets. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title :  Do Independent Directors Cause Improvements in Firm Transparency?\n",
            "Author/s :  C. Armstrong, J. Core, W. Guay\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Although recent research documents a positive relation between corporate transparency and the proportion of independent directors, the direction of causality is unclear. We examine a regulatory shock that substantially increased board independence for some firms, and find that information asymmetry, and to some extent management disclosure and financial intermediation, changed at firms affected by this shock. We also examine whether these effects vary as a function of management entrenchment, information processing costs, and required changes to audit committee independence. Our results suggest that firms can alter their corporate transparency to suit the informational demands of a particular board structure.\n",
            "------------------------------------\n",
            "Title :  Collaborative filtering recommender systems\n",
            "Author/s :  M. Nilashi, Karamollah Bagherifard, O. Ibrahim, H. Alizadeh, L. Nojeem, Nazanin Roozegar\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recommender Systems are software tools and techniques for suggesting items to users by considering their preferences in an automated fashion. The suggestions provided are aimed at support users in various decision- making processes. Technically, recommender system has their origins in different fields such as Information Retrieval (IR), text classification, machine learning and Decision Support Systems (DSS). Recommender systems are used to address the Information Overload (IO) problem by recommending potentially interesting or useful items to users. They have proven to be worthy tools for online users to deal with the IO and have become one of the most popular and powerful tools in E-commerce. Many existing recommender systems rely on the Collaborative Filtering (CF) and have been extensively used in E-commerce .They have proven to be very effective with powerful techniques in many famous E-commerce companies. This study presents an overview of the field of recommender systems with current generation of recommendation methods and examines comprehensively CF systems with its algorithms.\n",
            "------------------------------------\n",
            "Title :  Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\n",
            "Author/s :  Jun Liu, Amir Shahroudy, Dong Xu, G. Wang\n",
            "Venue :  European Conference on Computer Vision\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Generalized Multiview Analysis: A discriminative latent space\n",
            "Author/s :  Abhishek Sharma, Abhishek Kumar, Hal Daumé, D. Jacobs\n",
            "Venue :  2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2012\n",
            "Abstract :  This paper presents a general multi-view feature extraction approach that we call Generalized Multiview Analysis or GMA. GMA has all the desirable properties required for cross-view classification and retrieval: it is supervised, it allows generalization to unseen classes, it is multi-view and kernelizable, it affords an efficient eigenvalue based solution and is applicable to any domain. GMA exploits the fact that most popular supervised and unsupervised feature extraction techniques are the solution of a special form of a quadratic constrained quadratic program (QCQP), which can be solved efficiently as a generalized eigenvalue problem. GMA solves a joint, relaxed QCQP over different feature spaces to obtain a single (non)linear subspace. Intuitively, GMA is a supervised extension of Canonical Correlational Analysis (CCA), which is useful for cross-view classification and retrieval. The proposed approach is general and has the potential to replace CCA whenever classification or retrieval is the purpose and label information is available. We outperform previous approaches for textimage retrieval on Pascal and Wiki text-image data. We report state-of-the-art results for pose and lighting invariant face recognition on the MultiPIE face dataset, significantly outperforming other approaches.\n",
            "------------------------------------\n",
            "Title :  The Limits of Price Discrimination\n",
            "Author/s :  D. Bergemann, Benjamin A. Brooks, S. Morris\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  We analyze the welfare consequences of a monopolist having additional information about consumers' tastes, beyond the prior distribution; the additional information can be used to charge different prices to different segments of the market, i.e., carry out \"third degree price discrimination.\" We show that the segmentation and pricing induced by the additional information can achieve every combination of consumer and producer surplus such that: (i) consumer surplus is non-negative, (ii) producer surplus is at least as high as profits under the uniform monopoly price, and (iii) total surplus does not exceed the efficient gains from trade. As well as characterizing the welfare impact of price discrimination, we examine the limits of how prices and quantities can change under price discrimination. We also examine the limits of price discrimination in richer environments with quantity discrimination and limited ability to segment the market.\n",
            "------------------------------------\n",
            "Title :  Banks as Secret Keepers\n",
            "Author/s :  Tri Vi Dang, Gary B. Gorton, B. Holmström, G. Ordonez\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Banks are optimally opaque institutions. They produce debt for use as a transaction medium (bank money), which requires that information about the backing assets - loans - not be revealed, so that bank money does not fluctuate in value, reducing the efficiency of trade. This need for opacity conflicts with the production of information about investment projects, needed for allocative efficiency. Intermediaries exist to hide such information, so banks select portfolios of information-insensitive assets. For the economy as a whole, firms endogenously separate into bank finance and capital market/stock market finance depending on the cost of producing information about their projects.\n",
            "------------------------------------\n",
            "Title :  Functional correlates of the lateral and medial entorhinal cortex: objects, path integration and local–global reference frames\n",
            "Author/s :  J. Knierim, J. P. Neunuebel, Sachin S. Deshmukh\n",
            "Venue :  Philosophical Transactions of the Royal Society B: Biological Sciences\n",
            "year :  2014\n",
            "Abstract :  The hippocampus receives its major cortical input from the medial entorhinal cortex (MEC) and the lateral entorhinal cortex (LEC). It is commonly believed that the MEC provides spatial input to the hippocampus, whereas the LEC provides non-spatial input. We review new data which suggest that this simple dichotomy between ‘where’ versus ‘what’ needs revision. We propose a refinement of this model, which is more complex than the simple spatial–non-spatial dichotomy. MEC is proposed to be involved in path integration computations based on a global frame of reference, primarily using internally generated, self-motion cues and external input about environmental boundaries and scenes; it provides the hippocampus with a coordinate system that underlies the spatial context of an experience. LEC is proposed to process information about individual items and locations based on a local frame of reference, primarily using external sensory input; it provides the hippocampus with information about the content of an experience.\n",
            "------------------------------------\n",
            "Title :  Efficient Informative Sensing using Multiple Robots\n",
            "Author/s :  Amarjeet Singh, Andreas Krause, Carlos Guestrin, W. Kaiser\n",
            "Venue :  Journal of Artificial Intelligence Research\n",
            "year :  2014\n",
            "Abstract :  The need for efficient monitoring of spatio-temporal dynamics in large environmental applications, such as the water quality monitoring in rivers and lakes, motivates the use of robotic sensors in order to achieve sufficient spatial coverage. Typically, these robots have bounded resources, such as limited battery or limited amounts of time to obtain measurements. Thus, careful coordination of their paths is required in order to maximize the amount of information collected, while respecting the resource constraints. In this paper, we present an efficient approach for near-optimally solving the NP-hard optimization problem of planning such informative paths. In particular, we first develop eSIP (efficient Single-robot Informative Path planning), an approximation algorithm for optimizing the path of a single robot. Hereby, we use a Gaussian Process to model the underlying phenomenon, and use the mutual information between the visited locations and remainder of the space to quantify the amount of information collected. We prove that the mutual information collected using paths obtained by using eSIP is close to the information obtained by an optimal solution. We then provide a general technique, sequential allocation, which can be used to extend any single robot planning algorithm, such as eSIP, for the multi-robot problem. This procedure approximately generalizes any guarantees for the single-robot problem to the multi-robot case. We extensively evaluate the effectiveness of our approach on several experiments performed infield for two important environmental sensing applications, lake and river monitoring, and simulation experiments performed using several real world sensor network data sets.\n",
            "------------------------------------\n",
            "Title :  Quality of the Finnish Hospital Discharge Register: A systematic review\n",
            "Author/s :  R. Sund\n",
            "Venue :  Scandinavian Journal of Public Health\n",
            "year :  2012\n",
            "Abstract :  Aims: The Finnish Hospital Discharge Register (FHDR) is one of the oldest individual level hospital discharge registers and has been intensively used for research purposes. The aim of this study was to gather information concerning the quality of FHDR into one place in terms of a systematic review of validation studies that compare data to external information. Methods: Several reference databases were searched for validity articles published until January 2012. For each included study, focus of validation, register years examined, number of compared observations, external source(s) of data, summary of validation results, and conclusions concerning the validity of FHDR were extracted. Results: In total, 32 different studies comparing FHDR data to external information were identified. Most of the studies examined validity in the case of vascular disease, mental disorders or injuries. More than 95% of discharges could be identified from the register. Positive predictive value (PPV) for common diagnoses was between 75 and 99%. Conclusions: Completeness and accuracy in the register seem to vary from satisfactory to very good in the register as long as the recognised limitations are taking into account. Poor recording of subsidiary diagnoses and secondary operations and other rarely used items are the most obvious limitations in validity, but do not compromise the value of data in FHDR in being used in studies that are not feasible to conduct otherwise.\n",
            "------------------------------------\n",
            "Title :  Silent Listeners: The Evolution of Privacy and Disclosure on Facebook\n",
            "Author/s :  F. Stutzman, R. Gross, A. Acquisti\n",
            "Venue :  Journal of Privacy and Confidentiality\n",
            "year :  2013\n",
            "Abstract :  Over the past decade, social network sites have experienced dramatic growth in popularity, reaching most demographics and providing new opportunities for interaction and socialization. Through this growth, users have been challenged to manage novel privacy concerns and balance nuanced trade-offs between disclosing and withholding personal information. To date, however, no study has documented how privacy and disclosure evolved on social network sites over an extended period of time. In this manuscript we use profile data from a longitudinal panel of 5,076 Facebook users to understand how their privacy and disclosure behavior changed between 2005---the early days of the network---and 2011. Our analysis highlights three contrasting trends. First, over time Facebook users in our dataset exhibited increasingly privacy-seeking behavior, progressively decreasing the amount of personal data shared publicly with unconnected profiles in the same network. However, and second, changes implemented by Facebook near the end of the period of time under our observation arrested or in some cases inverted that trend. Third, the amount and scope of personal information that Facebook users revealed privately to other connected profiles actually increased over time---and because of that, so did disclosures to ``silent listeners'' on the network: Facebook itself, third-party apps, and (indirectly) advertisers. These findings highlight the tension between privacy choices as expressions of individual subjective preferences, and the role of the environment in shaping those choices.\n",
            "------------------------------------\n",
            "Title :  Immediate Psychological Responses and Associated Factors during the Initial Stage of the 2019 Coronavirus Disease (COVID-19) Epidemic among the General Population in China\n",
            "Author/s :  Cuiyan Wang, R. Pan, Xiaoyang Wan, Yilin Tan, Linkang Xu, C. Ho, R. Ho\n",
            "Venue :  International Journal of Environmental Research and Public Health\n",
            "year :  2020\n",
            "Abstract :  Background: The 2019 coronavirus disease (COVID-19) epidemic is a public health emergency of international concern and poses a challenge to psychological resilience. Research data are needed to develop evidence-driven strategies to reduce adverse psychological impacts and psychiatric symptoms during the epidemic. The aim of this study was to survey the general public in China to better understand their levels of psychological impact, anxiety, depression, and stress during the initial stage of the COVID-19 outbreak. The data will be used for future reference. Methods: From 31 January to 2 February 2020, we conducted an online survey using snowball sampling techniques. The online survey collected information on demographic data, physical symptoms in the past 14 days, contact history with COVID-19, knowledge and concerns about COVID-19, precautionary measures against COVID-19, and additional information required with respect to COVID-19. Psychological impact was assessed by the Impact of Event Scale-Revised (IES-R), and mental health status was assessed by the Depression, Anxiety and Stress Scale (DASS-21). Results: This study included 1210 respondents from 194 cities in China. In total, 53.8% of respondents rated the psychological impact of the outbreak as moderate or severe; 16.5% reported moderate to severe depressive symptoms; 28.8% reported moderate to severe anxiety symptoms; and 8.1% reported moderate to severe stress levels. Most respondents spent 20–24 h per day at home (84.7%); were worried about their family members contracting COVID-19 (75.2%); and were satisfied with the amount of health information available (75.1%). Female gender, student status, specific physical symptoms (e.g., myalgia, dizziness, coryza), and poor self-rated health status were significantly associated with a greater psychological impact of the outbreak and higher levels of stress, anxiety, and depression (p < 0.05). Specific up-to-date and accurate health information (e.g., treatment, local outbreak situation) and particular precautionary measures (e.g., hand hygiene, wearing a mask) were associated with a lower psychological impact of the outbreak and lower levels of stress, anxiety, and depression (p < 0.05). Conclusions: During the initial phase of the COVID-19 outbreak in China, more than half of the respondents rated the psychological impact as moderate-to-severe, and about one-third reported moderate-to-severe anxiety. Our findings identify factors associated with a lower level of psychological impact and better mental health status that can be used to formulate psychological interventions to improve the mental health of vulnerable groups during the COVID-19 epidemic.\n",
            "------------------------------------\n",
            "Title :  Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty.\n",
            "Author/s :  G. Baele, P. Lemey, T. Bedford, A. Rambaut, M. Suchard, A. Alekseyenko\n",
            "Venue :  Molecular biology and evolution\n",
            "year :  2012\n",
            "Abstract :  Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.\n",
            "------------------------------------\n",
            "Title :  Motivated numeracy and enlightened self-government\n",
            "Author/s :  D. Kahan, E. Peters, Erica Dawson, P. Slovic\n",
            "Venue :  Behavioural Public Policy\n",
            "year :  2017\n",
            "Abstract :  Abstract Why does public conflict over societal risks persist in the face of compelling and widely accessible scientific evidence? We conducted an experiment to probe two alternative answers: the ‘science comprehension thesis’ (SCT), which identifies defects in the public's knowledge and reasoning capacities as the source of such controversies; and the ‘identity-protective cognition thesis’ (ICT), which treats cultural conflict as disabling the faculties that members of the public use to make sense of decision-relevant science. In our experiment, we presented subjects with a difficult problem that turned on their ability to draw valid causal inferences from empirical data. As expected, subjects highest in numeracy – a measure of the ability and disposition to make use of quantitative information – did substantially better than less numerate ones when the data were presented as results from a study of a new skin rash treatment. Also as expected, subjects’ responses became politically polarized – and even less accurate – when the same data were presented as results from the study of a gun control ban. But contrary to the prediction of SCT, such polarization did not abate among subjects highest in numeracy; instead, it increased. This outcome supported ICT, which predicted that more numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlooks. We discuss the theoretical and practical significance of these findings.\n",
            "------------------------------------\n",
            "Title :  Preparing and conducting interviews to collect data.\n",
            "Author/s :  O. Doody, M. Noonan\n",
            "Venue :  Nurse Researcher\n",
            "year :  2013\n",
            "Abstract :  AIM\n",
            "To describe three styles of interviews and discuss issues regarding planning and conducting interviews.\n",
            "\n",
            "\n",
            "BACKGROUND\n",
            "Interviews are probably the approach most used to collect data in studies. They are particularly useful in uncovering the story behind a participant's experiences. Researchers can follow a line of questions to gain information about a topic, or further explore responses or findings. But the researcher needs to plan and decide the format of the interview before collecting data.\n",
            "\n",
            "\n",
            "REVIEW METHODS\n",
            "The authors included papers on structured, unstructured and semi-structured interviews published in a peer-reviewed joumrnal and in English.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Interviews are one of the most common metods of data collection in qualitative research. However they require the researcher to have a sound understanding of their use and appropriateness. The ability to conduct interviews is one that develops over time and to aid the researcher in developing their interview skills they should consult with other researchers, seeking comments and advice and, critically, to appraise audio recordings.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "This article aims to support students who are undertaking research modules as part of their academic studies, writing a research proposal or novice researchers who are about to use interviews as a means of data collection.\n",
            "\n",
            "\n",
            "IMPLICATIONS FOR RESEARCH/PRACTICE\n",
            "To conduct a successful interview, researchers need to develop their interview technique, choose the right method and carefully plan for all aspects of the process.\n",
            "------------------------------------\n",
            "Title :  Unique in the shopping mall: On the reidentifiability of credit card metadata\n",
            "Author/s :  Y. de Montjoye, Laura Radaelli, V. Singh, A. Pentland\n",
            "Venue :  Science\n",
            "year :  2015\n",
            "Abstract :  Large-scale data sets of human behavior have the potential to fundamentally transform the way we fight diseases, design cities, or perform research. Metadata, however, contain sensitive information. Understanding the privacy of these data sets is key to their broad use and, ultimately, their impact. We study 3 months of credit card records for 1.1 million people and show that four spatiotemporal points are enough to uniquely reidentify 90% of individuals. We show that knowing the price of a transaction increases the risk of reidentification by 22%, on average. Finally, we show that even data sets that provide coarse information at any or all of the dimensions provide little anonymity and that women are more reidentifiable than men in credit card metadata.\n",
            "------------------------------------\n",
            "Title :  OCNet: Object Context Network for Scene Parsing\n",
            "Author/s :  Yuhui Yuan, Jingdong Wang\n",
            "Venue :  ArXiv\n",
            "year :  2018\n",
            "Abstract :  In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. \n",
            "We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. \n",
            "To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff\n",
            "------------------------------------\n",
            "Title :  Big Data for All: Privacy and User Control in the Age of Analytics\n",
            "Author/s :  Omer Tene, Jules Polonetsky\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  We live in an age of “big data.” Data have become the raw material of production, a new source for immense economic and social value. Advances in data mining and analytics and the massive increase in computing power and data storage capacity have expanded by orders of magnitude the scope of information available for businesses and government. Data are now available for analysis in raw form, escaping the confines of structured databases and enhancing researchers’ abilities to identify correlations and conceive of new, unanticipated uses for existing information. In addition, the increasing number of people, devices, and sensors that are now connected by digital networks has revolutionized the ability to generate, communicate, share, and access data. Data creates enormous value for the world economy, driving innovation, productivity, efficiency and growth. At the same time, the “data deluge” presents privacy concerns which could stir a regulatory backlash dampening the data economy and stifling innovation. In order to craft a balance between beneficial uses of data and in individual privacy, policymakers must address some of the most fundamental concepts of privacy law, including the definition of “personally identifiable information”, the role of individual control, and the principles of data minimization and purpose limitation. This article emphasizes the importance of providing individuals with access to their data in usable format. This will let individuals share the wealth created by their information and incentivize developers to offer user-side features and applications harnessing the value of big data. Where individual access to data is impracticable, data are likely to be de-identified to an extent sufficient to diminish privacy concerns. In addition, organizations should be required to disclose their decisional criteria, since in a big data world it is often not the data but rather the inferences drawn from them that give cause for concern.\n",
            "------------------------------------\n",
            "Title :  Mobile health\n",
            "Author/s :  A. Monteiro\n",
            "Venue :  Radiologia Brasileira\n",
            "year :  2014\n",
            "Abstract :  Radiol Bras. 2014 Mar/Abr;47(2):IX mHealth, or mobile health is a term associated with the daily practice of medicine and public health supported by mobile devices such as cell phones and tablets. It is an universal trend of convergence of all patients’ information and images, data banks as source of information, academic social networks, specialized remote support systems and alike, as a support to the medical practice and to the teaching of medicine. Additionally there is the possibility of access by patients to their reports, tests results and schedules. However, other low-cost technologies are available, such as Raspberry Pi, a credit-card-sized computer developed in the United Kingdom by the Raspberry Pi Foundation. Such project was aimed at facilitating and encouraging the teaching of computer sciences for children in that country, and involving the study of computer techniques, methods and tools, processes automation and development of solutions based on the use of digital processing. The suc-\n",
            "------------------------------------\n",
            "Title :  What it will take to achieve the as-yet-unfulfilled promises of health information technology.\n",
            "Author/s :  A. Kellermann, Spencer S. Jones\n",
            "Venue :  Health Affairs\n",
            "year :  2013\n",
            "Abstract :  A team of RAND Corporation researchers projected in 2005 that rapid adoption of health information technology (IT) could save the United States more than $81 billion annually. Seven years later the empirical data on the technology's impact on health care efficiency and safety are mixed, and annual health care expenditures in the United States have grown by $800 billion. In our view, the disappointing performance of health IT to date can be largely attributed to several factors: sluggish adoption of health IT systems, coupled with the choice of systems that are neither interoperable nor easy to use; and the failure of health care providers and institutions to reengineer care processes to reap the full benefits of health IT. We believe that the original promise of health IT can be met if the systems are redesigned to address these flaws by creating more-standardized systems that are easier to use, are truly interoperable, and afford patients more access to and control over their health data. Providers must do their part by reengineering care processes to take full advantage of efficiencies offered by health IT, in the context of redesigned payment models that favor value over volume.\n",
            "------------------------------------\n",
            "Title :  Gene Ontology Consortium: going forward\n",
            "Author/s :  J. Blake, Kim M Rutherford, J. Chan, R. Kishore, P. Sternberg, K. V. Auken, Hans-Michael Müller, J. Done, Yanhong Li\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2014\n",
            "Abstract :  The Gene Ontology (GO; http://www.geneontology.org) is a community-based bioinformatics resource that supplies information about gene product function using ontologies to represent biological knowledge. Here we describe improvements and expansions to several branches of the ontology, as well as updates that have allowed us to more efficiently disseminate the GO and capture feedback from the research community. The Gene Ontology Consortium (GOC) has expanded areas of the ontology such as cilia-related terms, cell-cycle terms and multicellular organism processes. We have also implemented new tools for generating ontology terms based on a set of logical rules making use of templates, and we have made efforts to increase our use of logical definitions. The GOC has a new and improved web site summarizing new developments and documentation, serving as a portal to GO data. Users can perform GO enrichment analysis, and search the GO for terms, annotations to gene products, and associated metadata across multiple species using the all-new AmiGO 2 browser. We encourage and welcome the input of the research community in all biological areas in our continued effort to improve the Gene Ontology.\n",
            "------------------------------------\n",
            "Title :  How Technology Is Changing Work and Organizations\n",
            "Author/s :  W. Cascio, Ramiro Montealegre\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four ...\n",
            "------------------------------------\n",
            "Title :  Weighted-permutation entropy: a complexity measure for time series incorporating amplitude information.\n",
            "Author/s :  Bilal H. Fadlallah, Badong Chen, A. Keil, J. Príncipe\n",
            "Venue :  Physical review. E, Statistical, nonlinear, and soft matter physics\n",
            "year :  2013\n",
            "Abstract :  Permutation entropy (PE) has been recently suggested as a novel measure to characterize the complexity of nonlinear time series. In this paper, we propose a simple method to address some of PE's limitations, mainly its inability to differentiate between distinct patterns of a certain motif and the sensitivity of patterns close to the noise floor. The method relies on the fact that patterns may be too disparate in amplitudes and variances and proceeds by assigning weights for each extracted vector when computing the relative frequencies associated with every motif. Simulations were conducted over synthetic and real data for a weighting scheme inspired by the variance of each pattern. Results show better robustness and stability in the presence of higher levels of noise, in addition to a distinctive ability to extract complexity information from data with spiky features or having abrupt changes in magnitude.\n",
            "------------------------------------\n",
            "Title :  Age of Information: An Introduction and Survey\n",
            "Author/s :  R. Yates, Yin Sun, D. Brown, S. Kaul, E. Modiano, S. Ulukus\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2020\n",
            "Abstract :  We summarize recent contributions in the broad area of age of information (AoI). In particular, we describe the current state of the art in the design and optimization of low-latency cyberphysical systems and applications in which sources send time-stamped status updates to interested recipients. These applications desire status updates at the recipients to be as timely as possible; however, this is typically constrained by limited system resources. We describe AoI timeliness metrics and present general methods of AoI evaluation analysis that are applicable to a wide variety of sources and systems. Starting from elementary single-server queues, we apply these AoI methods to a range of increasingly complex systems, including energy harvesting sensors transmitting over noisy channels, parallel server systems, queueing networks, and various single-hop and multi-hop wireless networks. We also explore how update age is related to MMSE methods of sampling, estimation and control of stochastic processes. The paper concludes with a review of efforts to employ age optimization in cyberphysical applications.\n",
            "------------------------------------\n",
            "Title :  Teens, Health and Technology: A National Survey\n",
            "Author/s :  E. Wartella, V. Rideout, H. Montague, Leanne Beaudoin-Ryan, A. Lauricella\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  In the age of digital technology, as teens seem to be constantly connected online, via social media, and through mobile applications, it is no surprise that they increasingly turn to digital media to answer their health questions. This study is the first of its kind to survey a large, nationally-representative sample of teens to investigate how they use the newest digital technologies, including mobile apps, social networking sites, electronic gaming and wearable devices, to explore health topics. The survey covered the types of health topics teens most frequently search for, which technologies they are most likely to use and how they use them, and whether they report having changed their behaviors due to digital health information. In addition, this survey explores how the digital divide continues to impact adolescents. Results of this study indicate that teens are concerned about many health issues, ranging from fitness, sexual activity, drugs, hygiene as well as mental health and stress. As teens virtually always have a digital device at their fingertips, it is clear that public health interventions and informational campaigns must be tailored to reflect the ways that teens currently navigate digital health information and the health challenges that concern them most.\n",
            "------------------------------------\n",
            "Title :  Why did my car just do that? Explaining semi-autonomous driving actions to improve driver understanding, trust, and performance\n",
            "Author/s :  Jeamin Koo, Jungsuk Kwac, Wendy Ju, M. Steinert, L. Leifer, C. Nass\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Survey on Spectral–Spatial Classification Techniques Based on Attribute Profiles\n",
            "Author/s :  Pedram Ghamisi, M. Mura, J. Benediktsson\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2015\n",
            "Abstract :  Just over a decade has passed since the concept of morphological profile was defined for the analysis of remote sensing images. Since then, the morphological profile has largely proved to be a powerful tool able to model spatial information (e.g., contextual relations) of the image. However, due to the shortcomings of using the morphological profiles, many variants, extensions, and refinements of its definition have appeared stating that the morphological profile is still under continuous development. In this case, recently introduced theoretically sound attribute profiles (APs) can be considered as a generalization of the morphological profile, which is a powerful tool to model spatial information existing in the scene. Although the concept of the AP has been introduced in remote sensing only recently, an extensive literature on its use in different applications and on different types of data has appeared. To that end, the great amount of contributions in the literature that address the application of the AP to many tasks (e.g., classification, object detection, segmentation, change detection, etc.) and to different types of images (e.g., panchromatic, multispectral, and hyperspectral) proves how the AP is an effective and modern tool. The main objective of this survey paper is to recall the concept of the APs along with all its modifications and generalizations with special emphasis on remote sensing image classification and summarize the important aspects of its efficient utilization while also listing potential future works.\n",
            "------------------------------------\n",
            "Title :  PROV-O: The PROV Ontology\n",
            "Author/s :  Timothy Lebo, S. Sahoo, D. McGuinness, Khalid Belhajjame, J. Cheney, D. Corsar, D. Garijo, S. Soiland-Reyes, S. Zednik, Jun Zhao\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The PROV Ontology (PROV-O) expresses the PROV Data Model using the OWL2 Web Ontology Language. It provides a set of classes, properties, and restrictions that can be used to represent and interchange provenance information generated in different systems and under different contexts. It can also be specialized to create new classes and properties to model provenance information for different applications and domains.\n",
            "------------------------------------\n",
            "Title :  Digital Divide\n",
            "Author/s :  Peter A. Chow-White, Betty Ackah, Philippa R. Adams\n",
            "Venue :  Oxford Bibliographies Online Datasets\n",
            "year :  2018\n",
            "Abstract :  the Internet for older people by Peter Millward Focussing upon the elderly, this article utilises data discovered as researcher for Age Concern in Wigan (U.K.) and examines the feelings of older people toward the Internet. It explores the reasons why some clients and volunteers choose to use the Internet, whilst others do not, relating these perspectives to the organisations, alongside broader national (U.K.) and EU, commitments to reduce the digital divide. The article argues that for the elderly Internet usability is based upon more than availability of technology. Instead a lack of Web skills among the elderly leads to an opinion that information and communication technologies are for the young, leading to a long-term damage lack of interest in using the Internet.\n",
            "------------------------------------\n",
            "Title :  Infoglut: How Too Much Information Is Changing the Way We Think and Know\n",
            "Author/s :  M. Andrejevic\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Today, more mediated information is available to more people than at any other time in human history. New and revitalized sense-making strategies multiply in response to the challenges of \"cutting through the clutter\" of competing narratives and taming the avalanche of information. Data miners, \"sentiment analysts,\" and decision markets offer to help bodies of data \"speak for themselves\"making sense of their own patterns so we dont have to. Neuromarketers and body language experts promise to peer behind peoples words to see what their brains are really thinking and feeling. New forms of information processing promise to displace the need for expertise and even comprehensionat least for those with access to the data. Infoglut explores the connections between these wide-ranging sense-making strategies for an era of information overload and \"big data,\" and the new forms of control they enable. Andrejevic critiques the popular embrace of deconstructive debunkery, calling into question the post-truth, post-narrative, and post-comprehension politics it underwrites, and tracing a way beyond them.\n",
            "------------------------------------\n",
            "Title :  Positioning and Presenting Design Science Research for Maximum Impact\n",
            "Author/s :  S. Gregor, A. Hevner\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Design science research (DSR) has staked its rightful ground as an important and legitimate Information Systems (IS) research paradigm. We contend that DSR has yet to attain its full potential impact on the development and use of information systems due to gaps in the understanding and application of DSR concepts and methods. This essay aims to help researchers (1) appreciate the levels of artifact abstractions that may be DSR contributions, (2) identify appropriate ways of consuming and producing knowledge when they are preparing journal articles or other scholarly works, (3) understand and position the knowledge contributions of their research projects, and (4) structure a DSR article so that it emphasizes significant contributions to the knowledge base. Our focal contribution is the DSR knowledge contribution framework with two dimensions based on the existing state of knowledge in both the problem and solution domains for the research opportunity under study. In addition, we propose a DSR communication schema with similarities to more conventional publication patterns, but which substitutes the description of the DSR artifact in place of a traditional results section. We evaluate the DSR contribution framework and the DSR communication schema via examinations of DSR exemplar publications.\n",
            "------------------------------------\n",
            "Title :  Assessing the Probability of Bankruptcy\n",
            "Author/s :  Jarom Heaps\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Knowing whether or not a company is financial stable has always been a top concern for analysts and money managers. This paper compares the effectiveness of default prediction using two different types of measures: accounting and market based. Accounting measures have been the most popular even though, according to theory, a market based measure reflects all available information. Theory goes as far to say that accounting measures can add no incremental value to a market based measure. In my research I found that accounting based measures can be effective in their predictive power; the market-based measure (BSM) results were much more difficult to estimate within the limits of this research project.\n",
            "------------------------------------\n",
            "Title :  Advances in Quantum Cryptography\n",
            "Author/s :  S. Pirandola, U. Andersen, L. Banchi, M. Berta, D. Bunandar, R. Colbeck, D. Englund, T. Gehring, C. Lupo, C. Ottaviani, Jason L. Pereira, M. Razavi, J. S. Shaari, M. Tomamichel, Vladyslav C. Usenko, G. Vallone, P. Villoresi, P. Wallden\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  Quantum cryptography is arguably the fastest growing area in quantum information science. Novel theoretical protocols are designed on a regular basis, security proofs are constantly improving, and experiments are gradually moving from proof-of-principle lab demonstrations to in-field implementations and technological prototypes. In this review, we provide both a general introduction and a state of the art description of the recent advances in the field, both theoretically and experimentally. We start by reviewing protocols of quantum key distribution based on discrete variable systems. Next we consider aspects of device independence, satellite challenges, and high rate protocols based on continuous variable systems. We will then discuss the ultimate limits of point-to-point private communications and how quantum repeaters and networks may overcome these restrictions. Finally, we will discuss some aspects of quantum cryptography beyond standard quantum key distribution, including quantum data locking and quantum digital signatures.\n",
            "------------------------------------\n",
            "Title :  The Evolution of Social Commerce: The People, Management, Technology, and Information Dimensions\n",
            "Author/s :  Ching-Hsing Wang, Ping Zhang\n",
            "Venue :  Communications of the Association for Information Systems\n",
            "year :  2012\n",
            "Abstract :  Social commerce is a form of commerce mediated by social media and is converging both online and offline environments. As a relatively new phenomenon, social commerce has evolved quickly in practice, yet has gained little attention in the IS discipline. With its pervasiveness in businesses and people’s lives, social commerce presents ample research opportunities that can have both theoretical and practical significance and implications. This article aims to capture researchers’ attention by describing the characteristics of social commerce and its potential future directions. We trace the evolutionary patterns of social commerce chronologically, based on trade articles and academic publications from 2005 to 2011. A framework that combines people, management, technology, and information dimensions is used to provide a systematic analysis of social commerce development. Our examination shows that since 2005, the year the term social commerce was incepted, assumptions and understanding of people in social commerce move from a simple and general description of human social nature to a rich exploration with different angles from social psychology, social heuristics, national culture, and economic situations. On the management dimension, business strategies and models evolve from the short-tail to long-tail thinking, with invented concepts such as branded social networks/communities, niche social networks/communities, niche brands, co-creating, team-buying, and multichannel social networks. Technologically, IT platforms and capabilities for social commerce evolve from blogs, to social networking sites, to mediasharing sites, and to smartphones. While Facebook becomes a profit-generating platform, creating the notion of f-commerce, Google and Twitter become strong competitors with great potentials. Information in social commerce evolves from peer-generated, to community-generated (crowdsourcing), to consumer and marketer co-created, and to global crowdsourced. Our examination identifies various conceptualizations, terminologies, views, and perspectives about social commerce and its relation to other wellknown concepts such as e-commerce. In light of the evolution of social commerce, we provide possible future directions for research and practice.\n",
            "------------------------------------\n",
            "Title :  A Theoretical Framework for Conversational Search\n",
            "Author/s :  Filip Radlinski, Nick Craswell\n",
            "Venue :  Conference on Human Information Interaction and Retrieval\n",
            "year :  2017\n",
            "Abstract :  This paper studies conversational approaches to information retrieval, presenting a theory and model of information interaction in a chat setting. In particular, we consider the question of what properties would be desirable for a conversational information retrieval system so that the system can allow users to answer a variety of information needs in a natural and efficient manner. We study past work on human conversations, and propose a small set of properties that taken together could measure the extent to which a system is conversational. Following this, we present a theoretical model of a conversational system that implements the properties. We describe how this system could be implemented, making the action space of an conversational search agent explicit. Our analysis of this model shows that while theoretical, the model could be practically implemented to satisfy the desirable properties presented. In doing so, we show that the properties are also feasible.\n",
            "------------------------------------\n",
            "Title :  Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author/s :  G. Schryen\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  NEQR: a novel enhanced quantum representation of digital images\n",
            "Author/s :  Yi Zhang, Kai Lu, Yinghui Gao, Mo Wang\n",
            "Venue :  Quantum Information Processing\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Social Media, Knowledge Sharing, and Innovation: Toward a Theory of Communication Visibility\n",
            "Author/s :  P. Leonardi\n",
            "Venue :  Information systems research\n",
            "year :  2014\n",
            "Abstract :  This paper offers a theory of communication visibility based on a field study of the implementation of a new enterprise social networking site in a large financial services organization. The emerging theory suggests that once invisible communication occurring between others in the organization becomes visible for third parties, those third parties could improve their metaknowledge i.e., knowledge of who knows what and who knows whom. Communication visibility, in this case made possible by the enterprise social networking site, leads to enhanced awareness of who knows what and whom through two interrelated mechanisms: message transparency and network translucence. Seeing the contents of other's messages helps third-party observers make inferences about coworkers' knowledge. Tangentially, seeing the structure of coworkers' communication networks helps third-party observers make inferences about those with whom coworkers regularly communicate. The emerging theory further suggests that enhanced metaknowledge can lead to more innovative products and services and less knowledge duplication if employees learn to work in new ways. By learning vicariously rather than through experience, workers can more effectively recombine existing ideas into new ideas and avoid duplicating work. Moreover, they can begin to proactively aggregate information perceived daily rather than engaging in reactive search after confronting a problem. I discuss the important implications of this emerging theory of communication visibility for work in the knowledge economy.\n",
            "------------------------------------\n",
            "Title :  Addressing the Personalization-Privacy Paradox: An Empirical Assessment from a Field Experiment on Smartphone Users\n",
            "Author/s :  J. Sutanto, Elia Palme, Chuan-Hoo Tan, C. Phang\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Privacy has been an enduring concern associated with commercial information technology (IT) applications, in particular regarding the issue of personalization. IT-enabled personalization, while potentially making the user computing experience more gratifying, often relies heavily on the user's personal information to deliver individualized services, which raises the user's privacy concerns. We term the tension between personalization and privacy, which follows from marketers exploiting consumers' data to offer personalized product information, the personalization--privacy paradox. To better understand this paradox, we build on the theoretical lenses of uses and gratification theory and information boundary theory to conceptualize the extent to which privacy impacts the process and content gratifications derived from personalization, and how an IT solution can be designed to alleviate privacy concerns. \n",
            " \n",
            "Set in the context of personalized advertising applications for smartphones, we propose and prototype an IT solution, referred to as a personalized, privacy-safe application, that retains users' information locally on their smartphones while still providing them with personalized product messages. We validated this solution through a field experiment by benchmarking it against two more conventional applications: a base nonpersonalized application that broadcasts non-personalized product information to users, and a personalized, nonprivacy safe application that transmits user information to a central marketer's server. The results show that (compared to the non-personalized application), while personalized, privacy-safe or not increased application usage (reflecting process gratification), it was only when it was privacy-safe that users saved product messages (reflecting content gratification) more frequently. Follow-up surveys corroborated these nuanced findings and further revealed the users' psychological states, which explained our field experiment results. We found that saving advertisements for content gratification led to a perceived intrusion of information boundary that made users reluctant to do so. Overall our proposed IT solution, which delivers a personalized service but avoids transmitting users' personal information to third parties, reduces users' perceptions that their information boundaries are being intruded upon, thus mitigating the personalization--privacy paradox and increasing both process and content gratification.\n",
            "------------------------------------\n",
            "Title :  A survey on information visualization: recent advances and challenges\n",
            "Author/s :  Shixia Liu, Weiwei Cui, Yingcai Wu, Mengchen Liu\n",
            "Venue :  The Visual Computer\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A scoping review of rapid review methods\n",
            "Author/s :  A. Tricco, J. Antony, W. Zarin, L. Strifler, M. Ghassemi, J. Ivory, L. Perrier, B. Hutton, D. Moher, S. Straus\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Learning Discrete Representations via Information Maximizing Self-Augmented Training\n",
            "Author/s :  Weihua Hu, Takeru Miyato, Seiya Tokui, Eiichi Matsumoto, Masashi Sugiyama\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2017\n",
            "Abstract :  Learning discrete representations of data is a central machine learning task because of the compactness of the representations and ease of interpretation. The task includes clustering and hash learning as special cases. Deep neural networks are promising to be used because they can model the non-linearity of data and scale to large datasets. However, their model complexity is huge, and therefore, we need to carefully regularize the networks in order to learn useful representations that exhibit intended invariance for applications of interest. To this end, we propose a method called Information Maximizing Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose the invari-ance on discrete representations. More specifically, we encourage the predicted representations of augmented data points to be close to those of the original data points in an end-to-end fashion. At the same time, we maximize the information-theoretic dependency between data and their predicted discrete representations. Extensive experiments on benchmark datasets show that IMSAT produces state-of-the-art results for both clustering and unsupervised hash learning.\n",
            "------------------------------------\n",
            "Title :  Social Networks and the Diffusion of User-Generated Content: Evidence from YouTube\n",
            "Author/s :  Anjana Susarla, Jeong-ha Oh, Yong Tan\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This paper is motivated by the success of YouTube, which is attractive to content creators as well as corporations for its potential to rapidly disseminate digital content. The networked structure of interactions on YouTube and the tremendous variation in the success of videos posted online lends itself to an inquiry of the role of social influence. Using a unique data set of video information and user information collected from YouTube, we find that social interactions are influential not only in determining which videos become successful but also on the magnitude of that impact. We also find evidence for a number of mechanisms by which social influence is transmitted, such as (i) a preference for conformity and homophily and (ii) the role of social networks in guiding opinion formation and directing product search and discovery. Econometrically, the problem in identifying social influence is that individuals' choices depend in great part upon the choices of other individuals, referred to as the reflection problem. Another problem in identification is to distinguish between social contagion and user heterogeneity in the diffusion process. Our results are in sharp contrast to earlier models of diffusion, such as the Bass model, that do not distinguish between different social processes that are responsible for the process of diffusion. Our results are robust to potential self-selection according to user tastes, temporal heterogeneity and the reflection problem. Implications for researchers and managers are discussed.\n",
            "------------------------------------\n",
            "Title :  A social diffusion model of misinformation and disinformation for understanding human information behaviour\n",
            "Author/s :  N. Karlova, K. Fisher\n",
            "Venue :  Information Research\n",
            "year :  2013\n",
            "Abstract :  Introduction. People enjoy sharing information, even when they do not believe it. Thus, misinformation (inaccurate information) and disinformation (deceptive information) diffuse throughout social networks, as misinforming and disinforming are varieties of information behaviour. Social media have made such diffusion easier and faster. Many information behaviour models, however, suggest a normative model of information as true, accurate, complete, despite the ubiquity of misinformation and disinformation. Analysis. Misinformation and disinformation are defined and we show how they extend the concept of information through their informativeness. Table 1 summarizes the features of information, misinformation, and disinformation. Figure 1 illustrates the social diffusion process by which misinforming and disinforming function as types of information behaviour. Conclusion. Misinformation and disinformation are closely linked to information literacy, especially in terms of how they are diffused and shared and how people use both cues to credibility and cues to deception to make judgements. Misinformation and disinformation present both challenges and opportunities for individuals, businesses, and governments. Future work in immersive, 3D virtual worlds takes a naturalistic approach to understand the principal elements of cues to misinformation and disinformation.\n",
            "------------------------------------\n",
            "Title :  Information Dropout: Learning Optimal Representations Through Noisy Computation\n",
            "Author/s :  A. Achille, Stefano Soatto\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2016\n",
            "Abstract :  The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.\n",
            "------------------------------------\n",
            "Title :  What is big data? A consensual definition and a review of key research topics\n",
            "Author/s :  Andrea De Mauro, Marco Greco, M. Grimaldi\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Although Big Data is a trending buzzword in both academia and the industry, its meaning is still shrouded by much conceptual vagueness. The term is used to describe a wide range of concepts: from the technological ability to store, aggregate, and process data, to the cultural shift that is pervasively invading business and society, both drowning in information overload. The lack of a formal definition has led research to evolve into multiple and inconsistent paths. Furthermore, the existing ambiguity among researchers and practitioners undermines an efficient development of the subject. In this paper we have reviewed the existing literature on Big Data and analyzed its previous definitions in order to pursue two results: first, to provide a summary of the key research areas related to the phenomenon, identifying emerging trends and suggesting opportunities for future development; second, to provide a consensual definition for Big Data, by synthesizing common themes of existing works and patterns in previous definitions.\n",
            "------------------------------------\n",
            "Title :  CSI Phase Fingerprinting for Indoor Localization With a Deep Learning Approach\n",
            "Author/s :  Xuyu Wang, Lingjun Gao, S. Mao\n",
            "Venue :  IEEE Internet of Things Journal\n",
            "year :  2016\n",
            "Abstract :  With the increasing demand of location-based services, indoor localization based on fingerprinting has become an increasingly important technique due to its high accuracy and low hardware requirement. In this paper, we propose PhaseFi, a fingerprinting system for indoor localization with calibrated channel state information (CSI) phase information. In PhaseFi, the raw phase information is first extracted from the multiple antennas and multiple subcarriers of the IEEE 802.11n network interface card by accessing the modified device driver. Then a linear transformation is applied to extract the calibrated phase information, which we prove to have a bounded variance. For the offline stage, we design a deep network with three hidden layers to train the calibrated phase data, and employ the weights of the deep network to represent fingerprints. A greedy learning algorithm is incorporated to train the weights layer-by-layer to reduce computational complexity, where a subnetwork between two consecutive layers forms a restricted Boltzmann machine. In the online stage, we use a probabilistic method based on the radial basis function for online location estimation. The proposed PhaseFi scheme is implemented and validated with extensive experiments in two representation indoor environments. It is shown to outperform three benchmark schemes based on CSI or received signal strength in both scenarios.\n",
            "------------------------------------\n",
            "Title :  Influence of fake news in Twitter during the 2016 US presidential election\n",
            "Author/s :  A. Bovet, H. Makse\n",
            "Venue :  Nature Communications\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks\n",
            "Author/s :  Z. Cai, Zaobo He, Xin Guan, Yingshu Li\n",
            "Venue :  IEEE Transactions on Dependable and Secure Computing\n",
            "year :  2018\n",
            "Abstract :  Releasing social network data could seriously breach user privacy. User profile and friendship relations are inherently private. Unfortunately, sensitive information may be predicted out of released data through data mining techniques. Therefore, sanitizing network data prior to release is necessary. In this paper, we explore how to launch an inference attack exploiting social networks with a mixture of non-sensitive attributes and social relationships. We map this issue to a collective classification problem and propose a collective inference model. In our model, an attacker utilizes user profile and social relationships in a collective manner to predict sensitive information of related victims in a released social network dataset. To protect against such attacks, we propose a data sanitization method collectively manipulating user profile and friendship relations. Besides sanitizing friendship relations, the proposed method can take advantages of various data-manipulating methods. We show that we can easily reduce adversary’s prediction accuracy on sensitive information, while resulting in less accuracy decrease on non-sensitive information towards three social network datasets. This is the first work to employ collective methods involving various data-manipulating methods and social relationships to protect against inference attacks in social networks.\n",
            "------------------------------------\n",
            "Title :  Gated-SCNN: Gated Shape CNNs for Semantic Segmentation\n",
            "Author/s :  Towaki Takikawa, David Acuna, V. Jampani, S. Fidler\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2019\n",
            "Abstract :  Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.\n",
            "------------------------------------\n",
            "Title :  Adoption of Electronic Health Record Systems among U . S . Non-Federal Acute Care Hospitals : 2008-2015\n",
            "Author/s :  J. Henry, Yuriy Pylypchuk, Talisha Searcy, Vaishali Patel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The adoption and meaningful use of electronic health records (EHRs) are key objectives of the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the Federal Health IT Strategic Plan (1). This brief uses data from the American Hospital Association to describe trends in adoption of EHR technology among non-federal acute care hospitals from 2008 to 2015. It tracks the adoption of Basic EHR systems and the possession of certified EHR technology. Unless otherwise stated, this brief refers to Basic EHR adoption with clinical notes, a measure which represents a minimum use of 10 core functionalities determined to be essential to an EHR system (see Table A1)(2).\n",
            "------------------------------------\n",
            "Title :  Research Note - The Impact of External Word-of-Mouth Sources on Retailer Sales of High-Involvement Products\n",
            "Author/s :  B. Gu, Jaehong Park, Prabhudev Konana\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  Online word-of-mouth (WOM) such as consumer opinions, user experiences, and product reviews has become a major information source in consumer purchase decisions. Prior research on online WOM effect has focused mostly on low-involvement products such as books or CDs. For these products, retailer-hosted (internal) WOM is shown to influence sales overwhelmingly. Numerous surveys, however, suggest consumers often conduct pre-purchase searches for high-involvement products (e.g., digital cameras) and visit external WOM websites during the search process. In this study, we analyze the relative impact of external and internal WOMs on retailer sales for high-involvement products using a panel of sales and WOM data for 148 digital cameras from Amazon.com and three external WOM websites (Cnet, DpReview, and Epinions) over a four-month period. The results suggest that a retailer's internal WOM has a limited influence on its sales of high-involvement products, while external WOM sources have a significant impact on the retailer's sales. The findings imply that external WOM sources play an important role in the information search process.\n",
            "------------------------------------\n",
            "Title :  A Survey: Digital Image Watermarking Techniques\n",
            "Author/s :  P. Parashar, R. Singh\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Multimedia security is extremely significant concern for the internet technology because of the ease of the duplication, distribution and manipulation of the multimedia data. The digital watermarking is a field of information hiding which hide the crucial information in the original data for protection illegal duplication and distribution of multimedia data. This paper presents a survey on the existing digital image watermarking techniques. The results of various digital image watermarking techniques have been compared on the basis of outputs. In the digital watermarking the secret information are implanted into the original data for protecting the ownership rights of the multimedia data. The image watermarking techniques may divide on the basis of domain like spatial domain or transform domain or on the basis of wavelets. The spatial domain techniques directly work on the pixels and the frequency domain works on the transform coefficients of the image. This survey elaborates the most important methods of spatial domain and transform domain and focuses the merits and demerits of these techniques.\n",
            "------------------------------------\n",
            "Title :  Generalized Composite Kernel Framework for Hyperspectral Image Classification\n",
            "Author/s :  Jun Li, P. Marpu, A. Plaza, J. Bioucas-Dias, J. Benediktsson\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2013\n",
            "Abstract :  This paper presents a new framework for the development of generalized composite kernel machines for hyperspectral image classification. We construct a new family of generalized composite kernels which exhibit great flexibility when combining the spectral and the spatial information contained in the hyperspectral data, without any weight parameters. The classifier adopted in this work is the multinomial logistic regression, and the spatial information is modeled from extended multiattribute profiles. In order to illustrate the good performance of the proposed framework, support vector machines are also used for evaluation purposes. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible/Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the proposed framework leads to state-of-the-art classification performance in complex analysis scenarios.\n",
            "------------------------------------\n",
            "Title :  Convolutional Matrix Factorization for Document Context-Aware Recommendation\n",
            "Author/s :  Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, Hwanjo Yu\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2016\n",
            "Abstract :  Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.\n",
            "------------------------------------\n",
            "Title :  Dynamic consent: a patient interface for twenty-first century research networks\n",
            "Author/s :  J. Kaye, E. Whitley, David Lund, M. Morrison, H. Teare, Karen Melham\n",
            "Venue :  European Journal of Human Genetics\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Enhancing patient safety and quality of care by improving the usability of electronic health record systems: recommendations from AMIA.\n",
            "Author/s :  Blackford Middleton, M. Bloomrosen, Mark A. Dente, Bill Hashmat, R. Koppel, J. Overhage, T. Payne, S. Rosenbloom, Charlotte A. Weaver, Jiajie Zhang\n",
            "Venue :  JAMIA Journal of the American Medical Informatics Association\n",
            "year :  2013\n",
            "Abstract :  In response to mounting evidence that use of electronic medical record systems may cause unintended consequences, and even patient harm, the AMIA Board of Directors convened a Task Force on Usability to examine evidence from the literature and make recommendations. This task force was composed of representatives from both academic settings and vendors of electronic health record (EHR) systems. After a careful review of the literature and of vendor experiences with EHR design and implementation, the task force developed 10 recommendations in four areas: (1) human factors health information technology (IT) research, (2) health IT policy, (3) industry recommendations, and (4) recommendations for the clinician end-user of EHR software. These AMIA recommendations are intended to stimulate informed debate, provide a plan to increase understanding of the impact of usability on the effective use of health IT, and lead to safer and higher quality care with the adoption of useful and usable EHR systems.\n",
            "------------------------------------\n",
            "Title :  The role of e-learning, the advantages and disadvantages of its adoption in Higher Education.\n",
            "Author/s :  Valentina Arkorful, N. Abaidoo\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study investigates the effectiveness of using e-learning in teaching in tertiary institutions. In institutions of higher education, the issue of utilizing modern information and communication technologies for teaching and learning is very important. This study reviews literature and gives a scholarly background to the study by reviewing some contributions made by various researchers and institutions on the concept of e-learning, particularly its usage in teaching and learning in higher educational institutions. It unveils some views that people and institutions have shared globally on the adoption and integration of e-learning technologies in education through surveys and other observations. It looks at the meaning or definitions of e-learning as given by different researchers and the role that e-learning plays in higher educational institutions in relation to teaching and learning processes, and the advantages and disadvantages of its adoption and implemention.\n",
            "------------------------------------\n",
            "Title :  Geographical tracking and mapping of coronavirus disease COVID-19/severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) epidemic and associated events around the world: how 21st century GIS technologies are supporting the global fight against outbreaks and epidemics\n",
            "Author/s :  M. N. Kamel Boulos, E. Geraghty\n",
            "Venue :  International Journal of Health Geographics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  News Recommendations from Social Media Opinion Leaders: Effects on Media Trust and Information Seeking\n",
            "Author/s :  J. Turcotte, Chance York, Jacob Irving, Rosanne M. Scholl, Raymond J. Pingree\n",
            "Venue :  J. Comput. Mediat. Commun.\n",
            "year :  2015\n",
            "Abstract :  Polls show a strong decline in public trust of traditional news outlets; however, social media offers new avenues for receiving news content. This experiment used the Facebook API to manipulate whether a news story appeared to have been posted on Facebook by one of the respondent's real-life Facebook friends. Results show that social media recommendations improve levels of media trust, and also make people want to follow more news from that particular media outlet in the future. Moreover, these effects are amplified when the real-life friend sharing the story on social media is perceived as an opinion leader. Implications for democracy and the news business are discussed.\n",
            "------------------------------------\n",
            "Title :  Multimodal Data Fusion: An Overview of Methods, Challenges, and Prospects\n",
            "Author/s :  D. Lahat, T. Adalı, C. Jutten\n",
            "Venue :  Proceedings of the IEEE\n",
            "year :  2015\n",
            "Abstract :  In various disciplines, information about the same phenomenon can be acquired from different types of detectors, at different conditions, in multiple experiments or subjects, among others. We use the term “modality” for each such acquisition framework. Due to the rich characteristics of natural phenomena, it is rare that a single modality provides complete knowledge of the phenomenon of interest. The increasing availability of several modalities reporting on the same system introduces new degrees of freedom, which raise questions beyond those related to exploiting each modality separately. As we argue, many of these questions, or “challenges,” are common to multiple domains. This paper deals with two key issues: “why we need data fusion” and “how we perform it.” The first issue is motivated by numerous examples in science and technology, followed by a mathematical framework that showcases some of the benefits that data fusion provides. In order to address the second issue, “diversity” is introduced as a key concept, and a number of data-driven solutions based on matrix and tensor decompositions are discussed, emphasizing how they account for diversity across the data sets. The aim of this paper is to provide the reader, regardless of his or her community of origin, with a taste of the vastness of the field, the prospects, and the opportunities that it holds.\n",
            "------------------------------------\n",
            "Title :  STITCH 5: augmenting protein–chemical interaction networks with tissue and affinity data\n",
            "Author/s :  Damian Szklarczyk, Alberto Santos, C. V. Mering, L. Jensen, P. Bork, Michael Kuhn\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  Interactions between proteins and small molecules are an integral part of biological processes in living organisms. Information on these interactions is dispersed over many databases, texts and prediction methods, which makes it difficult to get a comprehensive overview of the available evidence. To address this, we have developed STITCH (‘Search Tool for Interacting Chemicals’) that integrates these disparate data sources for 430 000 chemicals into a single, easy-to-use resource. In addition to the increased scope of the database, we have implemented a new network view that gives the user the ability to view binding affinities of chemicals in the interaction network. This enables the user to get a quick overview of the potential effects of the chemical on its interaction partners. For each organism, STITCH provides a global network; however, not all proteins have the same pattern of spatial expression. Therefore, only a certain subset of interactions can occur simultaneously. In the new, fifth release of STITCH, we have implemented functionality to filter out the proteins and chemicals not associated with a given tissue. The STITCH database can be downloaded in full, accessed programmatically via an extensive API, or searched via a redesigned web interface at http://stitch.embl.de.\n",
            "------------------------------------\n",
            "Title :  Sleep-dependent memory triage: evolving generalization through selective processing\n",
            "Author/s :  R. Stickgold, M. Walker\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Bayesian Persuasion and Information Design\n",
            "Author/s :  Emir Kamenica\n",
            "Venue :  Annual Review of Economics\n",
            "year :  2019\n",
            "Abstract :  A school may improve its students’ job outcomes if it issues only coarse grades. Google can reduce congestion on roads by giving drivers noisy information about the state of traffic. A social planner might raise everyone's welfare by providing only partial information about solvency of banks. All of this can happen even when everyone is fully rational and understands the data-generating process. Each of these examples raises questions of what is the (socially or privately) optimal information that should be revealed. In this article, I review the literature that answers such questions.\n",
            "------------------------------------\n",
            "Title :  COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author/s :  Cristina M. Pulido, Beatriz Villarejo-Carballido, Gisela Redondo-Sama, Aitor Gómez\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title :  The Filter Bubble\n",
            "Author/s :  Eli Pariser\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  : Introduced by tech entrepreneur and activist Eli Pariser in 2011, the ‘filter bubble’ is a persistent concept which suggests that search engines and social media, together with their recommendation and personalisation algorithms, are centrally culpable for the societal and ideological polarisation experienced in many countries: we no longer encounter a balanced and healthy information diet, but only see information that targets our established interests and reinforces our existing worldviews. Filter bubbles are seen as critical enablers of Brexit, Trump, Bolsonaro, and other populist political phenomena, and search and social media companies have been criticised for failing to prevent their development. Yet, there is scant empirical evidence for their existence, or for the related concept of ‘echo chambers’: indeed, search and social media users generally appear to encounter a highly centrist media diet that is, if anything, more diverse than that of non-users. However, the persistent use of these concepts in mainstream media and political debates has now created its own discursive reality that continues to impact materially on societal institutions, media and communication platforms, and ordinary users themselves. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to redirect scholarly attention from far more critical areas of enquiry.\n",
            "------------------------------------\n",
            "Title :  Multimodal Data Fusion: An Overview of Methods, Challenges, and Prospects\n",
            "Author/s :  D. Lahat, T. Adalı, C. Jutten\n",
            "Venue :  Proceedings of the IEEE\n",
            "year :  2015\n",
            "Abstract :  In various disciplines, information about the same phenomenon can be acquired from different types of detectors, at different conditions, in multiple experiments or subjects, among others. We use the term “modality” for each such acquisition framework. Due to the rich characteristics of natural phenomena, it is rare that a single modality provides complete knowledge of the phenomenon of interest. The increasing availability of several modalities reporting on the same system introduces new degrees of freedom, which raise questions beyond those related to exploiting each modality separately. As we argue, many of these questions, or “challenges,” are common to multiple domains. This paper deals with two key issues: “why we need data fusion” and “how we perform it.” The first issue is motivated by numerous examples in science and technology, followed by a mathematical framework that showcases some of the benefits that data fusion provides. In order to address the second issue, “diversity” is introduced as a key concept, and a number of data-driven solutions based on matrix and tensor decompositions are discussed, emphasizing how they account for diversity across the data sets. The aim of this paper is to provide the reader, regardless of his or her community of origin, with a taste of the vastness of the field, the prospects, and the opportunities that it holds.\n",
            "------------------------------------\n",
            "Title :  A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\n",
            "Author/s :  A. Casali, O. Gosseries, M. Rosanova, M. Boly, S. Sarasso, K. Casali, S. Casarotto, M. Bruno, Steven Laureys, G. Tononi, M. Massimini\n",
            "Venue :  Science Translational Medicine\n",
            "year :  2013\n",
            "Abstract :  A theory-derived index of consciousness, which quantifies the complexity of the brain’s response to a stimulus, measures the level of consciousness in awake, sleeping, anesthetized, and brain-damaged subjects. Quantifying the Unquantifiable Manipulation of consciousness is an everyday medical trick—think anesthesia—but physicians have only the crudest of tools to detect when a person is not aware. The usual question or physical stimulus does not always provide reliable reactions, and a more precise index is needed to avoid, for example, the conclusion that people who have locked-in syndrome (in which they are aware but cannot respond) are unconscious. Here, Casali et al. have extended their previous work on electrical correlates of consciousness to define an electroencephalographic-derived index of human consciousness [the perturbational complexity index (PCI)] that reflects the information content of the brain’s response to a magnetic stimulus. The PCI could allow tracking of consciousness in individual patients. The authors used data already collected from previous experiments, in which they had stimulated people’s brains with transcranial magnetic stimulation. By calculating the likely brain regional sources of the signals and then comparing the unique information in each, the authors derived PCI values. The values ranged from 0.44 to 0.67 in 32 awake healthy people, but fell to 0.18 to 0.28 during nonrapid eye movement (NREM) sleep. Then, to see whether a completely different way of inducing unconsciousness had the same effect on PCI, the authors assessed data from patients given various amounts of the anesthetics midazolam, xenon, and propofol. These agents too caused low “unconscious” values for the PCI: midazolam deep sedation, 0.23 to 0.31; propofol, 0.13 to 0.30; and xenon, 0.12 to 0.31. However, what about patients who suffer brain damage and who exhibit various levels of consciousness by conventional assessment methods? In these people, consciousness varies widely, as does the underlying damage from stroke or trauma. Here, too, the authors found promising results in those who had emerged from coma but were in a vegetative state or minimally conscious state, or exhibited locked-in syndrome. The PCI values from these patients clearly reflected the state of their consciousness, with the six patients in a vegetative state clearly unconscious (0.19 to 0.31), the two with locked-in syndrome clearly aware (0.51 to 0.62), and those in a minimally conscious state showing intermediate values (0.32 to 0.49). The validity of PCI for clinical application will need to be assessed in prospective trials, but it has the advantage of being derived from a simple noninvasive measurement. The new index reported by Casali et al. appears to be a robust measure that distinguishes conscious from unconscious states well enough to be used on an individual basis, a prerequisite for deployment in the clinic. One challenging aspect of the clinical assessment of brain-injured, unresponsive patients is the lack of an objective measure of consciousness that is independent of the subject’s ability to interact with the external environment. Theoretical considerations suggest that consciousness depends on the brain’s ability to support complex activity patterns that are, at once, distributed among interacting cortical areas (integrated) and differentiated in space and time (information-rich). We introduce and test a theory-driven index of the level of consciousness called the perturbational complexity index (PCI). PCI is calculated by (i) perturbing the cortex with transcranial magnetic stimulation (TMS) to engage distributed interactions in the brain (integration) and (ii) compressing the spatiotemporal pattern of these electrocortical responses to measure their algorithmic complexity (information). We test PCI on a large data set of TMS-evoked potentials recorded in healthy subjects during wakefulness, dreaming, nonrapid eye movement sleep, and different levels of sedation induced by anesthetic agents (midazolam, xenon, and propofol), as well as in patients who had emerged from coma (vegetative state, minimally conscious state, and locked-in syndrome). PCI reliably discriminated the level of consciousness in single individuals during wakefulness, sleep, and anesthesia, as well as in patients who had emerged from coma and recovered a minimal level of consciousness. PCI can potentially be used for objective determination of the level of consciousness at the bedside.\n",
            "------------------------------------\n",
            "Title :  Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment\n",
            "Author/s :  K. Huckvale, José Tomás Prieto, M. Tilney, Pierre Benghozi, J. Car\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Does Corruption Information Inspire the Fight or Quash the Hope? A Field Experiment in Mexico on Voter Turnout, Choice, and Party Identification\n",
            "Author/s :  Alberto Chong, A. De La O, D. Karlan, Léonard Wantchekon\n",
            "Venue :  Journal of Politics\n",
            "year :  2014\n",
            "Abstract :  Retrospective voting models assume that offering more information to voters about their incumbents’ performance strengthens electoral accountability. However, it is unclear whether incumbent corruption information translates into higher political participation and increased support for challengers. We provide experimental evidence that such information not only decreases incumbent party support in local elections in Mexico, but also decreases voter turnout and support for the challenger party, as well as erodes partisan attachments. While information clearly is necessary to improve accountability, corruption information is not sufficient because voters may respond to it by withdrawing from the political process. We conclude with a discussion of the implications of our findings for studies of voting behavior.\n",
            "------------------------------------\n",
            "Title :  NEQR: a novel enhanced quantum representation of digital images\n",
            "Author/s :  Yi Zhang, Kai Lu, Yinghui Gao, Mo Wang\n",
            "Venue :  Quantum Information Processing\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Framework for Managing the COVID-19 Infodemic: Methods and Results of an Online, Crowdsourced WHO Technical Consultation\n",
            "Author/s :  V. Tangcharoensathien, N. Calleja, Tim Nguyen, T. Purnat, Marcelo D'agostino, Sebastian Garcia-Saiso, M. Landry, A. Rashidian, Clayton Hamilton, Abdelhalim AbdAllah, I. Ghiga, Alexandra Hill, D. Hougendobler, J. van Andel, M. Nunn, Ian Brooks, P. Sacco, M. De Domenico, Philip Mai, A. Gruzd, Alexandre Alaphilippe, S. Briand\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background An infodemic is an overabundance of information—some accurate and some not—that occurs during an epidemic. In a similar manner to an epidemic, it spreads between humans via digital and physical information systems. It makes it hard for people to find trustworthy sources and reliable guidance when they need it. Objective A World Health Organization (WHO) technical consultation on responding to the infodemic related to the coronavirus disease (COVID-19) pandemic was held, entirely online, to crowdsource suggested actions for a framework for infodemic management. Methods A group of policy makers, public health professionals, researchers, students, and other concerned stakeholders was joined by representatives of the media, social media platforms, various private sector organizations, and civil society to suggest and discuss actions for all parts of society, and multiple related professional and scientific disciplines, methods, and technologies. A total of 594 ideas for actions were crowdsourced online during the discussions and consolidated into suggestions for an infodemic management framework. Results The analysis team distilled the suggestions into a set of 50 proposed actions for a framework for managing infodemics in health emergencies. The consultation revealed six policy implications to consider. First, interventions and messages must be based on science and evidence, and must reach citizens and enable them to make informed decisions on how to protect themselves and their communities in a health emergency. Second, knowledge should be translated into actionable behavior-change messages, presented in ways that are understood by and accessible to all individuals in all parts of all societies. Third, governments should reach out to key communities to ensure their concerns and information needs are understood, tailoring advice and messages to address the audiences they represent. Fourth, to strengthen the analysis and amplification of information impact, strategic partnerships should be formed across all sectors, including but not limited to the social media and technology sectors, academia, and civil society. Fifth, health authorities should ensure that these actions are informed by reliable information that helps them understand the circulating narratives and changes in the flow of information, questions, and misinformation in communities. Sixth, following experiences to date in responding to the COVID-19 infodemic and the lessons from other disease outbreaks, infodemic management approaches should be further developed to support preparedness and response, and to inform risk mitigation, and be enhanced through data science and sociobehavioral and other research. Conclusions The first version of this framework proposes five action areas in which WHO Member States and actors within society can apply, according to their mandate, an infodemic management approach adapted to national contexts and practices. Responses to the COVID-19 pandemic and the related infodemic require swift, regular, systematic, and coordinated action from multiple sectors of society and government. It remains crucial that we promote trusted information and fight misinformation, thereby helping save lives.\n",
            "------------------------------------\n",
            "Title :  Thalamus plays a central role in ongoing cortical functioning\n",
            "Author/s :  S. Sherman\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Semantic trajectories modeling and analysis\n",
            "Author/s :  C. Parent, S. Spaccapietra, C. Renso, G. Andrienko, N. Andrienko, V. Bogorny, M. Damiani, A. Gkoulalas-Divanis, J. Macêdo, N. Pelekis, Y. Theodoridis, Zhixian Yan\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Focus on movement data has increased as a consequence of the larger availability of such data due to current GPS, GSM, RFID, and sensors techniques. In parallel, interest in movement has shifted from raw movement data analysis to more application-oriented ways of analyzing segments of movement suitable for the specific purposes of the application. This trend has promoted semantically rich trajectories, rather than raw movement, as the core object of interest in mobility studies. This survey provides the definitions of the basic concepts about mobility data, an analysis of the issues in mobility data management, and a survey of the approaches and techniques for: (i) constructing trajectories from movement tracks, (ii) enriching trajectories with semantic information to enable the desired interpretations of movements, and (iii) using data mining to analyze semantic trajectories and extract knowledge about their characteristics, in particular the behavioral patterns of the moving objects. Last but not least, the article surveys the new privacy issues that arise due to the semantic aspects of trajectories.\n",
            "------------------------------------\n",
            "Title :  DroidScope: Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android Malware Analysis\n",
            "Author/s :  Lok K. Yan, Heng Yin\n",
            "Venue :  USENIX Security Symposium\n",
            "year :  2012\n",
            "Abstract :  The prevalence of mobile platforms, the large market share of Android, plus the openness of the Android Market makes it a hot target for malware attacks. Once a malware sample has been identified, it is critical to quickly reveal its malicious intent and inner workings. In this paper we present DroidScope, an Android analysis platform that continues the tradition of virtualization-based malware analysis. Unlike current desktop malware analysis platforms, DroidScope reconstructs both the OS-level and Java-level semantics simultaneously and seamlessly. To facilitate custom analysis, DroidScope exports three tiered APIs that mirror the three levels of an Android device: hardware, OS and Dalvik Virtual Machine. On top of DroidScope, we further developed several analysis tools to collect detailed native and Dalvik instruction traces, profile API-level activity, and track information leakage through both the Java and native components using taint analysis. These tools have proven to be effective in analyzing real world malware samples and incur reasonably low performance overheads.\n",
            "------------------------------------\n",
            "Title :  The Information . A History , a Theory , a Flood\n",
            "Author/s :  J. Rivera\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The book is full of interesting references to the history of information theory, but unfortunately lacks the theoretical rigor of an academic account of the topic. The reader can find really inspiring stories and draw out powerful insights about what information means, but also finds awkward reflections about its essence and about how the concept should be understood. On the positive side, we can mention the relevance of redundancy in language, a point that is wonderfully explained in the description of the drums' communication language, as well as in the process of breaking cryptographic codes. On the negative side, we should mention the Epilogue and its loose reflection around the meaning of meaning, that ultimately confuses information with knowledge, and thus presents networks and “the internet” as a social agent that “is changing the world”.\n",
            "------------------------------------\n",
            "Title :  What Does BERT Look at? An Analysis of BERT’s Attention\n",
            "Author/s :  Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning\n",
            "Venue :  BlackboxNLP@ACL\n",
            "year :  2019\n",
            "Abstract :  Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\n",
            "------------------------------------\n",
            "Title :  The Danish Medical Birth Register\n",
            "Author/s :  M. Bliddal, A. Broe, A. Pottegård, J. Olsen, J. Langhoff‐Roos\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers\n",
            "Author/s :  G. Ateniese, L. Mancini, A. Spognardi, Antonio Villani, Domenico Vitali, G. Felici\n",
            "Venue :  Int. J. Secur. Networks\n",
            "year :  2013\n",
            "Abstract :  Machine Learning (ML) algorithms are used to train computers to perform a variety of complex tasks and improve with experience. Computers learn how to recognize patterns, make unintended decisions, or react to a dynamic environment. Certain trained machines may be more effective than others because they are based on more suitable ML algorithms or because they were trained through superior training sets. Although ML algorithms are known and publicly released, training sets may not be reasonably ascertainable and, indeed, may be guarded as trade secrets. While much research has been performed about the privacy of the elements of training sets, in this paper we focus our attention on ML classifiers and on the statistical information that can be unconsciously or maliciously revealed from them. We show that it is possible to infer unexpected but useful information from ML classifiers. In particular, we build a novel meta-classifier and train it to hack other classifiers, obtaining meaningful information about their training sets. This kind of information leakage can be exploited, for example, by a vendor to build more effective classifiers or to simply acquire trade secrets from a competitor's apparatus, potentially violating its intellectual property rights.\n",
            "------------------------------------\n",
            "Title :  Exploring the Space of Topic Coherence Measures\n",
            "Author/s :  Michael Röder, A. Both, A. Hinneburg\n",
            "Venue :  Web Search and Data Mining\n",
            "year :  2015\n",
            "Abstract :  Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.\n",
            "------------------------------------\n",
            "Title :  Unifying distillation and privileged information\n",
            "Author/s :  David Lopez-Paz, L. Bottou, B. Schölkopf, V. Vapnik\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2015\n",
            "Abstract :  Distillation (Hinton et al., 2015) and privileged information (Vapnik & Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.\n",
            "------------------------------------\n",
            "Title :  Advances in optical security systems\n",
            "Author/s :  Wen Chen, B. Javidi, Xudong Chen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Information security with optical means, such as double random phase encoding, has been investigated by various researchers. It has been demonstrated that optical technology possesses several unique characteristics for securing information compared with its electronic counterpart, such as many degrees of freedom. In this paper, we present a review of optical technologies for information security. Optical security systems are reviewed, and theoretical principles and implementation examples are presented to illustrate each optical security system. In addition, advantages and potential weaknesses of each optical security system are analyzed and discussed. It is expected that this review not only will provide a clear picture about current developments in optical security systems but also may shed some light on future developments.\n",
            "------------------------------------\n",
            "Title :  Literature review of Industry 4.0 and related technologies\n",
            "Author/s :  Ercan Öztemel, S. Gursev\n",
            "Venue :  Journal of Intelligent Manufacturing\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Big Data for All: Privacy and User Control in the Age of Analytics\n",
            "Author/s :  Omer Tene, Jules Polonetsky\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  We live in an age of “big data.” Data have become the raw material of production, a new source for immense economic and social value. Advances in data mining and analytics and the massive increase in computing power and data storage capacity have expanded by orders of magnitude the scope of information available for businesses and government. Data are now available for analysis in raw form, escaping the confines of structured databases and enhancing researchers’ abilities to identify correlations and conceive of new, unanticipated uses for existing information. In addition, the increasing number of people, devices, and sensors that are now connected by digital networks has revolutionized the ability to generate, communicate, share, and access data. Data creates enormous value for the world economy, driving innovation, productivity, efficiency and growth. At the same time, the “data deluge” presents privacy concerns which could stir a regulatory backlash dampening the data economy and stifling innovation. In order to craft a balance between beneficial uses of data and in individual privacy, policymakers must address some of the most fundamental concepts of privacy law, including the definition of “personally identifiable information”, the role of individual control, and the principles of data minimization and purpose limitation. This article emphasizes the importance of providing individuals with access to their data in usable format. This will let individuals share the wealth created by their information and incentivize developers to offer user-side features and applications harnessing the value of big data. Where individual access to data is impracticable, data are likely to be de-identified to an extent sufficient to diminish privacy concerns. In addition, organizations should be required to disclose their decisional criteria, since in a big data world it is often not the data but rather the inferences drawn from them that give cause for concern.\n",
            "------------------------------------\n",
            "Title :  Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty.\n",
            "Author/s :  G. Baele, P. Lemey, T. Bedford, A. Rambaut, M. Suchard, A. Alekseyenko\n",
            "Venue :  Molecular biology and evolution\n",
            "year :  2012\n",
            "Abstract :  Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.\n",
            "------------------------------------\n",
            "Title :  An Overview of Multi-task Learning\n",
            "Author/s :  Yu Zhang, Qiang Yang\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.\n",
            "------------------------------------\n",
            "Title :  Business Intelligence in Blogs: Understanding Consumer Interactions and Communities\n",
            "Author/s :  M. Chau, J. Xu\n",
            "Venue :  MIS Q.\n",
            "year :  2012\n",
            "Abstract :  The increasing popularity of Web 2.0 has led to exponential growth of user-generated content in both volume and significance. One important type of user-generated content is the blog. Blogs encompass useful information (e.g., insightful product reviews and information-rich consumer communities) that could potentially be a gold mine for business intelligence, bringing great opportunities for both academic research and business applications. However, performing business intelligence on blogs is quite challenging because of the vast amount of information and the lack of commonly adopted methodology for effectively collecting and analyzing such information. In this paper, we propose a framework for gathering business intelligence from blogs by automatically collecting and analyzing blog contents and bloggers' interaction networks. Through a system developed using the framework, we conducted two case studies with one case focusing on a consumer product and the other on a company. Our case studies demonstrate how to use the framework and appropriate techniques to effectively collect, extract, and analyze blogs related to the topics of interest, reveal novel patterns in the blogger interactions and communities, and answer important business intelligence questions in the domains. The framework is sufficiently generic and can be applied to any topics of interest, organizations, and products. Future academic research and business applications related to the topics examined in the two cases can also be built using the findings of this study.\n",
            "------------------------------------\n",
            "Title :  Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm\n",
            "Author/s :  Mohammed A. Ambusaidi, Xiangjian He, P. Nanda, Zhiyuan Tan\n",
            "Venue :  IEEE transactions on computers\n",
            "year :  2016\n",
            "Abstract :  Redundant and irrelevant features in data have caused a long-term problem in network traffic classification. These features not only slow down the process of classification but also prevent a classifier from making accurate decisions, especially when coping with big data. In this paper, we propose a mutual information based algorithm that analytically selects the optimal feature for classification. This mutual information based feature selection algorithm can handle linearly and nonlinearly dependent data features. Its effectiveness is evaluated in the cases of network intrusion detection. An Intrusion Detection System (IDS), named Least Square Support Vector Machine based IDS (LSSVM-IDS), is built using the features selected by our proposed feature selection algorithm. The performance of LSSVM-IDS is evaluated using three intrusion detection evaluation datasets, namely KDD Cup 99, NSL-KDD and Kyoto 2006+ dataset. The evaluation results show that our feature selection algorithm contributes more critical features for LSSVM-IDS to achieve better accuracy and lower computational cost compared with the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Real-World Evidence - What Is It and What Can It Tell Us?\n",
            "Author/s :  Rachel E. Sherman, S. Anderson, G. D. Dal Pan, Gerry W Gray, T. Gross, Nina L. Hunter, L. LaVange, D. Marinac-Dabic, P. Marks, M. Robb, J. Shuren, R. Temple, J. Woodcock, L. Yue*, R. Califf\n",
            "Venue :  New England Journal of Medicine\n",
            "year :  2016\n",
            "Abstract :  The FDA is developing guidance on the use of “real-world evidence” — health care information from atypical sources, including electronic health records, billing databases, and product and disease registries — to assess the safety and effectiveness of drugs and devices.\n",
            "------------------------------------\n",
            "Title :  The Evolving Role of the Public Information Officer: An Examination of Social Media in Emergency Management\n",
            "Author/s :  Amanda Lee Hughes, L. Palen\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Abstract This work examines how the introduction of social media has affected the role of the Public Information Officer (PIO)—the public relations component of the National Incident Management System (NIMS). Through analysis of 25 PIO interviews, we examine the work practice of PIOs and find that social media expand not only the scope and type of PIO work activity, but also the “information pathways” that exist between PIOs, the media, and members of the public. We model these changes and examine how the presence of social media challenges previous conceptualizations of PIO work. Lastly, we present a view of how PIO work could be better imagined for the future of emergency management organizations.\n",
            "------------------------------------\n",
            "Title :  A Survey: Digital Image Watermarking Techniques\n",
            "Author/s :  P. Parashar, R. Singh\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Multimedia security is extremely significant concern for the internet technology because of the ease of the duplication, distribution and manipulation of the multimedia data. The digital watermarking is a field of information hiding which hide the crucial information in the original data for protection illegal duplication and distribution of multimedia data. This paper presents a survey on the existing digital image watermarking techniques. The results of various digital image watermarking techniques have been compared on the basis of outputs. In the digital watermarking the secret information are implanted into the original data for protecting the ownership rights of the multimedia data. The image watermarking techniques may divide on the basis of domain like spatial domain or transform domain or on the basis of wavelets. The spatial domain techniques directly work on the pixels and the frequency domain works on the transform coefficients of the image. This survey elaborates the most important methods of spatial domain and transform domain and focuses the merits and demerits of these techniques.\n",
            "------------------------------------\n",
            "Title :  Hidden factors and hidden topics: understanding rating dimensions with review text\n",
            "Author/s :  Julian McAuley, J. Leskovec\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2013\n",
            "Abstract :  In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.\n",
            "------------------------------------\n",
            "Title :  Object lens: a “spreadsheet” for cooperative work\n",
            "Author/s :  Kum-Yew Lai, T. Malone, Keh-Chiang Yu\n",
            "Venue :  TOIS\n",
            "year :  2018\n",
            "Abstract :  Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times.\n",
            "The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.\n",
            "------------------------------------\n",
            "Title :  Prominent Features of Rumor Propagation in Online Social Media\n",
            "Author/s :  Sejeong Kwon, M. Cha, Kyomin Jung, Wei Chen, Yajun Wang\n",
            "Venue :  2013 IEEE 13th International Conference on Data Mining\n",
            "year :  2013\n",
            "Abstract :  The problem of identifying rumors is of practical importance especially in online social networks, since information can diffuse more rapidly and widely than the offline counterpart. In this paper, we identify characteristics of rumors by examining the following three aspects of diffusion: temporal, structural, and linguistic. For the temporal characteristics, we propose a new periodic time series model that considers daily and external shock cycles, where the model demonstrates that rumor likely have fluctuations over time. We also identify key structural and linguistic differences in the spread of rumors and non-rumors. Our selected features classify rumors with high precision and recall in the range of 87% to 92%, that is higher than other states of the arts on rumor classification.\n",
            "------------------------------------\n",
            "Title :  Enhancing patient safety and quality of care by improving the usability of electronic health record systems: recommendations from AMIA.\n",
            "Author/s :  Blackford Middleton, M. Bloomrosen, Mark A. Dente, Bill Hashmat, R. Koppel, J. Overhage, T. Payne, S. Rosenbloom, Charlotte A. Weaver, Jiajie Zhang\n",
            "Venue :  JAMIA Journal of the American Medical Informatics Association\n",
            "year :  2013\n",
            "Abstract :  In response to mounting evidence that use of electronic medical record systems may cause unintended consequences, and even patient harm, the AMIA Board of Directors convened a Task Force on Usability to examine evidence from the literature and make recommendations. This task force was composed of representatives from both academic settings and vendors of electronic health record (EHR) systems. After a careful review of the literature and of vendor experiences with EHR design and implementation, the task force developed 10 recommendations in four areas: (1) human factors health information technology (IT) research, (2) health IT policy, (3) industry recommendations, and (4) recommendations for the clinician end-user of EHR software. These AMIA recommendations are intended to stimulate informed debate, provide a plan to increase understanding of the impact of usability on the effective use of health IT, and lead to safer and higher quality care with the adoption of useful and usable EHR systems.\n",
            "------------------------------------\n",
            "Title :  Content Based Video Retrival System for Mexican Culture Heritage Based on Object Matching and Local-Global Descriptors\n",
            "Author/s :  M. Cedillo-Hernández, F. Garcia-Ugalde, Antonio Cedillo-Hernández, M. Nakano-Miyatake, H. Perez-Meana\n",
            "Venue :  2014 International Conference on Mechatronics, Electronics and Automotive Engineering\n",
            "year :  2014\n",
            "Abstract :  Multimedia data and networking technologies have had a highly growing during the last decade, with these changes users have changed from text to content based video retrieval systems due to its better performance. We propose a fast content-based video retrieval system which involves the combination of a local descriptor obtained from the speeded-up robust feature algorithm together with an effective and fast object matching operation. To save computational time, compressed video data are partially decoded in order to get discrete cosine transform coefficients of key frames, which are used to obtain sub-block coefficients and a down-sampling version of frames. The preliminary results are ranking using an efficient color descriptor based on color correlogram and dominant color descriptors. To measure the performance of the proposed technique the precision and recall metrics are used. The experimental results show the accuracy of the proposed method applied to a database of Mexican Culture Heritage videos.\n",
            "------------------------------------\n",
            "Title :  ERNIE: Enhanced Language Representation with Informative Entities\n",
            "Author/s :  Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2019\n",
            "Abstract :  Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.\n",
            "------------------------------------\n",
            "Title :  Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author/s :  Christopher Courtney, Supradeep Dutta, Yong Li\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title :  Advances in Hyperspectral Image Classification: Earth Monitoring with Statistical Learning Methods\n",
            "Author/s :  Gustau Camps-Valls, D. Tuia, L. Bruzzone, J. Benediktsson\n",
            "Venue :  IEEE Signal Processing Magazine\n",
            "year :  2013\n",
            "Abstract :  The technological evolution of optical sensors over the last few decades has provided remote sensing analysts with rich spatial, spectral, and temporal information. In particular, the increase in spectral resolution of hyperspectral images (HSIs) and infrared sounders opens the doors to new application domains and poses new methodological challenges in data analysis. HSIs allow the characterization of objects of interest (e.g., land-cover classes) with unprecedented accuracy, and keeps inventories up to date. Improvements in spectral resolution have called for advances in signal processing and exploitation algorithms. This article focuses on the challenging problem of hyperspectral image classification, which has recently gained in popularity and attracted the interest of other scientific disciplines such as machine learning, image processing, and computer vision. In the remote sensing community, the term classification is used to denote the process that assigns single pixels to a set of classes, while the term segmentation is used for methods aggregating pixels into objects and then assigned to a class.\n",
            "------------------------------------\n",
            "Title :  SEISMIC: A Self-Exciting Point Process Model for Predicting Tweet Popularity\n",
            "Author/s :  Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, A. Rajaraman, J. Leskovec\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2015\n",
            "Abstract :  Social networking websites allow users to create and share content. Big information cascades of post resharing can form as users of these sites reshare others' posts with their friends and followers. One of the central challenges in understanding such cascading behaviors is in forecasting information outbreaks, where a single post becomes widely popular by being reshared by many users. In this paper, we focus on predicting the final number of reshares of a given post. We build on the theory of self-exciting point processes to develop a statistical model that allows us to make accurate predictions. Our model requires no training or expensive feature engineering. It results in a simple and efficiently computable formula that allows us to answer questions, in real-time, such as: Given a post's resharing history so far, what is our current estimate of its final number of reshares? Is the post resharing cascade past the initial stage of explosive growth? And, which posts will be the most reshared in the future? We validate our model using one month of complete Twitter data and demonstrate a strong improvement in predictive accuracy over existing approaches. Our model gives only 15% relative error in predicting final size of an average information cascade after observing it for just one hour.\n",
            "------------------------------------\n",
            "Title :  The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power\n",
            "Author/s :  Shoshana Zuboff\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  Society is at a turning point. The heady optimism that accompanied the advent of the Internet has gone, replaced with a deep unease as technology, capitalism and an unequal society combine to create the perfect storm. Tech companies are gathering our information online and selling it to the highest bidder, whether government or retailer. In this world of surveillance capitalism, profit depends not only on predicting but modifying our online behaviour. How will this fusion of capitalism and the digital shape the values that define our future?\n",
            "------------------------------------\n",
            "Title :  Flow-Guided Feature Aggregation for Video Object Detection\n",
            "Author/s :  Xizhou Zhu, Yujie Wang, Jifeng Dai, Lu Yuan, Yichen Wei\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong singleframe baselines in ImageNet VID [33], especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The code would be released.\n",
            "------------------------------------\n",
            "Title :  A Review of “Doing Case Study Research: A Practical Guide for Beginning Researchers”\n",
            "Author/s :  L. Vernon-Dotson\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  I n Doing Case Study Research: A Practical Guide for Beginning Researchers, Hancock and Algozzine provide a concrete, step-by-step process for beginning researchers who are conducting case study research. The authors claim that Doing Case Study Research is not a “case study research for dummies” (p. xii) manual, and I absolutely concur. They are successful in stripping away the theories and attacking case study research in a very rudimentary manner, hence providing readers a prescriptive approach. It is a practical look at doing case study research—a solid companion for those teaching, facilitating, or conducting introductory qualitative research. Doing Case Study Research is divided into three sections: “Foundations” (Chapters 1–2), “Stages of Doing Case Study Research” (Chapters 3–11), and “Putting It All Together” (Chapters 12–13). In the first part, Hancock and Algozzine provide insights into the purposes and processes of research, in general, and offer their readers an overview of basic types of qualitative and quantitative research. The authors fittingly provide the reader with guidance in selecting the appropriate research within the two broad traditions. Comprising 59 of the book’s 114 pages, the second section is truly the “nuts and bolts” of conducting case study research. In this section, the authors outline their prescriptive, step-by-step process, which spans from literature review and research design through data collection and interpretation and then ending with reporting and confirming the findings. Each chapter in this section is thorough, with just enough information as to not overwhelm novice researchers. For example, Chapter 4 (“Determining What We Know”) beautifully illustrates and iterates the rationale for the conceptual framework and outlines a seminal and well-documented process for writing a literature review. For instance, the authors suggest following Galvan’s (1999, 2009) key directions for writing literature reviews by first selecting a topic and identifying the literature to review followed by analyzing, criticizing, synthesizing, and documenting the literature. The final section focuses on preparing proposals and disseminating research. These last two chapters bring the book full circle by providing the reader with steps for the typical outlets of their completed work. This book is an easy, quick read and is very user friendly. Hancock and Algozzine offer a variety of cross-disciplinary examples from published works to support their basic process for doing case study research. For example, in Chapter 3 (“Setting the Stage”) the authors provide the readers with examples of published studies from researchers who utilized case study research through 18 brief descriptions of events, situations, programs, and activities across several disciplines including, but not limited to education, social work, counseling, technology, adult education, criminal justice, and psychology. At the conclusion of each chapter, the authors deliver questions (Content Review) and activities to facilitate understanding (Activities and Applications for Prospective Researchers). I greatly appreciated the attention to research design (Chapter 5: “Selecting a Design”); in many qualitative texts, this seems to be overlooked or lacking specificity within the context of case study research. I have reviewed several manuscripts submitted for publication where “case study research” was indicated as the “design.” It seems that beginning researchers (and some veterans) fail to realize that, as Hancock and Algozzine indicated, “[d]oing case study research means selecting a design that matches the disciplinary perspective of the investigation” (p. 37). Not only did the authors distinguish between the classifications, types, and orientations of case study research designs, they also provided 12 different examples that clearly illustrated these different designs. Although this is a practical guide for implementing case study research, a few weaknesses should be noted. First, Hancock and Algozzine make it sound easy. They do mention that qualitative research is a time-consuming task in the first section of the book; however, the time factor is not otherwise stressed. Further, the data analysis section just scratches the surface of what needs to be done to effectively interpret mass amounts of data typically gathered over a long period of time. With that said, the authors appropriately emphasize the need to remain focused on the research questions when sifting through the data—something both beginning and seasoned qualitative researchers tend to forget. Finally, a chapter on the uses, pros, and cons of qualitative data management systems versus just mentioning them in passing (Chapter 9: “Summarizing and Interpreting the Information”) may be helpful to novice researchers who may mistakenly believe that the software (e.g., NVivo, NUDIST, Atlis-ti) actually analyze the data with the click of a button. The lack of context and theory in Doing Case Study Research is both purposeful and effective. Hancock and Algozzine fill a gap in the literature with regard to case study research and their book makes a very useful accompaniment to qualitative research courses. It may not teach some old research dogs new tricks, but Doing Case Study Research is definitely a useful resource to pass along to more novice researchers.\n",
            "------------------------------------\n",
            "Title :  Decoding neural representational spaces using multivariate pattern analysis.\n",
            "Author/s :  J. Haxby, Andrew C. Connolly, J. S. Guntupalli\n",
            "Venue :  Annual Review of Neuroscience\n",
            "year :  2014\n",
            "Abstract :  A major challenge for systems neuroscience is to break the neural code. Computational algorithms for encoding information into neural activity and extracting information from measured activity afford understanding of how percepts, memories, thought, and knowledge are represented in patterns of brain activity. The past decade and a half has seen significant advances in the development of methods for decoding human neural activity, such as multivariate pattern classification, representational similarity analysis, hyperalignment, and stimulus-model-based encoding and decoding. This article reviews these advances and integrates neural decoding methods into a common framework organized around the concept of high-dimensional representational spaces.\n",
            "------------------------------------\n",
            "Title :  Seeking and sharing health information online: comparing search engines and social media\n",
            "Author/s :  M. Choudhury, M. Morris, Ryen W. White\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2014\n",
            "Abstract :  Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
            "------------------------------------\n",
            "Title :  Unpacking the Use of Social Media for Protest Behavior\n",
            "Author/s :  S. Valenzuela\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recent studies have shown a positive link between frequency of social media use and political participation. However, there has been no clear elaboration of how using social media translates into increased political activity. The current study examines three explanations for this relationship in the context of citizens’ protest behavior: information (social media as a source for news), opinion expression (using social media to express political opinions), and activism (joining causes and finding mobilizing information through social media). To test these relationships, the study uses survey data collected in Chile in 2011, amid massive demonstrations demanding wholesale changes in education and energy policy. Findings suggest that using social media for opinion expression and activism mediates the relationship between overall social media use and protest behavior. These findings deepen our knowledge of the uses and effects of social media and provide new evidence on the role of digital platforms as facilitators of direct political action.\n",
            "------------------------------------\n",
            "Title :  Replacing the Soft-Decision FEC Limit Paradigm in the Design of Optical Communication Systems*\n",
            "Author/s :  A. Alvarado, E. Agrell, D. Lavery, R. Maher, P. Bayvel\n",
            "Venue :  Journal of Lightwave Technology\n",
            "year :  2015\n",
            "Abstract :  The FEC limit paradigm is the prevalent practice for designing optical communication systems to attain a certain bit error rate (BER) without forward error correction (FEC). This practice assumes that there is an FEC code that will reduce the BER after decoding to the desired level. In this paper, we challenge this practice and show that the concept of a channel-independent FEC limit is invalid for soft-decision bit-wise decoding. It is shown that for low code rates and high-order modulation formats, the use of the soft-decision FEC limit paradigm can underestimate the spectral efficiencies by up to 20%. A better predictor for the BER after decoding is the generalized mutual information, which is shown to give consistent post-FEC BER predictions across different channel conditions and modulation formats. Extensive optical full-field simulations and experiments are carried out in both the linear and nonlinear transmission regimes to confirm the theoretical analysis.\n",
            "------------------------------------\n",
            "Title :  Training Very Deep Networks\n",
            "Author/s :  R. Srivastava, Klaus Greff, J. Schmidhuber\n",
            "Venue :  NIPS\n",
            "year :  2015\n",
            "Abstract :  Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.\n",
            "------------------------------------\n",
            "Title :  Understanding customers' repeat purchase intentions in B2C e‐commerce: the roles of utilitarian value, hedonic value and perceived risk\n",
            "Author/s :  Chao-Min Chiu, Eric T. G. Wang, Yu-Hui Fang, Hsin-Yi Huang\n",
            "Venue :  Information Systems Journal\n",
            "year :  2014\n",
            "Abstract :  Customer loyalty or repeat purchasing is critical for the survival and success of any store. By focusing on online stores, this study investigates the repeat purchase intention of experienced online buyers based on means‐end chain theory and prospect theory. In the research model, both utilitarian value and hedonic value are hypothesised to affect repeat purchase intention positively. Perceived risk is hypothesised to affect repeat purchase intention negatively and moderate the effects of utilitarian and hedonic values on repeat purchase intention. Utilitarian value is proposed as a formative second‐order construct formed by product offerings, product information, monetary savings and convenience. Hedonic value is also proposed as a formative second‐order construct formed by the six hedonic benefits that have been identified in prior research. Data collected from 782 Yahoo!Kimo customers provide strong support for the research model. The results indicate that both the utilitarian value and hedonic value are positively associated with buyers' repeat purchase intention. A higher level of perceived risk reduces the effect of utilitarian value and increases the effect of hedonic value on repeat purchase intention. Implications for theory and practice and suggestions for future research are provided.\n",
            "------------------------------------\n",
            "Title :  Psychological Frictions and the Incomplete Take-Up of Social Benefits: Evidence from an IRS Field Experiment\n",
            "Author/s :  Saurabh Bhargava, Dayanand Manoli\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  We address the role of “psychological frictions” in the incomplete take-up of EITC benefits with an IRS field experiment. We specifically assess the influence of program confusion, informational complexity, and stigma by evaluating response to experimental mailings distributed to 35,050 tax filers who failed to claim $26 million despite an initial notice. While the mere receipt of the mailing, simplification, and the heightened salience of benefits led to substantial additional claiming, attempts to reduce perceived costs of stigma, application, and audits did not. The study, and accompanying surveys, suggests that low program awareness/understanding and informational complexity contribute to the puzzle of low take-up. (JEL C93, D03, H24, M38)\n",
            "------------------------------------\n",
            "Title :  Do Prices Reveal the Presence of Informed Trading?\n",
            "Author/s :  P. Collin-Dufresne, Vyacheslav Fos\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Using a comprehensive sample of trades by Schedule 13D filers, who possess valuable private information when they accumulate stocks of targeted companies, this paper studies whether several liquidity measures reveal the presence of informed trading. The evidence suggests that when Schedule 13D filers trade aggressively, both high-frequency and low-frequency measures of stock liquidity indicate a higher stock liquidity. Importantly, measures that have been used as direct proxies for adverse selection, such the Kyle (1985) lambda, the Easley et al. (1996) pin measure, and the Amihud (2002) illiquidity measure, suggest that the adverse selection is lower when informed trading takes place. The evidence is consistent with informed traders being more aggressive when measured stock liquidity is high.\n",
            "------------------------------------\n",
            "Title :  Examining the Role of Social Media in Effective Crisis Management\n",
            "Author/s :  Yan Jin, B. Liu, Lucinda L. Austin\n",
            "Venue :  Communication Research\n",
            "year :  2014\n",
            "Abstract :  Publics increasingly use social media during crises and, consequently, crisis communication professionals need to understand how to strategically optimize these tools. Despite this need, there is scarce theory-grounded research to understand key factors that affect how publics consume crisis information via social media compared to other sources. To fill this gap, an emerging model helps crisis managers understand how publics produce, consume, and/or share crisis information via social media and other sources: the social-mediated crisis communication model (SMCC). This study tests essential components of the SMCC model through a 3 (crisis information form) x 2 (crisis information source) x 2 (crisis origin) mixed-design experiment (N = 338). The findings indicate the key role of crisis origin in affecting publics’ preferred information form (social media, traditional media, or word-of-mouth communication) and source (organization in crisis or third party), which influences how publics anticipate an organization should respond to a crisis and what crisis emotions they are likely to feel when exposed to crisis information.\n",
            "------------------------------------\n",
            "Title :  Information Sharing in a Supply Chain with a Common Retailer\n",
            "Author/s :  Weixin Shang, Albert Y. Ha, Shilu Tong\n",
            "Venue :  Management Sciences\n",
            "year :  2013\n",
            "Abstract :  We study the problem of information sharing in a supply chain with two competing manufacturers selling substitutable products through a common retailer. Our analysis shows that the retailer’s incentive to share information strongly depends on nonlinear production cost, competition intensity, and whether the retailer can offer a contract to charge a payment for the information. Without information contracting, the retailer has an incentive to share information for free when production economy is large but has no incentive to do so when there is production diseconomy. With information contracting, the retailer has an incentive to share information when either production diseconomy/economy is large or competition is intense. We characterize the conditions under which the retailer shares information with none, one, or both of the manufacturers. We also show that the retailer prefers to sell information sequentially rather than concurrently to the manufacturers, whereas the manufacturers’ preferences are reversed. This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  Hierarchical recurrent neural network for skeleton based action recognition\n",
            "Author/s :  Yong Du, Wei Wang, Liang Wang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2015\n",
            "Abstract :  Human actions can be represented by the trajectories of skeleton joints. Traditional methods generally model the spatial structure and temporal dynamics of human skeleton with hand-crafted features and recognize human actions by well-designed classifiers. In this paper, considering that recurrent neural network (RNN) can model the long-term contextual information of temporal sequences well, we propose an end-to-end hierarchical RNN for skeleton based action recognition. Instead of taking the whole skeleton as the input, we divide the human skeleton into five parts according to human physical structure, and then separately feed them to five subnets. As the number of layers increases, the representations extracted by the subnets are hierarchically fused to be the inputs of higher layers. The final representations of the skeleton sequences are fed into a single-layer perceptron, and the temporally accumulated output of the perceptron is the final decision. We compare with five other deep RNN architectures derived from our model to verify the effectiveness of the proposed network, and also compare with several other methods on three publicly available datasets. Experimental results demonstrate that our model achieves the state-of-the-art performance with high computational efficiency.\n",
            "------------------------------------\n",
            "Title :  TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence of User Trust and of Item Ratings\n",
            "Author/s :  G. Guo, Jie Zhang, N. Yorke-Smith\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " Collaborative filtering suffers from the problems of data sparsity and cold start, which dramatically degrade recommendation performance. To help resolve these issues, we propose TrustSVD, a trust-based matrix factorization technique. By analyzing the social trust data from four real-world data sets, we conclude that not only the explicit but also the implicit influence of both ratings and trust should be taken into consideration in a recommendation model. Hence, we build on top of a state-of-the-art recommendation algorithm SVD++ which inherently involves the explicit and implicit influence of rated items, by further incorporating both the explicit and implicit influence of trusted users on the prediction of items for an active user. To our knowledge, the work reported is the first to extend SVD++ with social trust information. Experimental results on the four data sets demonstrate that our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Infoglut: How Too Much Information Is Changing the Way We Think and Know\n",
            "Author/s :  M. Andrejevic\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Today, more mediated information is available to more people than at any other time in human history. New and revitalized sense-making strategies multiply in response to the challenges of \"cutting through the clutter\" of competing narratives and taming the avalanche of information. Data miners, \"sentiment analysts,\" and decision markets offer to help bodies of data \"speak for themselves\"making sense of their own patterns so we dont have to. Neuromarketers and body language experts promise to peer behind peoples words to see what their brains are really thinking and feeling. New forms of information processing promise to displace the need for expertise and even comprehensionat least for those with access to the data. Infoglut explores the connections between these wide-ranging sense-making strategies for an era of information overload and \"big data,\" and the new forms of control they enable. Andrejevic critiques the popular embrace of deconstructive debunkery, calling into question the post-truth, post-narrative, and post-comprehension politics it underwrites, and tracing a way beyond them.\n",
            "------------------------------------\n",
            "Title :  Infographics: The Power of Visual Storytelling\n",
            "Author/s :  Jason Lankow, J. Ritchie, Ross Crooks\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Intro 1. Introduction 010 A Brief History of Infographics 014 The Purpose of This Book 018 What This Book Is Not 018 A Note on Terminology 019 How to Use This Book 024 Chapter 01. Importance and Efficacy: Why Our Brains Love Infographics 028 Varied Perspectives on Information Design: A Brief History 031 Objectives of Visualization 038 Appeal 040 Comprehension 044 Retention 050 Chapter 02. Infographic Formats: Choosing the Right Vehicle for Your Message 056 Static Infographics 060 Motion Graphics 074 Interactive Infographics 082 Chapter 03. The Visual Storytelling Spectrum: An Objective Approach 088 Understanding the Visual Storytelling Spectrum 090 Chapter 04. Editorial Infographics 112 What Are Editorial Infographics? 114 Origins of Editorial Infographics 122 Editorial Infographic Production 128 Chapter 05. Content Distribtion: Sharing Your Story 146 Posting on Your Site 149 Distribution Your Content 152 Patience Pays Dividends 159\n",
            "------------------------------------\n",
            "Title :  Peningkatan Kemampuan Menulis Teks Deskripsi Siswa Kelas VII SMP Berdasarkan Level Pemula Menggunakan Teknik Retrival Jaringan Semantik\n",
            "Author/s :  Tobias Nggaruaka, A. Hermansyah, Santi Monika\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  Kemampuan menulis teks deskripsi siswa kelas VII SMP YPPGI Geradus Adii Merauke masih rendah. Berdasarkan permasalahan tersebut tujuan penelitian ini adalah meningkatkan kemampuan menulis teks deskripsi dengan menggunakan teknik retrival jaringan semantik. Penelitian ini menggunakan jenis penelitian kualitatif dengan rancangan penelitian tindakan kelas (PTK). Rancangan penelitian yang digunakan meliputi: observasi, analisis, perencanaan, pelaksanaan, refleksi, dan evaluasi. Data penelitian ini adalah berupa data proses dan data hasil penilaian pembelajaran. Data tersebut dikumpulkan dengan menggunakan instrumen penelitian yaitu; hasil pengamatan, wawancara, hasil tindakan, catatan lapangan, dan dokumentasi. Hasil penelitian menunjukkan bahwa pembelajaran pada siklus I pertemuan I dengan presentasi 28,57%. Sedangkan pada pertemuan II siklus I hasil pembelajaran meningkat menjadi 57,14%. Hasil pembelajaran pada siklus II pertemuan I meningkat menjadi 85,71%. Sedangkan pada pertemuan II siklus II meningkat menjadi 100% dengan kriteria ketuntasan minimal.\n",
            "------------------------------------\n",
            "Title :  Learning Discrete Representations via Information Maximizing Self-Augmented Training\n",
            "Author/s :  Weihua Hu, Takeru Miyato, Seiya Tokui, Eiichi Matsumoto, Masashi Sugiyama\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2017\n",
            "Abstract :  Learning discrete representations of data is a central machine learning task because of the compactness of the representations and ease of interpretation. The task includes clustering and hash learning as special cases. Deep neural networks are promising to be used because they can model the non-linearity of data and scale to large datasets. However, their model complexity is huge, and therefore, we need to carefully regularize the networks in order to learn useful representations that exhibit intended invariance for applications of interest. To this end, we propose a method called Information Maximizing Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose the invari-ance on discrete representations. More specifically, we encourage the predicted representations of augmented data points to be close to those of the original data points in an end-to-end fashion. At the same time, we maximize the information-theoretic dependency between data and their predicted discrete representations. Extensive experiments on benchmark datasets show that IMSAT produces state-of-the-art results for both clustering and unsupervised hash learning.\n",
            "------------------------------------\n",
            "Title :  Characterizing the Propagation of Situational Information in Social Media During COVID-19 Epidemic: A Case Study on Weibo\n",
            "Author/s :  Lifang Li, Qingpeng Zhang, Xiao Wang, J. Zhang, Tao Wang, Tian-Lu Gao, Wei Duan, K. Tsoi, Fei-yue Wang\n",
            "Venue :  IEEE Transactions on Computational Social Systems\n",
            "year :  2020\n",
            "Abstract :  During the ongoing outbreak of coronavirus disease (COVID-19), people use social media to acquire and exchange various types of information at a historic and unprecedented scale. Only the situational information are valuable for the public and authorities to response to the epidemic. Therefore, it is important to identify such situational information and to understand how it is being propagated on social media, so that appropriate information publishing strategies can be informed for the COVID-19 epidemic. This article sought to fill this gap by harnessing Weibo data and natural language processing techniques to classify the COVID-19-related information into seven types of situational information. We found specific features in predicting the reposted amount of each type of information. The results provide data-driven insights into the information need and public attention.\n",
            "------------------------------------\n",
            "Title :  Gated-SCNN: Gated Shape CNNs for Semantic Segmentation\n",
            "Author/s :  Towaki Takikawa, David Acuna, V. Jampani, S. Fidler\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2019\n",
            "Abstract :  Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.\n",
            "------------------------------------\n",
            "Title :  Adoption of Electronic Health Record Systems among U . S . Non-Federal Acute Care Hospitals : 2008-2015\n",
            "Author/s :  J. Henry, Yuriy Pylypchuk, Talisha Searcy, Vaishali Patel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The adoption and meaningful use of electronic health records (EHRs) are key objectives of the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the Federal Health IT Strategic Plan (1). This brief uses data from the American Hospital Association to describe trends in adoption of EHR technology among non-federal acute care hospitals from 2008 to 2015. It tracks the adoption of Basic EHR systems and the possession of certified EHR technology. Unless otherwise stated, this brief refers to Basic EHR adoption with clinical notes, a measure which represents a minimum use of 10 core functionalities determined to be essential to an EHR system (see Table A1)(2).\n",
            "------------------------------------\n",
            "Title :  Variable selection – A review and recommendations for the practicing statistician\n",
            "Author/s :  G. Heinze, C. Wallisch, D. Dunkler\n",
            "Venue :  Biometrical journal. Biometrische Zeitschrift\n",
            "year :  2018\n",
            "Abstract :  Statistical models support medical research by facilitating individualized outcome prognostication conditional on independent variables or by estimating effects of risk factors adjusted for covariates. Theory of statistical models is well‐established if the set of independent variables to consider is fixed and small. Hence, we can assume that effect estimates are unbiased and the usual methods for confidence interval estimation are valid. In routine work, however, it is not known a priori which covariates should be included in a model, and often we are confronted with the number of candidate variables in the range 10–30. This number is often too large to be considered in a statistical model. We provide an overview of various available variable selection methods that are based on significance or information criteria, penalized likelihood, the change‐in‐estimate criterion, background knowledge, or combinations thereof. These methods were usually developed in the context of a linear regression model and then transferred to more generalized linear models or models for censored survival data. Variable selection, in particular if used in explanatory modeling where effect estimates are of central interest, can compromise stability of a final model, unbiasedness of regression coefficients, and validity of p‐values or confidence intervals. Therefore, we give pragmatic recommendations for the practicing statistician on application of variable selection methods in general (low‐dimensional) modeling problems and on performing stability investigations and inference. We also propose some quantities based on resampling the entire variable selection process to be routinely reported by software packages offering automated variable selection algorithms.\n",
            "------------------------------------\n",
            "Title :  Spindle Net: Person Re-identification with Human Body Region Guided Feature Decomposition and Fusion\n",
            "Author/s :  Haiyu Zhao, Maoqing Tian, Shuyang Sun, Jing Shao, Junjie Yan, Shuai Yi, Xiaogang Wang, Xiaoou Tang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2017\n",
            "Abstract :  Person re-identification (ReID) is an important task in video surveillance and has various applications. It is non-trivial due to complex background clutters, varying illumination conditions, and uncontrollable camera settings. Moreover, the person body misalignment caused by detectors or pose variations is sometimes too severe for feature matching across images. In this study, we propose a novel Convolutional Neural Network (CNN), called Spindle Net, based on human body region guided multi-stage feature decomposition and tree-structured competitive feature fusion. It is the first time human body structure information is considered in a CNN framework to facilitate feature learning. The proposed Spindle Net brings unique advantages: 1) it separately captures semantic features from different body regions thus the macro-and micro-body features can be well aligned across images, 2) the learned region features from different semantic regions are merged with a competitive scheme and discriminative features can be well preserved. State of the art performance can be achieved on multiple datasets by large margins. We further demonstrate the robustness and effectiveness of the proposed Spindle Net on our proposed dataset SenseReID without fine-tuning.\n",
            "------------------------------------\n",
            "Title :  Rumor Cascades\n",
            "Author/s :  A. Friggeri, Lada A. Adamic, Dean Eckles, Justin Cheng\n",
            "Venue :  International Conference on Web and Social Media\n",
            "year :  2014\n",
            "Abstract :  \n",
            " \n",
            " Online social networks provide a rich substrate for rumor propagation. Information received via friends tends to be trusted, and online social networks allow individuals to transmit information to many friends at once. By referencing known rumors from Snopes.com, a popular website documenting memes and urban legends, we track the propagation of thousands of rumors appearing on Facebook. From this sample we infer the rates at which rumors from different categories and of varying truth value are uploaded and reshared. We find that rumor cascades run deeper in the social network than reshare cascades in general. We then examine the effect of individual reshares receiving a comment containing a link to a Snopes article on the evolution of the cascade. We find that receiving such a comment increases the likelihood that a reshare of a rumor will be deleted. Furthermore, large cascades are able to accumulate hundreds of Snopes comments while continuing to propagate. Finally, using a dataset of rumors copied and pasted from one status update to another, we show that rumors change over time and that different variants tend to dominate different bursts in popularity.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Teens, Health and Technology: A National Survey\n",
            "Author/s :  E. Wartella, V. Rideout, H. Montague, Leanne Beaudoin-Ryan, A. Lauricella\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  In the age of digital technology, as teens seem to be constantly connected online, via social media, and through mobile applications, it is no surprise that they increasingly turn to digital media to answer their health questions. This study is the first of its kind to survey a large, nationally-representative sample of teens to investigate how they use the newest digital technologies, including mobile apps, social networking sites, electronic gaming and wearable devices, to explore health topics. The survey covered the types of health topics teens most frequently search for, which technologies they are most likely to use and how they use them, and whether they report having changed their behaviors due to digital health information. In addition, this survey explores how the digital divide continues to impact adolescents. Results of this study indicate that teens are concerned about many health issues, ranging from fitness, sexual activity, drugs, hygiene as well as mental health and stress. As teens virtually always have a digital device at their fingertips, it is clear that public health interventions and informational campaigns must be tailored to reflect the ways that teens currently navigate digital health information and the health challenges that concern them most.\n",
            "------------------------------------\n",
            "Title :  The role of collaboration in supply chain resilience\n",
            "Author/s :  K. Scholten, Sanne Schilder\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            "– This paper aims to explore how collaboration influences supply chain resilience. Collaborative activities and their underlying mechanisms in relation to visibility, velocity and flexibility are investigated. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            "– An exploratory case study consisting of eight buyer–supplier relationships in the food processing industry was conducted. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            "– Key findings show how specific collaborative activities (information-sharing, collaborative communication, mutually created knowledge and joint relationship efforts) increase supply chain resilience via increased visibility, velocity and flexibility. Underlying mechanisms and interdependencies of these factors within the supply chain network are identified. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            "– This is one of the first papers to provide in-depth insights into collaboration as a formative element of resilience in a supply chain setting. A series of propositions explain the specific influence of collaborative activities on supply chain resilience beyond a single company perspective.\n",
            "------------------------------------\n",
            "Title :  Direct and Mediated Associations among Earnings Quality, Information Asymmetry, and the Cost of Equity\n",
            "Author/s :  Nilabhra Bhattacharya, Frank Ecker, Per Olsson, K. Schipper\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  ABSTRACT: Using path analysis, we investigate the direct and indirect links between three measures of earnings quality and the cost of equity. Our investigation is motivated by analytical models that specify both a direct link and an indirect link that is mediated by information asymmetry, but do not suggest which link would be more important empirically. We measure information asymmetry as both the adverse selection component of the bid-ask spread and the probability of informed trading (PIN). For a large sample of Value Line firms during 1993–2005, we find statistically reliable evidence of both a direct path from earnings quality to the cost of equity, and an indirect path that is mediated by information asymmetry, with the weight of the evidence favoring the direct path as the more important.\n",
            "------------------------------------\n",
            "Title :  Data Resource Profile: The Korea National Health and Nutrition Examination Survey (KNHANES)\n",
            "Author/s :  Sanghui Kweon, Yuna Kim, Myoung-jin Jang, Yoonjung Kim, Kirang Kim, Sunhye Choi, Chaemin Chun, Y. Khang, Kyungwon Oh\n",
            "Venue :  International Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  The Korea National Health and Nutrition Examination Survey (KNHANES) is a national surveillance system that has been assessing the health and nutritional status of Koreans since 1998. Based on the National Health Promotion Act, the surveys have been conducted by the Korea Centers for Disease Control and Prevention (KCDC). This nationally representative cross-sectional survey includes approximately 10 000 individuals each year as a survey sample and collects information on socioeconomic status, health-related behaviours, quality of life, healthcare utilization, anthropometric measures, biochemical and clinical profiles for non-communicable diseases and dietary intakes with three component surveys: health interview, health examination and nutrition survey. The health interview and health examination are conducted by trained staff members, including physicians, medical technicians and health interviewers, at a mobile examination centre, and dieticians’ visits to the homes of the study participants are followed up. KNHANES provides statistics for health-related policies in Korea, which also serve as the research infrastructure for studies on risk factors and diseases by supporting over 500 publications. KCDC has also supported researchers in Korea by providing annual workshops for data users. KCDC has published the Korea Health Statistics each year, and microdata are publicly available through the KNHANES website (http://knhanes.cdc.go.kr).\n",
            "------------------------------------\n",
            "Title :  The End of Framing as we Know it … and the Future of Media Effects\n",
            "Author/s :  M. Cacciatore, D. Scheufele, S. Iyengar\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Framing has become one of the most popular areas of research for scholars in communication and a wide variety of other disciplines, such as psychology, behavioral economics, political science, and sociology. Particularly in the communication discipline, however, ambiguities surrounding how we conceptualize and therefore operationalize framing have begun to overlap with other media effects models to a point that is dysfunctional. This article provides an in-depth examination of framing and positions the theory in the context of recent evolutions in media effects research. We begin by arguing for changes in how communication scholars approach framing as a theoretical construct. We urge scholars to abandon the general term “framing” altogether and instead distinguish between different types of framing. We also propose that, as a field, we refocus attention on the concept's original theoretical foundations and, more important, the potential empirical contributions that the concept can make to our field and our understanding of media effects. Finally, we discuss framing as a bridge between paradigms as we shift from an era of mass communication to one of echo chambers, tailored information and microtargeting in the new media environment.\n",
            "------------------------------------\n",
            "Title :  Information-theoretic analysis of generalization capability of learning algorithms\n",
            "Author/s :  Aolin Xu, M. Raginsky\n",
            "Venue :  NIPS\n",
            "year :  2017\n",
            "Abstract :  We derive upper bounds on the generalization error of a learning algorithm in terms of the mutual information between its input and output. The bounds provide an information-theoretic understanding of generalization in learning problems, and give theoretical guidelines for striking the right balance between data fit and generalization by controlling the input-output mutual information. We propose a number of methods for this purpose, among which are algorithms that regularize the ERM algorithm with relative entropy or with random noise. Our work extends and leads to nontrivial improvements on the recent results of Russo and Zou.\n",
            "------------------------------------\n",
            "Title :  Recommender systems based on user reviews: the state of the art\n",
            "Author/s :  Li Chen, Guanliang Chen, Feng Wang\n",
            "Venue :  User modeling and user-adapted interaction\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Influence of fake news in Twitter during the 2016 US presidential election\n",
            "Author/s :  A. Bovet, H. Makse\n",
            "Venue :  Nature Communications\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Belief Echoes: The Persistent Effects of Corrected Misinformation\n",
            "Author/s :  Emily A. Thorson\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Across three separate experiments, I find that exposure to negative political information continues to shape attitudes even after the information has been effectively discredited. I call these effects “belief echoes.” Results suggest that belief echoes can be created through an automatic or deliberative process. Belief echoes occur even when the misinformation is corrected immediately, the “gold standard” of journalistic fact-checking. The existence of belief echoes raises ethical concerns about journalists’ and fact-checking organizations’ efforts to publicly correct false claims.\n",
            "------------------------------------\n",
            "Title :  How Virtualization, Decentralization and Network Building Change the Manufacturing Landscape: An Industry 4.0 Perspective\n",
            "Author/s :  Malte Brettel, Niklas Friederichsen, M. Keller, Marius Rosenberg\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  : The German manufacturing industry has to withstand an increasing global competition on product quality and production costs. As labor costs are high, several industries have suffered severely under the relocation of production facilities towards aspiring countries, which have managed to close the productivity and quality gap substantially. Established manufacturing companies have recognized that customers are not willing to pay large price premiums for incremental quality improvements. As a consequence, many companies from the German manufacturing industry adjust their production focusing on customized products and fast time to market. Leveraging the advantages of novel production strategies such as Agile Manufacturing and Mass Customization, manufacturing companies transform into integrated networks, in which companies unite their core competencies. Hereby, virtualization of the process- and supply-chain ensures smooth inter-company operations providing real-time access to relevant product and production information for all participating entities. Boundaries of companies deteriorate, as autonomous systems exchange data, gained by embedded systems throughout the entire value chain. By including Cyber-Physical-Systems, advanced communication between machines is tantamount to their dialogue with humans. The increasing utilization of information and communication technology allows digital engineering of products and production processes alike. Modular simulation and modeling techniques allow decentralized units to flexibly alter products and thereby enable rapid product innovation. The present article describes the developments of Industry 4.0 within the literature and reviews the associated research streams. Hereby, we analyze eight scientific journals with regards to the following research fields: Individualized production, end-to-end engineering in a virtual process chain and production networks. We employ cluster analysis to assign sub-topics into the respective research field. To assess the practical implications, we conducted face-to-face interviews with managers from the industry as well as from the consulting business using a structured interview guideline. The results reveal reasons for the adaption and refusal of Industry 4.0 practices from a managerial point of view. Our findings contribute to the upcoming research stream of Industry 4.0 and support decision-makers to assess their need for transformation towards Industry 4.0 practices.\n",
            "------------------------------------\n",
            "Title :  Physical Layer Security for Next Generation Wireless Networks: Theories, Technologies, and Challenges\n",
            "Author/s :  Yiliang Liu, Hsiao-Hwa Chen, Liangmin Wang\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2017\n",
            "Abstract :  Physical layer security (PHY-security) takes the advantages of channel randomness nature of transmission media to achieve communication confidentiality and authentication. Wiretap coding and signal processing technologies are expected to play vital roles in this new security mechanism. PHY-security has attracted a lot of attention due to its unique features and the fact that our daily life relies heavily on wireless communications for sensitive and private information transmissions. Compared to conventional cryptography that works to ensure all involved entities to load proper and authenticated cryptographic information, PHY-security technologies perform security functions without considering about how those security protocols are executed. In other words, it does not require to implement any extra security schemes or algorithms on other layers above the physical layer. This survey introduces the fundamental theories of PHY-security, covering confidentiality and authentication, and provides an overview on the state-of-the-art works on PHY-security technologies that can provide secure communications in wireless systems, along with the discussions on challenges and their proposed solutions. Furthermore, at the end of this paper, the open issues are identified as our future research directions.\n",
            "------------------------------------\n",
            "Title :  How Technology Is Changing Work and Organizations\n",
            "Author/s :  W. Cascio, Ramiro Montealegre\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four ...\n",
            "------------------------------------\n",
            "Title :  EltonTraits 1.0: Species-level foraging attributes of the world's birds and mammals\n",
            "Author/s :  H. Wilman, J. Belmaker, J. Simpson, C. Rosa, M. Rivadeneira, W. Jetz\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Species are characterized by physiological, behavioral, and ecological attributes that are all subject to varying evolutionary and ecological constraints and jointly determine species' role and function in ecosystems. Attributes such as diet, foraging strata, foraging time, and body size, in particular, characterize a large portion of the “Eltonian” niches of species. Here we present a global species-level compilation of these key attributes for all 9993 and 5400 extant bird and mammal species derived from key literature sources. Global handbooks and monographs allowed the consistent sourcing of attributes for most species. For diet and foraging stratum we followed a defined protocol to translate the verbal descriptions into standardized, semiquantitative information about relative importance of different categories. Together with body size (continuous) and activity time (categorical) this enables a much finer distinction of species' foraging ecology than typical categorical guild assignments allow. Attri...\n",
            "------------------------------------\n",
            "Title :  Machine Learning Models that Remember Too Much\n",
            "Author/s :  Congzheng Song, T. Ristenpart, Vitaly Shmatikov\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2017\n",
            "Abstract :  Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data. We consider a malicious ML provider who supplies model-training code to the data holder, does \\emph{not} observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that \"memorize\" information about the training dataset in the model\\textemdash yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data.\n",
            "------------------------------------\n",
            "Title :  Political Parties, Motivated Reasoning, and Public Opinion Formation\n",
            "Author/s :  Thomas J. Leeper, Rune Slothuus\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  A key characteristic of democratic politics is competition between groups, first of all political parties. Yet, the unavoidably partisan nature of political conflict has had too little influence on scholarship on political psychology. Despite more than 50 years of research on political parties and citizens, we continue to lack a systematic understanding of when and how political parties influence public opinion. We suggest that alternative approaches to political parties and public opinion can be best reconciled and examined through a richer theoretical perspective grounded in motivated reasoning theory. Clearly, parties shape citizens' opinions by mobilizing, influencing, and structuring choices among political alternatives. But the answer to when and how parties influence citizens' reasoning and political opinions depends on an interaction between citizens' motivations, effort, and information generated from the political environment (particularly through competition between parties). The contribution of motivated reasoning, as we describe it, is to provide a coherent theoretical framework for understanding partisan influence on citizens' political opinions. We review recent empirical work consistent with this framework. We also point out puzzles ripe for future research and discuss how partisan-motivated reasoning provides a useful point of departure for such work.\n",
            "------------------------------------\n",
            "Title :  RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems\n",
            "Author/s :  Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, M. Guo\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2018\n",
            "Abstract :  To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple \"ripples\" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.\n",
            "------------------------------------\n",
            "Title :  SpotFi: Decimeter Level Localization Using WiFi\n",
            "Author/s :  Manikanta Kotaru, K. Joshi, Dinesh Bharadia, S. Katti\n",
            "Venue :  Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication\n",
            "year :  2015\n",
            "Abstract :  This paper presents the design and implementation of SpotFi, an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes, yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First, SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second, it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath.\n",
            "------------------------------------\n",
            "Title :  Integrated Risk Information System\n",
            "Author/s :  Ord, Ncea, Irisd\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  EPA's Integrated Risk Information System (IRIS) is a human health assessment program that evaluates information on health effects that may result from exposure to environmental contaminants.\n",
            "------------------------------------\n",
            "Title :  Impact of Online Information on Self-Isolation Intention During the COVID-19 Pandemic: Cross-Sectional Study\n",
            "Author/s :  Ali Farooq, Samuli Laato, A. Islam\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background During the coronavirus disease (COVID-19) pandemic, governments issued movement restrictions and placed areas into quarantine to combat the spread of the disease. In addition, individuals were encouraged to adopt personal health measures such as social isolation. Information regarding the disease and recommended avoidance measures were distributed through a variety of channels including social media, news websites, and emails. Previous research suggests that the vast amount of available information can be confusing, potentially resulting in overconcern and information overload. Objective This study investigates the impact of online information on the individual-level intention to voluntarily self-isolate during the pandemic. Using the protection-motivation theory as a framework, we propose a model outlining the effects of cyberchondria and information overload on individuals’ perceptions and motivations. Methods To test the proposed model, we collected data with an online survey (N=225) and analyzed it using partial least square-structural equation modeling. The effects of social media and living situation were tested through multigroup analysis. Results Cyberchondria and information overload had a significant impact on individuals’ threat and coping perceptions, and through them on self-isolation intention. Among the appraisal constructs, perceived severity (P=.002) and self-efficacy (P=.003) positively impacted self-isolation intention, while response cost (P<.001) affected the intention negatively. Cyberchondria (P=.003) and information overload (P=.003) indirectly affected self-isolation intention through the aforementioned perceptions. Using social media as an information source increased both cyberchondria and information overload. No differences in perceptions were found between people living alone and those living with their families. Conclusions During COVID-19, frequent use of social media contributed to information overload and overconcern among individuals. To boost individuals’ motivation to adopt preventive measures such as self-isolation, actions should focus on lowering individuals’ perceived response costs in addition to informing them about the severity of the situation.\n",
            "------------------------------------\n",
            "Title :  A scoping review of rapid review methods\n",
            "Author/s :  A. Tricco, J. Antony, W. Zarin, L. Strifler, M. Ghassemi, J. Ivory, L. Perrier, B. Hutton, D. Moher, S. Straus\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Giving too much social support: social overload on social networking sites\n",
            "Author/s :  C. Maier, Sven Laumer, Andreas Eckhardt, Tim Weitzel\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Topic Aware Neural Response Generation\n",
            "Author/s :  Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, M. Zhou, Wei-Ying Ma\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  \n",
            " \n",
            " We consider incorporating topic information into a sequence-to-sequence framework to generate informative and interesting responses for chatbots. To this end, we propose a topic aware sequence-to-sequence (TA-Seq2Seq) model. The model utilizes topics to simulate prior human knowledge that guides them to form informative and interesting responses in conversation, and leverages topic information in generation by a joint attention mechanism and a biased generation probability. The joint attention mechanism summarizes the hidden vectors of an input message as context vectors by message attention and synthesizes topic vectors by topic attention from the topic words of the message obtained from a pre-trained LDA model, with these vectors jointly affecting the generation of words in decoding. To increase the possibility of topic words appearing in responses, the model modifies the generation probability of topic words by adding an extra probability item to bias the overall distribution. Empirical studies on both automatic evaluation metrics and human annotations show that TA-Seq2Seq can generate more informative and interesting responses, significantly outperforming state-of-the-art response generation models.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  A Survey of Physical Layer Security Techniques for 5G Wireless Networks and Challenges Ahead\n",
            "Author/s :  Yongpeng Wu, A. Khisti, Chengshan Xiao, G. Caire, Kai‐Kit Wong, Xiqi Gao\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2018\n",
            "Abstract :  Physical layer security which safeguards data confidentiality based on the information-theoretic approaches has received significant research interest recently. The key idea behind physical layer security is to utilize the intrinsic randomness of the transmission channel to guarantee the security in physical layer. The evolution toward 5G wireless communications poses new challenges for physical layer security research. This paper provides a latest survey of the physical layer security research on various promising 5G technologies, including physical layer security coding, massive multiple-input multiple-output, millimeter wave communications, heterogeneous networks, non-orthogonal multiple access, full duplex technology, and so on. Technical challenges which remain unresolved at the time of writing are summarized and the future trends of physical layer security in 5G and beyond are discussed.\n",
            "------------------------------------\n",
            "Title :  Graph Convolutional Matrix Completion\n",
            "Author/s :  Rianne van den Berg, Thomas Kipf, M. Welling\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Understanding the Factors That Influence the Adoption and Meaningful Use of Social Media by Physicians to Share Medical Information\n",
            "Author/s :  B. Mcgowan, M. Wasko, B. Vartabedian, Robert S. Miller, Desirae D Freiherr, M. Abdolrasulnia\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2012\n",
            "Abstract :  Background Within the medical community there is persistent debate as to whether the information available through social media is trustworthy and valid, and whether physicians are ready to adopt these technologies and ultimately embrace them as a format for professional development and lifelong learning. Objective To identify how physicians are using social media to share and exchange medical information with other physicians, and to identify the factors that influence physicians’ use of social media as a component of their lifelong learning and continuing professional development. Methods We developed a survey instrument based on the Technology Acceptance Model, hypothesizing that technology usage is best predicted by a physician’s attitudes toward the technology, perceptions about the technology’s usefulness and ease of use, and individual factors such as personal innovativeness. The survey was distributed via email to a random sample of 1695 practicing oncologists and primary care physicians in the United States in March 2011. Responses from 485 physicians were analyzed (response rate 28.61%). Results Overall, 117 of 485 (24.1%) of respondents used social media daily or many times daily to scan or explore medical information, whereas 69 of 485 (14.2%) contributed new information via social media on a daily basis. On a weekly basis or more, 296 of 485 (61.0%) scanned and 223 of 485 (46.0%) contributed. In terms of attitudes toward the use of social media, 279 of 485 respondents (57.5%) perceived social media to be beneficial, engaging, and a good way to get current, high-quality information. In terms of usefulness, 281 of 485 (57.9%) of respondents stated that social media enabled them to care for patients more effectively, and 291 of 485 (60.0%) stated it improved the quality of patient care they delivered. The main factors influencing a physician’s usage of social media to share medical knowledge with other physicians were perceived ease of use and usefulness. Respondents who had positive attitudes toward the use of social media were more likely to use social media and to share medical information with other physicians through social media. Neither age nor gender had a significant impact on adoption or usage of social media. Conclusions Based on the results of this study, the use of social media applications may be seen as an efficient and effective method for physicians to keep up-to-date and to share newly acquired medical knowledge with other physicians within the medical community and to improve the quality of patient care. Future studies are needed to examine the impact of the meaningful use of social media on physicians’ knowledge, attitudes, skills, and behaviors in practice.\n",
            "------------------------------------\n",
            "Title :  Organizations' Information Security Policy Compliance: Stick or Carrot Approach?\n",
            "Author/s :  Yan Chen, K. Ramamurthy, Kuang-Wei Wen\n",
            "Venue :  Journal of Management Information Systems\n",
            "year :  2012\n",
            "Abstract :  Companies' information security efforts are often threatened by employee negligence and insider breach. To deal with these insider issues, this study draws on the compliance theory and the general deterrence theory to propose a research model in which the relations among coercive control, which has been advocated by scholars and widely practiced by companies; remunerative control, which is generally missing in both research and practice; and certainty of control are studied. A Web-based field experiment involving real-world employees in their natural settings was used to empirically test the model. While lending further support to the general deterrence theory, our findings highlight that reward enforcement, a remunerative control mechanism in the information systems security context, could be an alternative for organizations where sanctions do not successfully prevent violation. The significant interactions between punishment and reward found in the study further indicate a need for a more comprehensive enforcement system that should include a reward enforcement scheme through which the organizational moral standards and values are established or reemphasized. The findings of this study can potentially be used to guide the design of more effective security enforcement systems that encompass remunerative control mechanisms.\n",
            "------------------------------------\n",
            "Title :  Comprehending and Learning From Internet Sources: Processing Patterns of Better and Poorer Learners\n",
            "Author/s :  S. Goldman, Jason L. G. Braasch, J. Wiley, A. Graesser, Kamila Brodowinska\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Readers increasingly attempt to understand and learn from information sources they find on the Internet. Doing so highlights the crucial role that evaluative processes play in selecting and making sense of the information. In a prior study, Wiley et al. (2009, Experiment 1) asked undergraduates to perform a web-based inquiry task about volcanoes using multiple Internet sources. A major finding established a clear link between learning outcomes, source evaluations, and reading behaviors. The present study used think-aloud protocol methodology to better understand the processing that learners engaged in during this task: 10 better learners were contrasted with 11 poorer learners. Results indicate that better learners engaged in more sense-making, self-explanation, and comprehension-monitoring processes on reliable sites as compared with unreliable sites, and did so by a larger margin than did poorer learners. Better learners also engaged in more goal-directed navigation than poorer learners. Case studies of two better and two poorer learners further illustrate how evaluation processes contributed to navigation decisions. Findings suggest that multiple-source comprehension is a dynamic process that involves interplay among sense-making, monitoring, and evaluation processes, all of which promote strategic reading. \n",
            " \n",
            " \n",
            " \n",
            "阅读者日益想要弄明白及学习他们从互联网上各种来源所找到的信息资料。他们这样做突显出在选择和弄明白这些信息时评价过程所起的重要作用。威立等人在以前一项研究(2009,实验1)中,参与研究的大学生要利用互联网多种资源来完成一项关于火山的網路探究式学习任务。该研究的一个主要结果是建立了学习成果、信息来源评价与阅读行为之间的明确联系。本研究则使用有声思维研究方法,以深入考查学习者在参与同一个学习任务时他们处理信息的过程,并以10名表现较好的与11名表现较差的学习者作比对。结果显示,对于可靠网站上的资料,表现较好的学习者较多致力于弄明白自我解释的过程和理解监控的过程,而对于不可靠网站上的资料,这种行为则较少;他们这种行为亦远多于表现较差的学习者。此外,表现较好的学习者比表现较差的学习者较多致力于有目标的网上浏览。两个表现较好及两个表现较差的学习者的案例研究,进一步说明评价过程如何有助于在网上浏览时所作的决定。本研究结果显示,理解多种来源的信息是一个动态的过程,其中涉及弄明白、监控和评价过程之间的相互作用,而这些过程均能促进策略性阅读。 \n",
            " \n",
            " \n",
            " \n",
            "Es cada vez mas comun que lectores intenten entender y aprender de fuentes de informacion del Internet. Esto demuestra el rol crucial que los procesos de evaluacion tienen en seleccionar y sacar sentido de la informacion recibida. En un estudio anterior, Wiley et al. (2009, Experiment 1) les pidieron a subgraduados que hicieran una busqueda en la red sobre volcanes usando multiples fuentes del Internet. Un resultado clave establecio una conexion clara entre los resultados del aprendizaje, la evaluacion de las fuentes, y la manera de leer. El presente estudio uso la metodologia del protocolo de pensar en voz alta para mejor entender los procesos usados por los aprendices al cumplir dicha tarea: se compararon 10 aprendices mejores con 11 aprendices pobres. Los resultados senalan que los mejores aprendices buscaban sus propias explicaciones que hicieran sentido y procesos de monitoreo de comprension en sitios confiables comparados con los sitios que no eran confiables, y lo hacian con un margen mayor que los aprendices pobres. Un estudio de casos de dos mejores y dos pobres aprendices ilustran aun mas como los procesos de evaluacion contribuian al proceso de navegacion. Los resultados sugieren que la comprension de multiples fuentes es un proceso dinamico que requiere interaccion entre los procesos de hacer sentido, monitoreo, y evaluacion, todos de los cuales promulgan la lectura estrategica. \n",
            " \n",
            " \n",
            " \n",
            "يحاول القراء بشكل متزايد الفهم والتعلم من مصادر المعلومات التي يجدونها على شبكة الإنترنيت؛ وبذلك فهذا يسلط الضوء على الدور الحاسم الذي تلعبه عمليات التقييم في اختيار وإعطاء معنى للمعلومات. وفي دراسة سابقة طلب “وايلي” وآخرون (التجربة١،٢٠٠٩) من الطلبة الجامعيين إجراء بحث على شبكة الإنترنيت حول البراكين مستخدمين مصادر إنترنيت متعددة.تم التوصل إلى نتيجة رئيسية تقوم على أن هناك صلة واضحة بين التعلم وتقييمات المصدر وسلوكيات القراءة. استخدمت الدراسة الحالية منهجية بروتوكول التفكيير بصوت عال لفهم بشكل أفضل العمليات التي استخدمها المتعلمون أثناء هذه المهمة: تمت مقارنة ١٠من أفضل المتعلمين ب١١من أضعف المتعلمين. تشير النتائج إلى أن أفضل المتعلمين استخدموا عمليات أكثر في إعطاء معنى للتفسير الذاتي ومراقبة الفهم على مواقع موثوق بها بالمقارنة مع مواقع غير موثوق بها وفعلوا ذلك أكثر من أضعف المتعلمين. كما أن أفضل المتعلمين قد قاموا بالبحث على أهدافهم عبر الإنترنيت بصورة مباشرة. وتوضح كذلك دراسة الحالة لأفضل متعلمين وأضعف متعلمين كيف ساهمت عمليات التقييم في قرارات البحث عبر الإنترنيت. تشير النتائج إلى أن فهم المصادر المتعددة عملية فعالة تشمل التفاعل المتبادل بين إعطاء المعنى والمراقبة وعملية التقييم، وكل منها تنمي القراءة الاستراتيجية. \n",
            " \n",
            " \n",
            " \n",
            "Читaющиe люди вce чaщe oбpaщaютcя к интepнeтy кaк к иcтoчникy инфopмaции. Oднaкo, для eeгpaмoтнoгo oтбopa ивocпpиятиякpaйнeвaжнo yмeть oцeнить эти иcтoчники. B paнee пpoвeдeнныx иccлeдoвaнияx (Wiley и дp., 2009, Экcпepимeнт 1) yчeныe пpeдлoжили cтyдeнтaм млaдшиx кypcoв пoиcкaть мaтepиaл o вyлкaнax пo paзличныминтepнeт-caйтaм. B итoгe выявилacь пpямaя cвязь мeждy peзyльтaтaми yчeбнoй дeятeльнocти, yмeниeм oцeнить иcтoчники и caмим пoвeдeниeм cтyдeнтoв-читaтeлeй. B нacтoящeмиccлeдoвaнии, чтoбы лyчшe пoнять, кaк пpoиcxoдит пpoцecc oцeнивaния, иcпoльзoвaлcя мeтoд “paзмышлeниe вcлyx”, и cpaвнивaлиcь paзмышлeния дecяти лyчшиx и дecяти нaибoлee cлaбыx yчaщиxcя. Peзyльтaты пoкaзывaют, чтo cильныe yчaщиecя знaчитeльнo чaщe paбoтaют c нaдeжными caйтaми, бoльшe зaнимaютcя aнaлизoм инфopмaции и кoнтpoлиpyют coбcтвeннoe ocмыcлeниe пpoчитaннoгo. Кpoмe тoгo, caм пpoцecc иx ceтeвoгo пoиcкa бoлee цeлeнaпpaвлeн, чeм дeятeльнocть cлaбыx yчaщиxcя. B кaчecтвe иллюcтpaции oпиcaн пpoцecc oцeнивaния иcтoчникoв и cooтвeтcтвyющaя eмy тpaeктopия пoиcкa для двyx cильныx и двyx cлaбыx yчaщиxcя. Aвтopы пoлaгaют, чтo вocпpиятиe инфopмaции из мнoжecтвa иcтoчникoв – динaмичный пpoцecc, кoтopый coчeтaeт в ceбe вoccoздaниe нoвыx для читaтeля cмыcлoв, a тaкжe мoнитopинг и oцeнивaниe пpoцeccoв пoзнaния, чтo в coвoкyпнocти paзвивaeт нaвыки cтpaтeгичecкoгo чтeния. \n",
            " \n",
            " \n",
            " \n",
            "Les lecteurs essaient de plus en plus de comprendre et d'apprendre au moyen de sources d'information qu'ils trouvent sur Internet. Cette pratique souligne le role crucial que jouent les processus d’evaluation lors de la selection de l'information et du sens qu'on lui donne. Dans une etude precedente, Wiley et al. (2009, premiere experience) ont demande a des etudiants de premier cycle d'effectuer sur la Toile une recherche sur les volcans en utilisant plusieurs sources d'Internet. Des liens sont apparus clairement entre les resultats obtenus, les evaluations des sources et les comportements de lecture. L’etude presentee ici a utilise la methodologie du protocole consistant a penser a haute voix pour mieux comprendre la facon de proceder des lecteurs lors de cette tâche, ceci avec 10 eleves de bon niveau contrastes a 11 eleves de niveau faible. Les resultats montrent que les meilleurs eleves s'engagent dans des processus d'auto-explication de recherche du sens et de pilotage de la comprehension sur des sites plus fiables que d'autres, et qu'ils procedent ainsi plus largement que les moins bons eleves. Les meilleurs eleves sont aussi plus engages dans une navigation avec but que les moins bons eleves. L’etude de cas de deux bons eleves et de deux faibles permettant de mieux illustrer encore comment les processus d’evaluation contribuent aux decisions de navigation. Les resultats suggerent que la comprehension de sources multiples est un processus dynamique qui implique des interactions entre l'attribution de sens, le pilotage, et les processus d’evaluation, tous ces elements contribuant a une lecture strategique.\n",
            "------------------------------------\n",
            "Title :  Recurrent Convolutional Network for Video-Based Person Re-identification\n",
            "Author/s :  Niall McLaughlin, J. M. D. Rincón, P. Miller\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2016\n",
            "Abstract :  In this paper we propose a novel recurrent neural network architecture for video-based person re-identification. Given the video sequence of a person, features are extracted from each frame using a convolutional neural network that incorporates a recurrent final layer, which allows information to flow between time-steps. The features from all timesteps are then combined using temporal pooling to give an overall appearance feature for the complete sequence. The convolutional network, recurrent layer, and temporal pooling layer, are jointly trained to act as a feature extractor for video-based re-identification using a Siamese network architecture. Our approach makes use of colour and optical flow information in order to capture appearance and motion information which is useful for video re-identification. Experiments are conduced on the iLIDS-VID and PRID-2011 datasets to show that this approach outperforms existing methods of video-based re-identification.\n",
            "------------------------------------\n",
            "Title :  Knowledge Graph Convolutional Networks for Recommender Systems\n",
            "Author/s :  Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, M. Guo\n",
            "Venue :  The Web Conference\n",
            "year :  2019\n",
            "Abstract :  To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.\n",
            "------------------------------------\n",
            "Title :  Data-Driven Techniques in Disaster Information Management\n",
            "Author/s :  Tao Li, Ning Xie, Chunqiu Zeng, Wubai Zhou, Li Zheng, Yexi Jiang, Yimin Yang, Hsin-Yu Ha, Wei Xue, Yue Huang, Shu‐Ching Chen, J. Navlakha, S. S. Iyengar\n",
            "Venue :  ACM Computing Surveys\n",
            "year :  2017\n",
            "Abstract :  Improving disaster management and recovery techniques is one of national priorities given the huge toll caused by man-made and nature calamities. Data-driven disaster management aims at applying advanced data collection and analysis technologies to achieve more effective and responsive disaster management, and has undergone considerable progress in the last decade. However, to the best of our knowledge, there is currently no work that both summarizes recent progress and suggests future directions for this emerging research area. To remedy this situation, we provide a systematic treatment of the recent developments in data-driven disaster management. Specifically, we first present a general overview of the requirements and system architectures of disaster management systems and then summarize state-of-the-art data-driven techniques that have been applied on improving situation awareness as well as in addressing users’ information needs in disaster management. We also discuss and categorize general data-mining and machine-learning techniques in disaster management. Finally, we recommend several research directions for further investigations.\n",
            "------------------------------------\n",
            "Title :  Table of Pharmacogenomic Biomarkers in Drug Labeling\n",
            "Author/s :  \n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Pharmacogenomics can play an important role in identifying responders and non-responders to medications, avoiding adverse events, and optimizing drug dose. Drug ÙH labeling may contain information on genomic biomarkers and can describe: ? Drug exposure and clinical response variabilityeling ? Risk for adverse events ? Genotype-specific dosing strationl Ther ? Mechanisms of drug actionstrationl Ther ? Polymorphic drug target and disposition genes The table below lists FDA-approved drugs with pharmacogenomic information in their labeling. The labeling for some, but not all, of the products includes specific actions to be taken based on the biomarker information. Pharmacogenomic information can appear in different sections of the labeling depending on the actions. For more ÙH information, please refer to the appropriate labeling guidance. Biomarkers in the table include but are not limited to germ-line or somatic gene variants, functional deficiencies, expression changes, and chromosomal abnormalities; selected protein biomarkers that are used to select patients for treatment are also included. This table does not include non-human genetic biomarkers (e.g., microbial variants that influence sensitivity to antibiotics),; or biomarkers that are used solely for diagnostic purposes (e.g., for genetic diseases) unless they are linked to drug activity or used to identify a specific subset in whom prescribing information differs.\n",
            "------------------------------------\n",
            "Title :  Sustainability reports as simulacra? A counter-account of A and A+ GRI reports\n",
            "Author/s :  O. Boiral\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Purpose - – The purpose of this paper is to examine the extent to which sustainability reporting can be viewed as a simulacrum used to camouflage real sustainable-development problems and project an idealized view of the firms' situations. Design/methodology/approach - – The method was based on the content analysis and counter accounting of 23 sustainability reports from firms in the energy and mining sectors which had received application levels of A or A+ from the Global Reporting Initiative (GRI). The information disclosed in some 2,700 pages of reports was structured around 92 GRI indicators and compared with 116 significant news events that clearly addressed the responsibility of these firms in sustainable development problems. Moreover, the 1,258 pictures included in sustainability reports were categorized into recurring themes from an inductive perspective. Findings - – A total of 90 per cent of the significant negative events were not reported, contrary to the principles of balance, completeness and transparency of GRI reports. Moreover, the pictures included in these reports showcase various simulacra clearly disconnected with the impact of business activities. Originality/value - – The paper shows the relevance of the counter accounting approach in assessing the quality of sustainability reports and question the reliability of the GRI's A or A+ application levels. It contributes to debates concerning the transparency of sustainability reports in light of Debord's and Baudrillard's critical perspective. The paper reveals the underexplored role of images in the emergence of several types of simulacra.\n",
            "------------------------------------\n",
            "Title :  The New Ambiguity of 'Open Government'\n",
            "Author/s :  Harlan Yu, Harlan Yu, Harlan Yu, D. G. Robinson\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  “Open government” used to carry a hard political edge: it referred to politically sensitive disclosures of government information. The phrase was first used in the 1950s, in the debates leading up to passage of the Freedom of Information Act. But over the last few years, that traditional meaning has blurred, and has shifted toward technology. Open technologies involve sharing data over the Internet, and all kinds of governments can use them, for all kinds of reasons. Recent public policies have stretched the label “open government” to reach any public sector use of these technologies. Thus, “open government data” might refer to data that makes the government as a whole more open (that is, more accountable to the public), but might equally well refer to politically neutral public sector disclosures that are easy to reuse, but that may have nothing to do with public accountability. Today a regime can call itself “open” if it builds the right kind of web site — even if it does not become more accountable. This shift in vocabulary makes it harder for policymakers and activists to articulate clear priorities and make cogent demands.This essay proposes a more useful way for participants on all sides to frame the debate: We separate the politics of open government from the technologies of open data. Technology can make public information more adaptable, empowering third parties to contribute in exciting new ways across many aspects of civic life. But technological enhancements will not resolve debates about the best priorities for civic life, and enhancements to government services are no substitute for public accountability.\n",
            "------------------------------------\n",
            "Title :  Tri-Party Deep Network Representation\n",
            "Author/s :  Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang\n",
            "Venue :  International Joint Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  WiFall: Device-free fall detection by wireless networks\n",
            "Author/s :  Yuxi Wang, Kaishun Wu, L. Ni\n",
            "Venue :  IEEE Conference on Computer Communications\n",
            "year :  2017\n",
            "Abstract :  The world population is in the midst of a unique and irreversible process of aging. Fall, which is one of the major health threats and obstacles to independent living of elders, will aggravate the global pressure in elders' health care and injury rescue. Thus, automatic fall detection is highly in need. Current proposed fall detection systems either need hardware installation or disrupt people's daily life. These limitations make it hard to widely deploy fall detection systems in residential settings. In this work, we analyze the wireless signal propagation model considering human activities influence. We then propose a novel and truly unobtrusive detection method based on the advanced wireless technologies, which we call as WiFall. WiFall employs the time variability and special diversity of Channel State Information (CSI) as the indicator of human activities. As CSI is readily available in prevalent in-use wireless infrastructures, WiFall withdraws the need for hardware modification, environmental setup and worn or taken devices. We implement WiFall on laptops equipped with commercial 802.11n NICs. Two typical indoor scenarios and several layout schemes are examined. As demonstrated by the experimental results, WiFall yielded 87% detection precision with false alarm rate of 18% in average.\n",
            "------------------------------------\n",
            "Title :  Mobile Health (mHealth) Approaches and Lessons for Increased Performance and Retention of Community Health Workers in Low- and Middle-Income Countries: A Review\n",
            "Author/s :  Karin Källander, J. Tibenderana, O. Akpogheneta, D. Strachan, Z. Hill, A. T. ten Asbroek, L. Conteh, B. Kirkwood, S. Meek\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background Mobile health (mHealth) describes the use of portable electronic devices with software applications to provide health services and manage patient information. With approximately 5 billion mobile phone users globally, opportunities for mobile technologies to play a formal role in health services, particularly in low- and middle-income countries, are increasingly being recognized. mHealth can also support the performance of health care workers by the dissemination of clinical updates, learning materials, and reminders, particularly in underserved rural locations in low- and middle-income countries where community health workers deliver integrated community case management to children sick with diarrhea, pneumonia, and malaria. Objective Our aim was to conduct a thematic review of how mHealth projects have approached the intersection of cellular technology and public health in low- and middle-income countries and identify the promising practices and experiences learned, as well as novel and innovative approaches of how mHealth can support community health workers. Methods In this review, 6 themes of mHealth initiatives were examined using information from peer-reviewed journals, websites, and key reports. Primary mHealth technologies reviewed included mobile phones, personal digital assistants (PDAs) and smartphones, patient monitoring devices, and mobile telemedicine devices. We examined how these tools could be used for education and awareness, data access, and for strengthening health information systems. We also considered how mHealth may support patient monitoring, clinical decision making, and tracking of drugs and supplies. Lessons from mHealth trials and studies were summarized, focusing on low- and middle-income countries and community health workers. Results The review revealed that there are very few formal outcome evaluations of mHealth in low-income countries. Although there is vast documentation of project process evaluations, there are few studies demonstrating an impact on clinical outcomes. There is also a lack of mHealth applications and services operating at scale in low- and middle-income countries. The most commonly documented use of mHealth was 1-way text-message and phone reminders to encourage follow-up appointments, healthy behaviors, and data gathering. Innovative mHealth applications for community health workers include the use of mobile phones as job aides, clinical decision support tools, and for data submission and instant feedback on performance. Conclusions With partnerships forming between governments, technologists, non-governmental organizations, academia, and industry, there is great potential to improve health services delivery by using mHealth in low- and middle-income countries. As with many other health improvement projects, a key challenge is moving mHealth approaches from pilot projects to national scalable programs while properly engaging health workers and communities in the process. By harnessing the increasing presence of mobile phones among diverse populations, there is promising evidence to suggest that mHealth can be used to deliver increased and enhanced health care services to individuals and communities, while helping to strengthen health systems.\n",
            "------------------------------------\n",
            "Title :  InfoVAE: Information Maximizing Variational Autoencoders\n",
            "Author/s :  Shengjia Zhao, Jiaming Song, S. Ermon\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.\n",
            "------------------------------------\n",
            "Title :  Fundamentals of Wireless Information and Power Transfer: From RF Energy Harvester Models to Signal and System Designs\n",
            "Author/s :  B. Clerckx, Rui Zhang, R. Schober, Derrick Wing Kwan Ng, Dong In Kim, H. Poor\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2018\n",
            "Abstract :  Radio waves carry both energy and information simultaneously. Nevertheless, radio-frequency (RF) transmissions of these quantities have traditionally been treated separately. Currently, the community is experiencing a paradigm shift in wireless network design, namely, unifying wireless transmission of information and power so as to make the best use of the RF spectrum and radiation as well as the network infrastructure for the dual purpose of communicating and energizing. In this paper, we review and discuss recent progress in laying the foundations of the envisioned dual purpose networks by establishing a signal theory and design for wireless information and power transmission (WIPT) and identifying the fundamental tradeoff between conveying information and power wirelessly. We start with an overview of WIPT challenges and technologies, namely, simultaneous WIPT (SWIPT), wirelessly powered communication networks (WPCNs), and wirelessly powered backscatter communication (WPBC). We then characterize energy harvesters and show how WIPT signal and system designs crucially revolve around the underlying energy harvester model. To that end, we highlight three different energy harvester models, namely, one linear model and two nonlinear models, and show how WIPT designs differ for each of them in single-user and multi-user deployments. Topics discussed include rate-energy region characterization, transmitter and receiver architectures, waveform design, modulation, beamforming and input distribution optimizations, resource allocation, and RF spectrum use. We discuss and check the validity of the different energy harvester models and the resulting signal theory and design based on circuit simulations, prototyping, and experimentation. We also point out numerous directions that are promising for future research.\n",
            "------------------------------------\n",
            "Title :  Electronic Health Records: Then, Now, and in the Future.\n",
            "Author/s :  R. Evans\n",
            "Venue :  Yearbook of medical informatics\n",
            "year :  2016\n",
            "Abstract :  OBJECTIVES\n",
            "Describe the state of Electronic Health Records (EHRs) in 1992 and their evolution by 2015 and where EHRs are expected to be in 25 years. Further to discuss the expectations for EHRs in 1992 and explore which of them were realized and what events accelerated or disrupted/derailed how EHRs evolved.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Literature search based on \"Electronic Health Record\", \"Medical Record\", and \"Medical Chart\" using Medline, Google, Wikipedia Medical, and Cochrane Libraries resulted in an initial review of 2,356 abstracts and other information in papers and books. Additional papers and books were identified through the review of references cited in the initial review.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "By 1992, hardware had become more affordable, powerful, and compact and the use of personal computers, local area networks, and the Internet provided faster and easier access to medical information. EHRs were initially developed and used at academic medical facilities but since most have been replaced by large vendor EHRs. While EHR use has increased and clinicians are being prepared to practice in an EHR-mediated world, technical issues have been overshadowed by procedural, professional, social, political, and especially ethical issues as well as the need for compliance with standards and information security. There have been enormous advancements that have taken place, but many of the early expectations for EHRs have not been realized and current EHRs still do not meet the needs of today's rapidly changing healthcare environment.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The current use of EHRs initiated by new technology would have been hard to foresee. Current and new EHR technology will help to provide international standards for interoperable applications that use health, social, economic, behavioral, and environmental data to communicate, interpret, and act intelligently upon complex healthcare information to foster precision medicine and a learning health system.\n",
            "------------------------------------\n",
            "Title :  Dual-Function Radar-Communications: Information Embedding Using Sidelobe Control and Waveform Diversity\n",
            "Author/s :  A. Hassanien, M. Amin, Yimin D. Zhang, F. Ahmad\n",
            "Venue :  IEEE Transactions on Signal Processing\n",
            "year :  2016\n",
            "Abstract :  We develop a new technique for a dual-function system with joint radar and communication platforms. Sidelobe control of the transmit beamforming in tandem with waveform diversity enables communication links using the same pulse radar spectrum. Multiple simultaneously transmitted orthogonal waveforms are used for embedding a sequence of LB bits during each radar pulse. Two weight vectors are designed to achieve two transmit spatial power distribution patterns, which have the same main radar beam, but differ in sidelobe levels towards the intended communication receivers. The receiver interpretation of the bit is based on its radiated beam. The proposed technique allows information delivery to single or multiple communication directions outside the mainlobe of the radar. It is shown that the communication process is inherently secure against intercept from directions other than the pre-assigned communication directions. The employed waveform diversity scheme supports a multiple-input multiple-output radar operation mode. The performance of the proposed technique is investigated in terms of the bit error rate.\n",
            "------------------------------------\n",
            "Title :  A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\n",
            "Author/s :  A. Casali, O. Gosseries, M. Rosanova, M. Boly, S. Sarasso, K. Casali, S. Casarotto, M. Bruno, Steven Laureys, G. Tononi, M. Massimini\n",
            "Venue :  Science Translational Medicine\n",
            "year :  2013\n",
            "Abstract :  A theory-derived index of consciousness, which quantifies the complexity of the brain’s response to a stimulus, measures the level of consciousness in awake, sleeping, anesthetized, and brain-damaged subjects. Quantifying the Unquantifiable Manipulation of consciousness is an everyday medical trick—think anesthesia—but physicians have only the crudest of tools to detect when a person is not aware. The usual question or physical stimulus does not always provide reliable reactions, and a more precise index is needed to avoid, for example, the conclusion that people who have locked-in syndrome (in which they are aware but cannot respond) are unconscious. Here, Casali et al. have extended their previous work on electrical correlates of consciousness to define an electroencephalographic-derived index of human consciousness [the perturbational complexity index (PCI)] that reflects the information content of the brain’s response to a magnetic stimulus. The PCI could allow tracking of consciousness in individual patients. The authors used data already collected from previous experiments, in which they had stimulated people’s brains with transcranial magnetic stimulation. By calculating the likely brain regional sources of the signals and then comparing the unique information in each, the authors derived PCI values. The values ranged from 0.44 to 0.67 in 32 awake healthy people, but fell to 0.18 to 0.28 during nonrapid eye movement (NREM) sleep. Then, to see whether a completely different way of inducing unconsciousness had the same effect on PCI, the authors assessed data from patients given various amounts of the anesthetics midazolam, xenon, and propofol. These agents too caused low “unconscious” values for the PCI: midazolam deep sedation, 0.23 to 0.31; propofol, 0.13 to 0.30; and xenon, 0.12 to 0.31. However, what about patients who suffer brain damage and who exhibit various levels of consciousness by conventional assessment methods? In these people, consciousness varies widely, as does the underlying damage from stroke or trauma. Here, too, the authors found promising results in those who had emerged from coma but were in a vegetative state or minimally conscious state, or exhibited locked-in syndrome. The PCI values from these patients clearly reflected the state of their consciousness, with the six patients in a vegetative state clearly unconscious (0.19 to 0.31), the two with locked-in syndrome clearly aware (0.51 to 0.62), and those in a minimally conscious state showing intermediate values (0.32 to 0.49). The validity of PCI for clinical application will need to be assessed in prospective trials, but it has the advantage of being derived from a simple noninvasive measurement. The new index reported by Casali et al. appears to be a robust measure that distinguishes conscious from unconscious states well enough to be used on an individual basis, a prerequisite for deployment in the clinic. One challenging aspect of the clinical assessment of brain-injured, unresponsive patients is the lack of an objective measure of consciousness that is independent of the subject’s ability to interact with the external environment. Theoretical considerations suggest that consciousness depends on the brain’s ability to support complex activity patterns that are, at once, distributed among interacting cortical areas (integrated) and differentiated in space and time (information-rich). We introduce and test a theory-driven index of the level of consciousness called the perturbational complexity index (PCI). PCI is calculated by (i) perturbing the cortex with transcranial magnetic stimulation (TMS) to engage distributed interactions in the brain (integration) and (ii) compressing the spatiotemporal pattern of these electrocortical responses to measure their algorithmic complexity (information). We test PCI on a large data set of TMS-evoked potentials recorded in healthy subjects during wakefulness, dreaming, nonrapid eye movement sleep, and different levels of sedation induced by anesthetic agents (midazolam, xenon, and propofol), as well as in patients who had emerged from coma (vegetative state, minimally conscious state, and locked-in syndrome). PCI reliably discriminated the level of consciousness in single individuals during wakefulness, sleep, and anesthesia, as well as in patients who had emerged from coma and recovered a minimal level of consciousness. PCI can potentially be used for objective determination of the level of consciousness at the bedside.\n",
            "------------------------------------\n",
            "Title :  The Ease of Language Understanding (ELU) model: theoretical, empirical, and clinical advances\n",
            "Author/s :  J. Rönnberg, T. Lunner, A. Zekveld, Patrik Sörqvist, H. Danielsson, B. Lyxell, Ö. Dahlström, Carine Signoret, S. Stenfelt, M. Pichora-Fuller, M. Rudner\n",
            "Venue :  Frontiers in Systems Neuroscience\n",
            "year :  2013\n",
            "Abstract :  Working memory is important for online language processing during conversation. We use it to maintain relevant information, to inhibit or ignore irrelevant information, and to attend to conversation selectively. Working memory helps us to keep track of and actively participate in conversation, including taking turns and following the gist. This paper examines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg, 2003; Rönnberg et al., 2008) in light of new behavioral and neural findings concerning the role of working memory capacity (WMC) in uni-modal and bimodal language processing. The new ELU model is a meaning prediction system that depends on phonological and semantic interactions in rapid implicit and slower explicit processing mechanisms that both depend on WMC albeit in different ways. It is based on findings that address the relationship between WMC and (a) early attention processes in listening to speech, (b) signal processing in hearing aids and its effects on short-term memory, (c) inhibition of speech maskers and its effect on episodic long-term memory, (d) the effects of hearing impairment on episodic and semantic long-term memory, and finally, (e) listening effort. New predictions and clinical implications are outlined. Comparisons with other WMC and speech perception models are made.\n",
            "------------------------------------\n",
            "Title :  Photonic quantum information processing: a review\n",
            "Author/s :  F. Flamini, N. Spagnolo, F. Sciarrino\n",
            "Venue :  Reports on progress in physics. Physical Society\n",
            "year :  2018\n",
            "Abstract :  Photonic quantum technologies represent a promising platform for several applications, ranging from long-distance communications to the simulation of complex phenomena. Indeed, the advantages offered by single photons do make them the candidate of choice for carrying quantum information in a broad variety of areas with a versatile approach. Furthermore, recent technological advances are now enabling first concrete applications of photonic quantum information processing. The goal of this manuscript is to provide the reader with a comprehensive review of the state of the art in this active field, with a due balance between theoretical, experimental and technological results. When more convenient, we will present significant achievements in tables or in schematic figures, in order to convey a global perspective of the several horizons that fall under the name of photonic quantum information.\n",
            "------------------------------------\n",
            "Title :  Electronic Health Records: Then, Now, and in the Future.\n",
            "Author/s :  R. Evans\n",
            "Venue :  Yearbook of medical informatics\n",
            "year :  2016\n",
            "Abstract :  OBJECTIVES\n",
            "Describe the state of Electronic Health Records (EHRs) in 1992 and their evolution by 2015 and where EHRs are expected to be in 25 years. Further to discuss the expectations for EHRs in 1992 and explore which of them were realized and what events accelerated or disrupted/derailed how EHRs evolved.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Literature search based on \"Electronic Health Record\", \"Medical Record\", and \"Medical Chart\" using Medline, Google, Wikipedia Medical, and Cochrane Libraries resulted in an initial review of 2,356 abstracts and other information in papers and books. Additional papers and books were identified through the review of references cited in the initial review.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "By 1992, hardware had become more affordable, powerful, and compact and the use of personal computers, local area networks, and the Internet provided faster and easier access to medical information. EHRs were initially developed and used at academic medical facilities but since most have been replaced by large vendor EHRs. While EHR use has increased and clinicians are being prepared to practice in an EHR-mediated world, technical issues have been overshadowed by procedural, professional, social, political, and especially ethical issues as well as the need for compliance with standards and information security. There have been enormous advancements that have taken place, but many of the early expectations for EHRs have not been realized and current EHRs still do not meet the needs of today's rapidly changing healthcare environment.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The current use of EHRs initiated by new technology would have been hard to foresee. Current and new EHR technology will help to provide international standards for interoperable applications that use health, social, economic, behavioral, and environmental data to communicate, interpret, and act intelligently upon complex healthcare information to foster precision medicine and a learning health system.\n",
            "------------------------------------\n",
            "Title :  Information Sharing and Financial Sector Development in Africa\n",
            "Author/s :  Vanessa S. Tchamyou, S. Asongu\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  ABSTRACT This study investigates the effect information sharing has on financial sector development in 53 African countries for the period 2004 to 2011. Information sharing is measured with private credit bureaus and public credit registries. Hitherto unexplored dimensions of financial sector development are employed, namely: financial sector dynamics of formalization, informalization, and non-formalization. The empirical evidence is based on Ordinary Least Squares (OLS) and Generalized Method of Moments (GMM). The following findings are established. Information-sharing bureaus increase (reduce) formal (informal/non-formal) financial sector development. In order to ensure that information-sharing bureaus improve (decrease) formal (informal/non-formal) financial development, public credit registries should have between 45.45 and 50% coverage while private credit bureaus should have at least 26.25% coverage.\n",
            "------------------------------------\n",
            "Title :  Unpacking the Use of Social Media for Protest Behavior\n",
            "Author/s :  S. Valenzuela\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recent studies have shown a positive link between frequency of social media use and political participation. However, there has been no clear elaboration of how using social media translates into increased political activity. The current study examines three explanations for this relationship in the context of citizens’ protest behavior: information (social media as a source for news), opinion expression (using social media to express political opinions), and activism (joining causes and finding mobilizing information through social media). To test these relationships, the study uses survey data collected in Chile in 2011, amid massive demonstrations demanding wholesale changes in education and energy policy. Findings suggest that using social media for opinion expression and activism mediates the relationship between overall social media use and protest behavior. These findings deepen our knowledge of the uses and effects of social media and provide new evidence on the role of digital platforms as facilitators of direct political action.\n",
            "------------------------------------\n",
            "Title :  Industry Concentration and Corporate Disclosure Policy\n",
            "Author/s :  Ashiq Ali, Sandy J Klasa, P. Yeung\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study examines the association between U.S. Census industry concentration measures and the informativeness of corporate disclosure policy. We find that in more concentrated industries firms׳ management earnings forecasts are less frequent and have shorter horizons, their disclosure ratings by analysts are lower, and they have more opaque information environments, as measured by the properties of analysts׳ earnings forecasts. Also, when these firms raise funds they prefer private placements, which have minimal SEC-mandated disclosure requirements, over seasoned equity offerings. Overall, our findings suggest that firms in more concentrated industries disclose less and avoid certain financing decisions that have non-trivial disclosure implications, presumably due to proprietary costs of disclosure.\n",
            "------------------------------------\n",
            "Title :  Working Memory Underpins Cognitive Development, Learning, and Education\n",
            "Author/s :  N. Cowan\n",
            "Venue :  Educational Psychology Review\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Access to Care and Use of the Internet to Search for Health Information: Results From the US National Health Interview Survey\n",
            "Author/s :  Daniel J. Amante, T. Hogan, S. Pagoto, Thomas M. English, K. Lapane\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2015\n",
            "Abstract :  Background The insurance mandate of the Affordable Care Act has increased the number of people with health coverage in the United States. There is speculation that this increase in the number of insured could make accessing health care services more difficult. Those who are unable to access care in a timely manner may use the Internet to search for information needed to answer their health questions. Objective The aim was to determine whether difficulty accessing health care services for reasons unrelated to insurance coverage is associated with increased use of the Internet to obtain health information. Methods Survey data from 32,139 adults in the 2011 National Health Interview Study (NHIS) were used in this study. The exposure for this analysis was reporting difficulty accessing health care services or delaying getting care for a reason unrelated to insurance status. To define this exposure, we examined 8 questions that asked whether different access problems occurred during the previous 12 months. The outcome for this analysis, health information technology (HIT) use, was captured by examining 2 questions that asked survey respondents if they used an online health chat room or searched the Internet to obtain health information in the previous 12 months. Several multinomial logistic regressions estimating the odds of using HIT for each reported access difficulty were conducted to accomplish the study objective. Results Of a survey population of 32,139 adults, more than 15.90% (n=5109) reported experiencing at least one access to care barrier, whereas 3.63% (1168/32,139) reported using online health chat rooms and 43.55% (13,997/32,139) reported searching the Internet for health information. Adults who reported difficulty accessing health care services for reasons unrelated to their health insurance coverage had greater odds of using the Internet to obtain health information. Those who reported delaying getting care because they could not get an appointment soon enough (OR 2.2, 95% CI 1.9-2.5), were told the doctor would not accept them as a new patient or accept their insurance (OR 2.1, 95% CI 1.7-2.5 and OR 2.1, 95% CI 1.7-2.5, respectively), or because the doctor’s office was not open when they could go (OR 2.2, 95% CI 1.9-2.7) had more than twice the odds of using the Internet to obtain health information compared to those who did not report such access difficulties. Conclusions People experiencing trouble accessing health care services for reasons unrelated to their insurance status are more likely to report using the Internet to obtain health information. Improving the accuracy and reliability of health information resources that are publicly available online could help those who are searching for information due to trouble accessing health care services.\n",
            "------------------------------------\n",
            "Title :  Mining big data: current status, and forecast to the future\n",
            "Author/s :  Wei Fan, A. Bifet\n",
            "Venue :  SKDD\n",
            "year :  2013\n",
            "Abstract :  Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.\n",
            "------------------------------------\n",
            "Title :  Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\n",
            "Author/s :  Zuxuan Wu, Xi Wang, Yu-Gang Jiang, Hao Ye, X. Xue\n",
            "Venue :  ACM Multimedia\n",
            "year :  2015\n",
            "Abstract :  Classifying videos according to content semantics is an important problem with a wide range of applications. In this paper, we propose a hybrid deep learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos. Specifically, the spatial and the short-term motion features are extracted separately by two Convolutional Neural Networks (CNN). These two types of CNN-based features are then combined in a regularized feature fusion network for classification, which is able to learn and utilize feature relationships for improved performance. In addition, Long Short Term Memory (LSTM) networks are applied on top of the two features to further model longer-term temporal clues. The main contribution of this work is the hybrid learning framework that can model several important aspects of the video data. We also show that (1) combining the spatial and the short-term motion features in the regularized fusion network is better than direct classification and fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is highly complementary to the traditional classification strategy without considering the temporal frame orders. Extensive experiments are conducted on two popular and challenging benchmarks, the UCF-101 Human Actions and the Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves very competitive performance: 91.3% on the UCF-101 and 83.5% on the CCV.\n",
            "------------------------------------\n",
            "Title :  IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models\n",
            "Author/s :  Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, P. Zhang, Dell Zhang\n",
            "Venue :  Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year :  2017\n",
            "Abstract :  This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96% on Precision@5 and 15.50% on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering.\n",
            "------------------------------------\n",
            "Title :  Literature review of Industry 4.0 and related technologies\n",
            "Author/s :  Ercan Öztemel, S. Gursev\n",
            "Venue :  Journal of Intelligent Manufacturing\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Making existing production systems Industry 4.0-ready\n",
            "Author/s :  Jan Schlechtendahl, Matthias Keinert, F. Kretschmer, A. Lechler, A. Verl\n",
            "Venue :  Production Engineering\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  ClinVar: public archive of interpretations of clinically relevant variants\n",
            "Author/s :  M. Landrum, Jennifer M. Lee, M. Benson, Garth R. Brown, Chen Chao, S. Chitipiralla, Baoshan Gu, Jennifer Hart, Douglas Hoffman, Jeffrey Hoover, W. Jang, K. Katz, M. Ovetsky, George R. Riley, Amanjeev Sethi, R. E. Tully, Ricardo Villamarín-Salomón, W. Rubinstein, D. Maglott\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) at the National Center for Biotechnology Information (NCBI) is a freely available archive for interpretations of clinical significance of variants for reported conditions. The database includes germline and somatic variants of any size, type or genomic location. Interpretations are submitted by clinical testing laboratories, research laboratories, locus-specific databases, OMIM®, GeneReviews™, UniProt, expert panels and practice guidelines. In NCBI's Variation submission portal, submitters upload batch submissions or use the Submission Wizard for single submissions. Each submitted interpretation is assigned an accession number prefixed with SCV. ClinVar staff review validation reports with data types such as HGVS (Human Genome Variation Society) expressions; however, clinical significance is reported directly from submitters. Interpretations are aggregated by variant-condition combination and assigned an accession number prefixed with RCV. Clinical significance is calculated for the aggregate record, indicating consensus or conflict in the submitted interpretations. ClinVar uses data standards, such as HGVS nomenclature for variants and MedGen identifiers for conditions. The data are available on the web as variant-specific views; the entire data set can be downloaded via ftp. Programmatic access for ClinVar records is available through NCBI's E-utilities. Future development includes providing a variant-centric XML archive and a web page for details of SCV submissions.\n",
            "------------------------------------\n",
            "Title :  Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA\n",
            "Author/s :  Sahil Loomba, A. de Figueiredo, S. Piatek, K. de Graaf, H. Larson\n",
            "Venue :  Nature Human Behaviour\n",
            "year :  2021\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Electronic frog eye: Counting crowd using WiFi\n",
            "Author/s :  Wei Xi, Jizhong Zhao, Xiangyang Li, K. Zhao, Shaojie Tang, Xue Liu, Zhiping Jiang\n",
            "Venue :  IEEE Conference on Computer Communications\n",
            "year :  2014\n",
            "Abstract :  Crowd counting, which count or accurately estimate the number of human beings within a region, is critical in many applications, such as guided tour, crowd control and marketing research and analysis. A crowd counting solution should be scalable and be minimally intrusive (i.e., device-free) to users. Image-based solutions are device-free, but cannot work well in a dim or dark environment. Non-image based solutions usually require every human being carrying device, and are inaccurate and unreliable in practice. In this paper, we present FCC, a device-Free Crowd Counting approach based on Channel State Information (CSI). Our design is motivated by our observation that CSI is highly sensitive to environment variation, like a frog eye. We theoretically discuss the relationship between the number of moving people and the variation of wireless channel state. A major challenge in our design of FCC is to find a stable monotonic function to characterize the relationship between the crowd number and various features of CSI. To this end, we propose a metric, the Percentage of nonzero Elements (PEM), in the dilated CSI Matrix. The monotonic relationship can be explicitly formulated by the Grey Verhulst Model, which is used for crowd counting without a labor-intensive site survey. We implement FCC using off-the-shelf IEEE 802.11n devices and evaluate its performance via extensive experiments in typical real-world scenarios. Our results demonstrate that FCC outperforms the state-of-art approaches with much better accuracy, scalability and reliability.\n",
            "------------------------------------\n",
            "Title :  The Capacity of Private Information Retrieval\n",
            "Author/s :  Hua Sun, S. Jafar\n",
            "Venue :  Global Communications Conference\n",
            "year :  2016\n",
            "Abstract :  In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N^2 + &#183; &#183; &#183; + 1/N({K&#8722;1})^{&#8722;1}. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.\n",
            "------------------------------------\n",
            "Title :  The Consequences of Mandatory Corporate Sustainability Reporting\n",
            "Author/s :  I. Ioannou, George Serafeim\n",
            "Venue :  The Oxford Handbook of Corporate Social Responsibility\n",
            "year :  2017\n",
            "Abstract :  A key aspect of the governance process inside organizations and markets is the measurement and disclosure of important metrics and information. In this chapter, we examine the effect of sustainability disclosure regulations on firms’ disclosure practices and valuations. Specifically, we explore the implications of regulations mandating the disclosure of environmental, social, and governance (ESG) information in China, Denmark, Malaysia, and South Africa using differences-in-differences estimation with propensity score matched samples. We find that relative to propensity score matched control firms, treated firms significantly increased disclosure following the regulations. We also find increased likelihood by treated firms of voluntarily receiving assurance to enhance disclosure credibility and increased likelihood of voluntarily adopting reporting guidelines that enhance disclosure comparability. These results suggest that even in the absence of a regulation that mandates the adoption of assurance or specific guidelines, firms seek the qualitative properties of comparability and credibility. Instrumental variables analysis suggests that increases in sustainability disclosure driven by the regulation are associated with increases in firm valuations, as reflected in Tobin’s Q. Collectively, the evidence suggest that current efforts to increase transparency around organizations’ impact on society are effective at improving disclosure quantity and quality as well as corporate value.\n",
            "------------------------------------\n",
            "Title :  Semantic trajectories modeling and analysis\n",
            "Author/s :  C. Parent, S. Spaccapietra, C. Renso, G. Andrienko, N. Andrienko, V. Bogorny, M. Damiani, A. Gkoulalas-Divanis, J. Macêdo, N. Pelekis, Y. Theodoridis, Zhixian Yan\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Focus on movement data has increased as a consequence of the larger availability of such data due to current GPS, GSM, RFID, and sensors techniques. In parallel, interest in movement has shifted from raw movement data analysis to more application-oriented ways of analyzing segments of movement suitable for the specific purposes of the application. This trend has promoted semantically rich trajectories, rather than raw movement, as the core object of interest in mobility studies. This survey provides the definitions of the basic concepts about mobility data, an analysis of the issues in mobility data management, and a survey of the approaches and techniques for: (i) constructing trajectories from movement tracks, (ii) enriching trajectories with semantic information to enable the desired interpretations of movements, and (iii) using data mining to analyze semantic trajectories and extract knowledge about their characteristics, in particular the behavioral patterns of the moving objects. Last but not least, the article surveys the new privacy issues that arise due to the semantic aspects of trajectories.\n",
            "------------------------------------\n",
            "Title :  Accounting information systems\n",
            "Author/s :  S. Altschuller, Shaya Altschuller\n",
            "Venue :  The Routledge Companion to Risk, Crisis and Security in Business\n",
            "year :  2018\n",
            "Abstract :  Accounting Information Systems Introduction The development of information technology impacts significantly on various fields and activities. The biggest impact can be seen in accounting practice. The changes are becoming more and more complex as there are shifts in business activities, such as in organization management, the concept of change management, and integration activities making closer ties among suppliers, customers and even competitors (Computing Curricula 2005, Information System).\n",
            "------------------------------------\n",
            "Title :  Empirical Studies in Information Visualization: Seven Scenarios\n",
            "Author/s :  Heidi Lam, E. Bertini, P. Isenberg, C. Plaisant, M. Carpendale\n",
            "Venue :  IEEE Transactions on Visualization and Computer Graphics\n",
            "year :  2012\n",
            "Abstract :  We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.\n",
            "------------------------------------\n",
            "Title :  How to win in an Omnichannel world\n",
            "Author/s :  David R. Bell, Santiago Gallino, Antonio Moreno\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  The omnichannel environment presents new challenges and opportunities for both information and product fulfillment. While all retailers need to effectively and efficiently manage fulfillment and information provision, there are important nuances to how this happens, depending on where and how the retailer got started and what kinds of improvement create the most leverage. This article delivers a customer-focused framework showing how to win in the omni-channel environment through critical innovations in information delivery and product fulfillment. The framework emerged from our research with both traditional and nontraditional retailers. To thrive in the new environment, retailers of all stripes and origins need to deploy information and fulfillment strategies that reduce friction in every phase of the buying process. This means simultaneously providing, in a cost-effective and narrative-enhancing way\n",
            "------------------------------------\n",
            "Title :  Fused Matrix Factorization with Geographical and Social Influence in Location-Based Social Networks\n",
            "Author/s :  Chen-Kuang Cheng, Haiqin Yang, Irwin King, Michael R. Lyu\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2012\n",
            "Abstract :  \n",
            " \n",
            " Recently, location-based social networks (LBSNs), such as Gowalla, Foursquare, Facebook, and Brightkite, etc., have attracted millions of users to share their social friendship and their locations via check-ins. The available check-in information makes it possible to mine users’ preference on locations and to provide favorite recommendations. Personalized Point-of-interest (POI) recommendation is a significant task in LBSNs since it can help targeted users explore their surroundings as well as help third-party developers to provide personalized services. To solve this task, matrix factorization is a promising tool due to its success in recommender systems. However, previously proposed matrix factorization (MF) methods do not explore geographical influence, e.g., multi-center check-in property, which yields suboptimal solutions for the recommendation. In this paper, to the best of our knowledge, we are the first to fuse MF with geographical and social influence for POI recommendation in LBSNs. We first capture the geographical influence via modeling the probability of a user’s check-in on a location as a Multi-center Gaussian Model (MGM). Next, we include social information and fuse the geographical influence into a generalized matrix factorization framework. Our solution to POI recommendation is efficient and scales linearly with the number of observations. Finally, we conduct thorough experiments on a large-scale real-world LBSNs dataset and demonstrate that the fused matrix factorization framework with MGM utilizes the distance information sufficiently and outperforms other state-of-the-art methods significantly.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  \"Meaningful Information\" and the Right to Explanation\n",
            "Author/s :  Andrew D. Selbst, Julia E. Powles\n",
            "Venue :  FAT\n",
            "year :  2017\n",
            "Abstract :  There is no single, neat statutory provision labeled the “right to explanation” in Europe’s new General Data Protection Regulation (GDPR). But nor is such a right illusory. \n",
            "Responding to two prominent papers that, in turn, conjure and critique the right to explanation in the context of automated decision-making, we advocate a return to the text of the GDPR. \n",
            "Articles 13-15 provide rights to “meaningful information about the logic involved” in automated decisions. This is a right to explanation, whether one uses the phrase or not. \n",
            "The right to explanation should be interpreted functionally, flexibly, and should, at a minimum, enable a data subject to exercise his or her rights under the GDPR and human rights law.\n",
            "------------------------------------\n",
            "Title :  An event-driven manufacturing information system architecture for Industry 4.0\n",
            "Author/s :  Alfred Theorin, Kristofer Bengtsson, Julien Provost, Michael Lieder, C. Johnsson, T. Lundholm, B. Lennartson\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2017\n",
            "Abstract :  Future manufacturing systems need to be more flexible, to embrace tougher and constantly changing market demands. They need to make better use of plant data, ideally utilising all data from the entire plant. Low-level data should be refined to real-time information for decision-making, to facilitate competitiveness through informed and timely decisions. The Line Information System Architecture (LISA), is presented in this paper. It is an event-driven architecture featuring loose coupling, a prototype-oriented information model and formalised transformation services. LISA is designed to enable flexible factory integration and data utilisation. The focus of LISA is on integration of devices and services on all levels, simplifying hardware changes and integration of new smart services as well as supporting continuous improvements on information visualisation and control. The architecture has been evaluated on both real industrial data and industrial demonstrators and it is also being installed at a large automotive company. This article is an extended and revised version of the paper presented at the 2015 IFAC Symposium on Information Control in Manufacturing (INCOM 2015). The paper has been restructured in regards to the order and title of the chapters, and additional information about the integration between devices and services aspects have been added. The introduction and the general structure of the paper now better highlight the contributions of the paper and the uniqueness of the framework.\n",
            "------------------------------------\n",
            "Title :  Mobile health 2012\n",
            "Author/s :  Maeve Duggan, Susannah Fox\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Half of smartphone owners use their devices to get health information and one-fifth of smartphone owners have health apps. The results reported here come from a nationwide survey of 3,014 adults living in the United States. Telephone interviews were conducted by landline (1,808) and cell phone (1,206, including 624 without a landline phone). The survey was conducted by Princeton Survey Research Associates International. Interviews were done in English and Spanish by Princeton Data Source from August 7 to September 6, 2012. Statistical results are weighted to correct known demographic discrepancies. The margin of sampling error for the complete set of weighted data is ±2.4 percentage points.\n",
            "------------------------------------\n",
            "Title :  Content Sharing in a Social Broadcasting Environment: Evidence from Twitter\n",
            "Author/s :  Zhan Shi, Huaxia Rui, Andrew Whinston\n",
            "Venue :  MIS Q.\n",
            "year :  2014\n",
            "Abstract :  The rise of social broadcasting technologies has greatly facilitated open access to information worldwide, not only by powering decentralized information production and consumption, but also by expediting information diffusion through social interactions like content sharing. Voluntary information sharing by users in the context of Twitter, the predominant social broadcasting site, is studied by modeling both the technology and user behavior. A detailed data set about the official content-sharing function on Twitter, called retweet, is collected and the statistical relationships between users' social network characteristics and their retweeting acts are documented. A two-stage consumption-sharing model is then estimated using the conditional maximum likelihood estimatio (MLE) method. The empirical results convincingly support our hypothesis that weak ties (in the form of unidirectional links) are more likely to engage in the social exchange process of content sharing. Specifically, we find that after a median quality tweet (as defined in the sample) is consumed, the likelihood that a unidirectional follower will retweet is 3.1 percentage point higher than the likelihood that a bidirectional follower will do so.\n",
            "------------------------------------\n",
            "Title :  Tweeting From Left to Right\n",
            "Author/s :  Pablo Barberá, J. Jost, Jonathan Nagler, Joshua A. Tucker, Richard Bonneau\n",
            "Venue :  Psychology Science\n",
            "year :  2015\n",
            "Abstract :  We estimated ideological preferences of 3.8 million Twitter users and, using a data set of nearly 150 million tweets concerning 12 political and nonpolitical issues, explored whether online communication resembles an “echo chamber” (as a result of selective exposure and ideological segregation) or a “national conversation.” We observed that information was exchanged primarily among individuals with similar ideological preferences in the case of political issues (e.g., 2012 presidential election, 2013 government shutdown) but not many other current events (e.g., 2013 Boston Marathon bombing, 2014 Super Bowl). Discussion of the Newtown shootings in 2012 reflected a dynamic process, beginning as a national conversation before transforming into a polarized exchange. With respect to both political and nonpolitical issues, liberals were more likely than conservatives to engage in cross-ideological dissemination; this is an important asymmetry with respect to the structure of communication that is consistent with psychological theory and research bearing on ideological differences in epistemic, existential, and relational motivation. Overall, we conclude that previous work may have overestimated the degree of ideological segregation in social-media usage.\n",
            "------------------------------------\n",
            "Title :  The Ethics of Information\n",
            "Author/s :  L. Floridi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  PREFACE 1. ETHICS AFTER THE INFORMATION REVOLUTION 2. WHAT IS INFORMATION ETHICS? 3. THE METHOD OF ABSTRACTION 4. INFORMATION ETHICS AS E-NVIRONMENTAL ETHICS 5. INFORMATION ETHICS AND THE FOUNDATIONALIST DEBATE 6. THE INTRINSIC VALUE OF THE INFOSPHERE 7. THE MORALITY OF ARTIFICIAL AGENTS 8. THE CONSTRUCTIONIST VALUES OF HOMO POIETICUS 9. ARTIFICIAL EVIL 10. THE TRAGEDY OF THE GOOD WILL 11. THE INFORMATIONAL NATURE OF SELVES 12. THE ONTOLOGICAL INTERPRETATION OF INFORMATIONAL PRIVACY 13. DISTRIBUTED MORALITY 14. INFORMATION BUSINESS ETHICS 15. GLOBAL INFORMATION ETHICS 16. A DEFENCE OF INFORMATION ETHICS EPILOGUE REFERENCES INDEX\n",
            "------------------------------------\n",
            "Title :  AIDR: artificial intelligence for disaster response\n",
            "Author/s :  Muhammad Imran, Carlos Castillo, J. Lucas, P. Meier, Sarah Vieweg\n",
            "Venue :  The Web Conference\n",
            "year :  2014\n",
            "Abstract :  We present AIDR (Artificial Intelligence for Disaster Response), a platform designed to perform automatic classification of crisis-related microblog communications. AIDR enables humans and machines to work together to apply human intelligence to large-scale data at high speed. The objective of AIDR is to classify messages that people post during disasters into a set of user-defined categories of information (e.g., \"needs\", \"damage\", etc.) For this purpose, the system continuously ingests data from Twitter, processes it (i.e., using machine learning classification techniques) and leverages human-participation (through crowdsourcing) in real-time. AIDR has been successfully tested to classify informative vs. non-informative tweets posted during the 2013 Pakistan Earthquake. Overall, we achieved a classification quality (measured using AUC) of 80%. AIDR is available at http://aidr.qcri.org/.\n",
            "------------------------------------\n",
            "Title :  Coronavirus: the spread of misinformation\n",
            "Author/s :  A. Mian, Shujhat Khan\n",
            "Venue :  BMC Medicine\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Variational Information Distillation for Knowledge Transfer\n",
            "Author/s :  Sungsoo Ahn, S. Hu, A. Damianou, Neil D. Lawrence, Zhenwen Dai\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  Transferring knowledge from a teacher neural network pretrained on the same or a similar task to a student neural network can significantly improve the performance of the student neural network. Existing knowledge transfer approaches match the activations or the corresponding hand-crafted features of the teacher and the student networks. We propose an information-theoretic framework for knowledge transfer which formulates knowledge transfer as maximizing the mutual information between the teacher and the student networks. We compare our method with existing knowledge transfer methods on both knowledge distillation and transfer learning tasks and show that our method consistently outperforms existing methods. We further demonstrate the strength of our method on knowledge transfer across heterogeneous network architectures by transferring knowledge from a convolutional neural network (CNN) to a multi-layer perceptron (MLP) on CIFAR-10. The resulting MLP significantly outperforms the-state-of-the-art methods and it achieves similar performance to the CNN with a single convolutional layer.\n",
            "------------------------------------\n",
            "Title :  Scaling the Ion Trap Quantum Processor\n",
            "Author/s :  C. Monroe, J. Kim\n",
            "Venue :  Science\n",
            "year :  2013\n",
            "Abstract :  Trapped atomic ions are standards for quantum information processing, serving as quantum memories, hosts of quantum gates in quantum computers and simulators, and nodes of quantum communication networks. Quantum bits based on trapped ions enjoy a rare combination of attributes: They have exquisite coherence properties, they can be prepared and measured with nearly 100% efficiency, and they are readily entangled with each other through the Coulomb interaction or remote photonic interconnects. The outstanding challenge is the scaling of trapped ions to hundreds or thousands of qubits and beyond, at which scale quantum processors can outperform their classical counterparts in certain applications. We review the latest progress and prospects in that effort, with the promise of advanced architectures and new technologies, such as microfabricated ion traps and integrated photonics.\n",
            "------------------------------------\n",
            "Title :  Room-Temperature Quantum Bit Memory Exceeding One Second\n",
            "Author/s :  P. Maurer, G. Kucsko, C. Latta, L. Jiang, N. Yao, S. Bennett, F. Pastawski, D. Hunger, N. Chisholm, M. Markham, D. Twitchen, J. Cirac, M. Lukin\n",
            "Venue :  Science\n",
            "year :  2012\n",
            "Abstract :  Extending Quantum Memory Practical applications in quantum communication and quantum computation require the building blocks—quantum bits and quantum memory—to be sufficiently robust and long-lived to allow for manipulation and storage (see the Perspective by Boehme and McCarney). Steger et al. (p. 1280) demonstrate that the nuclear spins of 31P impurities in an almost isotopically pure sample of 28Si can have a coherence time of as long as 192 seconds at a temperature of ∼1.7 K. In diamond at room temperature, Maurer et al. (p. 1283) show that a spin-based qubit system comprised of an isotopic impurity (13C) in the vicinity of a color defect (a nitrogen-vacancy center) could be manipulated to have a coherence time exceeding one second. Such lifetimes promise to make spin-based architectures feasible building blocks for quantum information science. Defects in diamond can be operated as quantum memories at room temperature. Stable quantum bits, capable both of storing quantum information for macroscopic time scales and of integration inside small portable devices, are an essential building block for an array of potential applications. We demonstrate high-fidelity control of a solid-state qubit, which preserves its polarization for several minutes and features coherence lifetimes exceeding 1 second at room temperature. The qubit consists of a single 13C nuclear spin in the vicinity of a nitrogen-vacancy color center within an isotopically purified diamond crystal. The long qubit memory time was achieved via a technique involving dissipative decoupling of the single nuclear spin from its local environment. The versatility, robustness, and potential scalability of this system may allow for new applications in quantum information science.\n",
            "------------------------------------\n",
            "Title :  A Survey of Text Similarity Approaches\n",
            "Author/s :  W. H. Gomaa, A. Fahmy\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT Measuring the similarity between words, sentences, paragraphs and documents is an important component in various tasks such as information retrieval, document clustering, word-sense disambiguation, automatic essay scoring, short answer grading, machine translation and text summarization. This survey discusses the existing works on text similarity through partitioning them into three approaches; String-based, Corpus-based and Knowledge-based similarities. Furthermore, samples of combination between these similarities are presented. General Terms Text Mining, Natural Language Processing. Keywords BasedText Similarity, Semantic Similarity, String-Based Similarity, Corpus-Based Similarity, Knowledge-Based Similarity. NeedlemanWunsch 1. INTRODUCTION Text similarity measures play an increasingly important role in text related research and applications in tasks Nsuch as information retrieval, text classification, document clustering, topic detection, topic tracking, questions generation, question answering, essay scoring, short answer scoring, machine translation, text summarization and others. Finding similarity between words is a fundamental part of text similarity which is then used as a primary stage for sentence, paragraph and document similarities. Words can be similar in two ways lexically and semantically. Words are similar lexically if they have a similar character sequence. Words are similar semantically if they have the same thing, are opposite of each other, used in the same way, used in the same context and one is a type of another. DistanceLexical similarity is introduced in this survey though different String-Based algorithms, Semantic similarity is introduced through Corpus-Based and Knowledge-Based algorithms. String-Based measures operate on string sequences and character composition. A string metric is a metric that measures similarity or dissimilarity (distance) between two text strings for approximate string matching or comparison. Corpus-Based similarity is a semantic similarity measure that determines the similarity between words according to information gained from large corpora. Knowledge-Based similarity is a semantic similarity measure that determines the degree of similarity between words using information derived from semantic networks. The most popular for each type will be presented briefly. This paper is organized as follows: Section two presents String-Based algorithms by partitioning them into two types character-based and term-based measures. Sections three and four introduce Corpus-Based and knowledge-Based algorithms respectively. Samples of combinations between similarity algorithms are introduced in section five and finally section six presents conclusion of the survey.\n",
            "------------------------------------\n",
            "Title :  To stay or leave?: the relationship of emotional and informational support to commitment in online health support groups\n",
            "Author/s :  Yi-Chia Wang, R. Kraut, J. Levine\n",
            "Venue :  Conference on Computer Supported Cooperative Work\n",
            "year :  2012\n",
            "Abstract :  Today many people with serious diseases use online support groups to seek social support. For these groups to be sustained and effective, member retention and commitment is important. Our study examined how different types and amounts of social support in an online cancer support group are associated with participants' length of membership. We first built machine learning models to automatically identify the extent to which messages contained emotional and informational support. Agreement with human judges was high (r > 0.76). We then used these models to measure the support exchanged in 1.5 million messages. Finally, we applied quantitative event history analysis to assess how exposure to emotional and informational support predicted group members' length of subsequent participation. The results demonstrated that the more emotional support members were exposed to, the lower the risk of dropout. In contrast, informational support did not have the same strong effects on commitment. We speculate that emotional support enhanced members' relationships with one another or the group as a whole, whereas informational support satisfied members' short-term information needs.\n",
            "------------------------------------\n",
            "Title :  Predictive information in a sensory population\n",
            "Author/s :  S. Palmer, O. Marre, Michael J. Berry, W. Bialek\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2013\n",
            "Abstract :  Significance Prediction is an essential part of life. However, are we really “good” at making predictions? More specifically, are pieces of our brain close to being optimal predictors? To assess the efficiency of prediction, we need to measure the information that neurons carry about the future of our sensory experiences. We show how to do this, at least in simplified contexts, and find that groups of neurons in the retina indeed are close to maximally efficient at separating predictive information from the nonpredictive background. Efficient coding of predictive information is a principle that can be applied at every stage of neural computation. Guiding behavior requires the brain to make predictions about the future values of sensory inputs. Here, we show that efficient predictive computation starts at the earliest stages of the visual system. We compute how much information groups of retinal ganglion cells carry about the future state of their visual inputs and show that nearly every cell in the retina participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons that exhibit feature selectivity that would support predictive computations. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.\n",
            "------------------------------------\n",
            "Title :  The evidence for motivated reasoning in climate change preference formation\n",
            "Author/s :  J. Druckman, Mary C. McGrath\n",
            "Venue :  Nature Climate Change\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Toward a synthesis of cognitive biases: how noisy information processing can bias human decision making.\n",
            "Author/s :  M. Hilbert\n",
            "Venue :  Psychological bulletin\n",
            "year :  2012\n",
            "Abstract :  A single coherent framework is proposed to synthesize long-standing research on 8 seemingly unrelated cognitive decision-making biases. During the past 6 decades, hundreds of empirical studies have resulted in a variety of rules of thumb that specify how humans systematically deviate from what is normatively expected from their decisions. Several complementary generative mechanisms have been proposed to explain those cognitive biases. Here it is suggested that (at least) 8 of these empirically detected decision-making biases can be produced by simply assuming noisy deviations in the memory-based information processes that convert objective evidence (observations) into subjective estimates (decisions). An integrative framework is presented to show how similar noise-based mechanisms can lead to conservatism, the Bayesian likelihood bias, illusory correlations, biased self-other placement, subadditivity, exaggerated expectation, the confidence bias, and the hard-easy effect. Analytical tools from information theory are used to explore the nature and limitations that characterize such information processes for binary and multiary decision-making exercises. The ensuing synthesis offers formal mathematical definitions of the biases and their underlying generative mechanism, which permits a consolidated analysis of how they are related. This synthesis contributes to the larger goal of creating a coherent picture that explains the relations among the myriad of seemingly unrelated biases and their potential psychological generative mechanisms. Limitations and research questions are discussed.\n",
            "------------------------------------\n",
            "Title :  PubChem in 2021: new data content and improved web interfaces\n",
            "Author/s :  Sunghwan Kim, Jie Chen, Tiejun Cheng, A. Gindulyte, Jia He, Siqian He, Qingliang Li, B. Shoemaker, P. Thiessen, Bo Yu, L. Zaslavsky, Jian Zhang, Evan E. Bolton\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2020\n",
            "Abstract :  Abstract PubChem (https://pubchem.ncbi.nlm.nih.gov) is a popular chemical information resource that serves the scientific community as well as the general public, with millions of unique users per month. In the past two years, PubChem made substantial improvements. Data from more than 100 new data sources were added to PubChem, including chemical-literature links from Thieme Chemistry, chemical and physical property links from SpringerMaterials, and patent links from the World Intellectual Properties Organization (WIPO). PubChem's homepage and individual record pages were updated to help users find desired information faster. This update involved a data model change for the data objects used by these pages as well as by programmatic users. Several new services were introduced, including the PubChem Periodic Table and Element pages, Pathway pages, and Knowledge panels. Additionally, in response to the coronavirus disease 2019 (COVID-19) outbreak, PubChem created a special data collection that contains PubChem data related to COVID-19 and the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).\n",
            "------------------------------------\n",
            "Title :  Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm\n",
            "Author/s :  Mohammed A. Ambusaidi, Xiangjian He, P. Nanda, Zhiyuan Tan\n",
            "Venue :  IEEE transactions on computers\n",
            "year :  2016\n",
            "Abstract :  Redundant and irrelevant features in data have caused a long-term problem in network traffic classification. These features not only slow down the process of classification but also prevent a classifier from making accurate decisions, especially when coping with big data. In this paper, we propose a mutual information based algorithm that analytically selects the optimal feature for classification. This mutual information based feature selection algorithm can handle linearly and nonlinearly dependent data features. Its effectiveness is evaluated in the cases of network intrusion detection. An Intrusion Detection System (IDS), named Least Square Support Vector Machine based IDS (LSSVM-IDS), is built using the features selected by our proposed feature selection algorithm. The performance of LSSVM-IDS is evaluated using three intrusion detection evaluation datasets, namely KDD Cup 99, NSL-KDD and Kyoto 2006+ dataset. The evaluation results show that our feature selection algorithm contributes more critical features for LSSVM-IDS to achieve better accuracy and lower computational cost compared with the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  What's in a hashtag?: content based prediction of the spread of ideas in microblogging communities\n",
            "Author/s :  Oren Tsur, A. Rappoport\n",
            "Venue :  Web Search and Data Mining\n",
            "year :  2012\n",
            "Abstract :  Current social media research mainly focuses on temporal trends of the information flow and on the topology of the social graph that facilitates the propagation of information. In this paper we study the effect of the content of the idea on the information propagation. We present an efficient hybrid approach based on a linear regression for predicting the spread of an idea in a given time frame. We show that a combination of content features with temporal and topological features minimizes prediction error.\n",
            " Our algorithm is evaluated on Twitter hashtags extracted from a dataset of more than 400 million tweets. We analyze the contribution and the limitations of the various feature types to the spread of information, demonstrating that content aspects can be used as strong predictors thus should not be disregarded. We also study the dependencies between global features such as graph topology and content features.\n",
            "------------------------------------\n",
            "Title :  Big data: A review\n",
            "Author/s :  Ş. Sağiroğlu, Duygu Sinanc\n",
            "Venue :  International Conference on Collaboration Technologies and Systems\n",
            "year :  2013\n",
            "Abstract :  Big data is a term for massive data sets having large, more varied and complex structure with the difficulties of storing, analyzing and visualizing for further processes or results. The process of research into massive amounts of data to reveal hidden patterns and secret correlations named as big data analytics. These useful informations for companies or organizations with the help of gaining richer and deeper insights and getting an advantage over the competition. For this reason, big data implementations need to be analyzed and executed as accurately as possible. This paper presents an overview of big data's content, scope, samples, methods, advantages and challenges and discusses privacy concern on it.\n",
            "------------------------------------\n",
            "Title :  The longitudinal integrated database for health insurance and labour market studies (LISA) and its use in medical research\n",
            "Author/s :  J. Ludvigsson, P. Svedberg, O. Olén, G. Bruze, M. Neovius\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  On the joys of missing data.\n",
            "Author/s :  T. Little, T. Jorgensen, Kyle M Lang, E. Moore\n",
            "Venue :  Journal of Pediatric Psychology\n",
            "year :  2014\n",
            "Abstract :  We provide conceptual introductions to missingness mechanisms--missing completely at random, missing at random, and missing not at random--and state-of-the-art methods of handling missing data--full-information maximum likelihood and multiple imputation--followed by a discussion of planned missing designs: Multiform questionnaire protocols, 2-method measurement models, and wave-missing longitudinal designs. We reviewed 80 articles of empirical studies published in the 2012 issues of the Journal of Pediatric Psychology to present a picture of how adequately missing data are currently handled in this field. To illustrate the benefits of using multiple imputation or full-information maximum likelihood and incorporating planned missingness into study designs, we provide example analyses of empirical data gathered using a 3-form planned missing design.\n",
            "------------------------------------\n",
            "Title :  Guide to health informatics\n",
            "Author/s :  E. Coiera\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Basic Concepts in Informatics Models Information Information Systems Informatics Skills Communicating Structuring Questioning Searching Making Decisions Information Systems in Healthcare Information Management Systems The Electronic Health Record Designing and Evaluating Information and Communication Systems Implementation Information System Safety Information Economics Guideline- and Protocol-Based Systems Guidelines, Protocols and Evidence-Based Healthcare Computer-Based Protocol Systems Designing, Disseminating and Applying protocols Communication Systems in Healthcare Communication Systems Basics Interlude-the Internet and the World Wide Web Information and Communication Networks Social Networks and Social Media Interventions Telehealth and Mobile Health Language, Coding and Classification Terms, Codes and Classification Healthcare Terminologies and Classification Systems Natural Language and Formal Terminology Clinical Decision Support and Analytics Clinical Decision Support Systems Interlude-Artificial Intelligence in Medicine Computational Reasoning Methods Model Building for Decision Support, Data Analysis and Scientific Discovery Specialized Applications for Health Informatics Patient Monitoring and Control Population Surveillance and Public Health Informatics Bioinformatics Clinical Bioinformatics and Personalized Medicine Consumer Health Informatics Glossary References\n",
            "------------------------------------\n",
            "Title :  Selecting optimal partitioning schemes for phylogenomic datasets\n",
            "Author/s :  R. Lanfear, B. Calcott, D. Kainer, C. Mayer, A. Stamatakis\n",
            "Venue :  BMC Evolutionary Biology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The role of collaboration in supply chain resilience\n",
            "Author/s :  K. Scholten, Sanne Schilder\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            "– This paper aims to explore how collaboration influences supply chain resilience. Collaborative activities and their underlying mechanisms in relation to visibility, velocity and flexibility are investigated. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            "– An exploratory case study consisting of eight buyer–supplier relationships in the food processing industry was conducted. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            "– Key findings show how specific collaborative activities (information-sharing, collaborative communication, mutually created knowledge and joint relationship efforts) increase supply chain resilience via increased visibility, velocity and flexibility. Underlying mechanisms and interdependencies of these factors within the supply chain network are identified. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            "– This is one of the first papers to provide in-depth insights into collaboration as a formative element of resilience in a supply chain setting. A series of propositions explain the specific influence of collaborative activities on supply chain resilience beyond a single company perspective.\n",
            "------------------------------------\n",
            "Title :  RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments\n",
            "Author/s :  Peter Henry, Michael Krainin, E. Herbst, Xiaofeng Ren, D. Fox\n",
            "Venue :  Int. J. Robotics Res.\n",
            "year :  2012\n",
            "Abstract :  RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.\n",
            "------------------------------------\n",
            "Title :  Context dependent recurrent neural network language model\n",
            "Author/s :  Tomas Mikolov, G. Zweig\n",
            "Venue :  Spoken Language Technology Workshop\n",
            "year :  2012\n",
            "Abstract :  Recurrent neural network language models (RNNLMs) have recently demonstrated state-of-the-art performance across a variety of tasks. In this paper, we improve their performance by providing a contextual real-valued input vector in association with each word. This vector is used to convey contextual information about the sentence being modeled. By performing Latent Dirichlet Allocation using a block of preceding text, we achieve a topic-conditioned RNNLM. This approach has the key advantage of avoiding the data fragmentation associated with building multiple topic models on different data subsets. We report perplexity results on the Penn Treebank data, where we achieve a new state-of-the-art. We further apply the model to the Wall Street Journal speech recognition task, where we observe improvements in word-error-rate.\n",
            "------------------------------------\n",
            "Title :  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n",
            "Author/s :  Kai Sheng Tai, R. Socher, Christopher D. Manning\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2015\n",
            "Abstract :  Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).\n",
            "------------------------------------\n",
            "Title :  Learning Character-level Representations for Part-of-Speech Tagging\n",
            "Author/s :  C. D. Santos, B. Zadrozny\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2014\n",
            "Abstract :  Distributed word representations have recently been proven to be an invaluable resource for NLP. These representations are normally learned using neural networks and capture syntactic and semantic information about words. Information about word morphology and shape is normally ignored when learning word representations. However, for tasks like part-of-speech tagging, intra-word information is extremely useful, specially when dealing with morphologically rich languages. In this paper, we propose a deep neural network that learns character-level representation of words and associate them with usual word representations to perform POS tagging. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for two languages: English, with 97.32% accuracy on the Penn Treebank WSJ corpus; and Portuguese, with 97.47% accuracy on the Mac-Morpho corpus, where the latter represents an error reduction of 12.2% on the best previous known result.\n",
            "------------------------------------\n",
            "Title :  What is consciousness, and could machines have it?\n",
            "Author/s :  S. Dehaene, H. Lau, S. Kouider\n",
            "Venue :  Science\n",
            "year :  2017\n",
            "Abstract :  The controversial question of whether machines may ever be conscious must be based on a careful consideration of how consciousness arises in the only physical system that undoubtedly possesses it: the human brain. We suggest that the word “consciousness” conflates two different types of information-processing computations in the brain: the selection of information for global broadcasting, thus making it flexibly available for computation and report (C1, consciousness in the first sense), and the self-monitoring of those computations, leading to a subjective sense of certainty or error (C2, consciousness in the second sense). We argue that despite their recent successes, current machines are still mostly implementing computations that reflect unconscious processing (C0) in the human brain. We review the psychological and neural science of unconscious (C0) and conscious computations (C1 and C2) and outline how they may inspire novel machine architectures.\n",
            "------------------------------------\n",
            "Title :  Socio-Economic Impact of Mobile Phones on Indian Agriculture\n",
            "Author/s :  Surabhi Mittal, S. Gandhi, G. Tripathi\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Deficits in physical infrastructure, problems with availability of agricultural inputs and poor access to agriculture-related information are the major constraints on the growth of agricultural productivity in India. The more rapid growth of mobile telephony as compared to fixed line telephony and the recent introduction of mobileenabled information services provide a means to overcome existing information asymmetry. It also helps, at least partially, to bridge the gap between the availability and delivery of agricultural inputs and agriculture infrastructure. This paper investigates a series of questions that explore this topic : What kind of information do farmers value the most to improve agricultural productivity? Do mobile phones and mobile-enabled agricultural services have an impact on agriculture? What are the factors that impede the realisation of the full productivity enhancing potential of mobile phones? The answers to these questions have important implications for mobile operators, for information service providers, and for policymakers. The quality of information, its timeliness and trustworthiness are the three important features that have to be ensured to enable farmers to use it effectively to improve productivity. The study found evidence that mobiles are being used in ways which contribute to productivity enhancement. However, to leverage the full potential of information dissemination enabled by mobile telephony will require significant improvements in supporting infrastructure and capacity building amongst farmers to enable them to use the information they access effectively. As mobile penetration continues to increase among farming communities and information services continue to adapt and proliferate, the scope exists for a much greater rural productivity impact in the future.\n",
            "------------------------------------\n",
            "Title :  The development of student feedback literacy: enabling uptake of feedback\n",
            "Author/s :  D. Carless, D. Boud\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Abstract Student feedback literacy denotes the understandings, capacities and dispositions needed to make sense of information and use it to enhance work or learning strategies. In this conceptual paper, student responses to feedback are reviewed and a number of barriers to student uptake of feedback are discussed. Four inter-related features are proposed as a framework underpinning students’ feedback literacy: appreciating feedback; making judgments; managing affect; and taking action. Two well-established learning activities, peer feedback and analysing exemplars, are discussed to illustrate how this framework can be operationalized. Some ways in which these two enabling activities can be re-focused more explicitly towards developing students’ feedback literacy are elaborated. Teachers are identified as playing important facilitating roles in promoting student feedback literacy through curriculum design, guidance and coaching. The implications and conclusion summarise recommendations for teaching and set out an agenda for further research.\n",
            "------------------------------------\n",
            "Title :  Smart Meter Privacy: A Theoretical Framework\n",
            "Author/s :  L. Sankar, S. Rajagopalan, S. Mohajer, H. Poor\n",
            "Venue :  IEEE Transactions on Smart Grid\n",
            "year :  2013\n",
            "Abstract :  The solutions offered to-date for end-user privacy in smart meter measurements, a well-known challenge in the smart grid, have been tied to specific technologies such as batteries or assumptions on data usage without quantifying the loss of benefit (utility) that results from any such approach. Using tools from information theory and a hidden Markov model for the measurements, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. For a stationary Gaussian model of the electricity load, it is shown that for a desired mean-square distortion (utility) measure between the measured and revealed data, the optimal privacy-preserving solution: i) exploits the presence of high-power but less private appliance spectra as implicit distortion noise, and ii) filters out frequency components with lower power relative to a distortion threshold; this approach encompasses many previously proposed approaches to smart meter privacy.\n",
            "------------------------------------\n",
            "Title :  The Impact of IT Capabilities on Firm Performance: The Mediating Roles of Absorptive Capacity and Supply Chain Agility\n",
            "Author/s :  Hefu Liu, Weiling Ke, K. Wei, Zhongsheng Hua\n",
            "Venue :  Decision Support Systems\n",
            "year :  2013\n",
            "Abstract :  Researchers and practitioners regard information technology (IT) as a competitive tool. However, current knowledge on IT capability mechanisms that affect firm performance remains unclear. Based on the dynamic capabilities perspective and the view of a hierarchy of capabilities, this article proposes a model to examine how IT capabilities (i.e., flexible IT infrastructure and IT assimilation) affect firm performance through absorptive capacity and supply chain agility in the supply chain context. Survey data show that absorptive capacity and supply chain agility fully mediate the influences of IT capabilities on firm performance. In addition to the direct effects, absorptive capacity also has indirect effects on firm performance by shaping supply chain agility. We conclude with implications and suggestions for future research.\n",
            "------------------------------------\n",
            "Title :  Characterizing nonclassical correlations via local quantum uncertainty.\n",
            "Author/s :  D. Girolami, T. Tufarelli, G. Adesso\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  Quantum mechanics predicts that measurements of incompatible observables carry a minimum uncertainty which is independent of technical deficiencies of the measurement apparatus or incomplete knowledge of the state of the system. Nothing yet seems to prevent a single physical quantity, such as one spin component, from being measured with arbitrary precision. Here, we show that an intrinsic quantum uncertainty on a single observable is ineludible in a number of physical situations. When revealed on local observables of a bipartite system, such uncertainty defines an entire class of bona fide measures of nonclassical correlations. For the case of 2 × d systems, we find that a unique measure is defined, which we evaluate in closed form. We then discuss the role that these correlations, which are of the \"discord\" type, can play in the context of quantum metrology. We show in particular that the amount of discord present in a bipartite mixed probe state guarantees a minimum precision, as quantified by the quantum Fisher information, in the optimal phase estimation protocol.\n",
            "------------------------------------\n",
            "Title :  HL7 FHIR: An Agile and RESTful approach to healthcare information exchange\n",
            "Author/s :  D. Bender, K. Sartipi\n",
            "Venue :  Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems\n",
            "year :  2013\n",
            "Abstract :  This research examines the potential for new Health Level 7 (HL7) standard Fast Healthcare Interoperability Resources (FHIR, pronounced “fire”) standard to help achieve healthcare systems interoperability. HL7 messaging standards are widely implemented by the healthcare industry and have been deployed internationally for decades. HL7 Version 2 (“v2”) health information exchange standards are a popular choice of local hospital communities for the exchange of healthcare information, including electronic medical record information. In development for 15 years, HL7 Version 3 (“v3”) was designed to be the successor to Version 2, addressing Version 2's shortcomings. HL7 v3 has been heavily criticized by the industry for being internally inconsistent even in it's own documentation, too complex and expensive to implement in real world systems and has been accused of contributing towards many failed and stalled systems implementations. HL7 is now experimenting with a new approach to the development of standards with FHIR. This research provides a chronicle of the evolution of the HL7 messaging standards, an introduction to HL7 FHIR and a comparative analysis between HL7 FHIR and previous HL7 messaging standards.\n",
            "------------------------------------\n",
            "Title :  Uncertainty, scepticism and attitudes towards climate change: biased assimilation and attitude polarisation\n",
            "Author/s :  A. Corner, L. Whitmarsh, D. Xenias\n",
            "Venue :  Climatic Change\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Externalities of Public Firm Presence: Evidence from Private Firms’ Investment Decisions\n",
            "Author/s :  Brad A. Badertscher, Nemit Shroff, H. White\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Public firms provide a large amount of information through their disclosures. In addition, information intermediaries publicly analyze, discuss and disseminate these disclosures. Thus, greater public firm presence in an industry should reduce uncertainty in that industry. Following the theoretical prediction of investment under uncertainty, we hypothesize and find that private firms are more responsive to their investment opportunities when they operate in industries with greater public firm presence. Further, we find that the effect of public firm presence is greater in industries with better information quality and in industries characterized by a greater degree of investment irreversibility. Our results suggest that public firms generate positive externalities by reducing industry uncertainty and facilitating more efficient private firm investment.\n",
            "------------------------------------\n",
            "Title :  Hidden factors and hidden topics: understanding rating dimensions with review text\n",
            "Author/s :  Julian McAuley, J. Leskovec\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2013\n",
            "Abstract :  In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.\n",
            "------------------------------------\n",
            "Title :  An Enhanced Fear Appeal Rhetorical Framework: Leveraging Threats to the Human Asset Through Sanctioning Rhetoric\n",
            "Author/s :  Allen C. Johnston, Merrill Warkentin, M. Siponen\n",
            "Venue :  MIS Q.\n",
            "year :  2015\n",
            "Abstract :  Fear appeals, which are used widely in information security campaigns, have become common tools in motivating individual compliance with information security policies and procedures. However, empirical assessments of the effectiveness of fear appeals have yielded mixed results, leading IS security scholars and practitioners to question the validity of the conventional fear appeal framework and the manner in which fear appeal behavioral modeling theories, such as protection motivation theory (PMT), have been applied to the study of information security phenomena. We contend that the conventional fear appeal rhetorical framework is inadequate when used in the context of information security threat warnings and that its primary behavioral modeling theory, PMT, has been misspecified in the extant information security research. Based on these arguments, we propose an enhanced fear appeal rhetorical framework that leverages sanctioning rhetoric as a secondary vector of threats to the human asset, thereby adding the dimension of personal relevance, which is critically absent from previous fear appeal frameworks and PMT-grounded security studies. Following a hypothetical scenario research approach involving the employees of a Finnish city government, we validate the efficacy of the enhanced fear appeal framework and determine that informal sanction rhetoric effectively enhances conventional fear appeals, thus providing a significant positive influence on compliance intentions.\n",
            "------------------------------------\n",
            "Title :  Service innovation in the digital age: key contributions and future directions\n",
            "Author/s :  M. Barrett, E. Davidson, Jaideep Prabhu, Stephen L. Vargo\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Over the last decade, there has been an increasing focus on service across socioeconomic sectors coupled with transformational developments in information and communication technologies (ICTs). Together these developments are engendering dramatic new opportunities for service innovation, the study of which is both timely and important. Fully understanding these opportunities challenges us to question conventional approaches that construe service as a distinctive form of socioeconomic exchange (i.e., as services) and to reconsider what service means and thus how service innovation may develop. The aim of this special issue, therefore, is to bring together some of the latest scholarship from the Marketing and Information Systems disciplines to advance theoretical developments on service innovation in a digital age.\n",
            "------------------------------------\n",
            "Title :  Susceptibility to misinformation about COVID-19 around the world\n",
            "Author/s :  J. Roozenbeek, C. Schneider, S. Dryhurst, J. Kerr, A. Freeman, G. Recchia, A. M. van der Bles, S. van der Linden\n",
            "Venue :  Royal Society Open Science\n",
            "year :  2020\n",
            "Abstract :  Misinformation about COVID-19 is a major threat to public health. Using five national samples from the UK (n = 1050 and n = 1150), Ireland (n = 700), the USA (n = 700), Spain (n = 700) and Mexico (n = 700), we examine predictors of belief in the most common statements about the virus that contain misinformation. We also investigate the prevalence of belief in COVID-19 misinformation across different countries and the role of belief in such misinformation in predicting relevant health behaviours. We find that while public belief in misinformation about COVID-19 is not particularly common, a substantial proportion views this type of misinformation as highly reliable in each country surveyed. In addition, a small group of participants find common factual information about the virus highly unreliable. We also find that increased susceptibility to misinformation negatively affects people's self-reported compliance with public health guidance about COVID-19, as well as people's willingness to get vaccinated against the virus and to recommend the vaccine to vulnerable friends and family. Across all countries surveyed, we find that higher trust in scientists and having higher numeracy skills were associated with lower susceptibility to coronavirus-related misinformation. Taken together, these results demonstrate a clear link between susceptibility to misinformation and both vaccine hesitancy and a reduced likelihood to comply with health guidance measures, and suggest that interventions which aim to improve critical thinking and trust in science may be a promising avenue for future research.\n",
            "------------------------------------\n",
            "Title :  OCNet: Object Context Network for Scene Parsing\n",
            "Author/s :  Yuhui Yuan, Jingdong Wang\n",
            "Venue :  ArXiv\n",
            "year :  2018\n",
            "Abstract :  In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. \n",
            "We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. \n",
            "To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff\n",
            "------------------------------------\n",
            "Title :  Mobile Health (mHealth) Approaches and Lessons for Increased Performance and Retention of Community Health Workers in Low- and Middle-Income Countries: A Review\n",
            "Author/s :  Karin Källander, J. Tibenderana, O. Akpogheneta, D. Strachan, Z. Hill, A. T. ten Asbroek, L. Conteh, B. Kirkwood, S. Meek\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background Mobile health (mHealth) describes the use of portable electronic devices with software applications to provide health services and manage patient information. With approximately 5 billion mobile phone users globally, opportunities for mobile technologies to play a formal role in health services, particularly in low- and middle-income countries, are increasingly being recognized. mHealth can also support the performance of health care workers by the dissemination of clinical updates, learning materials, and reminders, particularly in underserved rural locations in low- and middle-income countries where community health workers deliver integrated community case management to children sick with diarrhea, pneumonia, and malaria. Objective Our aim was to conduct a thematic review of how mHealth projects have approached the intersection of cellular technology and public health in low- and middle-income countries and identify the promising practices and experiences learned, as well as novel and innovative approaches of how mHealth can support community health workers. Methods In this review, 6 themes of mHealth initiatives were examined using information from peer-reviewed journals, websites, and key reports. Primary mHealth technologies reviewed included mobile phones, personal digital assistants (PDAs) and smartphones, patient monitoring devices, and mobile telemedicine devices. We examined how these tools could be used for education and awareness, data access, and for strengthening health information systems. We also considered how mHealth may support patient monitoring, clinical decision making, and tracking of drugs and supplies. Lessons from mHealth trials and studies were summarized, focusing on low- and middle-income countries and community health workers. Results The review revealed that there are very few formal outcome evaluations of mHealth in low-income countries. Although there is vast documentation of project process evaluations, there are few studies demonstrating an impact on clinical outcomes. There is also a lack of mHealth applications and services operating at scale in low- and middle-income countries. The most commonly documented use of mHealth was 1-way text-message and phone reminders to encourage follow-up appointments, healthy behaviors, and data gathering. Innovative mHealth applications for community health workers include the use of mobile phones as job aides, clinical decision support tools, and for data submission and instant feedback on performance. Conclusions With partnerships forming between governments, technologists, non-governmental organizations, academia, and industry, there is great potential to improve health services delivery by using mHealth in low- and middle-income countries. As with many other health improvement projects, a key challenge is moving mHealth approaches from pilot projects to national scalable programs while properly engaging health workers and communities in the process. By harnessing the increasing presence of mobile phones among diverse populations, there is promising evidence to suggest that mHealth can be used to deliver increased and enhanced health care services to individuals and communities, while helping to strengthen health systems.\n",
            "------------------------------------\n",
            "Title :  Deep High-Resolution Representation Learning for Human Pose Estimation\n",
            "Author/s :  Ke Sun, Bin Xiao, Dong Liu, Jingdong Wang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.\n",
            "------------------------------------\n",
            "Title :  Opportunities and Challenges for Smartphone Applications in Supporting Health Behavior Change: Qualitative Study\n",
            "Author/s :  L. Dennison, L. Morrison, G. Conway, L. Yardley\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background There is increasing interest from academics and clinicians in harnessing smartphone applications (apps) as a means of delivering behavioral interventions for health. Despite the growing availability of a range of health-related apps on the market, academic research on the development and evaluation of such apps is in the relatively early stages. A few existing studies have explored the views of various populations on using mobile phones for health-related issues and some studies are beginning to report user feedback on specific apps. However, there remains little in depth research on users’ (and potential users’) experiences and views on a wide range of features and technologies that apps are, or will soon be, capable of. In particular, research on young adults is lacking, which is an unfortunate omission considering that this group comprises of a good number of mobile technology adoptors. Objective The current study sought to explore young adults’ perspectives on apps related to health behavior change. It sought their experiences and views of features that might support health behavior change and issues that contribute to interest in and willingness to use such apps. Methods Four focus groups were conducted with 19 students and staff at a University in the United Kingdom. Participants included 13 females and 6 males with a mean age of 23.79 (SD 7.89). The focus group discussions centred on participants’ experiences of using smartphone apps to support a healthy lifestyle, and their interest in and feelings about features and capabilities of such apps. The focus groups were recorded, transcribed, and analyzed using inductive thematic analysis. Results Study findings suggested that young, currently healthy adults have some interest in apps that attempt to support health-related behavior change. Accuracy and legitimacy, security, effort required, and immediate effects on mood emerged as important influences on app usage. The ability to record and track behavior and goals and the ability to acquire advice and information “on the go” were valued. Context-sensing capabilities and social media features tended to be considered unnecessary and off-putting. Conclusions This study provided insight into the opportunities and challenges involved in delivering health-related behavioral interventions through smartphone apps. The findings suggested a number of valued features and characteristics that app developers may wish to consider when creating health behavior apps. Findings also highlighted several major challenges that appeared to need further consideration and research to ensure the development of effective and well-accepted behavior change apps.\n",
            "------------------------------------\n",
            "Title :  Information Acquisition and Welfare\n",
            "Author/s :  L. Colombo, Gianluca Femminis, A. Pavan\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We study information acquisition in a exible framework with strategic complementarity or substitutability in actions and a rich set of externalities that are responsible for possible wedges between the equilibrium and the efficient acquisition of information. First, we relate the (in)efficiency in the acquisition of information to the (in)efficiency in the use of information and explain why efficiency in the use does not guarantee efficiency in the acquisition. Next, we show how the acquisition of private information affects the social value of public information (i.e., the comparative statics of equilibrium welfare with respect to the quality of public information). Finally, we illustrate the implications of our results in a few applications that include beauty contests, monetary economies with price-setting complementarities, and economies with negative production externalities.\n",
            "------------------------------------\n",
            "Title :  Are we making a better world with ICTs? Reflections on a future agenda for the IS field\n",
            "Author/s :  G. Walsham\n",
            "Venue :  Journal of Information and Technology\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Decentralized Stochastic Control with Partial History Sharing: A Common Information Approach\n",
            "Author/s :  A. Nayyar, Aditya Mahajan, D. Teneketzis\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2012\n",
            "Abstract :  A general model of decentralized stochastic control called partial history sharing information structure is presented. In this model, at each step the controllers share part of their observation and control history with each other. This general model subsumes several existing models of information sharing as special cases. Based on the information commonly known to all the controllers, the decentralized problem is reformulated as an equivalent centralized problem from the perspective of a coordinator. The coordinator knows the common information and selects prescriptions that map each controller's local information to its control actions. The optimal control problem at the coordinator is shown to be a partially observable Markov decision process (POMDP) which is solved using techniques from Markov decision theory. This approach provides 1) structural results for optimal strategies and 2) a dynamic program for obtaining optimal strategies for all controllers in the original decentralized problem. Thus, this approach unifies the various ad-hoc approaches taken in the literature. In addition, the structural results on optimal control strategies obtained by the proposed approach cannot be obtained by the existing generic approach (the person-by-person approach) for obtaining structural results in decentralized problems; and the dynamic program obtained by the proposed approach is simpler than that obtained by the existing generic approach (the designer's approach) for obtaining dynamic programs in decentralized problems.\n",
            "------------------------------------\n",
            "Title :  Accessibility of Cities in the Digital Economy\n",
            "Author/s :  E. Tranos, A. Reggiani, P. Nijkamp\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This paper introduces a new measure to approach the accessibility of places in the frame of the digital economy. Information and Communication Technologies (ICTs) and the Internet are not equally spread around places and this heterogeneity affects spatial configuration. Despite the wide societal changes due to ICTs and the extensive interest in accessibility studies, these two themes have not yet come together in order to study the digital accessibility (DA) of places. Adopting an infrastructural perspective and a potential accessibility framework, a DA measure – embedding different types of impedance distance functions – is calculated for cities in Europe. Spatial Interaction Model and Complex Network Analysis are employed to calibrate and validate the DA results. The outcome of this approach is a new urban hierarchy which reveals a core-periphery pattern in Europe owing to digital accessibility.\n",
            "------------------------------------\n",
            "Title :  Correlates of Health-Related Social Media Use Among Adults\n",
            "Author/s :  R. Thackeray, B. Crookston, J. West\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background Sixty percent of Internet users report using the Internet to look for health information. Social media sites are emerging as a potential source for online health information. However, little is known about how people use social media for such purposes. Objectives The purpose of this study was two-fold: (1) to establish the frequency of various types of online health-seeking behaviors, and (2) to identify correlates of 2 health-related online activities, social networking sites (SNS) for health-related activities and consulting online user-generated content for answers about health care providers, health facilities, or medical treatment. Methods The study consisted of a telephone survey of 1745 adults who reported going online to look for health-related information. Four subscales were created to measure use of online resources for (1) using SNS for health-related activities; (2) consulting online rankings and reviews of doctors, hospitals or medical facilities, and drugs or medical treatments; (3) posting a review online of doctors, hospitals or medical facilities, and drugs or medical treatments, and (4) posting a comment or question about health or medical issues on various social media. Univariate and multivariate logistic regression analyses were performed. Results Respondents consulted online rankings or reviews (41.15%), used SNS for health (31.58%), posted reviews (9.91%), and posted a comment, question, or information (15.19%). Respondents with a chronic disease were nearly twice as likely to consult online rankings (odds ratio [OR] 2.09, 95% CI 1.66-2.63, P<.001). Lower odds of consulting online reviews were associated with less formal education (OR 0.49, 95% CI 0.37-0.65, P<.001) and being male (OR 0.71, 95% CI 0.57-0.87, P<.001). Respondents with higher incomes were 1.5 times as likely to consult online rankings or reviews (OR 1.49, 95% CI 0.10-2.24, P=.05), than respondents with a regular provider (OR 2.05, 95% CI 1.52-2.78, P<.001), or living in an urban/suburban location (OR 1.61, 95% CI 1.17-2.22, P<.001). Older respondents were less likely to use SNS for health-related activities (OR 0.96, 95% CI 0.95-0.97, P<.001), as were males (OR 0.70, 95% CI 0.56-0.87, P<.001), whereas respondents with a regular provider had nearly twice the likelihood of using SNS for health-related activities (OR 1.89, 95% CI 1.43-2.52, P<.001). Conclusions People are using social media for seeking health information. However, individuals are more likely to consume information than they are to contribute to the dialog. The inherent value of “social” in social media is not being captured with online health information seeking. People with a regular health care provider, chronic disease, and those in younger age groups are more likely to consult online rankings and reviews and use SNS for health-related activities.\n",
            "------------------------------------\n",
            "Title :  Nonprice incentives and energy conservation\n",
            "Author/s :  O. Asensio, M. Delmas\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance We investigate the effectiveness of nonprice incentives to motivate conservation behavior. We test whether tailored information about environmental and health damages produces behavior change in the residential electricity sector. In a randomized controlled trial with real-time appliance-level energy metering over 8 mo, we find that environment and health-based information strategies outperform monetary savings information to drive energy conservation. Environment and health-based messages, which communicate the environmental and public health externalities of electricity production—such as pounds of pollutants, childhood asthma, and cancer—motivated 8% energy savings versus control. This strategy was particularly effective on families with children, who achieved 19% energy savings. However, we do not study the persistence of these behavioral changes after the conclusion of the study. In the electricity sector, energy conservation through technological and behavioral change is estimated to have a savings potential of 123 million metric tons of carbon per year, which represents 20% of US household direct emissions in the United States. In this article, we investigate the effectiveness of nonprice information strategies to motivate conservation behavior. We introduce environment and health-based messaging as a behavioral strategy to reduce energy use in the home and promote energy conservation. In a randomized controlled trial with real-time appliance-level energy metering, we find that environment and health-based information strategies, which communicate the environmental and public health externalities of electricity production, such as pounds of pollutants, childhood asthma, and cancer, outperform monetary savings information to drive behavioral change in the home. Environment and health-based information treatments motivated 8% energy savings versus control and were particularly effective on families with children, who achieved up to 19% energy savings. Our results are based on a panel of 3.4 million hourly appliance-level kilowatt–hour observations for 118 residences over 8 mo. We discuss the relative impacts of both cost-savings information and environmental health messaging strategies with residential consumers.\n",
            "------------------------------------\n",
            "Title :  Work and information processing in a solvable model of Maxwell’s demon\n",
            "Author/s :  D. Mandal, C. Jarzynski\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2012\n",
            "Abstract :  We describe a minimal model of an autonomous Maxwell demon, a device that delivers work by rectifying thermal fluctuations while simultaneously writing information to a memory register. We solve exactly for the steady-state behavior of our model, and we construct its phase diagram. We find that our device can also act as a “Landauer eraser”, using externally supplied work to remove information from the memory register. By exposing an explicit, transparent mechanism of operation, our model offers a simple paradigm for investigating the thermodynamics of information processing by small systems.\n",
            "------------------------------------\n",
            "Title :  Use of the Internet as a Health Information Resource Among French Young Adults: Results From a Nationally Representative Survey\n",
            "Author/s :  F. Beck, J. Richard, V. Nguyen-Thanh, I. Montagni, I. Parizot, E. Renahy\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2014\n",
            "Abstract :  Background The Internet is one of the main resources of health information especially for young adults, but website content is not always trustworthy or validated. Little is known about this specific population and the importance of online health searches for use and impact. It is fundamental to assess behaviors and attitudes of young people looking for online health-related information and their level of trust in such information. Objective The objective is to describe the characteristics of Internet users aged 15-30 years who use the Web as a health information resource and their trust in it, and to define the context and the effect of such use on French young adults’ behavior in relation to their medical consultations. Methods We used the French Health Barometer 2010, a nationally representative survey of 27,653 individuals that investigates population health behaviors and concerns. Multivariate logistic regressions were performed using a subsample of 1052 young adults aged 15-30 years to estimate associations between demographics, socioeconomic, and health status and (1) the use of the Internet to search for health information, and (2) its impact on health behaviors and the physician-patient relationship. Results In 2010, 48.5% (474/977) of Web users aged 15-30 years used the Internet for health purposes. Those who did not use the Internet for health purposes reported being informed enough by other sources (75.0%, 377/503), stated they preferred seeing a doctor (74.1%, 373/503) or did not trust the information on the Internet (67.2%, 338/503). However, approximately 80% (371/474) of young online health seekers considered the information found online reliable. Women (P<.001) and people with higher sociocultural positions (OR 0.5, 95% CI 0.3-0.9 and OR 0.4, 95% CI 0.2-0.7 for employees and manual workers, respectively, vs individuals with executive or manager positions) were more likely to use the Internet for health purposes. For a subsample of women only, online health seeking was more likely among those having a child (OR 1.8, 95% CI 1.1-2.7) and experiencing psychological distress (OR 2.0, 95% CI 1.0-4.0). Finally, for online health seekers aged 15-30 years, one-third (33.3%, 157/474) reported they changed their health behaviors (eg, frequency of medical consultations, way of taking care of one’s own health) because of their online searches. Different factors were associated with different outcomes of change, but psychological distress, poor quality of life, and low income were the most common. Conclusions The Internet is a useful tool to spread health information and prevention campaigns, especially to target young adults. Young adults trust online information and consider the Internet as a valid source of health advice. Health agencies should ensure the improvement of online health information quality and the creation of health-related websites and programs dedicated to young adults.\n",
            "------------------------------------\n",
            "Title :  The role of data privacy in marketing\n",
            "Author/s :  Kelly D. Martin, P. Murphy\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author/s :  Lei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeleton-based action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.\n",
            "------------------------------------\n",
            "Title :  Database resources of the National Center for Biotechnology Information\n",
            "Author/s :  Huang Gao\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Additional NCBI resources focus on literature (PubMed Central (PMC), Bookshelf and PubReader), health (ClinVar, dbGaP, dbMHC, the Genetic Testing Registry, HIV-1/Human Protein Interaction Database and MedGen), genomes (BioProject, Assembly, Genome, BioSample, dbSNP, dbVar, Epigenomics, the Map Viewer, Nucleotide, Probe, RefSeq, Sequence Read Archive, the Taxonomy Browser and the Trace Archive), genes (Gene, Gene Expression Omnibus (GEO), HomoloGene, PopSet and UniGene), proteins (Protein, the Conserved Domain Database (CDD), COBALT, Conserved Domain Architecture Retrieval Tool (CDART), the Molecular Modeling Database (MMDB) and Protein Clusters) and chemicals (Biosystems and the PubChem suite of small molecule databases). The Entrez system provides search and retrieval operations for most of these databases. Augmenting many of the web applications are custom implementations of the BLAST program optimized to search specialized datasets. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title :  Quantum Fisher information matrix and multiparameter estimation\n",
            "Author/s :  Jing Liu, Haidong Yuan, Xiao-Ming Lu, Xiaoguang Wang\n",
            "Venue :  Journal of Physics A: Mathematical and Theoretical\n",
            "year :  2019\n",
            "Abstract :  Quantum Fisher information matrix (QFIM) is a core concept in theoretical quantum metrology due to the significant importance of quantum Cramér–Rao bound in quantum parameter estimation. However, studies in recent years have revealed wide connections between QFIM and other aspects of quantum mechanics, including quantum thermodynamics, quantum phase transition, entanglement witness, quantum speed limit and non-Markovianity. These connections indicate that QFIM is more than a concept in quantum metrology, but rather a fundamental quantity in quantum mechanics. In this paper, we summarize the properties and existing calculation techniques of QFIM for various cases, and review the development of QFIM in some aspects of quantum mechanics apart from quantum metrology. On the other hand, as the main application of QFIM, the second part of this paper reviews the quantum multiparameter Cramér–Rao bound, its attainability condition and the associated optimal measurements. Moreover, recent developments in a few typical scenarios of quantum multiparameter estimation and the quantum advantages are also thoroughly discussed in this part.\n",
            "------------------------------------\n",
            "Title :  Social Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature\n",
            "Author/s :  Joshua A. Tucker, A. Guess, Pablo Barberá, Cristian Vaccari, A. Siegel, Sergey Sanovich, D. Stukal, B. Nyhan\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  The following report is intended to provide an overview of the current state of the literature on the relationship between social media; political polarization; and political “disinformation,” a term used to encompass a wide range of types of information about politics found online, including “fake news,” rumors, deliberately factually incorrect information, inadvertently factually incorrect information, politically slanted information, and “hyperpartisan” news. The review of the literature is provided in six separate sections, each of which can be read individually but that cumulatively are intended to provide an overview of what is known—and unknown—about the relationship between social media, political polarization, and disinformation. The report concludes by identifying key gaps in our understanding of these phenomena and the data that are needed to address them.\n",
            "------------------------------------\n",
            "Title :  A comparative analysis of international frameworks for 21st century competences: Implications for national curriculum policies\n",
            "Author/s :  J. Voogt, N. P. Roblin\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  National curricula need to change drastically to comply with the competences needed for the 21st century. In this paper eight frameworks describing 21st century competences were analysed. A comprehensive search for information about 21st century competences was conducted across the official websites of the selected frameworks, resulting in 32 documents that were analysed in detail. Travers and Westbury’s framework of curriculum representations was used to determine horizontal and vertical consistency between the frameworks. The frameworks were compared on their underlying rationales and goals, their definition of 21st century competences, and the recommended strategies for the implementation and assessment of these skills in educational practice. In addition three international studies were examined to analyse how various countries (EU member states, OECD countries) and schools (SITES studies) deal (or not) with 21st century competences. The findings indicate a large extent of alignment between the frameworks about what 21st century competences are and why they are important (horizontal consistency), but intentions and practice seemed still far apart, indicating lack of vertical consistency. The implications of the implementation of 21st century competences in national curriculum policies are discussed and recommendations are provided.\n",
            "------------------------------------\n",
            "Title :  Geodesic Information Flows: Spatially-Variant Graphs and Their Application to Segmentation and Fusion\n",
            "Author/s :  M. Cardoso, M. Modat, R. Wolz, A. Melbourne, D. Cash, D. Rueckert, S. Ourselin\n",
            "Venue :  IEEE Transactions on Medical Imaging\n",
            "year :  2015\n",
            "Abstract :  Clinical annotations, such as voxel-wise binary or probabilistic tissue segmentations, structural parcellations, pathological regions-of-interest and anatomical landmarks are key to many clinical studies. However, due to the time consuming nature of manually generating these annotations, they tend to be scarce and limited to small subsets of data. This work explores a novel framework to propagate voxel-wise annotations between morphologically dissimilar images by diffusing and mapping the available examples through intermediate steps. A spatially-variant graph structure connecting morphologically similar subjects is introduced over a database of images, enabling the gradual diffusion of information to all the subjects, even in the presence of large-scale morphological variability. We illustrate the utility of the proposed framework on two example applications: brain parcellation using categorical labels and tissue segmentation using probabilistic features. The application of the proposed method to categorical label fusion showed highly statistically significant improvements when compared to state-of-the-art methodologies. Significant improvements were also observed when applying the proposed framework to probabilistic tissue segmentation of both synthetic and real data, mainly in the presence of large morphological variability.\n",
            "------------------------------------\n",
            "Title :  Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images\n",
            "Author/s :  Saurabh Gupta, Pablo Arbeláez, Jitendra Malik\n",
            "Venue :  2013 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2013\n",
            "Abstract :  We address the problems of contour detection, bottom-up grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information. We show that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.\n",
            "------------------------------------\n",
            "Title :  Roadmap on optical security\n",
            "Author/s :  B. Javidi, A. Carnicer, Masahiro Yamaguchi, T. Nomura, E. Pérez-Cabré, M. S. Millán, N. Nishchal, R. Torroba, J. F. Barrera, W. He, Xiang Peng, A. Stern, Y. Rivenson, A. Alfalou, C. Brosseau, Changliang Guo, J. Sheridan, G. Situ, M. Naruse, Tsutomu Matsumoto, I. Juvells, E. Tajahuerce, J. Lancis, Wen Chen, Xudong Chen, P. Pinkse, A. Mosk, A. Markman\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Information security and authentication are important challenges facing society. Recent attacks by hackers on the databases of large commercial and financial companies have demonstrated that more research and development of advanced approaches are necessary to deny unauthorized access to critical data. Free space optical technology has been investigated by many researchers in information security, encryption, and authentication. The main motivation for using optics and photonics for information security is that optical waveforms possess many complex degrees of freedom such as amplitude, phase, polarization, large bandwidth, nonlinear transformations, quantum properties of photons, and multiplexing that can be combined in many ways to make information encryption more secure and more difficult to attack. This roadmap article presents an overview of the potential, recent advances, and challenges of optical security and encryption using free space optics. The roadmap on optical security is comprised of six categories that together include 16 short sections written by authors who have made relevant contributions in this field. The first category of this roadmap describes novel encryption approaches, including secure optical sensing which summarizes double random phase encryption applications and flaws [Yamaguchi], the digital holographic encryption in free space optical technique which describes encryption using multidimensional digital holography [Nomura], simultaneous encryption of multiple signals [Pérez-Cabré], asymmetric methods based on information truncation [Nishchal], and dynamic encryption of video sequences [Torroba]. Asymmetric and one-way cryptosystems are analyzed by Peng. The second category is on compression for encryption. In their respective contributions, Alfalou and Stern propose similar goals involving compressed data and compressive sensing encryption. The very important area of cryptanalysis is the topic of the third category with two sections: Sheridan reviews phase retrieval algorithms to perform different attacks, whereas Situ discusses nonlinear optical encryption techniques and the development of a rigorous optical information security theory. The fourth category with two contributions reports how encryption could be implemented at the nano- or micro-scale. Naruse discusses the use of nanostructures in security applications and Carnicer proposes encoding information in a tightly focused beam. In the fifth category, encryption based on ghost imaging using single-pixel detectors is also considered. In particular, the authors [Chen, Tajahuerce] emphasize the need for more specialized hardware and image processing algorithms. Finally, in the sixth category, Mosk and Javidi analyze in their corresponding papers how quantum imaging can benefit optical encryption systems. Sources that use few photons make encryption systems much more difficult to attack, providing a secure method for authentication.\n",
            "------------------------------------\n",
            "Title :  New media landscapes and the science information consumer\n",
            "Author/s :  D. Brossard\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2013\n",
            "Abstract :  Individuals are increasingly turning to online environments to find information about science and to follow scientific developments. It is therefore crucial for scientists and scientific institutions to consider empirical findings from research in online science communication when thinking about science in the public sphere. After providing a snapshot of the current media landscape, this paper reviews recent major research findings related to science communication in the online environment and their implications for science in the 21st century. Particular emphasis is given to the bias introduced by search engines, the nature of scientific content encountered online, and the potential impact of the Internet on audiences’ knowledge and attitudes toward science.\n",
            "------------------------------------\n",
            "Title :  A Survey of Physical Layer Security Techniques for 5G Wireless Networks and Challenges Ahead\n",
            "Author/s :  Yongpeng Wu, A. Khisti, Chengshan Xiao, G. Caire, Kai‐Kit Wong, Xiqi Gao\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2018\n",
            "Abstract :  Physical layer security which safeguards data confidentiality based on the information-theoretic approaches has received significant research interest recently. The key idea behind physical layer security is to utilize the intrinsic randomness of the transmission channel to guarantee the security in physical layer. The evolution toward 5G wireless communications poses new challenges for physical layer security research. This paper provides a latest survey of the physical layer security research on various promising 5G technologies, including physical layer security coding, massive multiple-input multiple-output, millimeter wave communications, heterogeneous networks, non-orthogonal multiple access, full duplex technology, and so on. Technical challenges which remain unresolved at the time of writing are summarized and the future trends of physical layer security in 5G and beyond are discussed.\n",
            "------------------------------------\n",
            "Title :  End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures\n",
            "Author/s :  Makoto Miwa, Mohit Bansal\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2016\n",
            "Abstract :  We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components.\n",
            "------------------------------------\n",
            "Title :  Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-Temporal Path Proposals\n",
            "Author/s :  Yantao Shen, Tong Xiao, Hongsheng Li, Shuai Yi, Xiaogang Wang\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  Vehicle re-identification is an important problem and has many applications in video surveillance and intelligent transportation. It gains increasing attention because of the recent advances of person re-identification techniques. However, unlike person re-identification, the visual differences between pairs of vehicle images are usually subtle and even challenging for humans to distinguish. Incorporating additional spatio-temporal information is vital for solving the challenging re-identification task. Existing vehicle re-identification methods ignored or used oversimplified models for the spatio-temporal relations between vehicle images. In this paper, we propose a two-stage framework that incorporates complex spatio-temporal information for effectively regularizing the re-identification results. Given a pair of vehicle images with their spatiotemporal information, a candidate visual-spatio-temporal path is first generated by a chain MRF model with a deeply learned potential function, where each visual-spatiotemporal state corresponds to an actual vehicle image with its spatio-temporal information. A Siamese-CNN+Path- LSTM model takes the candidate path as well as the pairwise queries to generate their similarity score. Extensive experiments and analysis show the effectiveness of our proposed method and individual components.\n",
            "------------------------------------\n",
            "Title :  Searching for superspreaders of information in real-world social media\n",
            "Author/s :  S. Pei, Lev Muchnik, J. S. Andrade, Zhiming Zheng, H. Makse\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Measuring Information-Transfer Delays\n",
            "Author/s :  M. Wibral, Nicolae Pampu, V. Priesemann, F. Siebenhühner, Hannes Seiwert, Michael Lindner, J. Lizier, Raul Vicente\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  In complex networks such as gene networks, traffic systems or brain circuits it is important to understand how long it takes for the different parts of the network to effectively influence one another. In the brain, for example, axonal delays between brain areas can amount to several tens of milliseconds, adding an intrinsic component to any timing-based processing of information. Inferring neural interaction delays is thus needed to interpret the information transfer revealed by any analysis of directed interactions across brain structures. However, a robust estimation of interaction delays from neural activity faces several challenges if modeling assumptions on interaction mechanisms are wrong or cannot be made. Here, we propose a robust estimator for neuronal interaction delays rooted in an information-theoretic framework, which allows a model-free exploration of interactions. In particular, we extend transfer entropy to account for delayed source-target interactions, while crucially retaining the conditioning on the embedded target state at the immediately previous time step. We prove that this particular extension is indeed guaranteed to identify interaction delays between two coupled systems and is the only relevant option in keeping with Wiener’s principle of causality. We demonstrate the performance of our approach in detecting interaction delays on finite data by numerical simulations of stochastic and deterministic processes, as well as on local field potential recordings. We also show the ability of the extended transfer entropy to detect the presence of multiple delays, as well as feedback loops. While evaluated on neuroscience data, we expect the estimator to be useful in other fields dealing with network dynamics.\n",
            "------------------------------------\n",
            "Title :  A Group Incremental Approach to Feature Selection Applying Rough Set Technique\n",
            "Author/s :  Jiye Liang, Feng Wang, C. Dang, Y. Qian\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2014\n",
            "Abstract :  Many real data increase dynamically in size. This phenomenon occurs in several fields including economics, population studies, and medical research. As an effective and efficient mechanism to deal with such data, incremental technique has been proposed in the literature and attracted much attention, which stimulates the result in this paper. When a group of objects are added to a decision table, we first introduce incremental mechanisms for three representative information entropies and then develop a group incremental rough feature selection algorithm based on information entropy. When multiple objects are added to a decision table, the algorithm aims to find the new feature subset in a much shorter time. Experiments have been carried out on eight UCI data sets and the experimental results show that the algorithm is effective and efficient.\n",
            "------------------------------------\n",
            "Title :  Recognizing actions using depth motion maps-based histograms of oriented gradients\n",
            "Author/s :  Xiaodong Yang, Chenyang Zhang, Yingli Tian\n",
            "Venue :  ACM Multimedia\n",
            "year :  2012\n",
            "Abstract :  In this paper, we propose an effective method to recognize human actions from sequences of depth maps, which provide additional body shape and motion information for action recognition. In our approach, we project depth maps onto three orthogonal planes and accumulate global activities through entire video sequences to generate the Depth Motion Maps (DMM). Histograms of Oriented Gradients (HOG) are then computed from DMM as the representation of an action video. The recognition results on Microsoft Research (MSR) Action3D dataset show that our approach significantly outperforms the state-of-the-art methods, although our representation is much more compact. In addition, we investigate how many frames are required in our framework to recognize actions on the MSR Action3D dataset. We observe that a short sub-sequence of 30-35 frames is sufficient to achieve comparable results to that operating on entire video sequences.\n",
            "------------------------------------\n",
            "Title :  Blockchain Disruption and Smart Contracts\n",
            "Author/s :  L. Cong, Zhiguo He\n",
            "Venue :  The Review of financial studies\n",
            "year :  2018\n",
            "Abstract :  Blockchain technology provides decentralized consensus and potentially enlarges the contracting space using smart contracts with tamper-proofness and algorithmic executions. Meanwhile, generating decentralized consensus entails distributing information which necessarily alters the informational environment. We analyze how decentralization affects consensus effectiveness, and how the quintessential features of blockchain reshape industrial organization and the landscape of competition. Smart contracts can mitigate informational asymmetry and improve welfare and consumer surplus through enhanced entry and competition, yet the irreducible distribution of information during consensus generation may encourage greater collusion. In general, blockchains can sustain market equilibria with a wider range of economic outcomes. We further discuss anti-trust policy implications targeted to blockchain applications, such as separating consensus record-keepers from users.\n",
            "------------------------------------\n",
            "Title :  User preference of cyber security awareness delivery methods\n",
            "Author/s :  J. Abawajy\n",
            "Venue :  Behavior and Information Technology\n",
            "year :  2014\n",
            "Abstract :  Operating systems and programmes are more protected these days and attackers have shifted their attention to human elements to break into the organisation's information systems. As the number and frequency of cyber-attacks designed to take advantage of unsuspecting personnel are increasing, the significance of the human factor in information security management cannot be understated. In order to counter cyber-attacks designed to exploit human factors in information security chain, information security awareness with an objective to reduce information security risks that occur due to human related vulnerabilities is paramount. This paper discusses and evaluates the effects of various information security awareness delivery methods used in improving end-users’ information security awareness and behaviour. There are a wide range of information security awareness delivery methods such as web-based training materials, contextual training and embedded training. In spite of efforts to increase information security awareness, research is scant regarding effective information security awareness delivery methods. To this end, this study focuses on determining the security awareness delivery method that is most successful in providing information security awareness and which delivery method is preferred by users. We conducted information security awareness using text-based, game-based and video-based delivery methods with the aim of determining user preferences. Our study suggests that a combined delivery methods are better than individual security awareness delivery method.\n",
            "------------------------------------\n",
            "Title :  The Effect of Economic Policy Uncertainty on Investor Information Asymmetry and Management Disclosures\n",
            "Author/s :  Venky Nagar, Jordan Schoenfeld, Laura A. Wellman\n",
            "Venue :  Journal of Accounting & Economics\n",
            "year :  2018\n",
            "Abstract :  Abstract Investor uncertainty about firm value drives investors’ information collection and trading activities, as well as managers’ disclosure choices. This study examines an important source of uncertainty that likely cannot be influenced by most managers and investors: uncertainty about government economic policy. We find that this uncertainty is associated with increased bid-ask spreads and decreased stock price reactions to earnings surprises. Managers respond to this uncertainty by increasing their voluntary disclosures, but these disclosures only partly mitigate the bid-ask spread increase. We conclude that government economic policy uncertainty is an important component of firms’ information environments and managers’ voluntary disclosure decisions.\n",
            "------------------------------------\n",
            "Title :  Big Data in product lifecycle management\n",
            "Author/s :  Jingran Li, F. Tao, Ying Cheng, Lian Zhao\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author/s :  L. Thygesen, A. Ersbøll\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Guide to Field Notes for Qualitative Research: Context and Conversation\n",
            "Author/s :  Julia C Phillippi, J. Lauderdale\n",
            "Venue :  Qualitative Health Research\n",
            "year :  2018\n",
            "Abstract :  Field notes are widely recommended in qualitative research as a means of documenting needed contextual information. With growing use of data sharing, secondary analysis, and metasynthesis, field notes ensure rich context persists beyond the original research team. However, while widely regarded as essential, there is not a guide to field note collection within the literature to guide researchers. Using the qualitative literature and previous research experience, we provide a concise guide to collection, incorporation, and dissemination of field notes. We provide a description of field note content for contextualization of an entire study as well as individual interviews and focus groups. In addition, we provide two “sketch note” guides, one for study context and one for individual interviews or focus groups for use in the field. Our guides are congruent with many qualitative and mixed methodologies and ensure contextual information is collected, stored, and disseminated as an essential component of ethical, rigorous qualitative research.\n",
            "------------------------------------\n",
            "Title :  Science, New Media, and the Public\n",
            "Author/s :  D. Brossard, D. Scheufele\n",
            "Venue :  Science\n",
            "year :  2013\n",
            "Abstract :  A better understanding is needed about how the online environment affects the communication of science information to the public. Nine in 10 internet users in the United States turn to search engines to find information (1), and 60% of the U.S. public seeking information about specific scientific issues lists the Internet as their primary source of information (2). This has created a new urgency for scientists to pay attention to these trends and to the emerging scholarly literature about communicating science in this brave new “online” world.\n",
            "------------------------------------\n",
            "Title :  Scaling the Ion Trap Quantum Processor\n",
            "Author/s :  C. Monroe, J. Kim\n",
            "Venue :  Science\n",
            "year :  2013\n",
            "Abstract :  Trapped atomic ions are standards for quantum information processing, serving as quantum memories, hosts of quantum gates in quantum computers and simulators, and nodes of quantum communication networks. Quantum bits based on trapped ions enjoy a rare combination of attributes: They have exquisite coherence properties, they can be prepared and measured with nearly 100% efficiency, and they are readily entangled with each other through the Coulomb interaction or remote photonic interconnects. The outstanding challenge is the scaling of trapped ions to hundreds or thousands of qubits and beyond, at which scale quantum processors can outperform their classical counterparts in certain applications. We review the latest progress and prospects in that effort, with the promise of advanced architectures and new technologies, such as microfabricated ion traps and integrated photonics.\n",
            "------------------------------------\n",
            "Title :  Gender Differences in Searching for Health Information on the Internet and the Virtual Patient-Physician Relationship in Germany: Exploratory Results on How Men and Women Differ and Why\n",
            "Author/s :  Sonja Bidmon, R. Terlutter\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2015\n",
            "Abstract :  Background Many studies have shown that women use the Internet more often for health-related information searches than men, but we have limited knowledge about the underlying reasons. We also do not know whether and how women and men differ in their current use of the Internet for communicating with their general practitioner (GP) and in their future intention to do so (virtual patient-physician relationship). Objective This study investigates (1) gender differences in health-related information search behavior by exploring underlying emotional, motivational, attitudinal as well as cognitive variables, situational involvement, and normative influences, and different personal involvement regarding health-related information searching and (2) gender differences in the virtual patient-physician relationship. Methods Gender differences were analyzed based on an empirical online survey of 1006 randomly selected German patients. The sample was drawn from an e-panel maintained by GfK HealthCare. A total of 958 usable questionnaires were analyzed. Principal component analyses were carried out for some variables. Differences between men (517/958) and women (441/958) were analyzed using t tests and Kendall’s tau-b tests. The survey instrument was guided by several research questions and was based on existing literature. Results Women were more engaged in using the Internet for health-related information searching. Gender differences were found for the frequency of usage of various Internet channels for health-related information searches. Women used the Internet for health-related information searches to a higher degree for social motives and enjoyment and they judged the usability of the Internet medium and of the information gained by health information searches higher than men did. Women had a more positive attitude toward Web 2.0 than men did, but perceived themselves as less digitally competent. Women had a higher health and nutrition awareness and a greater reluctance to make use of medical support, as well as a higher personal disposition of being well-informed as a patient. Men may be more open toward the virtual patient-physician relationship. Conclusions Women have a stronger social motive for and experience greater enjoyment in health-related information searches, explained by social role interpretations, suggesting these needs should be met when offering health-related information on the Internet. This may be interesting for governmental bodies as well as for the insurance and the pharmaceutical industries. Furthermore, women may be more easily convinced by health awareness campaigns and are, therefore, the primary target group for them. Men are more open to engaging in a virtual relationship with the GP; therefore, they could be the primary target group for additional online services offered by GPs. There were several areas for GPs to reinforce the virtual patient-physician relationship: the fixing of personal appointments, referral to other doctors, writing prescriptions, and discussions of normal test results and doctor’s notes/certificates of health.\n",
            "------------------------------------\n",
            "Title :  Accounting information systems\n",
            "Author/s :  S. Altschuller, Shaya Altschuller\n",
            "Venue :  The Routledge Companion to Risk, Crisis and Security in Business\n",
            "year :  2018\n",
            "Abstract :  Accounting Information Systems Introduction The development of information technology impacts significantly on various fields and activities. The biggest impact can be seen in accounting practice. The changes are becoming more and more complex as there are shifts in business activities, such as in organization management, the concept of change management, and integration activities making closer ties among suppliers, customers and even competitors (Computing Curricula 2005, Information System).\n",
            "------------------------------------\n",
            "Title :  InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization\n",
            "Author/s :  Fan-Yun Sun, Jordan Hoffmann, Jian Tang\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2019\n",
            "Abstract :  This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.\n",
            "------------------------------------\n",
            "Title :  Nucleation, stability and current-induced motion of isolated magnetic skyrmions in nanostructures.\n",
            "Author/s :  J. Sampaio, V. Cros, S. Rohart, A. Thiaville, A. Fert\n",
            "Venue :  Nature Nanotechnology\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Inference Attacks on Property-Preserving Encrypted Databases\n",
            "Author/s :  Muhammad Naveed, S. Kamara, C. V. Wright\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2015\n",
            "Abstract :  Many encrypted database (EDB) systems have been proposed in the last few years as cloud computing has grown in popularity and data breaches have increased. The state-of-the-art EDB systems for relational databases can handle SQL queries over encrypted data and are competitive with commercial database systems. These systems, most of which are based on the design of CryptDB (SOSP 2011), achieve these properties by making use of property-preserving encryption schemes such as deterministic (DTE) and order- preserving encryption (OPE). In this paper, we study the concrete security provided by such systems. We present a series of attacks that recover the plaintext from DTE- and OPE-encrypted database columns using only the encrypted column and publicly-available auxiliary information. We consider well-known attacks, including frequency analysis and sorting, as well as new attacks based on combinatorial optimization. We evaluate these attacks empirically in an electronic medical records (EMR) scenario using real patient data from 200 U.S. hospitals. When the encrypted database is operating in a steady-state where enough encryption layers have been peeled to permit the application to run its queries, our experimental results show that an alarming amount of sensitive information can be recovered. In particular, our attacks correctly recovered certain OPE-encrypted attributes (e.g., age and disease severity) for more than 80% of the patient records from 95% of the hospitals; and certain DTE- encrypted attributes (e.g., sex, race, and mortality risk) for more than 60% of the patient records from more than 60% of the hospitals.\n",
            "------------------------------------\n",
            "Title :  Is the privacy paradox a relic of the past? An in‐depth analysis of privacy attitudes and privacy behaviors\n",
            "Author/s :  T. Dienlin, Sabine Trepte\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  The privacy paradox states that online privacy concerns do not sufficiently explain online privacy behaviors on social network sites (SNSs). In this study, it was first asked whether the privacy paradox would still exist when analyzed as in prior research. Second, it was hypothesized that the privacy paradox would disappear when analyzed in a new approach. The new approach featured a multidimensional operationalization of privacy by differentiating between informational, social, and psychological privacy. Next to privacy concerns, also, privacy attitudes and privacy intentions were analyzed. With the aim to improve methodological aspects, all items were designed on the basis of the theory of planned behavior. In an online questionnaire with N = 595 respondents, it was found that online privacy concerns were not significantly related to specific privacy behaviors, such as the frequency or content of disclosures on SNSs (e.g., name, cell-phone number, or religious views). This demonstrated that the privacy paradox still exists when it is operationalized as in prior research. With regard to the new approach, all hypotheses were confirmed: Results showed both a direct relation and an indirect relation between privacy attitudes and privacy behaviors, the latter mediated by privacy intentions. In addition, also an indirect relation between privacy concerns and privacy behaviors was found, mediated by privacy attitudes and privacy intentions. Therefore, privacy behaviors can be explained sufficiently when using privacy attitudes, privacy concerns, and privacy intentions within the theory of planned behavior. The behaviors of SNS users are not as paradoxical as was once believed. Copyright © 2014 John Wiley & Sons, Ltd.\n",
            "------------------------------------\n",
            "Title :  The Rise of the Network Society - The Information Age: Economy, Society, and Culture\n",
            "Author/s :  Taner Kizilhan, Sevil Bal Kızılhan\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Castell’s book is the first part of his milstone “The Information Age: Economy Society, and Culture” work. The author states that, the triology was prepared to be a single book, but then with the contributions of the editor, it was divided into three books by making each part of the study a separate book. In this particular book, Castells presents an easily understandable and comprehensive analysis by examining the economic, social, and cultural changes that caused by the Network Society. He does this by being as realistic as possible and reaching a clear conclusion by supporting all of his claims with various statistics and examples.\n",
            "------------------------------------\n",
            "Title :  Research Note - Effects of Individual Self-Protection, Industry Self-Regulation, and Government Regulation on Privacy Concerns: A Study of Location-Based Services\n",
            "Author/s :  Heng Xu, H. Teo, B. Tan, Ritu Agarwal\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This study seeks to clarify the nature of control in the context of information privacy to generate insights into the effects of different privacy assurance approaches on context-specific concerns for information privacy. We theorize that such effects are exhibited through mediation by perceived control over personal information and develop arguments in support of the interaction effects involving different privacy assurance approaches (individual self-protection, industry self-regulation, and government legislation). We test the research model in the context of location-based services using data obtained from 178 individuals in Singapore. In general, the results support our core assertion that perceived control over personal information is a key factor affecting context-specific concerns for information privacy. In addition to enhancing our theoretical understanding of the link between control and privacy concerns, these findings have important implications for service providers and consumers as well as for regulatory bodies and technology developers.\n",
            "------------------------------------\n",
            "Title :  Making existing production systems Industry 4.0-ready\n",
            "Author/s :  Jan Schlechtendahl, Matthias Keinert, F. Kretschmer, A. Lechler, A. Verl\n",
            "Venue :  Production Engineering\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Content-Aware Point of Interest Recommendation on Location-Based Social Networks\n",
            "Author/s :  Huiji Gao, Jiliang Tang, Xia Hu, Huan Liu\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " The rapid urban expansion has greatly extended the physical boundary of users' living area and developed a large number of POIs (points of interest). POI recommendation is a task that facilitates users' urban exploration and helps them filter uninteresting POIs for decision making. While existing work of POI recommendation on location-based social networks (LBSNs) discovers the spatial, temporal, and social patterns of user check-in behavior, the use of content information has not been systematically studied. The various types of content information available on LBSNs could be related to different aspects of a user's check-in action, providing a unique opportunity for POI recommendation. In this work, we study the content information on LBSNs w.r.t. POI properties, user interests, and sentiment indications. We model the three types of information under a unified POI recommendation framework with the consideration of their relationship to check-in actions. The experimental results exhibit the significance of content information in explaining user behavior, and demonstrate its power to improve POI recommendation performance on LBSNs.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  P-CNN: Pose-Based CNN Features for Action Recognition\n",
            "Author/s :  Guilhem Chéron, I. Laptev, C. Schmid\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2015\n",
            "Abstract :  This work targets human action recognition in video. While recent methods typically represent actions by statistics of local video features, here we argue for the importance of a representation derived from human pose. To this end we propose a new Pose-based Convolutional Neural Network descriptor (P-CNN) for action recognition. The descriptor aggregates motion and appearance information along tracks of human body parts. We investigate different schemes of temporal aggregation and experiment with P-CNN features obtained both for automatically estimated and manually annotated human poses. We evaluate our method on the recent and challenging JHMDB and MPII Cooking datasets. For both datasets our method shows consistent improvement over the state of the art.\n",
            "------------------------------------\n",
            "Title :  Character-Aware Neural Language Models\n",
            "Author/s :  Yoon Kim, Yacine Jernite, D. Sontag, Alexander M. Rush\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  PROV-DM: The PROV Data Model\n",
            "Author/s :  Khalid Belhajjame, Reza B'Far, J. Cheney, Sam Coppens, S. Cresswell, Y. Gil, Paul Groth, G. Klyne, Timothy Lebo, Jamie McCusker, S. Miles, J. Myers, S. Sahoo, C. Tilmes\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness. PROV-DM is the conceptual data model that forms a basis for the W3C provenance (PROV) family of specifications. PROV-DM distinguishes core structures, forming the essence of provenance information, from extended structures catering for more specific uses of provenance. PROV-DM is organized in six components, respectively dealing with: (1) entities and activities, and the time at which they were created, used, or ended; (2) derivations of entities from entities; (3) agents bearing responsibility for entities that were generated and activities that happened; (4) a notion of bundle, a mechanism to support provenance of provenance; (5) properties to link entities that refer to the same thing; and, (6) collections forming a logical structure for its members. This document introduces the provenance concepts found in PROV and defines PROV-DM types and relations. The PROV data model is domain-agnostic, but is equipped with extensibility points allowing domain-specific information to be included. Two further documents complete the specification of PROV-DM. First, a companion document specifies the set of constraints that provenance should follow. Second, a separate document describes a provenance notation for expressing instances of provenance for human consumption; this notation is used in examples in this document.\n",
            "------------------------------------\n",
            "Title :  Graph Convolution over Pruned Dependency Trees Improves Relation Extraction\n",
            "Author/s :  Yuhao Zhang, Peng Qi, Christopher D. Manning\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2018\n",
            "Abstract :  Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.\n",
            "------------------------------------\n",
            "Title :  A Survey of Text Similarity Approaches\n",
            "Author/s :  W. H. Gomaa, A. Fahmy\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT Measuring the similarity between words, sentences, paragraphs and documents is an important component in various tasks such as information retrieval, document clustering, word-sense disambiguation, automatic essay scoring, short answer grading, machine translation and text summarization. This survey discusses the existing works on text similarity through partitioning them into three approaches; String-based, Corpus-based and Knowledge-based similarities. Furthermore, samples of combination between these similarities are presented. General Terms Text Mining, Natural Language Processing. Keywords BasedText Similarity, Semantic Similarity, String-Based Similarity, Corpus-Based Similarity, Knowledge-Based Similarity. NeedlemanWunsch 1. INTRODUCTION Text similarity measures play an increasingly important role in text related research and applications in tasks Nsuch as information retrieval, text classification, document clustering, topic detection, topic tracking, questions generation, question answering, essay scoring, short answer scoring, machine translation, text summarization and others. Finding similarity between words is a fundamental part of text similarity which is then used as a primary stage for sentence, paragraph and document similarities. Words can be similar in two ways lexically and semantically. Words are similar lexically if they have a similar character sequence. Words are similar semantically if they have the same thing, are opposite of each other, used in the same way, used in the same context and one is a type of another. DistanceLexical similarity is introduced in this survey though different String-Based algorithms, Semantic similarity is introduced through Corpus-Based and Knowledge-Based algorithms. String-Based measures operate on string sequences and character composition. A string metric is a metric that measures similarity or dissimilarity (distance) between two text strings for approximate string matching or comparison. Corpus-Based similarity is a semantic similarity measure that determines the similarity between words according to information gained from large corpora. Knowledge-Based similarity is a semantic similarity measure that determines the degree of similarity between words using information derived from semantic networks. The most popular for each type will be presented briefly. This paper is organized as follows: Section two presents String-Based algorithms by partitioning them into two types character-based and term-based measures. Sections three and four introduce Corpus-Based and knowledge-Based algorithms respectively. Samples of combinations between similarity algorithms are introduced in section five and finally section six presents conclusion of the survey.\n",
            "------------------------------------\n",
            "Title :  Thermodynamics with Continuous Information Flow\n",
            "Author/s :  J. Horowitz, M. Esposito\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We provide a unified thermodynamic formalism describing information transfers in autonomous as well as nonautonomous systems described by stochastic thermodynamics. We demonstrate how information is continuously generated in an auxiliary system and then transferred to a relevant system that can utilize it to fuel otherwise impossible processes. Indeed, while the joint system satisfies the second law, the entropy balance for the relevant system is modified by an information term related to the mutual information rate between the two systems. We show that many important results previously derived for nonautonomous Maxwell demons can be recovered from our formalism and use a cycle decomposition to analyze the continuous information flow in autonomous systems operating at steady-state. A model system is used to illustrate our findings.\n",
            "------------------------------------\n",
            "Title :  Smart Refugees: How Syrian Asylum Migrants Use Social Media Information in Migration Decision-Making\n",
            "Author/s :  R. Dekker, G. Engbersen, Jeanine Klaver, Hanna Vonk\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Social media are increasingly popular channels of information on which migrants base their decisions on whether to migrate and the destinations where to settle. While social media offer a relatively cheap, easily accessible, and media-rich means of communication, their use is not without challenges for asylum migrants. Various studies describe issues with access and evaluation of the truthfulness of available information for this specific group of migrants. This article discusses social media use by asylum migrants prior to and during migration. This study is based on in-depth interviews with 54 Syrian asylum migrants who recently obtained refugee status in the Netherlands. Syrians were the largest group of migrants applying for asylum in European Union (EU) member states in 2015 and 2016. The findings show that the majority of Syrian asylum migrants have access to social media information before and during migration, often through the use of smartphones. Besides uneven access to technologies, fear of government surveillance restricts the smartphone use of asylum migrants. The results of this study indicate that Syrian asylum migrants prefer social media information that originates from existing social ties and information that is based on personal experiences. Generally, this information is considered more trustworthy. Asylum migrants use various strategies to validate rumors that are present on social media and come from unknown sources. These strategies include checking the source of information, validating information with trusted social ties, triangulation of online sources, and comparing information with their own experience.\n",
            "------------------------------------\n",
            "Title :  An event-driven manufacturing information system architecture for Industry 4.0\n",
            "Author/s :  Alfred Theorin, Kristofer Bengtsson, Julien Provost, Michael Lieder, C. Johnsson, T. Lundholm, B. Lennartson\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2017\n",
            "Abstract :  Future manufacturing systems need to be more flexible, to embrace tougher and constantly changing market demands. They need to make better use of plant data, ideally utilising all data from the entire plant. Low-level data should be refined to real-time information for decision-making, to facilitate competitiveness through informed and timely decisions. The Line Information System Architecture (LISA), is presented in this paper. It is an event-driven architecture featuring loose coupling, a prototype-oriented information model and formalised transformation services. LISA is designed to enable flexible factory integration and data utilisation. The focus of LISA is on integration of devices and services on all levels, simplifying hardware changes and integration of new smart services as well as supporting continuous improvements on information visualisation and control. The architecture has been evaluated on both real industrial data and industrial demonstrators and it is also being installed at a large automotive company. This article is an extended and revised version of the paper presented at the 2015 IFAC Symposium on Information Control in Manufacturing (INCOM 2015). The paper has been restructured in regards to the order and title of the chapters, and additional information about the integration between devices and services aspects have been added. The introduction and the general structure of the paper now better highlight the contributions of the paper and the uniqueness of the framework.\n",
            "------------------------------------\n",
            "Title :  Pyramid Stereo Matching Network\n",
            "Author/s :  Jia-Ren Chang, Yonghao Chen\n",
            "Venue :  2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  Recent work has shown that depth estimation from a stereo pair of images can be formulated as a supervised learning task to be resolved with convolutional neural networks (CNNs). However, current architectures rely on patch-based Siamese networks, lacking the means to exploit context information for finding correspondence in ill-posed regions. To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision. The proposed approach was evaluated on several benchmark datasets. Our method ranked first in the KITTI 2012 and 2015 leaderboards before March 18, 2018. The codes of PSMNet are available at: https://github.com/JiaRenChang/PSMNet.\n",
            "------------------------------------\n",
            "Title :  Deep High-Resolution Representation Learning for Human Pose Estimation\n",
            "Author/s :  Ke Sun, Bin Xiao, Dong Liu, Jingdong Wang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.\n",
            "------------------------------------\n",
            "Title :  The development of student feedback literacy: enabling uptake of feedback\n",
            "Author/s :  D. Carless, D. Boud\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Abstract Student feedback literacy denotes the understandings, capacities and dispositions needed to make sense of information and use it to enhance work or learning strategies. In this conceptual paper, student responses to feedback are reviewed and a number of barriers to student uptake of feedback are discussed. Four inter-related features are proposed as a framework underpinning students’ feedback literacy: appreciating feedback; making judgments; managing affect; and taking action. Two well-established learning activities, peer feedback and analysing exemplars, are discussed to illustrate how this framework can be operationalized. Some ways in which these two enabling activities can be re-focused more explicitly towards developing students’ feedback literacy are elaborated. Teachers are identified as playing important facilitating roles in promoting student feedback literacy through curriculum design, guidance and coaching. The implications and conclusion summarise recommendations for teaching and set out an agenda for further research.\n",
            "------------------------------------\n",
            "Title :  Editorial - Big Data, Data Science, and Analytics: The Opportunity and Challenge for IS Research\n",
            "Author/s :  Ritu Agarwal, V. Dhar\n",
            "Venue :  Information systems research\n",
            "year :  2014\n",
            "Abstract :  We address key questions related to the explosion of interest in the emerging fields of big data, analytics, and data science. We discuss the novelty of the fields and whether the underlying questions are fundamentally different, the strengths that the information systems IS community brings to this discourse, interesting research questions for IS scholars, the role of predictive and explanatory modeling, and how research in this emerging area should be evaluated for contribution and significance.\n",
            "------------------------------------\n",
            "Title :  China's Strategic Censorship\n",
            "Author/s :  Peter Lorentzen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  While it is often assumed that authoritarian regimes inevitably fear and restrict media independence, permitting watchdog journalism can actually help such regimes maintain power by improving governance. Yet such a strategy risks facilitating a coordinated uprising if discontent is revealed to be widespread. A formal model shows that under some conditions, a regime optimally permits investigative reporting on lower-level officialdom, adjusting how much reporting is allowed depending on the level of underlying social tensions. This strategy yields many of the benefits of free media without risking overthrow. An extension shows why an increase in uncontrollable information, such as from the Internet, may result in a reduction in media freedom. The model sheds light on important aspects of China's media policy and its evolution and on authoritarian media control more broadly.\n",
            "------------------------------------\n",
            "Title :  Research Note - Privacy Concerns and Privacy-Protective Behavior in Synchronous Online Social Interactions\n",
            "Author/s :  Z. Jiang, C. Heng, Ben C. F. Choi\n",
            "Venue :  Information systems research\n",
            "year :  2013\n",
            "Abstract :  Privacy is of prime importance to many individuals when they attempt to develop online social relationships. Nonetheless, it has been observed that individuals' behavior is at times inconsistent with their privacy concerns, e.g., they disclose substantial private information in synchronous online social interactions, even though they are aware of the risks involved. Drawing on the hyperpersonal framework and the privacy calculus perspective, this paper elucidates the interesting roles of privacy concerns and social rewards in synchronous online social interactions by examining the causes and the behavioral strategies that individuals utilize to protect their privacy. An empirical study involving 251 respondents was conducted in online chat rooms. Our results indicate that individuals utilize both self-disclosure and misrepresentation to protect their privacy and that social rewards help explain why individuals may not behave in accordance with their privacy concerns. In addition, we find that perceived anonymity of others and perceived intrusiveness affect both privacy concerns and social rewards. Our findings also suggest that higher perceived anonymity of self decreases individuals' privacy concerns, and higher perceived media richness increases social rewards. Generally, this study contributes to the information systems literature by integrating the hyperpersonal framework and the privacy calculus perspective to identify antecedents of privacy trade-off and predict individuals' behavior in synchronous online social interactions.\n",
            "------------------------------------\n",
            "Title :  Characterizing nonclassical correlations via local quantum uncertainty.\n",
            "Author/s :  D. Girolami, T. Tufarelli, G. Adesso\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  Quantum mechanics predicts that measurements of incompatible observables carry a minimum uncertainty which is independent of technical deficiencies of the measurement apparatus or incomplete knowledge of the state of the system. Nothing yet seems to prevent a single physical quantity, such as one spin component, from being measured with arbitrary precision. Here, we show that an intrinsic quantum uncertainty on a single observable is ineludible in a number of physical situations. When revealed on local observables of a bipartite system, such uncertainty defines an entire class of bona fide measures of nonclassical correlations. For the case of 2 × d systems, we find that a unique measure is defined, which we evaluate in closed form. We then discuss the role that these correlations, which are of the \"discord\" type, can play in the context of quantum metrology. We show in particular that the amount of discord present in a bipartite mixed probe state guarantees a minimum precision, as quantified by the quantum Fisher information, in the optimal phase estimation protocol.\n",
            "------------------------------------\n",
            "Title :  Quantum speed limit for physical processes.\n",
            "Author/s :  M. M. Taddei, B. Escher, L. Davidovich, R. de Matos Filho\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  The evaluation of the minimal evolution time between two distinguishable states of a system is important for assessing the maximal speed of quantum computers and communication channels. Lower bounds for this minimal time have been proposed for unitary dynamics. Here we show that it is possible to extend this concept to nonunitary processes, using an attainable lower bound that is connected to the quantum Fisher information for time estimation. This result is used to delimit the minimal evolution time for typical noisy channels.\n",
            "------------------------------------\n",
            "Title :  Variational Information Distillation for Knowledge Transfer\n",
            "Author/s :  Sungsoo Ahn, S. Hu, A. Damianou, Neil D. Lawrence, Zhenwen Dai\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  Transferring knowledge from a teacher neural network pretrained on the same or a similar task to a student neural network can significantly improve the performance of the student neural network. Existing knowledge transfer approaches match the activations or the corresponding hand-crafted features of the teacher and the student networks. We propose an information-theoretic framework for knowledge transfer which formulates knowledge transfer as maximizing the mutual information between the teacher and the student networks. We compare our method with existing knowledge transfer methods on both knowledge distillation and transfer learning tasks and show that our method consistently outperforms existing methods. We further demonstrate the strength of our method on knowledge transfer across heterogeneous network architectures by transferring knowledge from a convolutional neural network (CNN) to a multi-layer perceptron (MLP) on CIFAR-10. The resulting MLP significantly outperforms the-state-of-the-art methods and it achieves similar performance to the CNN with a single convolutional layer.\n",
            "------------------------------------\n",
            "Title :  How to win in an Omnichannel world\n",
            "Author/s :  David R. Bell, Santiago Gallino, Antonio Moreno\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  The omnichannel environment presents new challenges and opportunities for both information and product fulfillment. While all retailers need to effectively and efficiently manage fulfillment and information provision, there are important nuances to how this happens, depending on where and how the retailer got started and what kinds of improvement create the most leverage. This article delivers a customer-focused framework showing how to win in the omni-channel environment through critical innovations in information delivery and product fulfillment. The framework emerged from our research with both traditional and nontraditional retailers. To thrive in the new environment, retailers of all stripes and origins need to deploy information and fulfillment strategies that reduce friction in every phase of the buying process. This means simultaneously providing, in a cost-effective and narrative-enhancing way\n",
            "------------------------------------\n",
            "Title :  End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures\n",
            "Author/s :  Makoto Miwa, Mohit Bansal\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2016\n",
            "Abstract :  We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components.\n",
            "------------------------------------\n",
            "Title :  A comparative analysis of international frameworks for 21st century competences: Implications for national curriculum policies\n",
            "Author/s :  J. Voogt, N. P. Roblin\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  National curricula need to change drastically to comply with the competences needed for the 21st century. In this paper eight frameworks describing 21st century competences were analysed. A comprehensive search for information about 21st century competences was conducted across the official websites of the selected frameworks, resulting in 32 documents that were analysed in detail. Travers and Westbury’s framework of curriculum representations was used to determine horizontal and vertical consistency between the frameworks. The frameworks were compared on their underlying rationales and goals, their definition of 21st century competences, and the recommended strategies for the implementation and assessment of these skills in educational practice. In addition three international studies were examined to analyse how various countries (EU member states, OECD countries) and schools (SITES studies) deal (or not) with 21st century competences. The findings indicate a large extent of alignment between the frameworks about what 21st century competences are and why they are important (horizontal consistency), but intentions and practice seemed still far apart, indicating lack of vertical consistency. The implications of the implementation of 21st century competences in national curriculum policies are discussed and recommendations are provided.\n",
            "------------------------------------\n",
            "Title :  Specification of the IP Flow Information Export (IPFIX) Protocol for the Exchange of Flow Information\n",
            "Author/s :  B. Claise, B. Trammell, P. Aitken\n",
            "Venue :  Request for Comments\n",
            "year :  2013\n",
            "Abstract :  This document specifies the IP Flow Information Export (IPFIX) protocol, which serves as a means for transmitting Traffic Flow information over the network. In order to transmit Traffic Flow information from an Exporting Process to a Collecting Process, a common representation of flow data and a standard means of communicating them are required. This document describes how the IPFIX Data and Template Records are carried over a number of transport protocols from an IPFIX Exporting Process to an IPFIX Collecting Process. This document obsoletes RFC 5101.\n",
            "------------------------------------\n",
            "Title :  Recent automatic text summarization techniques: a survey\n",
            "Author/s :  Mahak Gambhir, Vishal Gupta\n",
            "Venue :  Artificial Intelligence Review\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Political Incentives to Suppress Negative Information: Evidence from Chinese Listed Firms\n",
            "Author/s :  Joseph D. Piotroski, T. Wong, Tian-Yu Zhang\n",
            "Venue :  Journal of Accounting Research\n",
            "year :  2015\n",
            "Abstract :  ABSTRACT This paper tests the proposition that politicians and their affiliated firms (i.e., firms operating in their province) temporarily suppress negative information in response to political incentives. We examine the stock price behavior of Chinese listed firms around two visible political events—meetings of the National Congress of the Chinese Communist Party and promotions of high‐level provincial politicians—that are expected to asymmetrically increase the costs of releasing bad news. The costs create an incentive for local politicians and their affiliated firms to temporarily restrict the flow of negative information about the companies. The result will be fewer stock price crashes for the affiliated firms during these event windows, followed by an increase in crashes after the event. Consistent with these predictions, we find that the affiliated firms experience a reduction (an increase) in negative stock return skewness before (after) the event. These effects are strongest in the three‐month period directly preceding the event, among firms that are more politically connected, and when the province is dominated by faction politics and cronyism. Additional tests document a significant reduction in published newspaper articles about affected firms in advance of these political events, suggestive of a link between our observed stock price behavior and temporary shifts in the listed firms’ information environment.\n",
            "------------------------------------\n",
            "Title :  Nonprice incentives and energy conservation\n",
            "Author/s :  O. Asensio, M. Delmas\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance We investigate the effectiveness of nonprice incentives to motivate conservation behavior. We test whether tailored information about environmental and health damages produces behavior change in the residential electricity sector. In a randomized controlled trial with real-time appliance-level energy metering over 8 mo, we find that environment and health-based information strategies outperform monetary savings information to drive energy conservation. Environment and health-based messages, which communicate the environmental and public health externalities of electricity production—such as pounds of pollutants, childhood asthma, and cancer—motivated 8% energy savings versus control. This strategy was particularly effective on families with children, who achieved 19% energy savings. However, we do not study the persistence of these behavioral changes after the conclusion of the study. In the electricity sector, energy conservation through technological and behavioral change is estimated to have a savings potential of 123 million metric tons of carbon per year, which represents 20% of US household direct emissions in the United States. In this article, we investigate the effectiveness of nonprice information strategies to motivate conservation behavior. We introduce environment and health-based messaging as a behavioral strategy to reduce energy use in the home and promote energy conservation. In a randomized controlled trial with real-time appliance-level energy metering, we find that environment and health-based information strategies, which communicate the environmental and public health externalities of electricity production, such as pounds of pollutants, childhood asthma, and cancer, outperform monetary savings information to drive behavioral change in the home. Environment and health-based information treatments motivated 8% energy savings versus control and were particularly effective on families with children, who achieved up to 19% energy savings. Our results are based on a panel of 3.4 million hourly appliance-level kilowatt–hour observations for 118 residences over 8 mo. We discuss the relative impacts of both cost-savings information and environmental health messaging strategies with residential consumers.\n",
            "------------------------------------\n",
            "Title :  Predictive Entropy Search for Efficient Global Optimization of Black-box Functions\n",
            "Author/s :  José Miguel Hernández-Lobato, Matthew W. Hoffman, Zoubin Ghahramani\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance.\n",
            "------------------------------------\n",
            "Title :  Adoption and use of social media among public health departments\n",
            "Author/s :  R. Thackeray, B. Neiger, Amanda Smith, Sarah B Van Wagenen\n",
            "Venue :  BMC Public Health\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Fused Matrix Factorization with Geographical and Social Influence in Location-Based Social Networks\n",
            "Author/s :  Chen-Kuang Cheng, Haiqin Yang, Irwin King, Michael R. Lyu\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2012\n",
            "Abstract :  \n",
            " \n",
            " Recently, location-based social networks (LBSNs), such as Gowalla, Foursquare, Facebook, and Brightkite, etc., have attracted millions of users to share their social friendship and their locations via check-ins. The available check-in information makes it possible to mine users’ preference on locations and to provide favorite recommendations. Personalized Point-of-interest (POI) recommendation is a significant task in LBSNs since it can help targeted users explore their surroundings as well as help third-party developers to provide personalized services. To solve this task, matrix factorization is a promising tool due to its success in recommender systems. However, previously proposed matrix factorization (MF) methods do not explore geographical influence, e.g., multi-center check-in property, which yields suboptimal solutions for the recommendation. In this paper, to the best of our knowledge, we are the first to fuse MF with geographical and social influence for POI recommendation in LBSNs. We first capture the geographical influence via modeling the probability of a user’s check-in on a location as a Multi-center Gaussian Model (MGM). Next, we include social information and fuse the geographical influence into a generalized matrix factorization framework. Our solution to POI recommendation is efficient and scales linearly with the number of observations. Finally, we conduct thorough experiments on a large-scale real-world LBSNs dataset and demonstrate that the fused matrix factorization framework with MGM utilizes the distance information sufficiently and outperforms other state-of-the-art methods significantly.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Evidence from internet search data shows information-seeking responses to news of local COVID-19 cases\n",
            "Author/s :  A. Bento, Thuy Nguyen, Coady Wing, Felipe Lozano-Rojas, Yong-Yeol Ahn, K. Simon\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2020\n",
            "Abstract :  The COVID-19 outbreak is a global pandemic with community circulation in many countries, including the United States, with confirmed cases in all states. The course of this pandemic will be shaped by how governments enact timely policies and disseminate information and by how the public reacts to policies and information. Here, we examine information-seeking responses to the first COVID-19 case public announcement in a state. Using an event study framework for all US states, we show that such news increases collective attention to the crisis right away. However, the elevated level of attention is short-lived, even though the initial announcements are followed by increasingly strong policy measures. Specifically, searches for “coronavirus” increased by about 36% (95% CI: 27 to 44%) on the day immediately after the first case announcement but decreased back to the baseline level in less than a week or two. We find that people respond to the first report of COVID-19 in their state by immediately seeking information about COVID-19, as measured by searches for coronavirus, coronavirus symptoms, and hand sanitizer. On the other hand, searches for information regarding community-level policies (e.g., quarantine, school closures, testing) or personal health strategies (e.g., masks, grocery delivery, over-the-counter medications) do not appear to be immediately triggered by first reports. These results are representative of the study period being relatively early in the epidemic, and more-elaborate policy responses were not yet part of the public discourse. Further analysis should track evolving patterns of responses to subsequent flows of public information.\n",
            "------------------------------------\n",
            "Title :  Energy-Efficient Information and Communication Infrastructures in the Smart Grid: A Survey on Interactions and Open Issues\n",
            "Author/s :  M. Erol-Kantarci, H. Mouftah\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2015\n",
            "Abstract :  Smart grid has modernized the way electricity is generated, transported, distributed, and consumed by integrating advanced sensing, communications, and control in the day-to-day operation of the grid. Electricity is a core utility for the functioning of society and for the services provided by information and communication technologies (ICTs). Several concepts of the smart grid, such as dynamic pricing, distributed generation, and demand management, have significantly impacted the operation of ICT services, in particular, communication networks and data centers. Ongoing energy-efficiency and operational expenditures reduction efforts in communication networks and data centers have gained another dimension with those smart grid concepts. In this paper, we provide a comprehensive survey on the smart grid-driven approaches in energy-efficient communications and data centers, and the interaction between smart grid and information and communication infrastructures. Although the studies on smart grid, energy-efficient communications, and green data centers have been separately surveyed in previous studies, to this end, research that falls in the intersection of those fields has not been properly classified and surveyed yet. We start our survey by providing background information on the smart grid and continue with surveying smart grid-driven approaches in energy-efficient communication systems, followed by energy, cost and emission minimizing approaches in data centers, and the corresponding cloud network infrastructure. We discuss the open issues in smart grid-driven approaches in ICTs and point some important research directions such as the distributed renewable energy generation capability-coupled communication infrastructures, optimum energy-efficient network design for the smart grid environment, the impact of green communication techniques on the reliability and latency requirements of smart grid data, workload consolidation with smart grid-awareness, and many more.\n",
            "------------------------------------\n",
            "Title :  Pengaruh Investasi Dan Ekspor Terhadap Pertumbuhan Ekonomi Serta Penyerapan Tenaga Kerja Provinsi Kalimantan Timur\n",
            "Author/s :  M. Taufik, Eny Rochaida, Fitriadi Fitriadi\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This research was aims to know the influence of investment and exports on economic growth and Labor recruitment of East Kalimantan Province. The research was analyzed by using model of analysis two lanes performed with SPSS software version 11.5 with data retrival based on primary data of investment, exports, economic growth and labor from BPS of East Kalimantan from 2003 until 2011. Based on analysis way substructure 1 model through F test, showed that the independent variables (investment and exports) have a significant influence on economic growth because the value of the probability of the F-statistic less than standard real (0,008 < 0,08). So it can be said that both free variables used in the model has a real influence on economic growth at 5% level of trust (a=0,05). On the sub structure 2 model, indicates that the three of independent variables (investment, exports, economic growth) has significant effects on the labor recruitment  because probability F statistic’s value is less than real standard used by (0,000 < 0,05). So it can be said which this third free variable has a significant influence to labor reqruitment at 5% level of trust (a=0,05).\n",
            "------------------------------------\n",
            "Title :  New Literacies: A Dual-Level Theory of the Changing Nature of Literacy, Instruction, and Assessment\n",
            "Author/s :  D. Leu, C. Kinzer, Julie Coiro, Jill Castek, L. Henry\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Today, the nature of literacy has become deictic. This simple idea carries important implications for literacy theory, research, and instruction that our field must begin to address. Deixis is a term used by linguists (Fillmore, 1966; Murphy, 1986; Traut & Kazzazi, 1996) to define words whose meanings change rapidly as their context changes. Tomorrow, for example, is a deictic term; the meaning of “tomorrow” becomes “today” every 24 hours. The meaning of literacy has also become deictic because we live in an age of rapidly changing information and communication technologies, each of which requires new literacies (Leu, 1997, 2000). Thus, to have been literate yesterday, in a world defined primarily by relatively static book technologies, does not ensure that one is fully literate today where we encounter new technologies such as Google docs, Skype, iMovie, Contribute, Basecamp, Dropbox, Facebook, Google, foursquare, Chrome, educational video games, or thousands of mobile apps. To be literate tomorrow will be defined by even newer technologies that have yet to appear and even newer discourses and social practices that will be created to meet future needs. Thus, when we speak of new literacies, we mean that literacy is not just new today; it becomes new every day of our lives. How should we theorize the new literacies that will define our future, when literacy has become deictic? The answer is important because our concept of literacy defines both who we are and who we shall become. But there is a conundrum here. How can we possibly develop adequate theory when the object that we seek to study is itself ephemeral, continuously being redefined by a changing context? This is an important theoretical challenge that our field has not previously faced. The purpose of this chapter is to advance theory in a world where literacy has become deictic. It suggests that a dual-level theory of New Literacies is a useful approach to theory building in a world where the nature of literacy continuously changes. We begin by making a central point: Social contexts have always shaped both the function and form of literate practices and been shaped by them in return. We discuss the social context of the current period and explain how this has produced new information and communication technologies (ICTs), and the new literacies that these technologies demand. Second, we explore several lowercase new literacies perspectives that are emerging. We argue that a dual-level New Literacies theory is essential to take full advantage of this important and diverse work. Third, we identify a set of principles, drawn from research, that inform an uppercase theory of New Literacies. Then, we present one lowercase theory of new literacies, the new literacies of online research and comprehension, to illustrate how a dual-level theory of New Literacies can inform new literacies research that takes related but different theoretical perspectives. We conclude by considering the implications of a dual-level theory of New Literacies for both research and practice.\n",
            "------------------------------------\n",
            "Title :  The longitudinal integrated database for health insurance and labour market studies (LISA) and its use in medical research\n",
            "Author/s :  J. Ludvigsson, P. Svedberg, O. Olén, G. Bruze, M. Neovius\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  EGNet: Edge Guidance Network for Salient Object Detection\n",
            "Author/s :  Jiaxing Zhao, Jiangjiang Liu, Deng-Ping Fan, Yang Cao, Jufeng Yang, Ming-Ming Cheng\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2019\n",
            "Abstract :  Fully convolutional neural networks (FCNs) have shown their advantages in the salient object detection task. However, most existing FCNs-based methods still suffer from coarse object boundaries. In this paper, to solve this problem, we focus on the complementarity between salient edge information and salient object information. Accordingly, we present an edge guidance network (EGNet) for salient object detection with three steps to simultaneously model these two kinds of complementary information in a single network. In the ﬁrst step, we extract the salient object features by a progressive fusion way. In the second step, we integrate the local edge information and global location information to obtain the salient edge features. Finally, to sufﬁciently leverage these complementary features, we couple the same salient edge features with salient object features at various resolutions. Beneﬁting from the rich edge information and location information in salient edge features, the fused features can help locate salient objects, especially their boundaries more accurately. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art methods on six widely used datasets without any pre-processing and post-processing. The source code is available at http: //mmcheng.net/egnet/.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Classification of Hyperspectral Data Based on Deep Belief Network\n",
            "Author/s :  Yushi Chen, Xing Zhao, X. Jia\n",
            "Venue :  IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "year :  2015\n",
            "Abstract :  Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  A Survey on Spectral–Spatial Classification Techniques Based on Attribute Profiles\n",
            "Author/s :  Pedram Ghamisi, M. Mura, J. Benediktsson\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2015\n",
            "Abstract :  Just over a decade has passed since the concept of morphological profile was defined for the analysis of remote sensing images. Since then, the morphological profile has largely proved to be a powerful tool able to model spatial information (e.g., contextual relations) of the image. However, due to the shortcomings of using the morphological profiles, many variants, extensions, and refinements of its definition have appeared stating that the morphological profile is still under continuous development. In this case, recently introduced theoretically sound attribute profiles (APs) can be considered as a generalization of the morphological profile, which is a powerful tool to model spatial information existing in the scene. Although the concept of the AP has been introduced in remote sensing only recently, an extensive literature on its use in different applications and on different types of data has appeared. To that end, the great amount of contributions in the literature that address the application of the AP to many tasks (e.g., classification, object detection, segmentation, change detection, etc.) and to different types of images (e.g., panchromatic, multispectral, and hyperspectral) proves how the AP is an effective and modern tool. The main objective of this survey paper is to recall the concept of the APs along with all its modifications and generalizations with special emphasis on remote sensing image classification and summarize the important aspects of its efficient utilization while also listing potential future works.\n",
            "------------------------------------\n",
            "Title :  Ebola, Twitter, and misinformation: a dangerous combination?\n",
            "Author/s :  S. O. Oyeyemi, E. Gabarron, R. Wynn\n",
            "Venue :  BMJ : British Medical Journal\n",
            "year :  2014\n",
            "Abstract :  The recent Ebola outbreak in west Africa has affected countries deeply in need of foreign aid.1 People desperately need correct information on how to prevent and treat Ebola. Despite the poverty, the increasing spread of computers, tablets, and smartphones in the region creates an opportunity for the rapid dissemination of information through the internet and social media, but there is no guarantee that …\n",
            "------------------------------------\n",
            "Title :  Photonic quantum simulators\n",
            "Author/s :  Alán Aspuru-Guzik, P. Walther\n",
            "Venue :  Nature Physics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Therapeutic target database 2020: enriched resource for facilitating research and early development of targeted therapeutics\n",
            "Author/s :  Yunxia Wang, Song-zhao Zhang, Fengcheng Li, Ying Zhou, Ying Zhang, Zhengwen Wang, Runyuan Zhang, Jiang Zhu, Yuxiang Ren, Ying Tan, C. Qin, Yinghong Li, Xiaoxu Li, Yuzong Chen, Feng Zhu\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2019\n",
            "Abstract :  Abstract Knowledge of therapeutic targets and early drug candidates is useful for improved drug discovery. In particular, information about target regulators and the patented therapeutic agents facilitates research regarding druggability, systems pharmacology, new trends, molecular landscapes, and the development of drug discovery tools. To complement other databases, we constructed the Therapeutic Target Database (TTD) with expanded information about (i) target-regulating microRNAs and transcription factors, (ii) target-interacting proteins, and (iii) patented agents and their targets (structures and experimental activity values if available), which can be conveniently retrieved and is further enriched with regulatory mechanisms or biochemical classes. We also updated the TTD with the recently released International Classification of Diseases ICD-11 codes and additional sets of successful, clinical trial, and literature-reported targets that emerged since the last update. TTD is accessible at http://bidd.nus.edu.sg/group/ttd/ttd.asp. In case of possible web connectivity issues, two mirror sites of TTD are also constructed (http://db.idrblab.org/ttd/ and http://db.idrblab.net/ttd/).\n",
            "------------------------------------\n",
            "Title :  Privacy in mobile technology for personal healthcare\n",
            "Author/s :  Sasikanth Avancha, Amit S. Baxi, D. Kotz\n",
            "Venue :  CSUR\n",
            "year :  2012\n",
            "Abstract :  Information technology can improve the quality, efficiency, and cost of healthcare. In this survey, we examine the privacy requirements of mobile computing technologies that have the potential to transform healthcare. Such mHealth technology enables physicians to remotely monitor patients' health and enables individuals to manage their own health more easily. Despite these advantages, privacy is essential for any personal monitoring technology. Through an extensive survey of the literature, we develop a conceptual privacy framework for mHealth, itemize the privacy properties needed in mHealth systems, and discuss the technologies that could support privacy-sensitive mHealth systems. We end with a list of open research questions.\n",
            "------------------------------------\n",
            "Title :  Mobile devices in medicine: a survey of how medical students, residents, and faculty use smartphones and other mobile devices to find information.\n",
            "Author/s :  J. Boruff, D. Storie\n",
            "Venue :  Journal of the Medical Library Association\n",
            "year :  2014\n",
            "Abstract :  OBJECTIVES\n",
            "The research investigated the extent to which students, residents, and faculty members in Canadian medical faculties use mobile devices, such as smartphones (e.g., iPhone, Android, Blackberry) and tablet computers (e.g., iPad), to answer clinical questions and find medical information. The results of this study will inform how health libraries can effectively support mobile technology and collections.\n",
            "\n",
            "\n",
            "METHODS\n",
            "An electronic survey was distributed by medical librarians at four Canadian universities to medical students, residents, and faculty members via departmental email discussion lists, personal contacts, and relevant websites. It investigated the types of information sought, facilitators to mobile device use in medical information seeking, barriers to access, support needs, familiarity with institutionally licensed resources, and most frequently used resources.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The survey of 1,210 respondents indicated widespread use of smartphones and tablets in clinical settings in 4 Canadian universities. Third- and fourth-year undergraduate students (i.e., those in their clinical clerkships) and medical residents, compared to other graduate students and faculty, used their mobile devices more often, used them for a broader range of activities, and purchased more resources for their devices.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Technological and intellectual barriers do not seem to prevent medical trainees and faculty from regularly using mobile devices for their medical information searches; however, barriers to access and lack of awareness might keep them from using reliable, library-licensed resources.\n",
            "\n",
            "\n",
            "IMPLICATIONS\n",
            "Libraries should focus on providing access to a smaller number of highly used mobile resources instead of a huge collection until library-licensed mobile resources have streamlined authentication processes.\n",
            "------------------------------------\n",
            "Title :  The eICU Collaborative Research Database, a freely available multi-center database for critical care research\n",
            "Author/s :  T. Pollard, A. Johnson, J. Raffa, L. Celi, R. Mark, O. Badawi\n",
            "Venue :  Scientific Data\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Correlates of Health-Related Social Media Use Among Adults\n",
            "Author/s :  R. Thackeray, B. Crookston, J. West\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background Sixty percent of Internet users report using the Internet to look for health information. Social media sites are emerging as a potential source for online health information. However, little is known about how people use social media for such purposes. Objectives The purpose of this study was two-fold: (1) to establish the frequency of various types of online health-seeking behaviors, and (2) to identify correlates of 2 health-related online activities, social networking sites (SNS) for health-related activities and consulting online user-generated content for answers about health care providers, health facilities, or medical treatment. Methods The study consisted of a telephone survey of 1745 adults who reported going online to look for health-related information. Four subscales were created to measure use of online resources for (1) using SNS for health-related activities; (2) consulting online rankings and reviews of doctors, hospitals or medical facilities, and drugs or medical treatments; (3) posting a review online of doctors, hospitals or medical facilities, and drugs or medical treatments, and (4) posting a comment or question about health or medical issues on various social media. Univariate and multivariate logistic regression analyses were performed. Results Respondents consulted online rankings or reviews (41.15%), used SNS for health (31.58%), posted reviews (9.91%), and posted a comment, question, or information (15.19%). Respondents with a chronic disease were nearly twice as likely to consult online rankings (odds ratio [OR] 2.09, 95% CI 1.66-2.63, P<.001). Lower odds of consulting online reviews were associated with less formal education (OR 0.49, 95% CI 0.37-0.65, P<.001) and being male (OR 0.71, 95% CI 0.57-0.87, P<.001). Respondents with higher incomes were 1.5 times as likely to consult online rankings or reviews (OR 1.49, 95% CI 0.10-2.24, P=.05), than respondents with a regular provider (OR 2.05, 95% CI 1.52-2.78, P<.001), or living in an urban/suburban location (OR 1.61, 95% CI 1.17-2.22, P<.001). Older respondents were less likely to use SNS for health-related activities (OR 0.96, 95% CI 0.95-0.97, P<.001), as were males (OR 0.70, 95% CI 0.56-0.87, P<.001), whereas respondents with a regular provider had nearly twice the likelihood of using SNS for health-related activities (OR 1.89, 95% CI 1.43-2.52, P<.001). Conclusions People are using social media for seeking health information. However, individuals are more likely to consume information than they are to contribute to the dialog. The inherent value of “social” in social media is not being captured with online health information seeking. People with a regular health care provider, chronic disease, and those in younger age groups are more likely to consult online rankings and reviews and use SNS for health-related activities.\n",
            "------------------------------------\n",
            "Title :  Nudging Energy Efficiency Behavior: The Role of Information Labels\n",
            "Author/s :  R. Newell, J. Siikamäki\n",
            "Venue :  Journal of the Association of Environmental and Resource Economists\n",
            "year :  2013\n",
            "Abstract :  We use choice experiments and randomized information treatments to study the effectiveness of alternative energy efficiency labels in guiding households’ energy efficiency decisions. We disentangle the relative importance of different types of information and distinguish it from intertemporal behavior. We find that insufficient information can lead to considerable undervaluation of energy efficiency. Simple information on the monetary value of energy savings was the most important element guiding cost-efficient energy efficiency investments, with information on physical energy use and carbon dioxide emissions having additional but lesser importance. The degree to which the current US EnergyGuide label guided cost-efficient decisions depends on the discount rate. Using elicited individual discount rates, the current EnergyGuide label came very close to guiding cost-efficient decisions. Using a uniform 5% discount rate, the current label led to one-third undervaluation of energy efficiency. Our results reinforce the centrality of discounting in understanding individual behavior and guiding policy.\n",
            "------------------------------------\n",
            "Title :  Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks\n",
            "Author/s :  Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, Yoav Goldberg\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2016\n",
            "Abstract :  There is a lot of research interest in encoding variable length sentences into fixed length vectors, in a way that preserves the sentence meanings. Two common methods include representations based on averaging word vectors, and representations based on the hidden states of recurrent neural networks such as LSTMs. The sentence vectors are used as features for subsequent machine learning tasks or for pre-training in the context of deep learning. However, not much is known about the properties that are encoded in these sentence representations and about the language information they capture. We propose a framework that facilitates better understanding of the encoded representations. We define prediction tasks around isolated aspects of sentence structure (namely sentence length, word content, and word order), and score representations by the ability to train a classifier to solve each prediction task when using the representation as input. We demonstrate the potential contribution of the approach by analyzing different sentence representation mechanisms. The analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks, and on the effect of the encoded vector's dimensionality on the resulting representations.\n",
            "------------------------------------\n",
            "Title :  Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author/s :  Sijie Yan, Yuanjun Xiong, Dahua Lin\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2018\n",
            "Abstract :  \n",
            " \n",
            " Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  How Much Information?: Effects of Transparency on Trust in an Algorithmic Interface\n",
            "Author/s :  René F. Kizilcec\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2016\n",
            "Abstract :  The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online field experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justification of perceived inconsistency. Designing for trust requires balanced interface transparency - not too little and not too much.\n",
            "------------------------------------\n",
            "Title :  Quality of patient health information on the Internet: reviewing a complex and evolving landscape.\n",
            "Author/s :  E. Fahy, R. Hardikar, A. Fox, S. Mackay\n",
            "Venue :  Australasian Medical Journal\n",
            "year :  2014\n",
            "Abstract :  BACKGROUND\n",
            "The popularity of the Internet has enabled unprecedented access to health information. As a largely unregulated source, there is potential for inconsistency in the quality of information that reaches the patient.\n",
            "\n",
            "\n",
            "AIMS\n",
            "To review the literature relating to the quality indicators of health information for patients on the Internet.\n",
            "\n",
            "\n",
            "METHOD\n",
            "A search of English language literature was conducted using PubMed, Google Scholar and EMBASE databases.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Many articles have been published which assess the quality of information relating to specific medical conditions. Indicators of quality have been defined in an attempt to predict higher quality health information on the Internet. Quality evaluation tools are scoring systems based on indicators of quality. Established tools such as the HONcode may help patients navigate to more reliable information. Google and Wikipedia are important emerging sources of patient health information.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The Internet is crucial for modern dissemination of health information, but it is clear that quality varies significantly between sources. Quality indicators for web-information have been developed but there is no agreed standard yet. We envisage that reliable rating tools, effective search engine ranking and progress in crowd-edited websites will enhance patient access to health information on the Internet.\n",
            "------------------------------------\n",
            "Title :  Digital twin-driven product design, manufacturing and service with big data\n",
            "Author/s :  F. Tao, Jiangfeng Cheng, Qinglin Qi, Meng Zhang, He Zhang, Fangyuan Sui\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The Impact of Electronic Patient Portals on Patient Care: A Systematic Review of Controlled Trials\n",
            "Author/s :  E. Ammenwerth, P. Schnell-Inderst, A. Hoerbst\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2012\n",
            "Abstract :  Background Modern information technology is changing and provides new challenges to health care. The emergence of the Internet and the electronic health record (EHR) has brought new opportunities for patients to play a more active role in his/her care. Although in many countries patients have the right to access their clinical information, access to clinical records electronically is not common. Patient portals consist of provider-tethered applications that allow patients to electronically access health information that are documented and managed by a health care institution. Although patient portals are already being implemented, it is still unclear in which ways these technologies can influence patient care. Objective To systematically review the available evidence on the impact of electronic patient portals on patient care. Methods A systematic search was conducted using PubMed and other sources to identify controlled experimental or quasi-experimental studies on the impact of patient portals that were published between 1990 and 2011. A total of 1,306 references from all the publication hits were screened, and 13 papers were retrieved for full text analysis. Results We identified 5 papers presenting 4 distinct studies. There were no statistically significant changes between intervention and control group in the 2 randomized controlled trials investigating the effect of patient portals on health outcomes. Significant changes in the patient portal group, compared to a control group, could be observed for the following parameters: quicker decrease in office visit rates and slower increase in telephone contacts; increase in number of messages sent; changes of the medication regimen; and better adherence to treatment. Conclusions The number of available controlled studies with regard to patient portals is low. Even when patient portals are often discussed as a way to empower patients and improve quality of care, there is insufficient evidence to support this assumption.\n",
            "------------------------------------\n",
            "Title :  New approach for understanding genome variations in KEGG\n",
            "Author/s :  M. Kanehisa, Yoko Sato, Miho Furumichi, Kanae Morishima, M. Tanabe\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2018\n",
            "Abstract :  Abstract KEGG (Kyoto Encyclopedia of Genes and Genomes; https://www.kegg.jp/ or https://www.genome.jp/kegg/) is a reference knowledge base for biological interpretation of genome sequences and other high-throughput data. It is an integrated database consisting of three generic categories of systems information, genomic information and chemical information, and an additional human-specific category of health information. KEGG pathway maps, BRITE hierarchies and KEGG modules have been developed as generic molecular networks with KEGG Orthology nodes of functional orthologs so that KEGG pathway mapping and other procedures can be applied to any cellular organism. Unfortunately, however, this generic approach was inadequate for knowledge representation in the health information category, where variations of human genomes, especially disease-related variations, had to be considered. Thus, we have introduced a new approach where human gene variants are explicitly incorporated into what we call ‘network variants’ in the recently released KEGG NETWORK database. This allows accumulation of knowledge about disease-related perturbed molecular networks caused not only by gene variants, but also by viruses and other pathogens, environmental factors and drugs. We expect that KEGG NETWORK will become another reference knowledge base for the basic understanding of disease mechanisms and practical use in clinical sequencing and drug development.\n",
            "------------------------------------\n",
            "Title :  Building Ontologies with Basic Formal Ontology\n",
            "Author/s :  R. Arp, Barry Smith, Andrew D. Spear\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In the era of \"big data,\" science is increasingly information driven, and the potential for computers to store, manage, and integrate massive amounts of data has given rise to such new disciplinary fields as biomedical informatics. Applied ontology offers a strategy for the organization of scientific information in computer-tractable form, drawing on concepts not only from computer and information science but also from linguistics, logic, and philosophy. This book provides an introduction to the field of applied ontology that is of particular relevance to biomedicine, covering theoretical components of ontologies, best practices for ontology design, and examples of biomedical ontologies in use.After defining an ontology as a representation of the types of entities in a given domain, the book distinguishes between different kinds of ontologies and taxonomies, and shows how applied ontology draws on more traditional ideas from metaphysics. It presents the core features of the Basic Formal Ontology (BFO), now used by over one hundred ontology projects around the world, and offers examples of domain ontologies that utilize BFO. The book also describes Web Ontology Language (OWL), a common framework for Semantic Web technologies. Throughout, the book provides concrete recommendations for the design and construction of domain ontologies.\n",
            "------------------------------------\n",
            "Title :  The Simple Rules of Social Contagion\n",
            "Author/s :  Nathan Oken Hodas, Kristina Lerman\n",
            "Venue :  Scientific Reports\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths\n",
            "Author/s :  Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2015\n",
            "Abstract :  Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an $F_1$-score of 83.7\\%, higher than competing methods in the literature.\n",
            "------------------------------------\n",
            "Title :  Uncertainty, scepticism and attitudes towards climate change: biased assimilation and attitude polarisation\n",
            "Author/s :  A. Corner, L. Whitmarsh, D. Xenias\n",
            "Venue :  Climatic Change\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Coronavirus disease 2019: The harms of exaggerated information and non‐evidence‐based measures\n",
            "Author/s :  J. Ioannidis\n",
            "Venue :  European Journal of Clinical Investigation\n",
            "year :  2020\n",
            "Abstract :  The evolving coronavirus disease 2019 (COVID-19) epidemic1 is certainly cause for concern. Proper communication and optimal decision-making is an ongoing challenge, as data evolve. The challenge is compounded, however, by exaggerated information. This can lead to inappropriate actions. It is important to differentiate promptly the true epidemic from an epidemic of false claims and potentially harmful actions.\n",
            "------------------------------------\n",
            "Title :  A Survey of the State-of-the-Art Localization Techniques and Their Potentials for Autonomous Vehicle Applications\n",
            "Author/s :  Sampo Kuutti, Saber Fallah, K. Katsaros, M. Dianati, F. Mccullough, A. Mouzakitis\n",
            "Venue :  IEEE Internet of Things Journal\n",
            "year :  2018\n",
            "Abstract :  For an autonomous vehicle to operate safely and effectively, an accurate and robust localization system is essential. While there are a variety of vehicle localization techniques in literature, there is a lack of effort in comparing these techniques and identifying their potentials and limitations for autonomous vehicle applications. Hence, this paper evaluates the state-of-the-art vehicle localization techniques and investigates their applicability on autonomous vehicles. The analysis starts with discussing the techniques which merely use the information obtained from on-board vehicle sensors. It is shown that although some techniques can achieve the accuracy required for autonomous driving but suffer from the high cost of the sensors and also sensor performance limitations in different driving scenarios (e.g., cornering and intersections) and different environmental conditions (e.g., darkness and snow). This paper continues the analysis with considering the techniques which benefit from off-board information obtained from V2X communication channels, in addition to vehicle sensory information. The analysis shows that augmenting off-board information to sensory information has potential to design low-cost localization systems with high accuracy and robustness, however, their performance depends on penetration rate of nearby connected vehicles or infrastructure and the quality of network service.\n",
            "------------------------------------\n",
            "Title :  Neural Collaborative Filtering\n",
            "Author/s :  Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua\n",
            "Venue :  The Web Conference\n",
            "year :  2017\n",
            "Abstract :  In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.\n",
            "------------------------------------\n",
            "Title :  Visual localization within LIDAR maps for automated urban driving\n",
            "Author/s :  R. W. Wolcott, R. Eustice\n",
            "Venue :  2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
            "year :  2014\n",
            "Abstract :  This paper reports on the problem of map-based visual localization in urban environments for autonomous vehicles. Self-driving cars have become a reality on roadways and are going to be a consumer product in the near future. One of the most significant road-blocks to autonomous vehicles is the prohibitive cost of the sensor suites necessary for localization. The most common sensor on these platforms, a three-dimensional (3D) light detection and ranging (LIDAR) scanner, generates dense point clouds with measures of surface reflectivity-which other state-of-the-art localization methods have shown are capable of centimeter-level accuracy. Alternatively, we seek to obtain comparable localization accuracy with significantly cheaper, commodity cameras. We propose to localize a single monocular camera within a 3D prior ground-map, generated by a survey vehicle equipped with 3D LIDAR scanners. To do so, we exploit a graphics processing unit to generate several synthetic views of our belief environment. We then seek to maximize the normalized mutual information between our real camera measurements and these synthetic views. Results are shown for two different datasets, a 3.0 km and a 1.5 km trajectory, where we also compare against the state-of-the-art in LIDAR map-based localization.\n",
            "------------------------------------\n",
            "Title :  Misleading Health-Related Information Promoted Through Video-Based Social Media: Anorexia on YouTube\n",
            "Author/s :  S. Syed-Abdul, L. Fernández-Luque, W. Jian, Yu-chuan Li, S. Crain, M. Hsu, Yao-Chin Wang, Dorjsuren Khandregzen, E. Chuluunbaatar, P. Nguyen, Der-Ming Liou\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Introduction The amount of information being uploaded onto social video platforms, such as YouTube, Vimeo, and Veoh, continues to spiral, making it increasingly difficult to discern reliable health information from misleading content. There are thousands of YouTube videos promoting misleading information about anorexia (eg, anorexia as a healthy lifestyle). Objective The aim of this study was to investigate anorexia-related misinformation disseminated through YouTube videos. Methods We retrieved YouTube videos related to anorexia using the keywords anorexia, anorexia nervosa, proana, and thinspo on October 10, 2011.Three doctors reviewed 140 videos with approximately 11 hours of video content, classifying them as informative, pro-anorexia, or others. By informative we mean content describing the health consequences of anorexia and advice on how to recover from it; by pro-anorexia we mean videos promoting anorexia as a fashion, a source of beauty, and that share tips and methods for becoming and remaining anorexic. The 40 most-viewed videos (20 informative and 20 pro-anorexia videos) were assessed to gauge viewer behavior. Results The interrater agreement of classification was moderate (Fleiss’ kappa=0.5), with 29.3% (n=41) being rated as pro-anorexia, 55.7% (n=78) as informative, and 15.0% (n=21) as others. Pro-anorexia videos were favored 3 times more than informative videos (odds ratio [OR] 3.3, 95% CI 3.3-3.4, P<.001). Conclusions Pro-anorexia information was identified in 29.3% of anorexia-related videos. Pro-anorexia videos are less common than informative videos; however, in proportional terms, pro-anorexia content is more highly favored and rated by its viewers. Efforts should focus on raising awareness, particularly among teenagers, about the trustworthiness of online information about beauty and healthy lifestyles. Health authorities producing videos to combat anorexia should consider involving celebrities and models to reach a wider audience. More research is needed to study the characteristics of pro-anorexia videos in order to develop algorithms that will automatically detect and filter those videos before they become popular.\n",
            "------------------------------------\n",
            "Title :  Advances in cognitive theory and therapy: the generic cognitive model.\n",
            "Author/s :  A. Beck, Emily A P Haigh\n",
            "Venue :  Annual Review of Clinical Psychology\n",
            "year :  2014\n",
            "Abstract :  For over 50 years, Beck's cognitive model has provided an evidence-based way to conceptualize and treat psychological disorders. The generic cognitive model represents a set of common principles that can be applied across the spectrum of psychological disorders. The updated theoretical model provides a framework for addressing significant questions regarding the phenomenology of disorders not explained in previous iterations of the original model. New additions to the theory include continuity of adaptive and maladaptive function, dual information processing, energizing of schemas, and attentional focus. The model includes a theory of modes, an organization of schemas relevant to expectancies, self-evaluations, rules, and memories. A description of the new theoretical model is followed by a presentation of the corresponding applied model, which provides a template for conceptualizing a specific disorder and formulating a case. The focus on beliefs differentiates disorders and provides a target for treatment. A variety of interventions are described.\n",
            "------------------------------------\n",
            "Title :  Ideology, Motivated Reasoning, and Cognitive Reflection: An Experimental Study\n",
            "Author/s :  D. Kahan\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Social psychologists have identified various plausible sources of ideological polarization over climate change, gun violence, national security, and like societal risks. This paper describes a study of three of them: the predominance of heuristic-driven information processing by members of the public; ideologically motivated cognition; and personality-trait correlates of political conservativism. The results of the study suggest reason to doubt two common surmises about how these dynamics interact. First, the study presents both observational and experimental data inconsistent with the hypothesis that political conservatism is distinctively associated with closed-mindedness: conservatives did no better or worse than liberals on an objective measure of cognitive reflection; and more importantly, both demonstrated the same unconscious tendency to fit assessments of empirical evidence to their ideological predispositions. Second, the study suggests that this form of bias is not a consequence of overreliance on heuristic or intuitive forms of reasoning; on the contrary, subjects who scored highest in cognitive reflection were the most likely to display ideologically motivated cognition. These findings corroborated the hypotheses of a third theory, which identifies motivated cognition as a form of information processing that rationally promotes individuals’ interests in forming and maintaining beliefs that signify their loyalty to important affinity groups. The paper discusses the normative significance of these findings, including the need to develop science communication strategies that shield policy-relevant facts from the influences that turn them into divisive symbols of identity.\n",
            "------------------------------------\n",
            "Title :  Natural Language Processing in Radiology: A Systematic Review.\n",
            "Author/s :  E. Pons, Loes M M Braun, M. Hunink, J. Kors\n",
            "Venue :  Radiology\n",
            "year :  2016\n",
            "Abstract :  Radiological reporting has generated large quantities of digital content within the electronic health record, which is potentially a valuable source of information for improving clinical care and supporting research. Although radiology reports are stored for communication and documentation of diagnostic imaging, harnessing their potential requires efficient and automated information extraction: they exist mainly as free-text clinical narrative, from which it is a major challenge to obtain structured data. Natural language processing (NLP) provides techniques that aid the conversion of text into a structured representation, and thus enables computers to derive meaning from human (ie, natural language) input. Used on radiology reports, NLP techniques enable automatic identification and extraction of information. By exploring the various purposes for their use, this review examines how radiology benefits from NLP. A systematic literature search identified 67 relevant publications describing NLP methods that support practical applications in radiology. This review takes a close look at the individual studies in terms of tasks (ie, the extracted information), the NLP methodology and tools used, and their application purpose and performance results. Additionally, limitations, future challenges, and requirements for advancing NLP in radiology will be discussed.\n",
            "------------------------------------\n",
            "Title :  Life With and Without Coding: Two Methods for Early-Stage Data Analysis in Qualitative Research Aiming at Causal Explanations\n",
            "Author/s :  J. Gläser, G. Laudel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Qualitative research aimed at \"mechanismic\" explanations poses specific challenges to qualitative data analysis because it must integrate existing theory with patterns identified in the data. We explore the utilization of two methods—coding and qualitative content analysis—for the first steps in the data analysis process, namely \"cleaning\" and organizing qualitative data. Both methods produce an information base that is structured by categories and can be used in the subsequent search for patterns in the data and integration of these patterns into a systematic, theoretically embedded explanation. Used as a stand-alone method outside the grounded theory approach, coding leads to an indexed text, i.e. both the original text and the index (the system of codes describing the content of text segments) are subjected to further analysis. Qualitative content analysis extracts the relevant information, i.e. separates it from the original text, and processes only this information. We suggest that qualitative content analysis has advantages compared to coding whenever the research question is embedded in prior theory and can be answered without processing knowledge about the form of statements and their position in the text, which usually is the case in the search for \"mechanismic\" explanations. Coding outperforms qualitative content analysis in research that needs this information in later stages of the analysis, e.g. the exploration of meaning or the study of the construction of narratives.\n",
            "------------------------------------\n",
            "Title :  Mapping Soil Properties of Africa at 250 m Resolution: Random Forests Significantly Improve Current Predictions\n",
            "Author/s :  T. Hengl, G. Heuvelink, B. Kempen, J. Leenaars, M. Walsh, K. Shepherd, A. Sila, R. MacMillan, Jorge Mendes de Jesus, L. Tamene, J. Tondoh\n",
            "Venue :  PLoS ONE\n",
            "year :  2015\n",
            "Abstract :  80% of arable land in Africa has low soil fertility and suffers from physical soil problems. Additionally, significant amounts of nutrients are lost every year due to unsustainable soil management practices. This is partially the result of insufficient use of soil management knowledge. To help bridge the soil information gap in Africa, the Africa Soil Information Service (AfSIS) project was established in 2008. Over the period 2008–2014, the AfSIS project compiled two point data sets: the Africa Soil Profiles (legacy) database and the AfSIS Sentinel Site database. These data sets contain over 28 thousand sampling locations and represent the most comprehensive soil sample data sets of the African continent to date. Utilizing these point data sets in combination with a large number of covariates, we have generated a series of spatial predictions of soil properties relevant to the agricultural management—organic carbon, pH, sand, silt and clay fractions, bulk density, cation-exchange capacity, total nitrogen, exchangeable acidity, Al content and exchangeable bases (Ca, K, Mg, Na). We specifically investigate differences between two predictive approaches: random forests and linear regression. Results of 5-fold cross-validation demonstrate that the random forests algorithm consistently outperforms the linear regression algorithm, with average decreases of 15–75% in Root Mean Squared Error (RMSE) across soil properties and depths. Fitting and running random forests models takes an order of magnitude more time and the modelling success is sensitive to artifacts in the input data, but as long as quality-controlled point data are provided, an increase in soil mapping accuracy can be expected. Results also indicate that globally predicted soil classes (USDA Soil Taxonomy, especially Alfisols and Mollisols) help improve continental scale soil property mapping, and are among the most important predictors. This indicates a promising potential for transferring pedological knowledge from data rich countries to countries with limited soil data.\n",
            "------------------------------------\n",
            "Title :  Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-Temporal Path Proposals\n",
            "Author/s :  Yantao Shen, Tong Xiao, Hongsheng Li, Shuai Yi, Xiaogang Wang\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  Vehicle re-identification is an important problem and has many applications in video surveillance and intelligent transportation. It gains increasing attention because of the recent advances of person re-identification techniques. However, unlike person re-identification, the visual differences between pairs of vehicle images are usually subtle and even challenging for humans to distinguish. Incorporating additional spatio-temporal information is vital for solving the challenging re-identification task. Existing vehicle re-identification methods ignored or used oversimplified models for the spatio-temporal relations between vehicle images. In this paper, we propose a two-stage framework that incorporates complex spatio-temporal information for effectively regularizing the re-identification results. Given a pair of vehicle images with their spatiotemporal information, a candidate visual-spatio-temporal path is first generated by a chain MRF model with a deeply learned potential function, where each visual-spatiotemporal state corresponds to an actual vehicle image with its spatio-temporal information. A Siamese-CNN+Path- LSTM model takes the candidate path as well as the pairwise queries to generate their similarity score. Extensive experiments and analysis show the effectiveness of our proposed method and individual components.\n",
            "------------------------------------\n",
            "Title :  Information Frictions in Trade\n",
            "Author/s :  Treb Allen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  It is costly to learn about market conditions elsewhere, especially in developing countries. This paper examines how such information frictions affect trade. Using data on regional agricultural trade in the Philippines, I first document a number of observed patterns in trade flows and prices that suggest the presence of information frictions. I then incorporate information frictions into a perfect competition trade model by embedding a process whereby heterogeneous producers engage in a costly sequential search process to determine where to sell their produce. I show that introducing information frictions reconciles the theory with the observed patterns in the data. Structural estimation of the model finds that information frictions are quantitatively important: roughly half the observed regional price dispersion is due to information frictions. Furthermore, incorporating information frictions improves the out‐of‐sample predictive power of the model.\n",
            "------------------------------------\n",
            "Title :  How Long to Wait? Predicting Bus Arrival Time With Mobile Phone Based Participatory Sensing\n",
            "Author/s :  Pengfei Zhou, Yuanqing Zheng, Mo Li\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  The bus arrival time is primary information to most city transport travelers. Excessively long waiting time at bus stops often discourages the travelers and makes them reluctant to take buses. In this paper, we present a bus arrival time prediction system based on bus passengers' participatory sensing. With commodity mobile phones, the bus passengers' surrounding environmental context is effectively collected and utilized to estimate the bus traveling routes and predict bus arrival time at various bus stops. The proposed system solely relies on the collaborative effort of the participating users and is independent from the bus operating companies, so it can be easily adopted to support universal bus service systems without requesting support from particular bus operating companies. Instead of referring to GPS-enabled location information, we resort to more generally available and energy efficient sensing resources, including cell tower signals, movement statuses, audio recordings, etc., which bring less burden to the participatory party and encourage their participation. We develop a prototype system with different types of Android-based mobile phones and comprehensively experiment with the NTU campus shuttle buses as well as Singapore public buses over a 7-week period. The evaluation results suggest that the proposed system achieves outstanding prediction accuracy compared with those bus operator initiated and GPS supported solutions. We further adopt our system and conduct quick trial experiments with London bus system for 4 days, which suggests the easy deployment of our system and promising system performance across cities. At the same time, the proposed solution is more generally available and energy friendly.\n",
            "------------------------------------\n",
            "Title :  The thermodynamics of prediction\n",
            "Author/s :  S. Still, David A. Sivak, A. J. Bell, G. Crooks\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  A system responding to a stochastic driving signal can be interpreted as computing, by means of its dynamics, an implicit model of the environmental variables. The system's state retains information about past environmental fluctuations, and a fraction of this information is predictive of future ones. The remaining nonpredictive information reflects model complexity that does not improve predictive power, and thus represents the ineffectiveness of the model. We expose the fundamental equivalence between this model inefficiency and thermodynamic inefficiency, measured by dissipation. Our results hold arbitrarily far from thermodynamic equilibrium and are applicable to a wide range of systems, including biomolecular machines. They highlight a profound connection between the effective use of information and efficient thermodynamic operation: any system constructed to keep memory about its environment and to operate with maximal energetic efficiency has to be predictive.\n",
            "------------------------------------\n",
            "Title :  An Integrated System for Regional Environmental Monitoring and Management Based on Internet of Things\n",
            "Author/s :  S. Fang, Lida Xu, Yunqiang Zhu, Jiaerheng Ahati, Huan Pei, Jianwu Yan, Zhihui Liu\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2014\n",
            "Abstract :  Climate change and environmental monitoring and management have received much attention recently, and an integrated information system (IIS) is considered highly valuable. This paper introduces a novel IIS that combines Internet of Things (IoT), Cloud Computing, Geoinformatics [remote sensing (RS), geographical information system (GIS), and global positioning system (GPS)], and e-Science for environmental monitoring and management, with a case study on regional climate change and its ecological effects. Multi-sensors and Web services were used to collect data and other information for the perception layer; both public networks and private networks were used to access and transport mass data and other information in the network layer. The key technologies and tools include real-time operational database (RODB); extraction-transformation-loading (ETL); on-line analytical processing (OLAP) and relational OLAP (ROLAP); naming, addressing, and profile server (NAPS); application gateway (AG); application software for different platforms and tasks (APPs); IoT application infrastructure (IoT-AI); GIS and e-Science platforms; and representational state transfer/Java database connectivity (RESTful/JDBC). Application Program Interfaces (APIs) were implemented in the middleware layer of the IIS. The application layer provides the functions of storing, organizing, processing, and sharing of data and other information, as well as the functions of applications in environmental monitoring and management. The results from the case study show that there is a visible increasing trend of the air temperature in Xinjiang over the last 50 years (1962-2011) and an apparent increasing trend of the precipitation since the early 1980s. Furthermore, from the correlation between ecological indicators [gross primary production (GPP), net primary production (NPP), and leaf area index (LAI)] and meteorological elements (air temperature and precipitation), water resource availability is the decisive factor with regard to the terrestrial ecosystem in the area. The study shows that the research work is greatly benefited from such an IIS, not only in data collection supported by IoT, but also in Web services and applications based on cloud computing and e-Science platforms, and the effectiveness of monitoring processes and decision-making can be obviously improved. This paper provides a prototype IIS for environmental monitoring and management, and it also provides a new paradigm for the future research and practice; especially in the era of big data and IoT.\n",
            "------------------------------------\n",
            "Title :  Local active information storage as a tool to understand distributed neural information processing\n",
            "Author/s :  M. Wibral, J. Lizier, Sebastian Vögler, V. Priesemann, R. Galuske\n",
            "Venue :  Front. Neuroinform.\n",
            "year :  2013\n",
            "Abstract :  Every act of information processing can in principle be decomposed into the component operations of information storage, transfer, and modification. Yet, while this is easily done for today's digital computers, the application of these concepts to neural information processing was hampered by the lack of proper mathematical definitions of these operations on information. Recently, definitions were given for the dynamics of these information processing operations on a local scale in space and time in a distributed system, and the specific concept of local active information storage was successfully applied to the analysis and optimization of artificial neural systems. However, no attempt to measure the space-time dynamics of local active information storage in neural data has been made to date. Here we measure local active information storage on a local scale in time and space in voltage sensitive dye imaging data from area 18 of the cat. We show that storage reflects neural properties such as stimulus preferences and surprise upon unexpected stimulus change, and in area 18 reflects the abstract concept of an ongoing stimulus despite the locally random nature of this stimulus. We suggest that LAIS will be a useful quantity to test theories of cortical function, such as predictive coding.\n",
            "------------------------------------\n",
            "Title :  Rating Agencies in the Face of Regulation\n",
            "Author/s :  C. Opp, Marcus M. Opp, M. Harris\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This paper develops a theoretical framework to shed light on variation in credit rating standards over time and across asset classes. Ratings issued by credit rating agencies serve a dual role: they provide information to investors and are used to regulate institutional investors. We show that introducing rating-contingent regulation that favors highly rated securities may increase or decrease rating informativeness, but unambiguously increases the volume of highly rated securities. If the regulatory advantage of highly rated securities is sufficiently large, delegated information acquisition is unsustainable, since the rating agency prefers to facilitate regulatory arbitrage by inflating ratings. Our model relates rating informativeness to the quality distribution of issuers, the complexity of assets, and issuers' outside options. We reconcile our results with the existing empirical literature and highlight new, testable implications, such as repercussions of the Dodd-Frank Act.\n",
            "------------------------------------\n",
            "Title :  Data Mining for Internet of Things: A Survey\n",
            "Author/s :  Chun-Wei Tsai, Chin-Feng Lai, Ming-Chao Chiang, L. Yang\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2014\n",
            "Abstract :  It sounds like mission impossible to connect everything on the Earth together via Internet, but Internet of Things (IoT) will dramatically change our life in the foreseeable future, by making many \"impossibles\" possible. To many, the massive data generated or captured by IoT are considered having highly useful and valuable information. Data mining will no doubt play a critical role in making this kind of system smart enough to provide more convenient services and environments. This paper begins with a discussion of the IoT. Then, a brief review of the features of \"data from IoT\" and \"data mining for IoT' is given. Finally, changes, potentials, open issues, and future trends of this field are addressed.\n",
            "------------------------------------\n",
            "Title :  Local E‐Government in the United States: Transformation or Incremental Change?\n",
            "Author/s :  D. Norris, C. Reddick\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  In this article, the authors address the recent trajectory of local e-government in the United States and compare it with the predictions of early e-government writings, using empirical data from two nationwide surveys of e-government among American local governments. The authors find that local e-government has not produced the results that those writings predicted. Instead, its development has largely been incremental, and local e-government is mainly about delivering information and services online, followed by a few transactions and limited interactivity. Local e-government is also mainly one way, from government to citizens, and there is little or no evidence that it is transformative in any way. This disparity between early predictions and actual results is partly attributable to the incremental nature of American public administration. Other reasons include a lack of attention by early writers to the history of information technology in government and the influence of technological determinism on those writings.\n",
            "------------------------------------\n",
            "Title :  Predictive information in a sensory population\n",
            "Author/s :  S. Palmer, O. Marre, Michael J. Berry, W. Bialek\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2013\n",
            "Abstract :  Significance Prediction is an essential part of life. However, are we really “good” at making predictions? More specifically, are pieces of our brain close to being optimal predictors? To assess the efficiency of prediction, we need to measure the information that neurons carry about the future of our sensory experiences. We show how to do this, at least in simplified contexts, and find that groups of neurons in the retina indeed are close to maximally efficient at separating predictive information from the nonpredictive background. Efficient coding of predictive information is a principle that can be applied at every stage of neural computation. Guiding behavior requires the brain to make predictions about the future values of sensory inputs. Here, we show that efficient predictive computation starts at the earliest stages of the visual system. We compute how much information groups of retinal ganglion cells carry about the future state of their visual inputs and show that nearly every cell in the retina participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons that exhibit feature selectivity that would support predictive computations. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.\n",
            "------------------------------------\n",
            "Title :  The Goldilocks Effect: Human Infants Allocate Attention to Visual Sequences That Are Neither Too Simple Nor Too Complex\n",
            "Author/s :  Celeste Kidd, S. Piantadosi, R. Aslin\n",
            "Venue :  PLoS ONE\n",
            "year :  2012\n",
            "Abstract :  Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants’ visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants’ probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.\n",
            "------------------------------------\n",
            "Title :  Jerusalem Lectures on Black Holes and Quantum Information\n",
            "Author/s :  D. Harlow\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  In these lectures I give an introduction to the quantum physics of black holes, including recent developments based on quantum information theory such as the rewall paradox and its various cousins. I also give an introduction to holography and the AdS/CFT correspondence, focusing on those aspects which are relevant for the black hole information problem.\n",
            "------------------------------------\n",
            "Title :  Quantum Systems, Channels, Information: A Mathematical Introduction\n",
            "Author/s :  A. Holevo\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  The subject of this book is theory of quantum system presented from information science perspective. The central role is played by the concept of quantum channel and its entropic and information characteristics. Quantum information theory gives a key to understanding elusive phenomena of quantum world and provides a background for development of experimental techniques that enable measuring and manipulation of individual quantum systems. This is important for the new efficient applications such as quantum computing, communication and cryptography. Research in the field of quantum informatics, including quantum information theory, is in progress in leading scientific centers throughout the world. This book gives an accessible, albeit mathematically rigorous and self-contained introduction to quantum information theory, starting from primary structures and leading to fundamental results and to exiting open problems.\n",
            "------------------------------------\n",
            "Title :  Compressed Sensing Signal and Data Acquisition in Wireless Sensor Networks and Internet of Things\n",
            "Author/s :  Shancang Li, Lida Xu, Xinheng Wang\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2013\n",
            "Abstract :  The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.\n",
            "------------------------------------\n",
            "Title :  Advances in quantum teleportation\n",
            "Author/s :  S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, S. Braunstein\n",
            "Venue :  Nature Photonics\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Communication dynamics in complex brain networks\n",
            "Author/s :  Andrea Avena-Koenigsberger, B. Mišić, O. Sporns\n",
            "Venue :  Nature Reviews Neuroscience\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  BIM for facility managers\n",
            "Author/s :  P. Teicholz\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Building owners and facility managers are discovering that Building Information Modeling (BIM) models of buildings are deep reservoirs of information that can provide valuable spatial and mechanical details on every aspect of a property. When used appropriately, this data can improve performance and save time, effort, and money in running and maintaining the building during its life cycle. It can also provide information for future modifications. For instance, a BIM could reveal everything from the manufacturer of a light fixture to its energy usage to maintenance instructions.\n",
            "------------------------------------\n",
            "Title :  A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information\n",
            "Author/s :  Yunan Luo, Xinbin Zhao, Jingtian Zhou, Jinling Yang, Yanqing Zhang, Wenhua Kuang, Jian Peng, Ligong Chen, Jianyang Zeng\n",
            "Venue :  bioRxiv\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Challenges and opportunities of digital information at the intersection of Big Data Analytics and supply chain management\n",
            "Author/s :  Florian Kache, S. Seuring\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Despite the variety of supply chain management (SCM) research, little attention has been given to the use of Big Data Analytics for increased information exploitation in a supply chain. The purpose of this paper is to contribute to theory development in SCM by investigating the potential impacts of Big Data Analytics on information usage in a corporate and supply chain context. As it is imperative for companies in the supply chain to have access to up-to-date, accurate, and meaningful information, the exploratory research will provide insights into the opportunities and challenges emerging from the adoption of Big Data Analytics in SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Although Big Data Analytics is gaining increasing attention in management, empirical research on the topic is still scarce. Due to the limited availability of comparable material at the intersection of Big Data Analytics and SCM, the authors apply the Delphi research technique. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Portraying the emerging transition trend from a digital business environment, the presented Delphi study findings contribute to extant knowledge by identifying 43 opportunities and challenges linked to the emergence of Big Data Analytics from a corporate and supply chain perspective. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Research limitations/implications \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "These constructs equip the research community with a first collection of aspects, which could provide the basis to tailor further research at the nexus of Big Data Analytics and SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The research adds to the existing knowledge base as no empirical research has been presented so far specifically assessing opportunities and challenges on corporate and supply chain level with a special focus on the implications imposed through Big Data Analytics.\n",
            "------------------------------------\n",
            "Title :  HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning\n",
            "Author/s :  Tao-yang Fu, Wang-Chien Lee, Zhen Lei\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2017\n",
            "Abstract :  In this paper, we propose a novel representation learning framework, namely HIN2Vec, for heterogeneous information networks (HINs). The core of the proposed framework is a neural network model, also called HIN2Vec, designed to capture the rich semantics embedded in HINs by exploiting different types of relationships among nodes. Given a set of relationships specified in forms of meta-paths in an HIN, HIN2Vec carries out multiple prediction training tasks jointly based on a target set of relationships to learn latent vectors of nodes and meta-paths in the HIN. In addition to model design, several issues unique to HIN2Vec, including regularization of meta-path vectors, node type selection in negative sampling, and cycles in random walks, are examined. To validate our ideas, we learn latent vectors of nodes using four large-scale real HIN datasets, including Blogcatalog, Yelp, DBLP and U.S. Patents, and use them as features for multi-label node classification and link prediction applications on those networks. Empirical results show that HIN2Vec soundly outperforms the state-of-the-art representation learning models for network data, including DeepWalk, LINE, node2vec, PTE, HINE and ESim, by 6.6% to 23.8% of $micro$-$f_1$ in multi-label node classification and 5% to 70.8% of $MAP$ in link prediction.\n",
            "------------------------------------\n",
            "Title :  A Theoretical Framework for Conversational Search\n",
            "Author/s :  Filip Radlinski, Nick Craswell\n",
            "Venue :  Conference on Human Information Interaction and Retrieval\n",
            "year :  2017\n",
            "Abstract :  This paper studies conversational approaches to information retrieval, presenting a theory and model of information interaction in a chat setting. In particular, we consider the question of what properties would be desirable for a conversational information retrieval system so that the system can allow users to answer a variety of information needs in a natural and efficient manner. We study past work on human conversations, and propose a small set of properties that taken together could measure the extent to which a system is conversational. Following this, we present a theoretical model of a conversational system that implements the properties. We describe how this system could be implemented, making the action space of an conversational search agent explicit. Our analysis of this model shows that while theoretical, the model could be practically implemented to satisfy the desirable properties presented. In doing so, we show that the properties are also feasible.\n",
            "------------------------------------\n",
            "Title :  Development of a Health Information Technology Acceptance Model Using Consumers’ Health Behavior Intention\n",
            "Author/s :  Jeongeun Kim, Hyeoun-Ae Park\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2012\n",
            "Abstract :  Background For effective health promotion using health information technology (HIT), it is mandatory that health consumers have the behavioral intention to measure, store, and manage their own health data. Understanding health consumers’ intention and behavior is needed to develop and implement effective and efficient strategies. Objective To develop and verify the extended Technology Acceptance Model (TAM) in health care by describing health consumers’ behavioral intention of using HIT. Methods This study used a cross-sectional descriptive correlational design. We extended TAM by adding more antecedents and mediating variables to enhance the model’s explanatory power and to make it more applicable to health consumers’ behavioral intention. Additional antecedents and mediating variables were added to the hypothetical model, based on their theoretical relevance, from the Health Belief Model and theory of planned behavior, along with the TAM. We undertook structural equation analysis to examine the specific nature of the relationship involved in understanding consumers’ use of HIT. Study participants were 728 members recruited from three Internet health portals in Korea. Data were collected by a Web-based survey using a structured self-administered questionnaire. Results The overall fitness indices for the model developed in this study indicated an acceptable fit of the model. All path coefficients were statistically significant. This study showed that perceived threat, perceived usefulness, and perceived ease of use significantly affected health consumers’ attitude and behavioral intention. Health consumers’ health status, health belief and concerns, subjective norm, HIT characteristics, and HIT self-efficacy had a strong indirect impact on attitude and behavioral intention through the mediators of perceived threat, perceived usefulness, and perceived ease of use. Conclusions An extended TAM in the HIT arena was found to be valid to describe health consumers’ behavioral intention. We categorized the concepts in the extended TAM into 3 domains: health zone, information zone, and technology zone.\n",
            "------------------------------------\n",
            "Title :  When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author/s :  L. Thygesen, A. Ersbøll\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A General Self-Organized Tree-Based Energy-Balance Routing Protocol for Wireless Sensor Network\n",
            "Author/s :  Zhao Han, Jie Wu, Jie Zhang, Liefeng Liu, Kaiyun Tian\n",
            "Venue :  IEEE Transactions on Nuclear Science\n",
            "year :  2012\n",
            "Abstract :  Wireless sensor network (WSN) is a system composed of a large number of low-cost micro-sensors. This network is used to collect and send various kinds of messages to a base station (BS). WSN consists of low-cost nodes with limited battery power, and the battery replacement is not easy for WSN with thousands of physically embedded nodes, which means energy efficient routing protocol should be employed to offer a long-life work time. To achieve the aim, we need not only to minimize total energy consumption but also to balance WSN load. Researchers have proposed many protocols such as LEACH, HEED, PEGASIS, TBC and PEDAP. In this paper, we propose a General Self-Organized Tree-Based Energy-Balance routing protocol (GSTEB) which builds a routing tree using a process where, for each round, BS assigns a root node and broadcasts this selection to all sensor nodes. Subsequently, each node selects its parent by considering only itself and its neighbors' information, thus making GSTEB a dynamic protocol. Simulation results show that GSTEB has a better performance than other protocols in balancing energy consumption, thus prolonging the lifetime of WSN.\n",
            "------------------------------------\n",
            "Title :  Neural Collaborative Filtering\n",
            "Author/s :  Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua\n",
            "Venue :  The Web Conference\n",
            "year :  2017\n",
            "Abstract :  In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.\n",
            "------------------------------------\n",
            "Title :  Visual localization within LIDAR maps for automated urban driving\n",
            "Author/s :  R. W. Wolcott, R. Eustice\n",
            "Venue :  2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
            "year :  2014\n",
            "Abstract :  This paper reports on the problem of map-based visual localization in urban environments for autonomous vehicles. Self-driving cars have become a reality on roadways and are going to be a consumer product in the near future. One of the most significant road-blocks to autonomous vehicles is the prohibitive cost of the sensor suites necessary for localization. The most common sensor on these platforms, a three-dimensional (3D) light detection and ranging (LIDAR) scanner, generates dense point clouds with measures of surface reflectivity-which other state-of-the-art localization methods have shown are capable of centimeter-level accuracy. Alternatively, we seek to obtain comparable localization accuracy with significantly cheaper, commodity cameras. We propose to localize a single monocular camera within a 3D prior ground-map, generated by a survey vehicle equipped with 3D LIDAR scanners. To do so, we exploit a graphics processing unit to generate several synthetic views of our belief environment. We then seek to maximize the normalized mutual information between our real camera measurements and these synthetic views. Results are shown for two different datasets, a 3.0 km and a 1.5 km trajectory, where we also compare against the state-of-the-art in LIDAR map-based localization.\n",
            "------------------------------------\n",
            "Title :  Advances in cognitive theory and therapy: the generic cognitive model.\n",
            "Author/s :  A. Beck, Emily A P Haigh\n",
            "Venue :  Annual Review of Clinical Psychology\n",
            "year :  2014\n",
            "Abstract :  For over 50 years, Beck's cognitive model has provided an evidence-based way to conceptualize and treat psychological disorders. The generic cognitive model represents a set of common principles that can be applied across the spectrum of psychological disorders. The updated theoretical model provides a framework for addressing significant questions regarding the phenomenology of disorders not explained in previous iterations of the original model. New additions to the theory include continuity of adaptive and maladaptive function, dual information processing, energizing of schemas, and attentional focus. The model includes a theory of modes, an organization of schemas relevant to expectancies, self-evaluations, rules, and memories. A description of the new theoretical model is followed by a presentation of the corresponding applied model, which provides a template for conceptualizing a specific disorder and formulating a case. The focus on beliefs differentiates disorders and provides a target for treatment. A variety of interventions are described.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Classification of Hyperspectral Data Based on Deep Belief Network\n",
            "Author/s :  Yushi Chen, Xing Zhao, X. Jia\n",
            "Venue :  IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "year :  2015\n",
            "Abstract :  Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  Natural Language Processing in Radiology: A Systematic Review.\n",
            "Author/s :  E. Pons, Loes M M Braun, M. Hunink, J. Kors\n",
            "Venue :  Radiology\n",
            "year :  2016\n",
            "Abstract :  Radiological reporting has generated large quantities of digital content within the electronic health record, which is potentially a valuable source of information for improving clinical care and supporting research. Although radiology reports are stored for communication and documentation of diagnostic imaging, harnessing their potential requires efficient and automated information extraction: they exist mainly as free-text clinical narrative, from which it is a major challenge to obtain structured data. Natural language processing (NLP) provides techniques that aid the conversion of text into a structured representation, and thus enables computers to derive meaning from human (ie, natural language) input. Used on radiology reports, NLP techniques enable automatic identification and extraction of information. By exploring the various purposes for their use, this review examines how radiology benefits from NLP. A systematic literature search identified 67 relevant publications describing NLP methods that support practical applications in radiology. This review takes a close look at the individual studies in terms of tasks (ie, the extracted information), the NLP methodology and tools used, and their application purpose and performance results. Additionally, limitations, future challenges, and requirements for advancing NLP in radiology will be discussed.\n",
            "------------------------------------\n",
            "Title :  Wireless Energy and Information Transfer Tradeoff for Limited-Feedback Multiantenna Systems With Energy Beamforming\n",
            "Author/s :  Xiaoming Chen, C. Yuen, Zhaoyang Zhang\n",
            "Venue :  IEEE Transactions on Vehicular Technology\n",
            "year :  2013\n",
            "Abstract :  In this paper, we consider a multiantenna system where the receiver should harvest energy from the transmitter by wireless energy transfer to support its wireless information transmission. To maximize the harvesting energy, we propose the performance of adaptive energy beamforming according to the instantaneous channel state information (CSI). To help the transmitter obtain the CSI for energy beamforming, we further propose a win-win CSI quantization feedback strategy to improve the efficiencies of both power and information transmission. The focus of this paper is on the tradeoff of wireless energy and information transfer by adjusting the transfer duration with a total duration constraint. By revealing the relationship between transmit power, transfer duration, and feedback amount, we derive two wireless energy and information transfer tradeoff schemes by maximizing an upper bound and an approximate lower bound of the average information transmission rate, respectively. Moreover, the impact of imperfect CSI at the receiver is investigated, and the corresponding wireless energy and information transfer tradeoff scheme is also given. Finally, numerical results validate the effectiveness of the proposed schemes.\n",
            "------------------------------------\n",
            "Title :  Life With and Without Coding: Two Methods for Early-Stage Data Analysis in Qualitative Research Aiming at Causal Explanations\n",
            "Author/s :  J. Gläser, G. Laudel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Qualitative research aimed at \"mechanismic\" explanations poses specific challenges to qualitative data analysis because it must integrate existing theory with patterns identified in the data. We explore the utilization of two methods—coding and qualitative content analysis—for the first steps in the data analysis process, namely \"cleaning\" and organizing qualitative data. Both methods produce an information base that is structured by categories and can be used in the subsequent search for patterns in the data and integration of these patterns into a systematic, theoretically embedded explanation. Used as a stand-alone method outside the grounded theory approach, coding leads to an indexed text, i.e. both the original text and the index (the system of codes describing the content of text segments) are subjected to further analysis. Qualitative content analysis extracts the relevant information, i.e. separates it from the original text, and processes only this information. We suggest that qualitative content analysis has advantages compared to coding whenever the research question is embedded in prior theory and can be answered without processing knowledge about the form of statements and their position in the text, which usually is the case in the search for \"mechanismic\" explanations. Coding outperforms qualitative content analysis in research that needs this information in later stages of the analysis, e.g. the exploration of meaning or the study of the construction of narratives.\n",
            "------------------------------------\n",
            "Title :  Technology acceptance model (TAM) and social media usage: an empirical study on Facebook\n",
            "Author/s :  Rupak Rauniar, Greg Rawski, Jei Yang, Ben Johnson\n",
            "Venue :  Journal of Enterprise Information Management\n",
            "year :  2014\n",
            "Abstract :  Purpose – Given the widespread popularity of social media, such as Twitter, Facebook, Google+, and LinkedIn, theorizing and understanding the user attitude and usage behavior of social media site is fundamental in developing future understandings and deployment of these new technologies. One approach to such studies on drivers of social media usage behavior would be to revisit the technology acceptance model (TAM). The purpose of this paper is to discuss these issues. Design/methodology/approach – Decades of extensive research have focussed on validating the TAM, proposed by Davis (1986), for various types of information systems and communication technologies. TAM forecasts individual adoption and voluntary use of technology. This study examines individual adoption behavior of the most popular social networking site Facebook. The influences on the intention of using social networking based on individual's perceived ease of use (EU), the user's critical mass (CM), social networking site capability (CP), pe...\n",
            "------------------------------------\n",
            "Title :  An Integrated System for Regional Environmental Monitoring and Management Based on Internet of Things\n",
            "Author/s :  S. Fang, Lida Xu, Yunqiang Zhu, Jiaerheng Ahati, Huan Pei, Jianwu Yan, Zhihui Liu\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2014\n",
            "Abstract :  Climate change and environmental monitoring and management have received much attention recently, and an integrated information system (IIS) is considered highly valuable. This paper introduces a novel IIS that combines Internet of Things (IoT), Cloud Computing, Geoinformatics [remote sensing (RS), geographical information system (GIS), and global positioning system (GPS)], and e-Science for environmental monitoring and management, with a case study on regional climate change and its ecological effects. Multi-sensors and Web services were used to collect data and other information for the perception layer; both public networks and private networks were used to access and transport mass data and other information in the network layer. The key technologies and tools include real-time operational database (RODB); extraction-transformation-loading (ETL); on-line analytical processing (OLAP) and relational OLAP (ROLAP); naming, addressing, and profile server (NAPS); application gateway (AG); application software for different platforms and tasks (APPs); IoT application infrastructure (IoT-AI); GIS and e-Science platforms; and representational state transfer/Java database connectivity (RESTful/JDBC). Application Program Interfaces (APIs) were implemented in the middleware layer of the IIS. The application layer provides the functions of storing, organizing, processing, and sharing of data and other information, as well as the functions of applications in environmental monitoring and management. The results from the case study show that there is a visible increasing trend of the air temperature in Xinjiang over the last 50 years (1962-2011) and an apparent increasing trend of the precipitation since the early 1980s. Furthermore, from the correlation between ecological indicators [gross primary production (GPP), net primary production (NPP), and leaf area index (LAI)] and meteorological elements (air temperature and precipitation), water resource availability is the decisive factor with regard to the terrestrial ecosystem in the area. The study shows that the research work is greatly benefited from such an IIS, not only in data collection supported by IoT, but also in Web services and applications based on cloud computing and e-Science platforms, and the effectiveness of monitoring processes and decision-making can be obviously improved. This paper provides a prototype IIS for environmental monitoring and management, and it also provides a new paradigm for the future research and practice; especially in the era of big data and IoT.\n",
            "------------------------------------\n",
            "Title :  Data Mining for Internet of Things: A Survey\n",
            "Author/s :  Chun-Wei Tsai, Chin-Feng Lai, Ming-Chao Chiang, L. Yang\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2014\n",
            "Abstract :  It sounds like mission impossible to connect everything on the Earth together via Internet, but Internet of Things (IoT) will dramatically change our life in the foreseeable future, by making many \"impossibles\" possible. To many, the massive data generated or captured by IoT are considered having highly useful and valuable information. Data mining will no doubt play a critical role in making this kind of system smart enough to provide more convenient services and environments. This paper begins with a discussion of the IoT. Then, a brief review of the features of \"data from IoT\" and \"data mining for IoT' is given. Finally, changes, potentials, open issues, and future trends of this field are addressed.\n",
            "------------------------------------\n",
            "Title :  T-CNN: Tubelets With Convolutional Neural Networks for Object Detection From Videos\n",
            "Author/s :  Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Binh Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang\n",
            "Venue :  IEEE transactions on circuits and systems for video technology (Print)\n",
            "year :  2016\n",
            "Abstract :  The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks, such as GoogleNet and VGG, novel object detection frameworks, such as R-CNN and its successors, Fast R-CNN, and Faster R-CNN, play an essential role in improving the state of the art. Despite their effectiveness on still images, those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this paper, we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN, i.e., tubelets with convolutional neueral networks. The proposed framework won newly introduced an object-detection-from-video task with provided data in the ImageNet Large-Scale Visual Recognition Challenge 2015. Code is publicly available at https://github.com/myfavouritekk/T-CNN.\n",
            "------------------------------------\n",
            "Title :  Local active information storage as a tool to understand distributed neural information processing\n",
            "Author/s :  M. Wibral, J. Lizier, Sebastian Vögler, V. Priesemann, R. Galuske\n",
            "Venue :  Front. Neuroinform.\n",
            "year :  2013\n",
            "Abstract :  Every act of information processing can in principle be decomposed into the component operations of information storage, transfer, and modification. Yet, while this is easily done for today's digital computers, the application of these concepts to neural information processing was hampered by the lack of proper mathematical definitions of these operations on information. Recently, definitions were given for the dynamics of these information processing operations on a local scale in space and time in a distributed system, and the specific concept of local active information storage was successfully applied to the analysis and optimization of artificial neural systems. However, no attempt to measure the space-time dynamics of local active information storage in neural data has been made to date. Here we measure local active information storage on a local scale in time and space in voltage sensitive dye imaging data from area 18 of the cat. We show that storage reflects neural properties such as stimulus preferences and surprise upon unexpected stimulus change, and in area 18 reflects the abstract concept of an ongoing stimulus despite the locally random nature of this stimulus. We suggest that LAIS will be a useful quantity to test theories of cortical function, such as predictive coding.\n",
            "------------------------------------\n",
            "Title :  The Goldilocks Effect: Human Infants Allocate Attention to Visual Sequences That Are Neither Too Simple Nor Too Complex\n",
            "Author/s :  Celeste Kidd, S. Piantadosi, R. Aslin\n",
            "Venue :  PLoS ONE\n",
            "year :  2012\n",
            "Abstract :  Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants’ visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants’ probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.\n",
            "------------------------------------\n",
            "Title :  Quantum Systems, Channels, Information: A Mathematical Introduction\n",
            "Author/s :  A. Holevo\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  The subject of this book is theory of quantum system presented from information science perspective. The central role is played by the concept of quantum channel and its entropic and information characteristics. Quantum information theory gives a key to understanding elusive phenomena of quantum world and provides a background for development of experimental techniques that enable measuring and manipulation of individual quantum systems. This is important for the new efficient applications such as quantum computing, communication and cryptography. Research in the field of quantum informatics, including quantum information theory, is in progress in leading scientific centers throughout the world. This book gives an accessible, albeit mathematically rigorous and self-contained introduction to quantum information theory, starting from primary structures and leading to fundamental results and to exiting open problems.\n",
            "------------------------------------\n",
            "Title :  Advances in quantum teleportation\n",
            "Author/s :  S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, S. Braunstein\n",
            "Venue :  Nature Photonics\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  BIM for facility managers\n",
            "Author/s :  P. Teicholz\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Building owners and facility managers are discovering that Building Information Modeling (BIM) models of buildings are deep reservoirs of information that can provide valuable spatial and mechanical details on every aspect of a property. When used appropriately, this data can improve performance and save time, effort, and money in running and maintaining the building during its life cycle. It can also provide information for future modifications. For instance, a BIM could reveal everything from the manufacturer of a light fixture to its energy usage to maintenance instructions.\n",
            "------------------------------------\n",
            "Title :  Mapping Soil Properties of Africa at 250 m Resolution: Random Forests Significantly Improve Current Predictions\n",
            "Author/s :  T. Hengl, G. Heuvelink, B. Kempen, J. Leenaars, M. Walsh, K. Shepherd, A. Sila, R. MacMillan, Jorge Mendes de Jesus, L. Tamene, J. Tondoh\n",
            "Venue :  PLoS ONE\n",
            "year :  2015\n",
            "Abstract :  80% of arable land in Africa has low soil fertility and suffers from physical soil problems. Additionally, significant amounts of nutrients are lost every year due to unsustainable soil management practices. This is partially the result of insufficient use of soil management knowledge. To help bridge the soil information gap in Africa, the Africa Soil Information Service (AfSIS) project was established in 2008. Over the period 2008–2014, the AfSIS project compiled two point data sets: the Africa Soil Profiles (legacy) database and the AfSIS Sentinel Site database. These data sets contain over 28 thousand sampling locations and represent the most comprehensive soil sample data sets of the African continent to date. Utilizing these point data sets in combination with a large number of covariates, we have generated a series of spatial predictions of soil properties relevant to the agricultural management—organic carbon, pH, sand, silt and clay fractions, bulk density, cation-exchange capacity, total nitrogen, exchangeable acidity, Al content and exchangeable bases (Ca, K, Mg, Na). We specifically investigate differences between two predictive approaches: random forests and linear regression. Results of 5-fold cross-validation demonstrate that the random forests algorithm consistently outperforms the linear regression algorithm, with average decreases of 15–75% in Root Mean Squared Error (RMSE) across soil properties and depths. Fitting and running random forests models takes an order of magnitude more time and the modelling success is sensitive to artifacts in the input data, but as long as quality-controlled point data are provided, an increase in soil mapping accuracy can be expected. Results also indicate that globally predicted soil classes (USDA Soil Taxonomy, especially Alfisols and Mollisols) help improve continental scale soil property mapping, and are among the most important predictors. This indicates a promising potential for transferring pedological knowledge from data rich countries to countries with limited soil data.\n",
            "------------------------------------\n",
            "Title :  A Theoretical Framework for Conversational Search\n",
            "Author/s :  Filip Radlinski, Nick Craswell\n",
            "Venue :  Conference on Human Information Interaction and Retrieval\n",
            "year :  2017\n",
            "Abstract :  This paper studies conversational approaches to information retrieval, presenting a theory and model of information interaction in a chat setting. In particular, we consider the question of what properties would be desirable for a conversational information retrieval system so that the system can allow users to answer a variety of information needs in a natural and efficient manner. We study past work on human conversations, and propose a small set of properties that taken together could measure the extent to which a system is conversational. Following this, we present a theoretical model of a conversational system that implements the properties. We describe how this system could be implemented, making the action space of an conversational search agent explicit. Our analysis of this model shows that while theoretical, the model could be practically implemented to satisfy the desirable properties presented. In doing so, we show that the properties are also feasible.\n",
            "------------------------------------\n",
            "Title :  Building Ontologies with Basic Formal Ontology\n",
            "Author/s :  R. Arp, Barry Smith, Andrew D. Spear\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In the era of \"big data,\" science is increasingly information driven, and the potential for computers to store, manage, and integrate massive amounts of data has given rise to such new disciplinary fields as biomedical informatics. Applied ontology offers a strategy for the organization of scientific information in computer-tractable form, drawing on concepts not only from computer and information science but also from linguistics, logic, and philosophy. This book provides an introduction to the field of applied ontology that is of particular relevance to biomedicine, covering theoretical components of ontologies, best practices for ontology design, and examples of biomedical ontologies in use.After defining an ontology as a representation of the types of entities in a given domain, the book distinguishes between different kinds of ontologies and taxonomies, and shows how applied ontology draws on more traditional ideas from metaphysics. It presents the core features of the Basic Formal Ontology (BFO), now used by over one hundred ontology projects around the world, and offers examples of domain ontologies that utilize BFO. The book also describes Web Ontology Language (OWL), a common framework for Semantic Web technologies. Throughout, the book provides concrete recommendations for the design and construction of domain ontologies.\n",
            "------------------------------------\n",
            "Title :  How Long to Wait? Predicting Bus Arrival Time With Mobile Phone Based Participatory Sensing\n",
            "Author/s :  Pengfei Zhou, Yuanqing Zheng, Mo Li\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  The bus arrival time is primary information to most city transport travelers. Excessively long waiting time at bus stops often discourages the travelers and makes them reluctant to take buses. In this paper, we present a bus arrival time prediction system based on bus passengers' participatory sensing. With commodity mobile phones, the bus passengers' surrounding environmental context is effectively collected and utilized to estimate the bus traveling routes and predict bus arrival time at various bus stops. The proposed system solely relies on the collaborative effort of the participating users and is independent from the bus operating companies, so it can be easily adopted to support universal bus service systems without requesting support from particular bus operating companies. Instead of referring to GPS-enabled location information, we resort to more generally available and energy efficient sensing resources, including cell tower signals, movement statuses, audio recordings, etc., which bring less burden to the participatory party and encourage their participation. We develop a prototype system with different types of Android-based mobile phones and comprehensively experiment with the NTU campus shuttle buses as well as Singapore public buses over a 7-week period. The evaluation results suggest that the proposed system achieves outstanding prediction accuracy compared with those bus operator initiated and GPS supported solutions. We further adopt our system and conduct quick trial experiments with London bus system for 4 days, which suggests the easy deployment of our system and promising system performance across cities. At the same time, the proposed solution is more generally available and energy friendly.\n",
            "------------------------------------\n",
            "Title :  Research on information systems failures and successes: Status update and future directions\n",
            "Author/s :  Yogesh Kumar Dwivedi, D. Wastell, Sven Laumer, H. Henriksen, M. Myers, D. Bunker, Amany R. Elbanna, M. Ravishankar, S. Srivastava\n",
            "Venue :  Inf. Syst. Frontiers\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Selecting optimal partitioning schemes for phylogenomic datasets\n",
            "Author/s :  R. Lanfear, B. Calcott, D. Kainer, C. Mayer, A. Stamatakis\n",
            "Venue :  BMC Evolutionary Biology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Exposure to opposing views on social media can increase political polarization\n",
            "Author/s :  C. Bail, Lisa P. Argyle, Taylor W. Brown, John P. Bumpus, Haohan Chen, M. F. Hunzaker, Jaemin Lee, M. Mann, Friedolin Merhout, A. Volfovsky\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2018\n",
            "Abstract :  Significance Social media sites are often blamed for exacerbating political polarization by creating “echo chambers” that prevent people from being exposed to information that contradicts their preexisting beliefs. We conducted a field experiment that offered a large group of Democrats and Republicans financial compensation to follow bots that retweeted messages by elected officials and opinion leaders with opposing political views. Republican participants expressed substantially more conservative views after following a liberal Twitter bot, whereas Democrats’ attitudes became slightly more liberal after following a conservative Twitter bot—although this effect was not statistically significant. Despite several limitations, this study has important implications for the emerging field of computational social science and ongoing efforts to reduce political polarization online. There is mounting concern that social media sites contribute to political polarization by creating “echo chambers” that insulate people from opposing views about current events. We surveyed a large sample of Democrats and Republicans who visit Twitter at least three times each week about a range of social policy issues. One week later, we randomly assigned respondents to a treatment condition in which they were offered financial incentives to follow a Twitter bot for 1 month that exposed them to messages from those with opposing political ideologies (e.g., elected officials, opinion leaders, media organizations, and nonprofit groups). Respondents were resurveyed at the end of the month to measure the effect of this treatment, and at regular intervals throughout the study period to monitor treatment compliance. We find that Republicans who followed a liberal Twitter bot became substantially more conservative posttreatment. Democrats exhibited slight increases in liberal attitudes after following a conservative Twitter bot, although these effects are not statistically significant. Notwithstanding important limitations of our study, these findings have significant implications for the interdisciplinary literature on political polarization and the emerging field of computational social science.\n",
            "------------------------------------\n",
            "Title :  High-dimensional quantum cryptography with twisted light\n",
            "Author/s :  M. Mirhosseini, O. Magaña-Loaiza, M. O’Sullivan, B. Rodenburg, M. Malik, M. Lavery, M. Padgett, D. Gauthier, R. Boyd\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Quantum key distribution (QKD) systems often rely on polarization of light for encoding, thus limiting the amount of information that can be sent per photon and placing tight bounds on the error rates that such a system can tolerate. Here we describe a proof-of-principle experiment that indicates the feasibility of high-dimensional QKD based on the transverse structure of the light field allowing for the transfer of more than 1 bit per photon. Our implementation uses the orbital angular momentum (OAM) of photons and the corresponding mutually unbiased basis of angular position (ANG). Our experiment uses a digital micro-mirror device for the rapid generation of OAM and ANG modes at 4 kHz, and a mode sorter capable of sorting single photons based on their OAM and ANG content with a separation efficiency of 93%. Through the use of a seven-dimensional alphabet encoded in the OAM and ANG bases, we achieve a channel capacity of 2.05 bits per sifted photon. Our experiment demonstrates that, in addition to having an increased information capacity, multilevel QKD systems based on spatial-mode encoding can be more resilient against intercept-resend eavesdropping attacks.\n",
            "------------------------------------\n",
            "Title :  Background and Data Configuration Process of a Nationwide Population-Based Study Using the Korean National Health Insurance System\n",
            "Author/s :  Sun-Ok Song, C. Jung, Y. Song, Cheol-Young Park, H. Kwon, B. Cha, J. Park, Ki-Up Lee, K. Ko, Byung-wan Lee\n",
            "Venue :  Diabetes & Metabolism Journal\n",
            "year :  2014\n",
            "Abstract :  Background The National Health Insurance Service (NHIS) recently signed an agreement to provide limited open access to the databases within the Korean Diabetes Association for the benefit of Korean subjects with diabetes. Here, we present the history, structure, contents, and way to use data procurement in the Korean National Health Insurance (NHI) system for the benefit of Korean researchers. Methods The NHIS in Korea is a single-payer program and is mandatory for all residents in Korea. The three main healthcare programs of the NHI, Medical Aid, and long-term care insurance (LTCI) provide 100% coverage for the Korean population. The NHIS in Korea has adopted a fee-for-service system to pay health providers. Researchers can obtain health information from the four databases of the insured that contain data on health insurance claims, health check-ups and LTCI. Results Metabolic disease as chronic disease is increasing with aging society. NHIS data is based on mandatory, serial population data, so, this might show the time course of disease and predict some disease progress, and also be used in primary and secondary prevention of disease after data mining. Conclusion The NHIS database represents the entire Korean population and can be used as a population-based database. The integrated information technology of the NHIS database makes it a world-leading population-based epidemiology and disease research platform.\n",
            "------------------------------------\n",
            "Title :  Advances in communications using optical vortices\n",
            "Author/s :  Jian Wang\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  An optical vortex having an isolated point singularity is associated with the spatial structure of light waves. A polarization vortex (vector beam) with a polarization singularity has spatially variant polarizations. A phase vortex with phase singularity or screw dislocation has a spiral phase front. The optical vortex has recently gained increasing interest in optical trapping, optical tweezers, laser machining, microscopy, quantum information processing, and optical communications. In this paper, we review recent advances in optical communications using optical vortices. First, basic concepts of polarization/phase vortex modulation and multiplexing in communications and key techniques of polarization/phase vortex generation and (de)multiplexing are introduced. Second, free-space and fiber optical communications using optical vortex modulation and optical vortex multiplexing are presented. Finally, key challenges and perspectives of optical communications using optical vortices are discussed. It is expected that optical vortices exploiting the space physical dimension of light waves might find more interesting applications in optical communications and interconnects.\n",
            "------------------------------------\n",
            "Title :  A survey of trust in social networks\n",
            "Author/s :  W. Sherchan, S. Nepal, Cécile Paris\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Web-based social networks have become popular as a medium for disseminating information and connecting like-minded people. The public accessibility of such networks with the ability to share opinions, thoughts, information, and experience offers great promise to enterprises and governments. In addition to individuals using such networks to connect to their friends and families, governments and enterprises have started exploiting these platforms for delivering their services to citizens and customers. However, the success of such attempts relies on the level of trust that members have with each other as well as with the service provider. Therefore, trust becomes an essential and important element of a successful social network. In this article, we present the first comprehensive review of social and computer science literature on trust in social networks. We first review the existing definitions of trust and define social trust in the context of social networks. We then discuss recent works addressing three aspects of social trust: trust information collection, trust evaluation, and trust dissemination. Finally, we compare and contrast the literature and identify areas for further research in social trust.\n",
            "------------------------------------\n",
            "Title :  Supervised Contrastive Learning\n",
            "Author/s :  Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan\n",
            "Venue :  Neural Information Processing Systems\n",
            "year :  2020\n",
            "Abstract :  Cross entropy is the most widely used loss function for supervised training of image classification models. In this paper, we propose a novel training methodology that consistently outperforms cross entropy on supervised learning tasks across different architectures and data augmentations. We modify the batch contrastive loss, which has recently been shown to be very effective at learning powerful representations in the self-supervised setting. We are thus able to leverage label information more effectively than cross entropy. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. In addition to this, we leverage key ingredients such as large batch sizes and normalized embeddings, which have been shown to benefit self-supervised learning. On both ResNet-50 and ResNet-200, we outperform cross entropy by over 1%, setting a new state of the art number of 78.8% among methods that use AutoAugment data augmentation. The loss also shows clear benefits for robustness to natural corruptions on standard benchmarks on both calibration and accuracy. Compared to cross entropy, our supervised contrastive loss is more stable to hyperparameter settings such as optimizers or data augmentations.\n",
            "------------------------------------\n",
            "Title :  Recent automatic text summarization techniques: a survey\n",
            "Author/s :  Mahak Gambhir, Vishal Gupta\n",
            "Venue :  Artificial Intelligence Review\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The Filter Bubble\n",
            "Author/s :  Eli Pariser\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  : Introduced by tech entrepreneur and activist Eli Pariser in 2011, the ‘filter bubble’ is a persistent concept which suggests that search engines and social media, together with their recommendation and personalisation algorithms, are centrally culpable for the societal and ideological polarisation experienced in many countries: we no longer encounter a balanced and healthy information diet, but only see information that targets our established interests and reinforces our existing worldviews. Filter bubbles are seen as critical enablers of Brexit, Trump, Bolsonaro, and other populist political phenomena, and search and social media companies have been criticised for failing to prevent their development. Yet, there is scant empirical evidence for their existence, or for the related concept of ‘echo chambers’: indeed, search and social media users generally appear to encounter a highly centrist media diet that is, if anything, more diverse than that of non-users. However, the persistent use of these concepts in mainstream media and political debates has now created its own discursive reality that continues to impact materially on societal institutions, media and communication platforms, and ordinary users themselves. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to redirect scholarly attention from far more critical areas of enquiry.\n",
            "------------------------------------\n",
            "Title :  Leveraging media and health communication strategies to overcome the COVID-19 infodemic\n",
            "Author/s :  Nour Mheidly, Jawad Fares\n",
            "Venue :  Journal of Public Health Policy\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Expectation and purpose: understanding users' mental models of mobile app privacy through crowdsourcing\n",
            "Author/s :  Jialiu Lin, N. Sadeh, Shahriyar Amini, J. Lindqvist, Jason I. Hong, J. Zhang\n",
            "Venue :  Ubiquitous Computing\n",
            "year :  2012\n",
            "Abstract :  Smartphone security research has produced many useful tools to analyze the privacy-related behaviors of mobile apps. However, these automated tools cannot assess people's perceptions of whether a given action is legitimate, or how that action makes them feel with respect to privacy. For example, automated tools might detect that a blackjack game and a map app both use one's location information, but people would likely view the map's use of that data as more legitimate than the game. Our work introduces a new model for privacy, namely privacy as expectations. We report on the results of using crowdsourcing to capture users' expectations of what sensitive resources mobile apps use. We also report on a new privacy summary interface that prioritizes and highlights places where mobile apps break people's expectations. We conclude with a discussion of implications for employing crowdsourcing as a privacy evaluation technique.\n",
            "------------------------------------\n",
            "Title :  How Is the Mobile Internet Different? Search Costs and Local Activities\n",
            "Author/s :  A. Ghose, Avi Goldfarb, S. Han\n",
            "Venue :  Information systems research\n",
            "year :  2013\n",
            "Abstract :  We explore how Internet browsing behavior varies between mobile phones and personal computers. Smaller screen sizes on mobile phones increase the cost to the user of browsing for information. In addition, a wider range of offline locations for mobile Internet usage suggests that local activities are particularly important. Using data on user behavior at a (Twitter-like) microblogging service, we exploit exogenous variation in the ranking mechanism of posts to identify the ranking effects. We show that (1) ranking effects are higher on mobile phones suggesting higher search costs: links that appear at the top of the screen are especially likely to be clicked on mobile phones and (2) the benefit of browsing for geographically close matches is higher on mobile phones: stores located in close proximity to a user's home are much more likely to be clicked on mobile phones. Thus, the mobile Internet is somewhat less “Internet-like”: search costs are higher and distance matters more. We speculate on how these cha...\n",
            "------------------------------------\n",
            "Title :  Fairness for Non-Orthogonal Multiple Access in 5G Systems\n",
            "Author/s :  S. Timotheou, I. Krikidis\n",
            "Venue :  IEEE Signal Processing Letters\n",
            "year :  2015\n",
            "Abstract :  In non-orthogonal multiple access (NOMA) downlink, multiple data flows are superimposed in the power domain and user decoding is based on successive interference cancellation. NOMA's performance highly depends on the power split among the data flows and the associated power allocation (PA) problem. In this letter, we study NOMA from a fairness standpoint and we investigate PA techniques that ensure fairness for the downlink users under i) instantaneous channel state information (CSI) at the transmitter, and ii) average CSI. Although the formulated problems are non-convex, we have developed low-complexity polynomial algorithms that yield the optimal solution in both cases considered.\n",
            "------------------------------------\n",
            "Title :  Age of Information: An Introduction and Survey\n",
            "Author/s :  R. Yates, Yin Sun, D. Brown, S. Kaul, E. Modiano, S. Ulukus\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2020\n",
            "Abstract :  We summarize recent contributions in the broad area of age of information (AoI). In particular, we describe the current state of the art in the design and optimization of low-latency cyberphysical systems and applications in which sources send time-stamped status updates to interested recipients. These applications desire status updates at the recipients to be as timely as possible; however, this is typically constrained by limited system resources. We describe AoI timeliness metrics and present general methods of AoI evaluation analysis that are applicable to a wide variety of sources and systems. Starting from elementary single-server queues, we apply these AoI methods to a range of increasingly complex systems, including energy harvesting sensors transmitting over noisy channels, parallel server systems, queueing networks, and various single-hop and multi-hop wireless networks. We also explore how update age is related to MMSE methods of sampling, estimation and control of stochastic processes. The paper concludes with a review of efforts to employ age optimization in cyberphysical applications.\n",
            "------------------------------------\n",
            "Title :  HL7 FHIR: An Agile and RESTful approach to healthcare information exchange\n",
            "Author/s :  D. Bender, K. Sartipi\n",
            "Venue :  Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems\n",
            "year :  2013\n",
            "Abstract :  This research examines the potential for new Health Level 7 (HL7) standard Fast Healthcare Interoperability Resources (FHIR, pronounced “fire”) standard to help achieve healthcare systems interoperability. HL7 messaging standards are widely implemented by the healthcare industry and have been deployed internationally for decades. HL7 Version 2 (“v2”) health information exchange standards are a popular choice of local hospital communities for the exchange of healthcare information, including electronic medical record information. In development for 15 years, HL7 Version 3 (“v3”) was designed to be the successor to Version 2, addressing Version 2's shortcomings. HL7 v3 has been heavily criticized by the industry for being internally inconsistent even in it's own documentation, too complex and expensive to implement in real world systems and has been accused of contributing towards many failed and stalled systems implementations. HL7 is now experimenting with a new approach to the development of standards with FHIR. This research provides a chronicle of the evolution of the HL7 messaging standards, an introduction to HL7 FHIR and a comparative analysis between HL7 FHIR and previous HL7 messaging standards.\n",
            "------------------------------------\n",
            "Title :  A predictive model for the temporal dynamics of information diffusion in online social networks\n",
            "Author/s :  Adrien Guille, Hakim Hacid\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  Today, online social networks have become powerful tools for the spread of information. They facilitate the rapid and large-scale propagation of content and the consequences of an information -- whether it is favorable or not to someone, false or true -- can then take considerable proportions. Therefore it is essential to provide means to analyze the phenomenon of information dissemination in such networks. Many recent studies have addressed the modeling of the process of information diffusion, from a topological point of view and in a theoretical perspective, but we still know little about the factors involved in it. With the assumption that the dynamics of the spreading process at the macroscopic level is explained by interactions at microscopic level between pairs of users and the topology of their interconnections, we propose a practical solution which aims to predict the temporal dynamics of diffusion in social networks. Our approach is based on machine learning techniques and the inference of time-dependent diffusion probabilities from a multidimensional analysis of individual behaviors. Experimental results on a real dataset extracted from Twitter show the interest and effectiveness of the proposed approach as well as interesting recommendations for future investigation.\n",
            "------------------------------------\n",
            "Title :  Integrated photonic quantum technologies\n",
            "Author/s :  Jianwei Wang, F. Sciarrino, A. Laing, M. Thompson\n",
            "Venue :  Nature Photonics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Integration of Online and Offline Channels in Retail: The Impact of Sharing Reliable Inventory Availability Information\n",
            "Author/s :  Santiago Gallino, Antonio Moreno\n",
            "Venue :  Management Sciences\n",
            "year :  2014\n",
            "Abstract :  Using a proprietary data set, we analyze the impact of the implementation of a “buy-online, pick-up-in-store” BOPS project. The implementation of this project is associated with a reduction in online sales and an increase in store sales and traffic. These results can be explained by two simultaneous phenomena: 1 additional store sales from customers who use the BOPS functionality and buy additional products in the stores cross-selling effect and 2 the shift of some customers from the online to the brick-and-mortar channel and the conversion of noncustomers into store customers channel-shift effect. We explain these channel-shift patterns as an increase in “research online, purchase offline” behavior enabled by BOPS implementation, and we validate this explanation with evidence from the change of cart abandonment and conversion rates of the brick-and-mortar and online channels. We interpret these results in light of recent operations management literature that analyzes the impact of sharing inventory availability information. Our analysis illustrates the limitations of drawing conclusions about complex interventions using single-channel data. \n",
            " \n",
            "This paper was accepted by Alok Gupta, special issue on business analytics.\n",
            "------------------------------------\n",
            "Title :  Comparison of co-expression measures: mutual information, correlation, and model based indices\n",
            "Author/s :  Lin Song, P. Langfelder, S. Horvath\n",
            "Venue :  BMC Bioinformatics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  EVOLUTION OF THE WORLD WIDE WEB : FROM WEB 1.0 TO WEB 4.0\n",
            "Author/s :  Sareh Aghaei, M. Nematbakhsh, Hadi Khosravi Farsani\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  The World Wide Web as the largest information construct has had much progress since its advent. This paper provides a background of the evolution of the web from web 1.0 to web 4.0. Web 1.0 as a web of information connections, Web 2.0 as a web of people connections, Web 3.0 as a web of knowledge connections and web 4.0 as a web of intelligence connections are described as four generations of the web in the paper.\n",
            "------------------------------------\n",
            "Title :  Accounting Conservatism and Stock Price Crash Risk: Firm-Level Evidence\n",
            "Author/s :  Jeong‐Bon Kim, Liandong Zhang\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Using a large sample of U.S. firms over the period 1964–2007, we find that conditional conservatism is associated with the lower likelihood of a firm’s future stock price crashes. This finding holds for multiple measures of conditional conservatism and crash risk and it is robust to controlling for other known determinants of crash risk and firm fixed effects. Moreover, we find that the relation between conservatism and crash risk is more pronounced for firms with higher information asymmetries. Overall, our results are consistent with the notion that conditional conservatism limits managers’ incentive and ability to overstate performance and hide bad news from investors, which, in turn, reduces stock price crash risk.\n",
            "------------------------------------\n",
            "Title :  Optimal Resource Allocation in Full-Duplex Wireless-Powered Communication Network\n",
            "Author/s :  Hyungsik Ju, Rui Zhang\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2014\n",
            "Abstract :  This paper studies optimal resource allocation in the wireless-powered communication network (WPCN), where one hybrid access point (H-AP) operating in full duplex (FD) broadcasts wireless energy to a set of distributed users in the downlink (DL) and, at the same time, receives independent information from the users via time-division multiple access in the uplink (UL). We design an efficient protocol to support simultaneous wireless energy transfer (WET) in the DL and wireless information transmission (WIT) in the UL for the proposed FD-WPCN. We jointly optimize the time allocations to the H-AP for DL WET and different users for UL WIT and the transmit power allocations over time at the H-AP to maximize the users' weighted sum rate of UL information transmission with harvested energy. We consider both the cases with perfect and imperfect self-interference cancellation (SIC) at the H-AP, for which we obtain optimal and suboptimal time and power allocation solutions, respectively. Furthermore, we consider the half-duplex (HD) WPCN as a baseline scheme and derive its optimal resource allocation solution. Simulation results show that the FD-WPCN outperforms the HD-WPCN when effective SIC can be implemented and more stringent peak power constraint is applied at the H-AP.\n",
            "------------------------------------\n",
            "Title :  Differential Recurrent Neural Networks for Action Recognition\n",
            "Author/s :  Vivek Veeriah, Naifan Zhuang, Guo-Jun Qi\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2015\n",
            "Abstract :  The long short-term memory (LSTM) neural network is capable of processing complex sequential information since it utilizes special gating schemes for learning representations from long input sequences. It has the potential to model any time-series or sequential data, where the current hidden state has to be considered in the context of the past hidden states. This property makes LSTM an ideal choice to learn the complex dynamics of various actions. Unfortunately, the conventional LSTMs do not consider the impact of spatio-temporal dynamics corresponding to the given salient motion patterns, when they gate the information that ought to be memorized through time. To address this problem, we propose a differential gating scheme for the LSTM neural network, which emphasizes on the change in information gain caused by the salient motions between the successive frames. This change in information gain is quantified by Derivative of States (DoS), and thus the proposed LSTM model is termed as differential Recurrent Neural Network (dRNN). We demonstrate the effectiveness of the proposed model by automatically recognizing actions from the real-world 2D and 3D human action datasets. Our study is one of the first works towards demonstrating the potential of learning complex time-series representations via high-order derivatives of states.\n",
            "------------------------------------\n",
            "Title :  Health-protective behaviour, social media usage and conspiracy belief during the COVID-19 public health emergency\n",
            "Author/s :  D. Allington, B. Duffy, S. Wessely, N. Dhavan, J. Rubin\n",
            "Venue :  Psychological Medicine\n",
            "year :  2020\n",
            "Abstract :  Abstract Background Social media platforms have long been recognised as major disseminators of health misinformation. Many previous studies have found a negative association between health-protective behaviours and belief in the specific form of misinformation popularly known as ‘conspiracy theory’. Concerns have arisen regarding the spread of COVID-19 conspiracy theories on social media. Methods Three questionnaire surveys of social media use, conspiracy beliefs and health-protective behaviours with regard to COVID-19 among UK residents were carried out online, one using a self-selecting sample (N = 949) and two using stratified random samples from a recruited panel (N = 2250, N = 2254). Results All three studies found a negative relationship between COVID-19 conspiracy beliefs and COVID-19 health-protective behaviours, and a positive relationship between COVID-19 conspiracy beliefs and use of social media as a source of information about COVID-19. Studies 2 and 3 also found a negative relationship between COVID-19 health-protective behaviours and use of social media as a source of information, and Study 3 found a positive relationship between health-protective behaviours and use of broadcast media as a source of information. Conclusions When used as an information source, unregulated social media may present a health risk that is partly but not wholly reducible to their role as disseminators of health-related conspiracy beliefs.\n",
            "------------------------------------\n",
            "Title :  What's in a hashtag?: content based prediction of the spread of ideas in microblogging communities\n",
            "Author/s :  Oren Tsur, A. Rappoport\n",
            "Venue :  Web Search and Data Mining\n",
            "year :  2012\n",
            "Abstract :  Current social media research mainly focuses on temporal trends of the information flow and on the topology of the social graph that facilitates the propagation of information. In this paper we study the effect of the content of the idea on the information propagation. We present an efficient hybrid approach based on a linear regression for predicting the spread of an idea in a given time frame. We show that a combination of content features with temporal and topological features minimizes prediction error.\n",
            " Our algorithm is evaluated on Twitter hashtags extracted from a dataset of more than 400 million tweets. We analyze the contribution and the limitations of the various feature types to the spread of information, demonstrating that content aspects can be used as strong predictors thus should not be disregarded. We also study the dependencies between global features such as graph topology and content features.\n",
            "------------------------------------\n",
            "Title :  Prefrontal–hippocampal interactions in episodic memory\n",
            "Author/s :  H. Eichenbaum\n",
            "Venue :  Nature Reviews Neuroscience\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Direction of information flow in large-scale resting-state networks is frequency-dependent\n",
            "Author/s :  A. Hillebrand, P. Tewarie, E. van Dellen, Meichen Yu, Ellen W. S. Carbo, L. Douw, A. Gouw, E. V. van Straaten, C. Stam\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2016\n",
            "Abstract :  Significance A description of the structural and functional connections in the human brain is necessary for the understanding of both normal and abnormal brain functioning. Although it has become clear in recent years that stable patterns of functional connectivity can be observed during the resting state, to date, it remains unclear what the dominant patterns of information flow are in this functional connectome and how these relate to the integration of brain function. Our results are the first to describe the large-scale frequency-specific patterns of information flow in the human brain, showing that different subsystems form a loop through which information “reverberates” or “circulates.” These results could be extended to give insights into how such flow optimizes integrative cognitive processing. Normal brain function requires interactions between spatially separated, and functionally specialized, macroscopic regions, yet the directionality of these interactions in large-scale functional networks is unknown. Magnetoencephalography was used to determine the directionality of these interactions, where directionality was inferred from time series of beamformer-reconstructed estimates of neuronal activation, using a recently proposed measure of phase transfer entropy. We observed well-organized posterior-to-anterior patterns of information flow in the higher-frequency bands (alpha1, alpha2, and beta band), dominated by regions in the visual cortex and posterior default mode network. Opposite patterns of anterior-to-posterior flow were found in the theta band, involving mainly regions in the frontal lobe that were sending information to a more distributed network. Many strong information senders in the theta band were also frequent receivers in the alpha2 band, and vice versa. Our results provide evidence that large-scale resting-state patterns of information flow in the human brain form frequency-dependent reentry loops that are dominated by flow from parieto-occipital cortex to integrative frontal areas in the higher-frequency bands, which is mirrored by a theta band anterior-to-posterior flow.\n",
            "------------------------------------\n",
            "Title :  Why People Use Chatbots\n",
            "Author/s :  P. Brandtzæg, A. Følstad\n",
            "Venue :  International Conference on Internet Science\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Quantum Secure Direct Communication with Quantum Memory.\n",
            "Author/s :  Wei Zhang, D. Ding, Y. Sheng, Lan Zhou, B. Shi, G. Guo\n",
            "Venue :  Physical Review Letters\n",
            "year :  2016\n",
            "Abstract :  Quantum communication provides an absolute security advantage, and it has been widely developed over the past 30 years. As an important branch of quantum communication, quantum secure direct communication (QSDC) promotes high security and instantaneousness in communication through directly transmitting messages over a quantum channel. The full implementation of a quantum protocol always requires the ability to control the transfer of a message effectively in the time domain; thus, it is essential to combine QSDC with quantum memory to accomplish the communication task. In this Letter, we report the experimental demonstration of QSDC with state-of-the-art atomic quantum memory for the first time in principle. We use the polarization degrees of freedom of photons as the information carrier, and the fidelity of entanglement decoding is verified as approximately 90%. Our work completes a fundamental step toward practical QSDC and demonstrates a potential application for long-distance quantum communication in a quantum network.\n",
            "------------------------------------\n",
            "Title :  Improving Diagnosis in Health Care\n",
            "Author/s :  E. Balogh, B. Miller, J. Ball\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Getting the right diagnosis is a key aspect of health care - it provides an explanation of a patient's health problem and informs subsequent health care decisions. The diagnostic process is a complex, collaborative activity that involves clinical reasoning and information gathering to determine a patient's health problem. According to Improving Diagnosis in Health Care, diagnostic errors-inaccurate or delayed diagnoses-persist throughout all settings of care and continue to harm an unacceptable number of patients. It is likely that most people will experience at least one diagnostic error in their lifetime, sometimes with devastating consequences. Diagnostic errors may cause harm to patients by preventing or delaying appropriate treatment, providing unnecessary or harmful treatment, or resulting in psychological or financial repercussions. The committee concluded that improving the diagnostic process is not only possible, but also represents a moral, professional, and public health imperative. Improving Diagnosis in Health Care a continuation of the landmark Institute of Medicine reports To Err Is Human (2000) and Crossing the Quality Chasm (2001) finds that diagnosis–and, in particular, the occurrence of diagnostic errors–has been largely unappreciated in efforts to improve the quality and safety of health care. Without a dedicated focus on improving diagnosis, diagnostic errors will likely worsen as the delivery of health care and the diagnostic process continue to increase in complexity. Just as the diagnostic process is a collaborative activity, improving diagnosis will require collaboration and a widespread commitment to change among health care professionals, health care organizations, patients and their families, researchers, and policy makers. The recommendations of Improving Diagnosis in Health Care contribute to the growing momentum for change in this crucial area of health care quality and safety.\n",
            "------------------------------------\n",
            "Title :  Compressed Sensing Signal and Data Acquisition in Wireless Sensor Networks and Internet of Things\n",
            "Author/s :  Shancang Li, Lida Xu, Xinheng Wang\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2013\n",
            "Abstract :  The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.\n",
            "------------------------------------\n",
            "Title :  Big Data-Survey\n",
            "Author/s :  P. Sri, M. Anusha\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Big data is the term for any gathering of information sets, so expensive and complex, that it gets to be hard to process for utilizing customary information handling applications. The difficulties incorporate investigation, catch, duration, inquiry, sharing, stockpiling, Exchange, perception, and protection infringement. To reduce spot business patterns, anticipate diseases, conflict etc., we require bigger data sets when compared with the smaller data sets. Enormous information is hard to work with utilizing most social database administration frameworks and desktop measurements and perception bundles, needing rather enormously parallel programming running on tens, hundreds, or even a large number of servers. In this paper there was an observation on Hadoop architecture, different tools used for big data and its security issues.\n",
            "------------------------------------\n",
            "Title :  LayoutLM: Pre-training of Text and Layout for Document Image Understanding\n",
            "Author/s :  Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2019\n",
            "Abstract :  Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm.\n",
            "------------------------------------\n",
            "Title :  The Impact of Study Size on Meta-analyses: Examination of Underpowered Studies in Cochrane Reviews\n",
            "Author/s :  R. Turner, S. Bird, J. Higgins\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  Background Most meta-analyses include data from one or more small studies that, individually, do not have power to detect an intervention effect. The relative influence of adequately powered and underpowered studies in published meta-analyses has not previously been explored. We examine the distribution of power available in studies within meta-analyses published in Cochrane reviews, and investigate the impact of underpowered studies on meta-analysis results. Methods and Findings For 14,886 meta-analyses of binary outcomes from 1,991 Cochrane reviews, we calculated power per study within each meta-analysis. We defined adequate power as ≥50% power to detect a 30% relative risk reduction. In a subset of 1,107 meta-analyses including 5 or more studies with at least two adequately powered and at least one underpowered, results were compared with and without underpowered studies. In 10,492 (70%) of 14,886 meta-analyses, all included studies were underpowered; only 2,588 (17%) included at least two adequately powered studies. 34% of the meta-analyses themselves were adequately powered. The median of summary relative risks was 0.75 across all meta-analyses (inter-quartile range 0.55 to 0.89). In the subset examined, odds ratios in underpowered studies were 15% lower (95% CI 11% to 18%, P<0.0001) than in adequately powered studies, in meta-analyses of controlled pharmacological trials; and 12% lower (95% CI 7% to 17%, P<0.0001) in meta-analyses of controlled non-pharmacological trials. The standard error of the intervention effect increased by a median of 11% (inter-quartile range −1% to 35%) when underpowered studies were omitted; and between-study heterogeneity tended to decrease. Conclusions When at least two adequately powered studies are available in meta-analyses reported by Cochrane reviews, underpowered studies often contribute little information, and could be left out if a rapid review of the evidence is required. However, underpowered studies made up the entirety of the evidence in most Cochrane reviews.\n",
            "------------------------------------\n",
            "Title :  CSI-Based Indoor Localization\n",
            "Author/s :  Kaishun Wu, Jiang Xiao, Youwen Yi, Dihu Chen, Xiaonan Luo, L. Ni\n",
            "Venue :  IEEE Transactions on Parallel and Distributed Systems\n",
            "year :  2013\n",
            "Abstract :  Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in orthogonal frequency division multiplexing systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to build a propagation model and a fingerprinting system at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.\n",
            "------------------------------------\n",
            "Title :  The Media and Mispricing: The Role of the Business Press in the Pricing of Accounting Information\n",
            "Author/s :  Michael S. Drake, Nicholas Guest, Brady J. Twedt\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  ABSTRACT: This study investigates the role of the business press in the pricing of accounting information. Using a comprehensive dataset of more than 111,000 earnings-related business press articles published from 2000 to 2010, we find that press coverage of the annual earnings announcement mitigates cash flow mispricing, but has a negligible effect on accrual mispricing. We provide evidence that this impact is driven primarily by the press disseminating the information more broadly, rather than by the creation of new content that helps investors understand the implications of accounting information. Our results suggest that the business press plays an important role in facilitating the market's ability to efficiently impound accounting information into stock prices and provide new insights into the role of the business press as an information intermediary in capital markets.\n",
            "------------------------------------\n",
            "Title :  Inefficient Hiring in Entry-Level Labor Markets\n",
            "Author/s :  Amanda Pallais\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Hiring inexperienced workers generates information about their abilities. If this information is public, workers obtain its benefits. If workers cannot compensate firms for hiring them, firms will hire too few inexperienced workers. I determine the effects of hiring workers and revealing more information about their abilities through a field experiment in an online marketplace. I hired 952 randomly-selected workers, giving them either detailed or coarse public evaluations. Both hiring workers and providing more detailed evaluations substantially improved workers' subsequent employment outcomes. Under plausible assumptions, the experiment's market-level benefits exceeded its cost, suggesting that some experimental workers had been inefficiently unemployed.\n",
            "------------------------------------\n",
            "Title :  Probabilistic data association for semantic SLAM\n",
            "Author/s :  Sean L. Bowman, Nikolay A. Atanasov, Kostas Daniilidis, George J. Pappas\n",
            "Venue :  IEEE International Conference on Robotics and Automation\n",
            "year :  2017\n",
            "Abstract :  Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.\n",
            "------------------------------------\n",
            "Title :  Connecting with new information landscapes: information literacy practices of refugees\n",
            "Author/s :  A. Lloyd, M. Kennan, K. Thompson, M. Qayyum\n",
            "Venue :  J. Documentation\n",
            "year :  2013\n",
            "Abstract :  Purpose – The purpose of the research reported in this article is to understand how refugees learn to engage with a complex, multimodal information landscape and how their information literacy practice may be constructed to enable them to connect and be included in their new information landscape. Design/methodology/approach – The study is framed through practice and socio‐cultural theories. A qualitative research design is employed including semi‐structured face‐to‐face interviews and focus groups which are thematically analysed through an information practice lens. Findings – Refugees encounter complex and challenging information landscapes that present barriers to their full participation in their new communities. Social inclusion becomes possible where information is provided via sharing through trusted mediators who assist with navigating the information landscape and information mapping, and through visual and social sources. Research limitations/implications – The study is local and situated and therefore not empirically generalizable. It does however provide rich, deep description and explanation that is instructive beyond the specific research site and contributes to theory building. Practical implications – The study highlights the role, and importance, of social and visual information sources and the key role of service providers as mediators and navigators. Governments, funders and service providers can use these findings to inform their service provision. Originality/value – This is an original research paper in which the results provide practical advice for those working with refugees and which also extends theories of information literacy practice as an information practice.\n",
            "------------------------------------\n",
            "Title :  The digital traces of bubbles: feedback cycles between socio-economic signals in the Bitcoin economy\n",
            "Author/s :  David García, C. Tessone, Pavlin Mavrodiev, N. Perony\n",
            "Venue :  Journal of the Royal Society Interface\n",
            "year :  2014\n",
            "Abstract :  What is the role of social interactions in the creation of price bubbles? Answering this question requires obtaining collective behavioural traces generated by the activity of a large number of actors. Digital currencies offer a unique possibility to measure socio-economic signals from such digital traces. Here, we focus on Bitcoin, the most popular cryptocurrency. Bitcoin has experienced periods of rapid increase in exchange rates (price) followed by sharp decline; we hypothesize that these fluctuations are largely driven by the interplay between different social phenomena. We thus quantify four socio-economic signals about Bitcoin from large datasets: price on online exchanges, volume of word-of-mouth communication in online social media, volume of information search and user base growth. By using vector autoregression, we identify two positive feedback loops that lead to price bubbles in the absence of exogenous stimuli: one driven by word of mouth, and the other by new Bitcoin adopters. We also observe that spikes in information search, presumably linked to external events, precede drastic price declines. Understanding the interplay between the socio-economic signals we measured can lead to applications beyond cryptocurrencies to other phenomena that leave digital footprints, such as online social network usage.\n",
            "------------------------------------\n",
            "Title :  An Evolutionary Upgrade of Cognitive Load Theory: Using the Human Motor System and Collaboration to Support the Learning of Complex Cognitive Tasks\n",
            "Author/s :  F. Paas, J. Sweller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Crowdsourcing Geographic Knowledge: Volunteered Geographic Information (VGI) in Theory and Practice\n",
            "Author/s :  D. Sui, S. Elwood, M. Goodchild\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Does Transparency Improve Governance\n",
            "Author/s :  Stephen Kosack, Archon Fung\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  In recent years, there has been increasing interest in the potential of transparency—the provision of information to the public—to improve governance in both developed and developing societies. In this article, we characterize and assess the evolution of transparency from an end in itself to a tool for resolving increasingly practical concerns of governance and government performance. After delineating four distinct varieties of transparency, we focus on the type that has received the most rigorous empirical scrutiny from social scientists—so-called “transparency and accountability” (T/A) interventions intended to improve the quality of public services and governance in developing countries. T/A interventions have yielded mixed results: some are highly successful; others appear to have little impact. We develop a rubric of five ideal-typical “worlds” facing transparency that helps to account for this variation in outcomes. Reform based on transparency can face obstacles of collective action, political res...\n",
            "------------------------------------\n",
            "Title :  PhosphoSitePlus, 2014: mutations, PTMs and recalibrations\n",
            "Author/s :  P. Hornbeck, Bin Zhang, Beth Murray, J. Kornhauser, V. Latham, E. Skrzypek\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2014\n",
            "Abstract :  PhosphoSitePlus® (PSP, http://www.phosphosite.org/), a knowledgebase dedicated to mammalian post-translational modifications (PTMs), contains over 330 000 non-redundant PTMs, including phospho, acetyl, ubiquityl and methyl groups. Over 95% of the sites are from mass spectrometry (MS) experiments. In order to improve data reliability, early MS data have been reanalyzed, applying a common standard of analysis across over 1 000 000 spectra. Site assignments with P > 0.05 were filtered out. Two new downloads are available from PSP. The ‘Regulatory sites’ dataset includes curated information about modification sites that regulate downstream cellular processes, molecular functions and protein-protein interactions. The ‘PTMVar’ dataset, an intersect of missense mutations and PTMs from PSP, identifies over 25 000 PTMVars (PTMs Impacted by Variants) that can rewire signaling pathways. The PTMVar data include missense mutations from UniPROTKB, TCGA and other sources that cause over 2000 diseases or syndromes (MIM) and polymorphisms, or are associated with hundreds of cancers. PTMVars include 18 548 phosphorlyation sites, 3412 ubiquitylation sites, 2316 acetylation sites, 685 methylation sites and 245 succinylation sites.\n",
            "------------------------------------\n",
            "Title :  A Turn Toward Avoidance? Selective Exposure to Online Political Information, 2004–2008\n",
            "Author/s :  R. Garrett, Dustin Carnahan, Emily K. Lynch\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Rumors and Health Care Reform: Experiments in Political Misinformation\n",
            "Author/s :  A. Berinsky\n",
            "Venue :  British Journal of Political Science\n",
            "year :  2015\n",
            "Abstract :  This article explores belief in political rumors surrounding the health care reforms enacted by Congress in 2010. Refuting rumors with statements from unlikely sources can, under certain circumstances, increase the willingness of citizens to reject rumors regardless of their own political predilections. Such source credibility effects, while well known in the political persuasion literature, have not been applied to the study of rumor. Though source credibility appears to be an effective tool for debunking political rumors, risks remain. Drawing upon research from psychology on ‘fluency’ – the ease of information recall – this article argues that rumors acquire power through familiarity. Attempting to quash rumors through direct refutation may facilitate their diffusion by increasing fluency. The empirical results find that merely repeating a rumor increases its power.\n",
            "------------------------------------\n",
            "Title :  Depth Map Prediction from a Single Image using a Multi-Scale Deep Network\n",
            "Author/s :  D. Eigen, Christian Puhrsch, R. Fergus\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence suffices for estimation, finding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that refines this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.\n",
            "------------------------------------\n",
            "Title :  Guiding Through the Fog: Financial Statement Complexity and Voluntary Disclosure\n",
            "Author/s :  W. Guay, Delphine Samuels, Daniel J. Taylor\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  A growing literature documents that complex financial statements negatively affect the information environment. In this paper, we examine whether managers use voluntary disclosure to mitigate these negative effects. Employing cross-sectional and within-firm designs, we find a robust positive relation between financial statement complexity and voluntary disclosure. This relation is stronger when liquidity decreases around the filing of the financial statements, is stronger when firms have more outside monitors, and is weaker when firms have poor performance and greater earnings management. We also examine the relation between financial statement complexity and voluntary disclosure using two quasi-natural experiments. Employing a generalized difference-in-differences design, we find firms affected by the adoption of complex accounting standards (e.g., SFAS 133 and SFAS 157) increase their voluntary disclosure to a greater extent than unaffected firms. Collectively, these findings suggest managers use voluntary disclosure to mitigate the negative effects of complex financial statements on the information environment.\n",
            "------------------------------------\n",
            "Title :  End-to-End Flow Correlation Tracking with Spatial-Temporal Attention\n",
            "Author/s :  Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan\n",
            "Venue :  2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year :  2017\n",
            "Abstract :  Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable performance in recent tracking benchmarks. However, most of existing DCF trackers only consider appearance features of current frame, and hardly benefit from motion and inter-frame information. The lack of temporal information degrades the tracking performance during challenges such as partial occlusion and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. The FlowTrack formulates individual components, including optical flow estimation, feature extraction, aggregation and correlation filters tracking as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in deep learning framework. Then the historical feature maps at predefined intervals are warped and aggregated with current ones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VOT2015 and VOT2016.\n",
            "------------------------------------\n",
            "Title :  Norm Perception as a Vehicle for Social Change\n",
            "Author/s :  Margaret E. Tankard, E. Paluck\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  How can we change social norms, the standards describing typical or desirable behavior? Because individuals’ perceptions of norms guide their personal behavior, influencing these perceptions is one way to create social change. And yet individuals do not form perceptions of typical or desirable behavior in an unbiased manner. Individuals attend to select sources of normative information, and their resulting perceptions rarely match actual rates of behavior in their environment. Thus, changing social norms requires an understanding of how individuals perceive norms in the first place. We describe three sources of information that people use to understand norms—individual behavior, summary information about a group, and institutional signals. Social change interventions have used each source to influence perceived norms and behaviors, including recycling, intimate-partner violence, and peer harassment. We discuss conditions under which influence over perceived norms is likely to be stronger, based on the source of the normative information and individuals’ relationship to the source. Finally, we point to future research and suggest when it is most appropriate to use a norm change strategy in the interest of behavior and social change.\n",
            "------------------------------------\n",
            "Title :  Building Information Modeling\n",
            "Author/s :  K. Kensek\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Preface Acknowledgements Introduction Fundamentals 1. BIM Overview Parametric Modeling and the Virtual Building Model BIM \"Dimensions\" Level of Development Summary 2. Stakeholders and BIM's Many Roles Architects, Engineers, Consultants Construction Managers, Contractors, Sub-contractors Fabricators Facilities Managers and Owners Summary 3. Data Exchange and Interoperability Interoperability Data Exchange Workflows Single Model and Federated Model Systems Data and Communication Formats Summary 4. BIM Implementation Transforming the Office to BIM Delivery Methods Legal Issues Office Standards BIM Execution Plan (BEP) Metrics for BIM Maturity Summary 5. Beyond Basic BIM BIM Analytics Cloud Computing Computational Design Increased Sophistication of Owners Summary Application: Project Case Studies designLAB: Small BIM Tames Big Brutalism ZGF: BIM in Transition: Making the Leap at a Large Firm CASE: Building Information Coordinators Mortenson Construction: Outstanding Project Success Through Collaboration Conclusion References and Software Mentioned Index\n",
            "------------------------------------\n",
            "Title :  Challenges and opportunities of digital information at the intersection of Big Data Analytics and supply chain management\n",
            "Author/s :  Florian Kache, S. Seuring\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Despite the variety of supply chain management (SCM) research, little attention has been given to the use of Big Data Analytics for increased information exploitation in a supply chain. The purpose of this paper is to contribute to theory development in SCM by investigating the potential impacts of Big Data Analytics on information usage in a corporate and supply chain context. As it is imperative for companies in the supply chain to have access to up-to-date, accurate, and meaningful information, the exploratory research will provide insights into the opportunities and challenges emerging from the adoption of Big Data Analytics in SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Although Big Data Analytics is gaining increasing attention in management, empirical research on the topic is still scarce. Due to the limited availability of comparable material at the intersection of Big Data Analytics and SCM, the authors apply the Delphi research technique. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Portraying the emerging transition trend from a digital business environment, the presented Delphi study findings contribute to extant knowledge by identifying 43 opportunities and challenges linked to the emergence of Big Data Analytics from a corporate and supply chain perspective. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Research limitations/implications \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "These constructs equip the research community with a first collection of aspects, which could provide the basis to tailor further research at the nexus of Big Data Analytics and SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The research adds to the existing knowledge base as no empirical research has been presented so far specifically assessing opportunities and challenges on corporate and supply chain level with a special focus on the implications imposed through Big Data Analytics.\n",
            "------------------------------------\n",
            "Title :  Uses and Grats 2.0: New Gratifications for New Media\n",
            "Author/s :  S. Sundar, Anthony M. Limperos\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This article responds to recent calls for conceptual and methodological refinement, issued by uses-and-gratifications scholars (Rubin, 2009; Ruggiero, 2000), for studying emergent media. Noting that studies on the uses of the Internet have generated a list of gratifications that are remarkably similar to those obtained from older media, it identifies two measurement artifacts—(1) measures designed for older media are used to capture gratifications from newer media; and (2) gratifications are conceptualized and operationalized too broadly (e.g., information-seeking), thus missing the nuanced gratifications obtained from newer media. It challenges the notion that all gratifications are borne out of innate needs, and proposes that affordances of media technology can shape user needs, giving rise to new and distinctive gratifications. A sample of new gratifications and potential measures for those are provided.\n",
            "------------------------------------\n",
            "Title :  Information network or social network?: the structure of the twitter follow graph\n",
            "Author/s :  Seth A. Myers, Aneesh Sharma, Pankaj Gupta, Jimmy J. Lin\n",
            "Venue :  The Web Conference\n",
            "year :  2014\n",
            "Abstract :  In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.\n",
            "------------------------------------\n",
            "Title :  Three-Way Decisions and Cognitive Computing\n",
            "Author/s :  Yiyu Yao\n",
            "Venue :  Cognitive Computation\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Curated Flows: A Framework for Mapping Media Exposure in the Digital Age\n",
            "Author/s :  Kjerstin Thorson, Chris Wells\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Advancing theory in media exposure and effects requires contending with an increasing level of complexity and contingency. Building on established theoretical concerns and the research possibilities enabled by large social datasets, we propose a framework for mapping information exposure of digitally situated individuals. We argue that from the perspective of an individual's personal communication network, comparable processes of “curation” are undertaken by a variety of actors—not only conventional newsmakers but also individual media users, social contacts, advertisers, and computer algorithms. Detecting the competition, intersection, and overlap of these flows is crucial to understanding media exposure and effects today. Our approach reframes research questions in debates such as polarization, selective and incidental exposure, participation, and conceptual orientations for computational approaches.\n",
            "------------------------------------\n",
            "Title :  Mixed Method Research: Instruments, Validity, Reliability and Reporting Findings\n",
            "Author/s :  Mohammad Zohrabi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The mixed method approaches have recently risen to prominence. The reason that more researchers are opting for these types of research is that both qualitative and quantitative data are simultaneously collected, analyzed and interpreted. In this article the main research instruments (questionnaire, interview and classroom observation) usually used in the mixed method designs are presented and elaborated on. It is believed that using different types of procedures for collecting data and obtaining that information through different sources (learners, teachers, program staff, etc.) can augment the validity and reliability of the data and their interpretation. Therefore, the various ways of boosting the validity and reliability of the data and instruments are delineated at length. Finally, an outline of reporting the findings in the mixed method approaches is sketched out. It is believed that this article can be useful and beneficial to the researchers in general and postgraduate students in particular who want to start or are involved in the process of conducting research.\n",
            "------------------------------------\n",
            "Title :  What's skill got to do with it?: Information literacy skills and self-views of ability among first-year college students\n",
            "Author/s :  M. Gross, D. Latham\n",
            "Venue :  J. Assoc. Inf. Sci. Technol.\n",
            "year :  2012\n",
            "Abstract :  This study replicates a previous study based on work in psychology, which demonstrates that students who score as below proficient in information literacy (IL) skills have a miscalibrated self-view of their ability. Simply stated, these students tend to believe that they have above-average IL skills, when, in fact, an objective test of their ability indicates that they are below-proficient in terms of their actual skills. This investigation was part of an Institute of Museum and Library Services-funded project and includes demographic data about participants, their scores on an objective test of their information literacy skills, and self-estimates of their ability. Findings support previous research that indicates many students come to college without proficient IL skills, that students with below-proficient IL skills have inflated views of their ability, and that this miscalibration can also be expressed by students who test as proficient. Implications for research and practice are discussed. © 2012 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title :  Risk Information Seeking and Processing Model: A Meta‐Analysis\n",
            "Author/s :  Z. J. Yang, Ariel M. Aloe, T. Feeley\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study relies on state-of-the-art meta-analytical techniques to assess overall effects of the Risk Information Seeking and Processing (RISP) model. The results support the utility of the RISP model in predicting risk information seeking and systematic processing. However, the model demonstrated limited explanatory power for heuristic processing. A reduced model composed of only 2 variables—current knowledge and informational subjective norms—accounted for a substantial proportion of variance in the outcome variables. This more parsimonious explanation of information seeking and systematic processing might extend the utility of the RISP model to other communication settings not related to risk. Theoretical boundaries of the RISP model and implications for future research are discussed.\n",
            "------------------------------------\n",
            "Title :  Tuning parameter selection in high dimensional penalized likelihood\n",
            "Author/s :  Yingying Fan, C. Tang\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Determining how to select the tuning parameter appropriately is essential in penalized likelihood methods for high dimensional data analysis. We examine this problem in the setting of penalized likelihood methods for generalized linear models, where the dimensionality of covariates p is allowed to increase exponentially with the sample size n. We propose to select the tuning parameter by optimizing the generalized information criterion with an appropriate model complexity penalty. To ensure that we consistently identify the true model, a range for the model complexity penalty is identified in the generlized information criterion. We find that this model complexity penalty should diverge at the rate of some power of log (p) depending on the tail probability behaviour of the response variables. This reveals that using the Akaike information criterion or Bayes information criterion to select the tuning parameter may not be adequate for consistently identifying the true model. On the basis of our theoretical study, we propose a uniform choice of the model complexity penalty and show that the approach proposed consistently identifies the true model among candidate models with asymptotic probability 1. We justify the performance of the procedure proposed by numerical simulations and a gene expression data analysis.\n",
            "------------------------------------\n",
            "Title :  Multi-Antenna Wireless Powered Communication With Energy Beamforming\n",
            "Author/s :  Liang Liu, Rui Zhang, K. Chua\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2013\n",
            "Abstract :  The newly emerging wireless powered communication networks (WPCNs) have recently drawn significant attention, where radio signals are used to power wireless terminals for information transmission. In this paper, we study a WPCN where one multi-antenna access point (AP) coordinates energy transfer and information transfer to/from a set of single-antenna users. A harvest-then-transmit protocol is assumed where the AP first broadcasts wireless power to all users via energy beamforming in the downlink (DL), and then, the users send their independent information to the AP simultaneously in the uplink (UL) using their harvested energy. To optimize the users' throughput and yet guarantee their rate fairness, we maximize the minimum throughput among all users by a joint design of the DL-UL time allocation, the DL energy beamforming, and the UL transmit power allocation, as well as receive beamforming. We solve this nonconvex problem optimally by two steps. First, we fix the DL-UL time allocation and obtain the optimal DL energy beamforming, UL power allocation, and receive beamforming to maximize the minimum signal-to-interference-plus-noise ratio of all users. This problem is shown to be still nonconvex; however, we convert it equivalently to a spectral radius minimization problem, which can be solved efficiently by applying the alternating optimization based on the nonnegative matrix theory. Then, the optimal time allocation is found by a one-dimensional search to maximize the minimum rate of all users. Furthermore, two suboptimal designs of lower complexity are also proposed, and their throughput performance is compared against that of the optimal solution.\n",
            "------------------------------------\n",
            "Title :  Privacy as part of the app decision-making process\n",
            "Author/s :  Patrick Gage Kelley, L. Cranor, N. Sadeh\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2013\n",
            "Abstract :  Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.\n",
            "------------------------------------\n",
            "Title :  Survey of Temporal Information Retrieval and Related Applications\n",
            "Author/s :  Ricardo Campos, G. Dias, A. Jorge, A. Jatowt\n",
            "Venue :  ACM Computing Surveys\n",
            "year :  2014\n",
            "Abstract :  Temporal information retrieval has been a topic of great interest in recent years. Its purpose is to improve the effectiveness of information retrieval methods by exploiting temporal information in documents and queries. In this article, we present a survey of the existing literature on temporal information retrieval. In addition to giving an overview of the field, we categorize the relevant research, describe the main contributions, and compare different approaches. We organize existing research to provide a coherent view, discuss several open issues, and point out some possible future research directions in this area. Despite significant advances, the area lacks a systematic arrangement of prior efforts and an overview of state-of-the-art approaches. Moreover, an effective end-to-end temporal retrieval system that exploits temporal information to improve the quality of the presented results remains undeveloped.\n",
            "------------------------------------\n",
            "Title :  Health-Related Internet Use by Children and Adolescents: Systematic Review\n",
            "Author/s :  Eunhee Park, M. Kwon\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2018\n",
            "Abstract :  Background The internet is widely used by children and adolescents, who generally have a high level of competency with technology. Thus, the internet has become a great resource for supporting youth self-care and health-related services. However, few studies have explored adolescents’ internet use for health-related matters. Objective The objective of this systematic literature review was to examine the phenomenon of children and adolescents’ health-related internet use and to identify gaps in the research. Methods A total of 19 studies were selected from a search of major electronic databases: PubMed, Cumulative Index of Nursing and Allied Health Literature, and PsycINFO using the following search terms: “health-related internet use,” “eHealth,” “Internet use for health-related purpose,” “Web-based resource,” “health information seeking,” and “online resource,” combined with “child,” “adolescent,” “student,” “youth,” and “teen.” The children’s and adolescents’ ages were limited to 24 years and younger. The search was conducted from September 2015 to October 2017. The studies identified to contain youth (<24 years) health-related internet use were all published in peer-reviewed journals in the past 10 years; these studies examined general internet use seeking health care services, resources, information, or using the internet for health promotion and self-care. Studies were excluded if they explored the role of the internet as a modality for surveys, recruitment, or searching for relevant literature without specifically aiming to study participants’ health-related internet use; focused solely on quality assurance for specific websites; or were designed to test a specific internet-based intervention. Results Interesting patterns in adolescents’ health-related internet use, such as seeking preventative health care and specific information about medical issues, were identified. Quantitative studies reported rates of the internet use and access among youth, and the purpose and patterns of health-related internet use among youth were identified. A major objective of health-related internet use is to gain information, but there are inconsistencies in adolescents’ perceptions of health-related internet use. Conclusions This study’s findings provide important information on how youth seek information and related support systems for their health care on the internet. The conceptual and methodological limitations of the identified studies, such as the lack of a theoretical background and unrepresentative samples, are discussed, and gaps within the studies are identified for future research. This review also suggests important features for potential Web-based health interventions for children and adolescents.\n",
            "------------------------------------\n",
            "Title :  Unmet care needs of advanced cancer patients and their informal caregivers: a systematic review\n",
            "Author/s :  Tao Wang, A. Molassiotis, B. Chung, J. Tan\n",
            "Venue :  BMC Palliative Care\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Effective Pattern Discovery for Text Mining\n",
            "Author/s :  N. Zhong, Yuefeng Li, Sheng-Tang Wu\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2012\n",
            "Abstract :  Many data mining techniques have been proposed for mining useful patterns in text documents. However, how to effectively use and update discovered patterns is still an open research issue, especially in the domain of text mining. Since most existing text mining methods adopted term-based approaches, they all suffer from the problems of polysemy and synonymy. Over the years, people have often held the hypothesis that pattern (or phrase)-based approaches should perform better than the term-based ones, but many experiments do not support this hypothesis. This paper presents an innovative and effective pattern discovery technique which includes the processes of pattern deploying and pattern evolving, to improve the effectiveness of using and updating discovered patterns for finding relevant and interesting information. Substantial experiments on RCV1 data collection and TREC topics demonstrate that the proposed solution achieves encouraging performance.\n",
            "------------------------------------\n",
            "Title :  Causal holographic information\n",
            "Author/s :  V. Hubeny, M. Rangamani\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Consumer Evaluation of the Quality of Online Health Information: Systematic Literature Review of Relevant Criteria and Indicators\n",
            "Author/s :  Yalin Sun, Yan Zhang, J. Gwizdka, Ciaran B. Trace\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2019\n",
            "Abstract :  Background As the quality of online health information remains questionable, there is a pressing need to understand how consumers evaluate this information. Past reviews identified content-, source-, and individual-related factors that influence consumer judgment in this area. However, systematic knowledge concerning the evaluation process, that is, why and how these factors influence the evaluation behavior, is lacking. Objective This review aims (1) to identify criteria (rules that reflect notions of value and worth) that consumers use to evaluate the quality of online health information and the indicators (properties of information objects to which criteria are applied to form judgments) they use to support the evaluation in order to achieve a better understanding of the process of information quality evaluation and (2) to explicate the relationship between indicators and criteria to provide clear guidelines for designers of consumer health information systems. Methods A systematic literature search was performed in seven digital reference databases including Medicine, Psychology, Communication, and Library and Information Science to identify empirical studies that report how consumers directly and explicitly describe their evaluation of online health information quality. Thirty-seven articles met the inclusion criteria. A qualitative content analysis was performed to identify quality evaluation criteria, indicators, and their relationships. Results We identified 25 criteria and 165 indicators. The most widely reported criteria used by consumers were trustworthiness, expertise, and objectivity. The indicators were related to source, content, and design. Among them, 114 were positive indicators (entailing positive quality judgments), 35 were negative indicators (entailing negative judgments), and 16 indicators had both positive and negative quality influence, depending on contextual factors (eg, source and individual differences) and criteria applied. The most widely reported indicators were site owners/sponsors; consensus among multiple sources; characteristics of writing and language; advertisements; content authorship; and interface design. Conclusions Consumer evaluation of online health information is a complex cost-benefit analysis process that involves the use of a wide range of criteria and a much wider range of quality indicators. There are commonalities in the use of criteria across user groups and source types, but the differences are hard to ignore. Evidently, consumers’ health information evaluation can be characterized as highly subjective and contextualized, and sometimes, misinformed. These findings invite more research into how different user groups evaluate different types of online sources and a personalized approach to educate users about evaluating online health information quality.\n",
            "------------------------------------\n",
            "Title :  Explanatory Factors of Integrated Sustainability and Financial Reporting\n",
            "Author/s :  José-Valeriano Frías-Aceituno, Lázaro Rodríguez‐Ariza, I. García‐Sánchez\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  The complexity of the business world has led to growing demands being made of companies regarding the information provided on their financial performance, corporate governance and contribution to developing sustainability. In response, some leading companies have begun to publish integrated reporting, in the form of a document providing a coherent summary of this information, thus facilitating stakeholder engagement. \n",
            " \n",
            "This paper examines the validity of the hypotheses of the theories of agency and of signalling, and analyses the political costs and those borne by owners in voluntarily developing this new type of business document. More specifically, in order to determine their prevalence among the suggested reasons for these paradigms, we analyse the effect of industry concentration, together with other factors, in the development of integrated reporting. \n",
            " \n",
            "The analysis of a non-balanced sample of 1590 international companies for the years 2008–2010, in which a logistic regression methodology is applied to panel data, reveals the negative impact of industry concentration on the development of a more pluralist report, simultaneously taking into account stakeholders, sustainability and the long-term viewpoint, as well as questions of responsible investment, business ethics and transparency. Copyright © 2012 John Wiley & Sons, Ltd and ERP Environment\n",
            "------------------------------------\n",
            "Title :  Energy-Efficient Information and Communication Infrastructures in the Smart Grid: A Survey on Interactions and Open Issues\n",
            "Author/s :  M. Erol-Kantarci, H. Mouftah\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2015\n",
            "Abstract :  Smart grid has modernized the way electricity is generated, transported, distributed, and consumed by integrating advanced sensing, communications, and control in the day-to-day operation of the grid. Electricity is a core utility for the functioning of society and for the services provided by information and communication technologies (ICTs). Several concepts of the smart grid, such as dynamic pricing, distributed generation, and demand management, have significantly impacted the operation of ICT services, in particular, communication networks and data centers. Ongoing energy-efficiency and operational expenditures reduction efforts in communication networks and data centers have gained another dimension with those smart grid concepts. In this paper, we provide a comprehensive survey on the smart grid-driven approaches in energy-efficient communications and data centers, and the interaction between smart grid and information and communication infrastructures. Although the studies on smart grid, energy-efficient communications, and green data centers have been separately surveyed in previous studies, to this end, research that falls in the intersection of those fields has not been properly classified and surveyed yet. We start our survey by providing background information on the smart grid and continue with surveying smart grid-driven approaches in energy-efficient communication systems, followed by energy, cost and emission minimizing approaches in data centers, and the corresponding cloud network infrastructure. We discuss the open issues in smart grid-driven approaches in ICTs and point some important research directions such as the distributed renewable energy generation capability-coupled communication infrastructures, optimum energy-efficient network design for the smart grid environment, the impact of green communication techniques on the reliability and latency requirements of smart grid data, workload consolidation with smart grid-awareness, and many more.\n",
            "------------------------------------\n",
            "Title :  CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations\n",
            "Author/s :  Stefan Seemayer, M. Gruber, J. Söding\n",
            "Venue :  Bioinform.\n",
            "year :  2014\n",
            "Abstract :  Motivation: Recent breakthroughs in protein residue–residue contact prediction have made reliable de novo prediction of protein structures possible. The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e. to separate direct from indirect effects. Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM). Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads. This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein–protein interactions. Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35–113 times faster and with the same precision as the most accurate published methods. For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4–14 times faster. Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15–60 s on a consumer-grade GPU and 1–6 min on a six-core CPU. Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title :  Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n",
            "Author/s :  I. Korstjens, A. Moser\n",
            "Venue :  European Journal of General Practice\n",
            "year :  2017\n",
            "Abstract :  Abstract In the course of our supervisory work over the years we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The first article provides an introduction to this series. The second article focused on context, research questions and designs. The third article focused on sampling, data collection and analysis. This fourth article addresses FAQs about trustworthiness and publishing. Quality criteria for all qualitative research are credibility, transferability, dependability, and confirmability. Reflexivity is an integral part of ensuring the transparency and quality of qualitative research. Writing a qualitative research article reflects the iterative nature of the qualitative research process: data analysis continues while writing. A qualitative research article is mostly narrative and tends to be longer than a quantitative paper, and sometimes requires a different structure. Editors essentially use the criteria: is it new, is it true, is it relevant? An effective cover letter enhances confidence in the newness, trueness and relevance, and explains why your study required a qualitative design. It provides information about the way you applied quality criteria or a checklist, and you can attach the checklist to the manuscript.\n",
            "------------------------------------\n",
            "Title :  Determinants of Sharing Travel Experiences in Social Media\n",
            "Author/s :  Myunghwa Kang, M. Schuett\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT The advent of Internet-based social media technologies has enabled travelers to quickly and conveniently share their travel experiences. Shared information on social media sites is recognized as an important information source which may influence travel decision making for potential travelers. This study tests a conceptual framework which examines why travelers share their travel experiences on social media based on the social influence theory and its three conceptual foundations—identification, internalization, and compliance. Data were collected using an online survey and the research model was tested with 543 respondents who were social media users. Results showed that identification and internalization are critical determinants that positively increase actual travel-experience sharing on social media as mediated by perceived enjoyment. Our research extends prior literature on social media by identifying specific determinants that can impact travel-experience sharing. Suggestions are provided for academics, the travel industry, and those working with social media.\n",
            "------------------------------------\n",
            "Title :  Millimeter-Wave Vehicular Communication to Support Massive Automotive Sensing\n",
            "Author/s :  Junil Choi, Vutha Va, N. G. Prelcic, R. Daniels, C. Bhat, R. Heath\n",
            "Venue :  IEEE Communications Magazine\n",
            "year :  2016\n",
            "Abstract :  As driving becomes more automated, vehicles are being equipped with more sensors generating even higher data rates. Radars are used for object detection, visual cameras as virtual mirrors, and LIDARs for generating high resolution depth associated range maps, all to enhance the safety and efficiency of driving. Connected vehicles can use wireless communication to exchange sensor data, allowing them to enlarge their sensing range and improve automated driving functions. Unfortunately, conventional technologies, such as DSRC and 4G cellular communication, do not support the gigabit-per-second data rates that would be required for raw sensor data exchange between vehicles. This article makes the case that mmWave communication is the only viable approach for high bandwidth connected vehicles. The motivations and challenges associated with using mmWave for vehicle-to-vehicle and vehicle-to-infrastructure applications are highlighted. A high-level solution to one key challenge - the overhead of mmWave beam training - is proposed. The critical feature of this solution is to leverage information derived from the sensors or DSRC as side information for the mmWave communication link configuration. Examples and simulation results show that the beam alignment overhead can be reduced by using position information obtained from DSRC.\n",
            "------------------------------------\n",
            "Title :  The CERT Guide to Insider Threats: How to Prevent, Detect, and Respond to Information Technology Crimes\n",
            "Author/s :  Dawn M. Cappelli, A. Moore, Randall F. Trzeciak\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Since 2001, the CERT Insider Threat Center at Carnegie Mellon Universitys Software Engineering Institute (SEI) has collected and analyzed information about more than seven hundred insider cyber crimes, ranging from national security espionage to theft of trade secrets. The CERT Guide to Insider Threats describes CERTs findings in practical terms, offering specific guidance and countermeasures that can be immediately applied by executives, managers, security officers, and operational staff within any private, government, or military organization. The authors systematically address attacks by all types of malicious insiders, including current and former employees, contractors, business partners, outsourcers, and even cloud-computing vendors. They cover all major types of insider cyber crime: IT sabotage, intellectual property theft, and fraud. For each, they present a crime profile describing how the crime tends to evolve over time, as well as motivations, attack methods, organizational issues, and precursor warnings that could have helped the organization prevent the incident or detect it earlier. Beyond identifying crucial patterns of suspicious behavior, the authors present concrete defensive measures for protecting both systems and data. This book also conveys the big picture of the insider threat problem over time: the complex interactions and unintended consequences of existing policies, practices, technology, insider mindsets, and organizational culture. Most important, it offers actionable recommendations for the entire organization, from executive management and board members to IT, data owners, HR, and legal departments. With this book, you will find out how to Identify hidden signs of insider IT sabotage, theft of sensitive information, and fraud Recognize insider threats throughout the software development life cycle Use advanced threat controls to resist attacks by both technical and nontechnical insiders Increase the effectiveness of existing technical security tools by enhancing rules, configurations, and associated business processes Prepare for unusual insider attacks, including attacks linked to organized crime or the Internet underground By implementing this books security practices, you will be incorporating protection mechanisms designed to resist the vast majority of malicious insider attacks.\n",
            "------------------------------------\n",
            "Title :  Smart Cities: Big Data, Civic Hackers, and the Quest for a New Utopia\n",
            "Author/s :  A. Townsend\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  We live in a world defined by urbanization and digital ubiquity, where mobile broadband connections outnumber fixed ones, machines dominate a new \"internet of things,\" and more people live in cities than in the countryside. In Smart Cities, urbanist and technology expert Anthony Townsend takes a broad historical look at the forces that have shaped the planning and design of cities and information technologies from the rise of the great industrial cities of the nineteenth century to the present. A century ago, the telegraph and the mechanical tabulator were used to tame cities of millions. Today, cellular networks and cloud computing tie together the complex choreography of mega-regions of tens of millions of people. In response, cities worldwide are deploying technology to address both the timeless challenges of government and the mounting problems posed by human settlements of previously unimaginable size and complexity. In Chicago, GPS sensors on snow plows feed a real-time \"plow tracker\" map that everyone can access. In Zaragoza, Spain, a \"citizen card\" can get you on the free city-wide Wi-Fi network, unlock a bike share, check a book out of the library, and pay for your bus ride home. In New York, a guerrilla group of citizen-scientists installed sensors in local sewers to alert you when stormwater runoff overwhelms the system, dumping waste into local waterways. As technology barons, entrepreneurs, mayors, and an emerging vanguard of civic hackers are trying to shape this new frontier, Smart Cities considers the motivations, aspirations, and shortcomings of them all while offering a new civics to guide our efforts as we build the future together, one click at a time.\n",
            "------------------------------------\n",
            "Title :  Crowdfunding: Geography, Social Networks, and the Timing of Investment Decisions\n",
            "Author/s :  A. Agrawal, Christian Catalini, Avi Goldfarb\n",
            "Venue :  Journal of Economics &amp; Management Strategy\n",
            "year :  2015\n",
            "Abstract :  type=\"main\"> We examine a crowdfunding platform that connects artists with funders. Although the Internet reduces many distance-related frictions, local and distant funders exhibit different funding patterns. Local funders appear less responsive to information about the cumulative funds raised by an artist. However, this distance effect appears to proxy for a social effect: it is largely explained by funders who likely have an offline social relationship with the artist (“friends and family”). Yet, this social effect does not persist past the first investment, suggesting that it may be driven by an activity like search but not monitoring. Thus, although the platform seems to diminish many distance-sensitive costs, it does not eliminate all of them. These findings provide a deeper understanding of the abilities and limitations of online markets to facilitate transactions and convey information between buyers and sellers with varying degrees of social connectedness.\n",
            "------------------------------------\n",
            "Title :  A strategy for the design of skyrmion racetrack memories\n",
            "Author/s :  R. Tomasello, E. Martínez, R. Zivieri, L. Torres, M. Carpentieri, G. Finocchio\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information Cascades among Investors in Equity Crowdfunding\n",
            "Author/s :  Silvio Vismara\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Finance studies on information cascades, usually in an initial public offering setting, typically differentiate between institutional and retail investors, as this is the only information available to potential backers. Information available through equity crowdfunding platforms includes details on individual investors as they may disclose information about themselves by linking their profile to social networks or websites. Using a sample of 132 equity offerings on Crowdcube in 2014, we show that information cascades among individual investors play a crucial role in crowdfunding campaigns. Investors with a public profile increase the appeal of the offer among early investors, who in turn attract late investors.\n",
            "------------------------------------\n",
            "Title :  What is an Information System?\n",
            "Author/s :  S. Boell, D. Cecez-Kecmanovic\n",
            "Venue :  Hawaii International Conference on System Sciences\n",
            "year :  2015\n",
            "Abstract :  This paper aims to advance understanding of information systems (IS) through a critical reflection on how IS are currently defined in the IS literature. Using the hermeneutic approach for conducting literature reviews the paper identifies 34 definitions of IS in the literature. Based on the analysis of these 34 definitions four different views of IS are distinguished: a technology view emphasizing the technological aspects of IS, a social view emphasizing the socio cultural aspects, a socio-technical view emphasizing the interconnection of technology and social elements, and a process view emphasizing the activity orientation of IS. The paper critically examines the contributions and limitations of these different approaches for understanding and theorizing IS. Based on this examination the paper argues to for the need to develop an additional, alternative sociomaterial conceptualization of IS based on a non-dualist, relational ontology.\n",
            "------------------------------------\n",
            "Title :  Quantum Systems, Channels, Information: A Mathematical Introduction\n",
            "Author/s :  A. Holevo\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  The subject of this book is theory of quantum system presented from information science perspective. The central role is played by the concept of quantum channel and its entropic and information characteristics. Quantum information theory gives a key to understanding elusive phenomena of quantum world and provides a background for development of experimental techniques that enable measuring and manipulation of individual quantum systems. This is important for the new efficient applications such as quantum computing, communication and cryptography. Research in the field of quantum informatics, including quantum information theory, is in progress in leading scientific centers throughout the world. This book gives an accessible, albeit mathematically rigorous and self-contained introduction to quantum information theory, starting from primary structures and leading to fundamental results and to exiting open problems.\n",
            "------------------------------------\n",
            "Title :  Rise and fall patterns of information diffusion: model and implications\n",
            "Author/s :  Yasuko Matsubara, Yasushi Sakurai, B. Prakash, Lei Li, C. Faloutsos\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2012\n",
            "Abstract :  The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated faster propagation of news and rumors. How quickly does a piece of news spread over these media? How does its popularity diminish over time? Does the rising and falling pattern follow a simple universal law?\n",
            " In this paper, we propose SpikeM, a concise yet flexible analytical model for the rise and fall patterns of influence propagation. Our model has the following advantages: (a) unification power: it generalizes and explains earlier theoretical models and empirical observations; (b) practicality: it matches the observed behavior of diverse sets of real data; (c) parsimony: it requires only a handful of parameters; and (d) usefulness: it enables further analytics tasks such as fore- casting, spotting anomalies, and interpretation by reverse- engineering the system parameters of interest (e.g. quality of news, count of interested bloggers, etc.).\n",
            " Using SpikeM, we analyzed 7.2GB of real data, most of which were collected from the public domain. We have shown that our SpikeM model accurately and succinctly describes all the patterns of the rise-and-fall spikes in these real datasets.\n",
            "------------------------------------\n",
            "Title :  Integrated photonic quantum technologies\n",
            "Author/s :  Jianwei Wang, F. Sciarrino, A. Laing, M. Thompson\n",
            "Venue :  Nature Photonics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Hybrid Collaborative Filtering Model with Deep Structure for Recommender Systems\n",
            "Author/s :  Xin Dong, Lei Yu, Zhonghuo Wu, Yuxia Sun, Lingfeng Yuan, Fangxi Zhang\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2017\n",
            "Abstract :  \n",
            " \n",
            " Collaborative filtering (CF) is a widely used approach in recommender systems to solve many real-world problems. Traditional CF-based methods employ the user-item matrix which encodes the individual preferences of users for items for learning to make recommendation. In real applications, the rating matrix is usually very sparse, causing CF-based methods to degrade significantly in recommendation performance. In this case, some improved CF methods utilize the increasing amount of side information to address the data sparsity problem as well as the cold start problem. However, the learned latent factors may not be effective due to the sparse nature of the user-item matrix and the side information. To address this problem, we utilize advances of learning effective representations in deep learning, and propose a hybrid model which jointly performs deep users and items’ latent factors learning from side information and collaborative filtering from the rating matrix. Extensive experimental results on three real-world datasets show that our hybrid model outperforms other methods in effectively utilizing side information and achieves performance improvement.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Resolving human object recognition in space and time\n",
            "Author/s :  Radoslaw Martin Cichy, D. Pantazis, A. Oliva\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images\n",
            "Author/s :  Saurabh Gupta, Pablo Arbeláez, Jitendra Malik\n",
            "Venue :  2013 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2013\n",
            "Abstract :  We address the problems of contour detection, bottom-up grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information. We show that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.\n",
            "------------------------------------\n",
            "Title :  Smart Refugees: How Syrian Asylum Migrants Use Social Media Information in Migration Decision-Making\n",
            "Author/s :  R. Dekker, G. Engbersen, Jeanine Klaver, Hanna Vonk\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Social media are increasingly popular channels of information on which migrants base their decisions on whether to migrate and the destinations where to settle. While social media offer a relatively cheap, easily accessible, and media-rich means of communication, their use is not without challenges for asylum migrants. Various studies describe issues with access and evaluation of the truthfulness of available information for this specific group of migrants. This article discusses social media use by asylum migrants prior to and during migration. This study is based on in-depth interviews with 54 Syrian asylum migrants who recently obtained refugee status in the Netherlands. Syrians were the largest group of migrants applying for asylum in European Union (EU) member states in 2015 and 2016. The findings show that the majority of Syrian asylum migrants have access to social media information before and during migration, often through the use of smartphones. Besides uneven access to technologies, fear of government surveillance restricts the smartphone use of asylum migrants. The results of this study indicate that Syrian asylum migrants prefer social media information that originates from existing social ties and information that is based on personal experiences. Generally, this information is considered more trustworthy. Asylum migrants use various strategies to validate rumors that are present on social media and come from unknown sources. These strategies include checking the source of information, validating information with trusted social ties, triangulation of online sources, and comparing information with their own experience.\n",
            "------------------------------------\n",
            "Title :  The Role of the Board in the Dissemination of Integrated Corporate Social Reporting\n",
            "Author/s :  José-Valeriano Frías-Aceituno, Lázaro Rodríguez‐Ariza, I. García‐Sánchez\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The stakeholder theory recognizes that, besides shareholders and creditors, there exists a broad range of agents who are interested in companies' attitudes towards sustainability. Through corporate social reporting, the social and environmental effects of companies' economic actions are communicated to interest groups. However, the information contained in financial and social reports tends to be presented quite separately from that in the others, and this may lead to confusion among users. Therefore, several major companies have introduced an integrated reporting system, which coherently summarizes the information available, thus making stakeholders participants in business management. \n",
            " \n",
            "Corporate governance mechanisms such as the Board of Directors play an important role in good practices of corporate social responsibility, implementing policies of stakeholder engagement, including processes to achieve holistic transparency. \n",
            " \n",
            "The aim of this paper is to demonstrate the influence played by certain features of the Board of Directors in the degree of information integration presented by leading non-financial multinational firms. Specifically, we examined 568 companies from 15 countries, for the period 2008–2010. The results obtained show that growth opportunities, the size of a company and its management bodies, together with gender diversity, are the most important factors in the integrated dissemination of information. This effect has been confirmed for the Anglo-Saxon, Germanic and Latin models of corporate governance. Copyright © 2012 John Wiley & Sons, Ltd and ERP Environment\n",
            "------------------------------------\n",
            "Title :  Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols\n",
            "Author/s :  P. Campos, F. Díez, Iván Cantador\n",
            "Venue :  User modeling and user-adapted interaction\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Recognizing actions using depth motion maps-based histograms of oriented gradients\n",
            "Author/s :  Xiaodong Yang, Chenyang Zhang, Yingli Tian\n",
            "Venue :  ACM Multimedia\n",
            "year :  2012\n",
            "Abstract :  In this paper, we propose an effective method to recognize human actions from sequences of depth maps, which provide additional body shape and motion information for action recognition. In our approach, we project depth maps onto three orthogonal planes and accumulate global activities through entire video sequences to generate the Depth Motion Maps (DMM). Histograms of Oriented Gradients (HOG) are then computed from DMM as the representation of an action video. The recognition results on Microsoft Research (MSR) Action3D dataset show that our approach significantly outperforms the state-of-the-art methods, although our representation is much more compact. In addition, we investigate how many frames are required in our framework to recognize actions on the MSR Action3D dataset. We observe that a short sub-sequence of 30-35 frames is sufficient to achieve comparable results to that operating on entire video sequences.\n",
            "------------------------------------\n",
            "Title :  The evolutionary basis of human social learning\n",
            "Author/s :  T. Morgan, L. Rendell, M. Ehn, W. Hoppitt, K. Laland\n",
            "Venue :  Proceedings of the Royal Society B: Biological Sciences\n",
            "year :  2012\n",
            "Abstract :  Humans are characterized by an extreme dependence on culturally transmitted information. Such dependence requires the complex integration of social and asocial information to generate effective learning and decision making. Recent formal theory predicts that natural selection should favour adaptive learning strategies, but relevant empirical work is scarce and rarely examines multiple strategies or tasks. We tested nine hypotheses derived from theoretical models, running a series of experiments investigating factors affecting when and how humans use social information, and whether such behaviour is adaptive, across several computer-based tasks. The number of demonstrators, consensus among demonstrators, confidence of subjects, task difficulty, number of sessions, cost of asocial learning, subject performance and demonstrator performance all influenced subjects' use of social information, and did so adaptively. Our analysis provides strong support for the hypothesis that human social learning is regulated by adaptive learning rules.\n",
            "------------------------------------\n",
            "Title :  Dimensionality Reduction Technique on SIFT Feature Vector for Content Based Image Retrival\n",
            "Author/s :  Mukul Kirti Verma, Rajesh Dwivedi, Ajay Kumar Mallick, Ebenezer Jangam\n",
            "Venue :  International Conference on Recent Trends in Image Processing and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Three Phased Component Retrival Technique (TPCRT) for Best Qualified Component\n",
            "Author/s :  Vishnu Sharma, V. Shekhawat\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The focus of this paper is to suggest a efficient component retrieval technique. Here a combined architecture of three search techniques from traditional (Keywords based) to latest approach (deductive search) is used to get best qualified component. This approach is useful for the software developers to get the appropriate components to develop efficient software within a short span of time. It also provides an efficient way to retrieve appropriate component from repository. The suggested design effectively supports query specification and component search. It further guides users to exploit component resources for reuse.\n",
            "------------------------------------\n",
            "Title :  A Diversity-Promoting Objective Function for Neural Conversation Models\n",
            "Author/s :  Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, W. Dolan\n",
            "Venue :  North American Chapter of the Association for Computational Linguistics\n",
            "year :  2015\n",
            "Abstract :  Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., \"I don't know\") regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations.\n",
            "------------------------------------\n",
            "Title :  Feature Selection\n",
            "Author/s :  Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P. Trevino, Jiliang Tang, Huan Liu\n",
            "Venue :  Encyclopedia of Machine Learning and Data Mining\n",
            "year :  2016\n",
            "Abstract :  Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.\n",
            "------------------------------------\n",
            "Title :  Information Weighted Consensus Filters and Their Application in Distributed Camera Networks\n",
            "Author/s :  A. Kamal, J. Farrell, A. Roy-Chowdhury\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2013\n",
            "Abstract :  Due to their high fault-tolerance and scalability to large networks, consensus-based distributed algorithms have recently gained immense popularity in the sensor networks community. Large-scale camera networks are a special case. In a consensus-based state estimation framework, multiple neighboring nodes iteratively communicate with each other, exchanging their own local information about each target's state with the goal of converging to a single state estimate over the entire network. However, the state estimation problem becomes challenging when some nodes have limited observability of the state. In addition, the consensus estimate is suboptimal when the cross-covariances between the individual state estimates across different nodes are not incorporated in the distributed estimation framework. The cross-covariance is usually neglected because the computational and bandwidth requirements for its computation become unscalable for a large network. These limitations can be overcome by noting that, as the state estimates at different nodes converge, the information at each node becomes correlated. This fact can be utilized to compute the optimal estimate by proper weighting of the prior state and measurement information. Motivated by this idea, we propose information-weighted consensus algorithms for distributed maximum a posteriori parameter estimation, and their extension to the information-weighted consensus filter (ICF) for state estimation. We compare the performance of the ICF with existing consensus algorithms analytically, as well as experimentally by considering the scenario of a distributed camera network under various operating conditions.\n",
            "------------------------------------\n",
            "Title :  Optimal network modularity for information diffusion.\n",
            "Author/s :  Azadeh Nematzadeh, Emilio Ferrara, A. Flammini, Yong-Yeol Ahn\n",
            "Venue :  Physical Review Letters\n",
            "year :  2014\n",
            "Abstract :  We investigate the impact of community structure on information diffusion with the linear threshold model. Our results demonstrate that modular structure may have counterintuitive effects on information diffusion when social reinforcement is present. We show that strong communities can facilitate global diffusion by enhancing local, intracommunity spreading. Using both analytic approaches and numerical simulations, we demonstrate the existence of an optimal network modularity, where global diffusion requires the minimal number of early adopters.\n",
            "------------------------------------\n",
            "Title :  Representation Learning of Knowledge Graphs with Hierarchical Types\n",
            "Author/s :  Ruobing Xie, Zhiyuan Liu, Maosong Sun\n",
            "Venue :  International Joint Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  Representation learning of knowledge graphs aims to encode both entities and relations into a continuous low-dimensional vector space. Most existing methods only concentrate on learning representations with structured information located in triples, regardless of the rich information located in hierarchical types of entities, which could be collected in most knowledge graphs. In this paper, we propose a novel method named Type-embodied Knowledge Representation Learning (TKRL) to take advantages of hierarchical entity types. We suggest that entities should have multiple representations in different types. More specifically, we consider hierarchical types as projection matrices for entities, with two type encoders designed to model hierarchical structures. Meanwhile, type information is also utilized as relation-specific type constraints. We evaluate our models on two tasks including knowledge graph completion and triple classification, and further explore the performances on long-tail dataset. Experimental results show that our models significantly outperform all baselines on both tasks, especially with long-tail distribution. It indicates that our models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs. The source code of this paper can be obtained from https://github.com/thunlp/TKRL.\n",
            "------------------------------------\n",
            "Title :  Remote Sensing Technologies for Enhancing Forest Inventories: A Review\n",
            "Author/s :  J. White, N. Coops, M. Wulder, M. Vastaranta, T. Hilker, P. Tompalski\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Abstract Forest inventory and management requirements are changing rapidly in the context of an increasingly complex set of economic, environmental, and social policy objectives. Advanced remote sensing technologies provide data to assist in addressing these escalating information needs and to support the subsequent development and parameterization of models for an even broader range of information needs. This special issue contains papers that use a variety of remote sensing technologies to derive forest inventory or inventory-related information. Herein, we review the potential of 4 advanced remote sensing technologies, which we posit as having the greatest potential to influence forest inventories designed to characterize forest resource information for strategic, tactical, and operational planning: airborne laser scanning (ALS), terrestrial laser scanning (TLS), digital aerial photogrammetry (DAP), and high spatial resolution (HSR)/very high spatial resolution (VHSR) satellite optical imagery. ALS, in particular, has proven to be a transformative technology, offering forest inventories the required spatial detail and accuracy across large areas and a diverse range of forest types. The coupling of DAP with ALS technologies will likely have the greatest impact on forest inventory practices in the next decade, providing capacity for a broader suite of attributes, as well as for monitoring growth over time.\n",
            "------------------------------------\n",
            "Title :  The Impact of Study Size on Meta-analyses: Examination of Underpowered Studies in Cochrane Reviews\n",
            "Author/s :  R. Turner, S. Bird, J. Higgins\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  Background Most meta-analyses include data from one or more small studies that, individually, do not have power to detect an intervention effect. The relative influence of adequately powered and underpowered studies in published meta-analyses has not previously been explored. We examine the distribution of power available in studies within meta-analyses published in Cochrane reviews, and investigate the impact of underpowered studies on meta-analysis results. Methods and Findings For 14,886 meta-analyses of binary outcomes from 1,991 Cochrane reviews, we calculated power per study within each meta-analysis. We defined adequate power as ≥50% power to detect a 30% relative risk reduction. In a subset of 1,107 meta-analyses including 5 or more studies with at least two adequately powered and at least one underpowered, results were compared with and without underpowered studies. In 10,492 (70%) of 14,886 meta-analyses, all included studies were underpowered; only 2,588 (17%) included at least two adequately powered studies. 34% of the meta-analyses themselves were adequately powered. The median of summary relative risks was 0.75 across all meta-analyses (inter-quartile range 0.55 to 0.89). In the subset examined, odds ratios in underpowered studies were 15% lower (95% CI 11% to 18%, P<0.0001) than in adequately powered studies, in meta-analyses of controlled pharmacological trials; and 12% lower (95% CI 7% to 17%, P<0.0001) in meta-analyses of controlled non-pharmacological trials. The standard error of the intervention effect increased by a median of 11% (inter-quartile range −1% to 35%) when underpowered studies were omitted; and between-study heterogeneity tended to decrease. Conclusions When at least two adequately powered studies are available in meta-analyses reported by Cochrane reviews, underpowered studies often contribute little information, and could be left out if a rapid review of the evidence is required. However, underpowered studies made up the entirety of the evidence in most Cochrane reviews.\n",
            "------------------------------------\n",
            "Title :  Debunking in a world of tribes\n",
            "Author/s :  Fabiana Zollo, Alessandro Bessi, Michela Del Vicario, A. Scala, G. Caldarelli, L. Shekhtman, S. Havlin, W. Quattrociocchi\n",
            "Venue :  PLoS ONE\n",
            "year :  2015\n",
            "Abstract :  Social media aggregate people around common interests eliciting collective framing of narratives and worldviews. However, in such a disintermediated environment misinformation is pervasive and attempts to debunk are often undertaken to contrast this trend. In this work, we examine the effectiveness of debunking on Facebook through a quantitative analysis of 54 million users over a time span of five years (Jan 2010, Dec 2014). In particular, we compare how users usually consuming proven (scientific) and unsubstantiated (conspiracy-like) information on Facebook US interact with specific debunking posts. Our findings confirm the existence of echo chambers where users interact primarily with either conspiracy-like or scientific pages. However, both groups interact similarly with the information within their echo chamber. Then, we measure how users from both echo chambers interacted with 50,220 debunking posts accounting for both users consumption patterns and the sentiment expressed in their comments. Sentiment analysis reveals a dominant negativity in the comments to debunking posts. Furthermore, such posts remain mainly confined to the scientific echo chamber. Only few conspiracy users engage with corrections and their liking and commenting rates on conspiracy posts increases after the interaction.\n",
            "------------------------------------\n",
            "Title :  Improving bug localization using structured information retrieval\n",
            "Author/s :  Ripon K. Saha, Matthew Lease, S. Khurshid, D. Perry\n",
            "Venue :  International Conference on Automated Software Engineering\n",
            "year :  2013\n",
            "Abstract :  Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool.\n",
            "------------------------------------\n",
            "Title :  Supervised hashing with kernels\n",
            "Author/s :  W. Liu, Jun Wang, R. Ji, Yu-Gang Jiang, Shih-Fu Chang\n",
            "Venue :  2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2012\n",
            "Abstract :  Recent years have witnessed the growing popularity of hashing in large-scale vision problems. It has been shown that the hashing quality could be boosted by leveraging supervised information into hash function learning. However, the existing supervised methods either lack adequate performance or often incur cumbersome model training. In this paper, we propose a novel kernel-based supervised hashing model which requires a limited amount of supervised information, i.e., similar and dissimilar data pairs, and a feasible training cost in achieving high quality hashing. The idea is to map the data to compact binary codes whose Hamming distances are minimized on similar pairs and simultaneously maximized on dissimilar pairs. Our approach is distinct from prior works by utilizing the equivalence between optimizing the code inner products and the Hamming distances. This enables us to sequentially and efficiently train the hash functions one bit at a time, yielding very short yet discriminative codes. We carry out extensive experiments on two image benchmarks with up to one million samples, demonstrating that our approach significantly outperforms the state-of-the-arts in searching both metric distance neighbors and semantically similar neighbors, with accuracy gains ranging from 13% to 46%.\n",
            "------------------------------------\n",
            "Title :  A survey of trust in social networks\n",
            "Author/s :  W. Sherchan, S. Nepal, Cécile Paris\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Web-based social networks have become popular as a medium for disseminating information and connecting like-minded people. The public accessibility of such networks with the ability to share opinions, thoughts, information, and experience offers great promise to enterprises and governments. In addition to individuals using such networks to connect to their friends and families, governments and enterprises have started exploiting these platforms for delivering their services to citizens and customers. However, the success of such attempts relies on the level of trust that members have with each other as well as with the service provider. Therefore, trust becomes an essential and important element of a successful social network. In this article, we present the first comprehensive review of social and computer science literature on trust in social networks. We first review the existing definitions of trust and define social trust in the context of social networks. We then discuss recent works addressing three aspects of social trust: trust information collection, trust evaluation, and trust dissemination. Finally, we compare and contrast the literature and identify areas for further research in social trust.\n",
            "------------------------------------\n",
            "Title :  Information geometry\n",
            "Author/s :  S. Amari\n",
            "Venue :  Japanese journal of mathematics\n",
            "year :  2021\n",
            "Abstract :  Information geometry has emerged from the study of the invariant structure in families of probability distributions. This invariance uniquely determines a second-order symmetric tensor g and third-order symmetric tensor T in a manifold of probability distributions. A pair of these tensors ( g, T ) defines a Riemannian metric and a pair of affine connections which together preserve the metric. Information geometry involves studying a Riemannian manifold having a pair of dual affine connections. Such a structure also arises from an asymmetric divergence function and affine differential geometry. A dually flat Riemannian manifold is particularly useful for various applications, because a generalized Pythagorean theorem and projection theorem hold. The Wasserstein distance gives another important geometry on probability distributions, which is non-invariant but responsible for the metric properties of a sample space. I attempt to construct information geometry of the entropy-regularized Wasserstein distance.\n",
            "------------------------------------\n",
            "Title :  Pragmatism vs interpretivism in qualitative information systems research\n",
            "Author/s :  G. Goldkuhl\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Faces in Context: A Review and Systematization of Contextual Influences on Affective Face Processing\n",
            "Author/s :  M. Wieser, T. Brosch\n",
            "Venue :  Front. Psychology\n",
            "year :  2012\n",
            "Abstract :  Facial expressions are of eminent importance for social interaction as they convey information about other individuals’ emotions and social intentions. According to the predominant “basic emotion” approach, the perception of emotion in faces is based on the rapid, automatic categorization of prototypical, universal expressions. Consequently, the perception of facial expressions has typically been investigated using isolated, de-contextualized, static pictures of facial expressions that maximize the distinction between categories. However, in everyday life, an individual’s face is not perceived in isolation, but almost always appears within a situational context, which may arise from other people, the physical environment surrounding the face, as well as multichannel information from the sender. Furthermore, situational context may be provided by the perceiver, including already present social information gained from affective learning and implicit processing biases such as race bias. Thus, the perception of facial expressions is presumably always influenced by contextual variables. In this comprehensive review, we aim at (1) systematizing the contextual variables that may influence the perception of facial expressions and (2) summarizing experimental paradigms and findings that have been used to investigate these influences. The studies reviewed here demonstrate that perception and neural processing of facial expressions are substantially modified by contextual information, including verbal, visual, and auditory information presented together with the face as well as knowledge or processing biases already present in the observer. These findings further challenge the assumption of automatic, hardwired categorical emotion extraction mechanisms predicted by basic emotion theories. Taking into account a recent model on face processing, we discuss where and when these different contextual influences may take place, thus outlining potential avenues in future research.\n",
            "------------------------------------\n",
            "Title :  Internet of Things-IOT : Definition , Characteristics , Architecture , Enabling Technologies , Application & Future Challenges\n",
            "Author/s :  Keyur K. Patel, Sunil M Patel\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  The Internet of things refers to a type of network to connect anything with the Internet based on stipulated protocols through information sensing equipments to conduct information exchange and communications in order to achieve smart recognitions, positioning, tracing, monitoring, and administration. In this paper we briefly discussed about what IOT is, how IOT enables different technologies, about its architecture, characteristics & applications, IOT functional view & what are the future challenges for IOT. Key Terms: IOT (Internet of Things), IOT definitions, IOT functional view, architecture, characteristics, future challenges.\n",
            "------------------------------------\n",
            "Title :  Personalised risk communication for informed decision making about taking screening tests.\n",
            "Author/s :  A. Edwards, G. Naik, Harry Ahmed, G. Elwyn, T. Pickles, K. Hood, R. Playle\n",
            "Venue :  Cochrane Database of Systematic Reviews\n",
            "year :  2013\n",
            "Abstract :  BACKGROUND\n",
            "There is a trend towards greater patient involvement in healthcare decisions. Although screening is usually perceived as good for the health of the population, there are risks associated with the tests involved. Achieving both adequate involvement of consumers and informed decision making are now seen as important goals for screening programmes. Personalised risk estimates have been shown to be effective methods of risk communication.\n",
            "\n",
            "\n",
            "OBJECTIVES\n",
            "To assess the effects of personalised risk communication on informed decision making by individuals taking screening tests. We also assess individual components that constitute informed decisions.\n",
            "\n",
            "\n",
            "SEARCH METHODS\n",
            "Two authors searched the Cochrane Central Register of Controlled Trials (CENTRAL, The Cochrane Library, Issue 3, 2012), MEDLINE (OvidSP), EMBASE (OvidSP), CINAHL (EbscoHOST) and PsycINFO (OvidSP) without language restrictions. We searched from 2006 to March 2012. The date ranges for the previous searches were from 1989 to December 2005 for PsycINFO and from 1985 to December 2005 for other databases. For the original version of this review, we also searched CancerLit  and Science Citation Index (March 2001). We also reviewed the reference lists and conducted citation searches of included studies and other systematic reviews in the field, to identify any studies missed during the initial search.\n",
            "\n",
            "\n",
            "SELECTION CRITERIA\n",
            "Randomised controlled trials incorporating an intervention with a 'personalised risk communication element' for individuals undergoing screening procedures, and reporting measures of informed decisions and also cognitive, affective, or behavioural outcomes addressing the decision by such individuals, of whether or not to undergo screening.\n",
            "\n",
            "\n",
            "DATA COLLECTION AND ANALYSIS\n",
            "Two authors independently assessed each included trial for risk of bias, and extracted data. We extracted data about the nature and setting of interventions, and relevant outcome data. We used standard statistical methods to combine data using RevMan version 5, including analysis according to different levels of detail of personalised risk communication, different conditions for screening, and studies based only on high-risk participants rather than people at 'average' risk. \n",
            "\n",
            "\n",
            "MAIN RESULTS\n",
            "We included 41 studies involving 28,700 people. Nineteen new studies were identified in this update, adding to the 22 studies included in the previous two iterations of the review. Three studies measured informed decision with regard to the uptake of screening following personalised risk communication as a part of their intervention. All of these three studies were at low risk of bias and there was strong evidence that the interventions enhanced informed decision making, although with heterogeneous results. Overall 45.2% (592/1309) of participants who received personalised risk information made informed choices, compared to 20.2% (229/1135) of participants who received generic risk information. The overall odds ratios (ORs) for informed decision were 4.48 (95% confidence interval (CI) 3.62 to 5.53 for fixed effect) and 3.65 (95% CI 2.13 to 6.23 for random effects). Nine studies measured increase in knowledge, using different scales. All of these studies showed an increase in knowledge with personalised risk communication. In three studies the interventions showed a trend towards more accurate risk perception, but the evidence was of poor quality. Four out of six studies reported non-significant changes in anxiety following personalised risk communication to the participants. Overall there was a small non-significant decrease in the anxiety scores. Most studies (32/41) measured the uptake of screening tests following interventions. Our results (OR 1.15 (95% CI 1.02 to 1.29)) constitute low quality evidence, consistent with a small effect, that personalised risk communication in which a risk score was provided (6 studies) or the participants were given their categorised risk (6 studies), increases uptake of screening tests. \n",
            "\n",
            "\n",
            "AUTHORS' CONCLUSIONS\n",
            "There is strong evidence from three trials that personalised risk estimates incorporated within communication interventions for screening programmes enhance informed choices. However the evidence for increasing the uptake of such screening tests with similar interventions is weak, and it is not clear if this increase is associated with informed choices. Studies included a diverse range of screening programmes. Therefore, data from this review do not allow us to draw conclusions about the best interventions to deliver personalised risk communication for enhancing informed decisions. The results are dominated by findings from the topic area of mammography and colorectal cancer. Caution is therefore required in generalising from these results, and particularly for clinical topics other than mammography and colorectal cancer screening.\n",
            "------------------------------------\n",
            "Title :  Deep Recurrent Q-Learning for Partially Observable MDPs\n",
            "Author/s :  Matthew J. Hausknecht, P. Stone\n",
            "Venue :  AAAI Fall Symposia\n",
            "year :  2015\n",
            "Abstract :  Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network} (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.\n",
            "------------------------------------\n",
            "Title :  Determinants of patient choice of healthcare providers: a scoping review\n",
            "Author/s :  A. Victoor, D. Delnoij, R. Friele, J. Rademakers\n",
            "Venue :  BMC Health Services Research\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Advances in photonic quantum sensing\n",
            "Author/s :  S. Pirandola, B. R. Bardhan, T. Gehring, C. Weedbrook, S. Lloyd\n",
            "Venue :  Nature Photonics\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  DNA Fountain enables a robust and efficient storage architecture\n",
            "Author/s :  Yaniv Erlich, Dina Zielinski\n",
            "Venue :  Science\n",
            "year :  2016\n",
            "Abstract :  A reliable and efficient DNA storage architecture DNA has the potential to provide large-capacity information storage. However, current methods have only been able to use a fraction of the theoretical maximum. Erlich and Zielinski present a method, DNA Fountain, which approaches the theoretical maximum for information stored per nucleotide. They demonstrated efficient encoding of information—including a full computer operating system—into DNA that could be retrieved at scale after multiple rounds of polymerase chain reaction. Science, this issue p. 950 A resilient DNA storage strategy enables near-maximal information content per nucleotide. DNA is an attractive medium to store digital information. Here we report a storage strategy, called DNA Fountain, that is highly robust and approaches the information capacity per nucleotide. Using our approach, we stored a full computer operating system, movie, and other files with a total of 2.14 × 106 bytes in DNA oligonucleotides and perfectly retrieved the information from a sequencing coverage equivalent to a single tile of Illumina sequencing. We also tested a process that can allow 2.18 × 1015 retrievals using the original DNA sample and were able to perfectly decode the data. Finally, we explored the limit of our architecture in terms of bytes per molecule and obtained a perfect retrieval from a density of 215 petabytes per gram of DNA, orders of magnitude higher than previous reports.\n",
            "------------------------------------\n",
            "Title :  Searching for explanations: How the Internet inflates estimates of internal knowledge.\n",
            "Author/s :  Matthew Fisher, M. Goddu, F. Keil\n",
            "Venue :  Journal of experimental psychology. General\n",
            "year :  2015\n",
            "Abstract :  As the Internet has become a nearly ubiquitous resource for acquiring knowledge about the world, questions have arisen about its potential effects on cognition. Here we show that searching the Internet for explanatory knowledge creates an illusion whereby people mistake access to information for their own personal understanding of the information. Evidence from 9 experiments shows that searching for information online leads to an increase in self-assessed knowledge as people mistakenly think they have more knowledge \"in the head,\" even seeing their own brains as more active as depicted by functional MRI (fMRI) images.\n",
            "------------------------------------\n",
            "Title :  Core concepts of spatial information for transdisciplinary research\n",
            "Author/s :  W. Kuhn\n",
            "Venue :  International Journal of Geographical Information Science\n",
            "year :  2012\n",
            "Abstract :  Geographic information science is emerging from its niche ‘behind the systems’, getting ready to contribute to transdisciplinary research. To succeed, a conceptual consensus across multiple disciplines on what spatial information is and how it can be used is needed. This article proposes a set of 10 core concepts of spatial information, intended to be meaningful to scientists who are not specialists of spatial information: location, neighbourhood, field, object, network, event, granularity, accuracy, meaning, and value. Each proposed concept is briefly characterized, demonstrating the need to map between their different disciplinary uses.\n",
            "------------------------------------\n",
            "Title :  Determinants of Sharing Travel Experiences in Social Media\n",
            "Author/s :  Myunghwa Kang, M. Schuett\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT The advent of Internet-based social media technologies has enabled travelers to quickly and conveniently share their travel experiences. Shared information on social media sites is recognized as an important information source which may influence travel decision making for potential travelers. This study tests a conceptual framework which examines why travelers share their travel experiences on social media based on the social influence theory and its three conceptual foundations—identification, internalization, and compliance. Data were collected using an online survey and the research model was tested with 543 respondents who were social media users. Results showed that identification and internalization are critical determinants that positively increase actual travel-experience sharing on social media as mediated by perceived enjoyment. Our research extends prior literature on social media by identifying specific determinants that can impact travel-experience sharing. Suggestions are provided for academics, the travel industry, and those working with social media.\n",
            "------------------------------------\n",
            "Title :  Analyst Information Discovery and Interpretation Roles: A Topic Modeling Approach\n",
            "Author/s :  Allen H. Huang, Reuven Lehavy, Amy Y. Zang, Rong Zheng\n",
            "Venue :  Management Sciences\n",
            "year :  2016\n",
            "Abstract :  This study examines analyst information intermediary roles using a textual analysis of analyst reports and corporate disclosures. We employ a topic modeling methodology from computational linguistic research to compare the thematic content of a large sample of analyst reports issued promptly after earnings conference calls with the content of the calls themselves. We show that analysts discuss exclusive topics beyond those from conference calls and interpret topics from conference calls. In addition, we find that investors place a greater value on new information in analyst reports when managers face greater incentives to withhold value-relevant information. Analyst interpretation is particularly valuable when the processing costs of conference call information increase. Finally, we document that investors react to analyst report content that simply confirms managers’ conference call discussions. Overall, our study shows that analysts play the information intermediary roles by discovering information beyond corporate disclosures and by clarifying and confirming corporate disclosures.\n",
            "------------------------------------\n",
            "Title :  FPGA based Real time 'secure' body temperature monitoring suitable for WBSN 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing\n",
            "Author/s :  M. Rao, T. Newe, I. Grout, E. Lewis, Avijit Mathur\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In wireless body sensor networks (WBSNs), sensors continuously monitor human physiological activities using medical sensors, for example; blood pressure, body temperature and electrocardiography (ECG). A WBSN can be used to develop a patient monitoring system. The traditional body sensor networks (BSNs) have limited hardware resources in terms of computational capabilities, data processing speed, memory and battery life. Also these BSNs are generally not suitable for the implementation of security mechanisms, reason is that, implementation of security mechanisms require relatively more hardware resources because of the complexity of their algorithms. To get rid of these limitations a Field Programmable Gate Array (FPGA) device is suitable because of its flexible architecture and high performance features. In this paper an FPGA based experimental framework is investigated to implement real time body temperature monitoring with reliable data transmission, using data integrity verification. This data integrity check is very important for patient monitoring systems as unreliable data could lead the healthcare professionals to make an incorrect diagnosis concerning patients health. The data integrity verification is achieved using newly selected cryptographic hash function called, SHA-3 (Secure Hash Algorithm-3). To the best of authors knowledge, all previously published FPGA based WBSNs implementations did not implemented any security mechanisms to secure physiological data, so this work is the first contribution regarding it.\n",
            "------------------------------------\n",
            "Title :  The Determinants and Consequences of Information Acquisition via EDGAR\n",
            "Author/s :  Michael S. Drake, D. Roulstone, Jacob R. Thornock\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Using a novel dataset that tracks all web traffic on the SEC’s EDGAR servers from 2008-2011, we examine the determinants and capital market consequences of investor information acquisition of SEC filings. The average user employs the database very few times per quarter and most users target specific filing types such as periodic accounting reports; a small subset of users employ EDGAR almost daily and access many filings. EDGAR activity is positively related with corporate events (particularly restatements, earnings announcements, and acquisition announcements), poor stock performance, and the strength of a firm’s information environment. EDGAR activity is related to, but distinct from, other proxies of investor interest such as trading volume, business press articles, and Google searches. Finally, information acquisition via EDGAR, both to obtain earnings news and to provide context for it, has a positive influence on market efficiency with respect to earnings news. Overall, our results provide a unique, user-based perspective on investor access of mandatory disclosures and its impact on price formation.\n",
            "------------------------------------\n",
            "Title :  Probabilistic data association for semantic SLAM\n",
            "Author/s :  Sean L. Bowman, Nikolay A. Atanasov, Kostas Daniilidis, George J. Pappas\n",
            "Venue :  IEEE International Conference on Robotics and Automation\n",
            "year :  2017\n",
            "Abstract :  Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.\n",
            "------------------------------------\n",
            "Title :  The entropy of bulk quantum fields and the entanglement wedge of an evaporating black hole\n",
            "Author/s :  Ahmed Almheiri, Netta Engelhardt, D. Marolf, Henry Maxfield\n",
            "Venue :  Journal of High Energy Physics\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  User cooperation in wireless powered communication networks\n",
            "Author/s :  Hyungsik Ju, Rui Zhang\n",
            "Venue :  2014 IEEE Global Communications Conference\n",
            "year :  2014\n",
            "Abstract :  This paper studies user cooperation in the emerging wireless powered communication network (WPCN) for throughput optimization. For the purpose of exposition, we consider a two-user WPCN, in which one hybrid access point (H-AP) broadcasts wireless energy to two distributed users in the downlink (DL) and the users transmit their independent information using their individually harvested energy to the H-AP in the uplink (UL) through time-division-multiple-access (TDMA). We propose user cooperation in the WPCN where the user that is nearer to the H-AP and in general has a better channel for DL energy harvesting as well as UL information transmission uses part of its allocated UL time and DL harvested energy to help relay the far user's information to the H-AP, in order to achieve more balanced throughput. We maximize the weighted sum-rate (WSR) of the two users by jointly optimizing the time and power allocations in the network for both wireless energy transfer in the DL and wireless information transmission and relaying in the UL. Simulation results show that the proposed user cooperation scheme can effectively improve the achievable throughput in the WPCN with desired user fairness.\n",
            "------------------------------------\n",
            "Title :  A brief introduction to weakly supervised learning\n",
            "Author/s :  Zhi-Hua Zhou\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.\n",
            "------------------------------------\n",
            "Title :  Position-aware Graph Neural Networks\n",
            "Author/s :  Jiaxuan You, Rex Ying, J. Leskovec\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2019\n",
            "Abstract :  Learning node embeddings that capture a node's position within the broader graph structure is crucial for many prediction tasks on graphs. However, existing Graph Neural Network (GNN) architectures have limited power in capturing the position/location of a given node with respect to all other nodes of the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a new class of GNNs for computing position-aware node embeddings. P-GNN first samples sets of anchor nodes, computes the distance of a given target node to each anchor-set,and then learns a non-linear distance-weighted aggregation scheme over the anchor-sets. This way P-GNNs can capture positions/locations of nodes with respect to the anchor nodes. P-GNNs have several advantages: they are inductive, scalable,and can incorporate node feature information. We apply P-GNNs to multiple prediction tasks including link prediction and community detection. We show that P-GNNs consistently outperform state of the art GNNs, with up to 66% improvement in terms of the ROC AUC score.\n",
            "------------------------------------\n",
            "Title :  Quantum Secure Direct Communication with Quantum Memory.\n",
            "Author/s :  Wei Zhang, D. Ding, Y. Sheng, Lan Zhou, B. Shi, G. Guo\n",
            "Venue :  Physical Review Letters\n",
            "year :  2016\n",
            "Abstract :  Quantum communication provides an absolute security advantage, and it has been widely developed over the past 30 years. As an important branch of quantum communication, quantum secure direct communication (QSDC) promotes high security and instantaneousness in communication through directly transmitting messages over a quantum channel. The full implementation of a quantum protocol always requires the ability to control the transfer of a message effectively in the time domain; thus, it is essential to combine QSDC with quantum memory to accomplish the communication task. In this Letter, we report the experimental demonstration of QSDC with state-of-the-art atomic quantum memory for the first time in principle. We use the polarization degrees of freedom of photons as the information carrier, and the fidelity of entanglement decoding is verified as approximately 90%. Our work completes a fundamental step toward practical QSDC and demonstrates a potential application for long-distance quantum communication in a quantum network.\n",
            "------------------------------------\n",
            "Title :  The Evolving Disclosure Landscape: How Changes in Technology, the Media, and Capital Markets Are Affecting Disclosure\n",
            "Author/s :  Gregory S. Miller, Douglas J. Skinner\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Recent changes in technology and the media are causing significant changes in how capital markets assimilate and respond to information. We identify important themes in the disclosure literature and use this as a framework to discuss the conference papers that appear in this volume. These papers examine how managers’ disclosure practices are being affected by changes in technology, the media, and capital markets. While this work makes important progress, we discuss how continuing technological change and the emergence of new forms of media offer further opportunities for research on the role of disclosure in capital markets.\n",
            "------------------------------------\n",
            "Title :  GSDS 2.0: an upgraded gene feature visualization server\n",
            "Author/s :  B. Hu, Jinpu Jin, Anyuan Guo, He Zhang, Jingchu Luo, G. Gao\n",
            "Venue :  Bioinform.\n",
            "year :  2014\n",
            "Abstract :  Summary: Visualizing genes’ structure and annotated features helps biologists to investigate their function and evolution intuitively. The Gene Structure Display Server (GSDS) has been widely used by more than 60 000 users since its first publication in 2007. Here, we reported the upgraded GSDS 2.0 with a newly designed interface, supports for more types of annotation features and formats, as well as an integrated visual editor for editing the generated figure. Moreover, a user-specified phylogenetic tree can be added to facilitate further evolutionary analysis. The full source code is also available for downloading. Availability and implementation: Web server and source code are freely available at http://gsds.cbi.pku.edu.cn. Contact: gaog@mail.cbi.pku.edu.cn or gsds@mail.cbi.pku.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title :  Supplier Encroachment under Asymmetric Information\n",
            "Author/s :  Z. Li, S. Gilbert, Guoming Lai\n",
            "Venue :  Management Sciences\n",
            "year :  2012\n",
            "Abstract :  Prior literature has shown that, for a symmetric information setting, supplier encroachment into a reseller's market can mitigate double marginalization and benefit both the supplier and the reseller. This paper extends the investigation of supplier encroachment to the environment where the reseller might be better informed than the supplier. We find that the launch of the supplier's direct channel can result in costly signaling behavior on the part of the reseller, in which he reduces his order quantity when the market size is small. Such a downward order distortion can amplify double marginalization. As a result, in addition to the “win--win” and “win--lose” outcomes for the supplier and the reseller, supplier encroachment can also lead to “lose--lose” and “lose--win” outcomes, particularly when the reseller has a significant efficiency advantage in the selling process and the prior probability of a large market is low. We further explore the implications of those findings for information management in supply chains. Complementing the conventional understanding, we show that with the ability to encroach, the supplier may prefer to sell to either a better informed or an uninformed reseller in different scenarios. On the other hand, as a result of a supplier developing encroachment capability, a reseller either may choose not to develop an advanced informational capability or may become more willing to find a means of credibly sharing his information. \n",
            " \n",
            "This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  China's Strategic Censorship\n",
            "Author/s :  Peter Lorentzen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  While it is often assumed that authoritarian regimes inevitably fear and restrict media independence, permitting watchdog journalism can actually help such regimes maintain power by improving governance. Yet such a strategy risks facilitating a coordinated uprising if discontent is revealed to be widespread. A formal model shows that under some conditions, a regime optimally permits investigative reporting on lower-level officialdom, adjusting how much reporting is allowed depending on the level of underlying social tensions. This strategy yields many of the benefits of free media without risking overthrow. An extension shows why an increase in uncontrollable information, such as from the Internet, may result in a reduction in media freedom. The model sheds light on important aspects of China's media policy and its evolution and on authoritarian media control more broadly.\n",
            "------------------------------------\n",
            "Title :  Oruta: privacy-preserving public auditing for shared data in the cloud\n",
            "Author/s :  Boyang Wang, Baochun Li, Hui Li\n",
            "Venue :  IEEE Transactions on Cloud Computing\n",
            "year :  2012\n",
            "Abstract :  With cloud data services, it is commonplace for data to be not only stored in the cloud, but also shared across multiple users. Unfortunately, the integrity of cloud data is subject to skepticism due to the existence of hardware/software failures and human errors. Several mechanisms have been designed to allow both data owners and public verifiers to efficiently audit cloud data integrity without retrieving the entire data from the cloud server. However, public auditing on the integrity of shared data with these existing mechanisms will inevitably reveal confidential information-identity privacy-to public verifiers. In this paper, we propose a novel privacy-preserving mechanism that supports public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute verification metadata needed to audit the correctness of shared data. With our mechanism, the identity of the signer on each block in shared data is kept private from public verifiers, who are able to efficiently verify shared data integrity without retrieving the entire file. In addition, our mechanism is able to perform multiple auditing tasks simultaneously instead of verifying them one by one. Our experimental results demonstrate the effectiveness and efficiency of our mechanism when auditing shared data integrity.\n",
            "------------------------------------\n",
            "Title :  Mobile Data Offloading through Opportunistic Communications and Social Participation\n",
            "Author/s :  B. Han, Pan Hui, V. S. A. Kumar, M. Marathe, Jianhua Shao, A. Srinivasan\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these algorithms for both synthetic and real-world mobility traces. For example, the Heuristic algorithm can offload mobile data traffic by up to 73.66 percent for a real-world mobility trace. Moreover, to investigate the feasibility of opportunistic communications for mobile phones, we implement a proof-of-concept prototype, called Opp-off, on Nokia N900 smartphones, which utilizes their Bluetooth interface for device/service discovery and content transfer.\n",
            "------------------------------------\n",
            "Title :  Psychological characteristics associated with COVID-19 vaccine hesitancy and resistance in Ireland and the United Kingdom\n",
            "Author/s :  Jamie Murphy, F. Vallières, R. Bentall, M. Shevlin, O. McBride, T. Hartman, R. McKay, K. Bennett, L. Mason, J. Gibson-Miller, L. Levita, Antón P. Martínez, T. Stocks, T. Karatzias, P. Hyland\n",
            "Venue :  Nature Communications\n",
            "year :  2021\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Database resources of the National Center for Biotechnology Information.\n",
            "Author/s :  E. Sayers, J. Beck, J. R. Brister, Evan E. Bolton, Kathi Canese, Donald C. Comeau, Kathryn Funk, A. Ketter, Sunghwan Kim, Avi Kimchi, P. Kitts, A. Kuznetsov, S. Lathrop, Zhiyong Lu, Kelly M. McGarvey, T. Madden, Terence D. Murphy, N. O'Leary, Lon Phan, Valerie A. Schneider, F. Thibaud-Nissen, B. Trawick, K. Pruitt, J. Ostell\n",
            "Venue :  Nucleic Acids Research\n",
            "year :  2019\n",
            "Abstract :  The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface, a sequence database search and a gene orthologs page. Additional resources that were updated in the past year include PMC, Bookshelf, My Bibliography, Assembly, RefSeq, viral genomes, the prokaryotic genome annotation pipeline, Genome Workbench, dbSNP, BLAST, Primer-BLAST, IgBLAST and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title :  An Integrated System for Regional Environmental Monitoring and Management Based on Internet of Things\n",
            "Author/s :  S. Fang, Lida Xu, Yunqiang Zhu, Jiaerheng Ahati, Huan Pei, Jianwu Yan, Zhihui Liu\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2014\n",
            "Abstract :  Climate change and environmental monitoring and management have received much attention recently, and an integrated information system (IIS) is considered highly valuable. This paper introduces a novel IIS that combines Internet of Things (IoT), Cloud Computing, Geoinformatics [remote sensing (RS), geographical information system (GIS), and global positioning system (GPS)], and e-Science for environmental monitoring and management, with a case study on regional climate change and its ecological effects. Multi-sensors and Web services were used to collect data and other information for the perception layer; both public networks and private networks were used to access and transport mass data and other information in the network layer. The key technologies and tools include real-time operational database (RODB); extraction-transformation-loading (ETL); on-line analytical processing (OLAP) and relational OLAP (ROLAP); naming, addressing, and profile server (NAPS); application gateway (AG); application software for different platforms and tasks (APPs); IoT application infrastructure (IoT-AI); GIS and e-Science platforms; and representational state transfer/Java database connectivity (RESTful/JDBC). Application Program Interfaces (APIs) were implemented in the middleware layer of the IIS. The application layer provides the functions of storing, organizing, processing, and sharing of data and other information, as well as the functions of applications in environmental monitoring and management. The results from the case study show that there is a visible increasing trend of the air temperature in Xinjiang over the last 50 years (1962-2011) and an apparent increasing trend of the precipitation since the early 1980s. Furthermore, from the correlation between ecological indicators [gross primary production (GPP), net primary production (NPP), and leaf area index (LAI)] and meteorological elements (air temperature and precipitation), water resource availability is the decisive factor with regard to the terrestrial ecosystem in the area. The study shows that the research work is greatly benefited from such an IIS, not only in data collection supported by IoT, but also in Web services and applications based on cloud computing and e-Science platforms, and the effectiveness of monitoring processes and decision-making can be obviously improved. This paper provides a prototype IIS for environmental monitoring and management, and it also provides a new paradigm for the future research and practice; especially in the era of big data and IoT.\n",
            "------------------------------------\n",
            "Title :  Top Concerns of Tweeters During the COVID-19 Pandemic: Infoveillance Study\n",
            "Author/s :  Alaa A. Abd-alrazaq, Dari Alhuwail, M. Househ, Mounir Hamdi, Zubair Shah\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background The recent coronavirus disease (COVID-19) pandemic is taking a toll on the world’s health care infrastructure as well as the social, economic, and psychological well-being of humanity. Individuals, organizations, and governments are using social media to communicate with each other on a number of issues relating to the COVID-19 pandemic. Not much is known about the topics being shared on social media platforms relating to COVID-19. Analyzing such information can help policy makers and health care organizations assess the needs of their stakeholders and address them appropriately. Objective This study aims to identify the main topics posted by Twitter users related to the COVID-19 pandemic. Methods Leveraging a set of tools (Twitter’s search application programming interface (API), Tweepy Python library, and PostgreSQL database) and using a set of predefined search terms (“corona,” “2019-nCov,” and “COVID-19”), we extracted the text and metadata (number of likes and retweets, and user profile information including the number of followers) of public English language tweets from February 2, 2020, to March 15, 2020. We analyzed the collected tweets using word frequencies of single (unigrams) and double words (bigrams). We leveraged latent Dirichlet allocation for topic modeling to identify topics discussed in the tweets. We also performed sentiment analysis and extracted the mean number of retweets, likes, and followers for each topic and calculated the interaction rate per topic. Results Out of approximately 2.8 million tweets included, 167,073 unique tweets from 160,829 unique users met the inclusion criteria. Our analysis identified 12 topics, which were grouped into four main themes: origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating the risk of infection. The mean sentiment was positive for 10 topics and negative for 2 topics (deaths caused by COVID-19 and increased racism). The mean for tweet topics of account followers ranged from 2722 (increased racism) to 13,413 (economic losses). The highest mean of likes for the tweets was 15.4 (economic loss), while the lowest was 3.94 (travel bans and warnings). Conclusions Public health crisis response activities on the ground and online are becoming increasingly simultaneous and intertwined. Social media provides an opportunity to directly communicate health information to the public. Health systems should work on building national and international disease detection and surveillance systems through monitoring social media. There is also a need for a more proactive and agile public health presence on social media to combat the spread of fake news.\n",
            "------------------------------------\n",
            "Title :  Community Detection in Networks with Node Attributes\n",
            "Author/s :  Jaewon Yang, Julian McAuley, J. Leskovec\n",
            "Venue :  2013 IEEE 13th International Conference on Data Mining\n",
            "year :  2013\n",
            "Abstract :  Community detection algorithms are fundamental tools that allow us to uncover organizational principles in networks. When detecting communities, there are two possible sources of information one can use: the network structure, and the features and attributes of nodes. Even though communities form around nodes that have common edges and common attributes, typically, algorithms have only focused on one of these two data modalities: community detection algorithms traditionally focus only on the network structure, while clustering algorithms mostly consider only node attributes. In this paper, we develop Communities from Edge Structure and Node Attributes (CESNA), an accurate and scalable algorithm for detecting overlapping communities in networks with node attributes. CESNA statistically models the interaction between the network structure and the node attributes, which leads to more accurate community detection as well as improved robustness in the presence of noise in the network structure. CESNA has a linear runtime in the network size and is able to process networks an order of magnitude larger than comparable approaches. Last, CESNA also helps with the interpretation of detected communities by finding relevant node attributes for each community.\n",
            "------------------------------------\n",
            "Title :  Comparison of SEER Treatment Data With Medicare Claims\n",
            "Author/s :  A. Noone, J. Lund, A. Mariotto, K. Cronin, T. McNeel, D. Deapen, J. Warren\n",
            "Venue :  Medical Care\n",
            "year :  2016\n",
            "Abstract :  Background:The population-based Surveillance, Epidemiology, and End Results (SEER) registries collect information on first-course treatment, including surgery, chemotherapy, radiation therapy, and hormone therapy. However, the SEER program does not release data on chemotherapy or hormone therapy due to uncertainties regarding data completeness. Activities are ongoing to investigate the opportunity to supplement SEER treatment data with other data sources. Methods:Using the linked SEER-Medicare data, we examined the validity of the SEER data to identify receipt of chemotherapy and radiation therapy among those aged 65 and older diagnosed from 2000 to 2006 with bladder, female breast, colorectal, lung, ovarian, pancreas, or prostate cancer and hormone therapy among men diagnosed with prostate cancer at age 65 or older. Treatment collected by SEER was compared with treatment as determined by Medicare claims, using Medicare claims as the gold standard. The &kgr;, sensitivity, specificity, positive predictive values, and negative predictive values were calculated for the receipt of each treatment modality. Results:The overall sensitivity of SEER data to identify chemotherapy, radiation, and hormone therapy receipt was moderate (68%, 80%, and 69%, respectively) and varied by cancer site, stage, and patient characteristics. The overall positive predictive value was high (>85%) for all treatment types and cancer sites except chemotherapy for prostate cancer. Conclusions:SEER data should not generally be used for comparisons of treated and untreated individuals or to estimate the proportion of treated individuals in the population. Augmenting SEER data with other data sources will provide the most accurate treatment information.\n",
            "------------------------------------\n",
            "Title :  An Evolutionary Upgrade of Cognitive Load Theory: Using the Human Motor System and Collaboration to Support the Learning of Complex Cognitive Tasks\n",
            "Author/s :  F. Paas, J. Sweller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Neural Collaborative Filtering\n",
            "Author/s :  Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua\n",
            "Venue :  The Web Conference\n",
            "year :  2017\n",
            "Abstract :  In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.\n",
            "------------------------------------\n",
            "Title :  \"Meaningful Information\" and the Right to Explanation\n",
            "Author/s :  Andrew D. Selbst, Julia E. Powles\n",
            "Venue :  FAT\n",
            "year :  2017\n",
            "Abstract :  There is no single, neat statutory provision labeled the “right to explanation” in Europe’s new General Data Protection Regulation (GDPR). But nor is such a right illusory. \n",
            "Responding to two prominent papers that, in turn, conjure and critique the right to explanation in the context of automated decision-making, we advocate a return to the text of the GDPR. \n",
            "Articles 13-15 provide rights to “meaningful information about the logic involved” in automated decisions. This is a right to explanation, whether one uses the phrase or not. \n",
            "The right to explanation should be interpreted functionally, flexibly, and should, at a minimum, enable a data subject to exercise his or her rights under the GDPR and human rights law.\n",
            "------------------------------------\n",
            "Title :  The Economics of Crowdfunding Platforms\n",
            "Author/s :  Paul Belleflamme, N. Omrani, M. Peitz\n",
            "Venue :  Information Economics and Policy\n",
            "year :  2015\n",
            "Abstract :  This paper provides a description of the crowdfunding sector, considering investment- based crowdfunding platforms as well as platforms in which funders do not obtain monetary payments. It lays out key features of this quickly developing sector and explores the economic forces at play that can explain the design of these platforms. In particular, it elaborates on cross-group and within-group external effects and asymmetric information on crowdfunding platforms.\n",
            "------------------------------------\n",
            "Title :  The Generative Mechanisms of Digital Infrastructure Evolution\n",
            "Author/s :  O. Henfridsson, B. Bygstad\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  The current literature on digital infrastructure offers powerful lenses for conceptualizing the increasingly interconnected information system collectives found in contemporary organizations. However, little attention has been paid to the generative mechanisms of digital infrastructure, that is, the causal powers that explain how and why such infrastructure evolves over time. This is unfortunate, since more knowledge about what drives digital infrastructures would be highly valuable for managers and IT professionals confronted by the complexity of managing them. To this end, this paper adopts a critical realist view for developing a configurational perspective of infrastructure evolution. Our theorizing draws on a multimethod research design comprising an in-depth case study and a case survey. The in-depth case study, conducted at a Scandinavian airline, distinguishes three key mechanisms of digital infrastructure evolution: adoption, innovation, and scaling. The case survey research of 41 cases of digital infrastructure then identifies and analyzes causal paths through which configurations of these mechanisms lead to successful evolution outcomes. The study reported in this paper contributes to the infrastructure literature in two ways. First, we identify three generative mechanisms of digital infrastructure and how they contingently lead to evolution outcomes. Second, we use these mechanisms as a basis for developing a configurational perspective that advances current knowledge about why some digital infrastructures evolve successfully while others do not. In addition, the paper demonstrates and discusses the efficacy of critical realism as a philosophical tradition for developing substantive contributions in the field of information systems.\n",
            "------------------------------------\n",
            "Title :  Social Collaborative Filtering by Trust\n",
            "Author/s :  Bo Yang, Yu Lei, Da-you Liu, Jiming Liu\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2013\n",
            "Abstract :  Recommender systems are used to accurately and actively provide users with potentially interesting information or services. Collaborative filtering is a widely adopted approach to recommendation, but sparse data and cold-start users are often barriers to providing high quality recommendations. To address such issues, we propose a novel method that works to improve the performance of collaborative filtering recommendations by integrating sparse rating data given by users and sparse social trust network among these same users. This is a model-based method that adopts matrix factorization technique that maps users into low-dimensional latent feature spaces in terms of their trust relationship, and aims to more accurately reflect the users reciprocal influence on the formation of their own opinions and to learn better preferential patterns of users for high-quality recommendations. We use four large-scale datasets to show that the proposed method performs much better, especially for cold start users, than state-of-the-art recommendation algorithms for social collaborative filtering based on trust.\n",
            "------------------------------------\n",
            "Title :  Regularizing Rioting: Permitting Public Protest in an Authoritarian Regime\n",
            "Author/s :  Peter Lorentzen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Lacking the informative feedback provided by competitive elections, an unfettered press and an active civil society, authoritarian regimes can find it difficult to identify which social groups have become dangerously discontented and to monitor lower levels of government. While a rise in public protest is often seen as a harbinger of regime collapse in such states, this paper uses a formal model and a close examination of the Chinese case to show that the informal toleration and even encouragement of small-scale, narrowly economic protests can be an effective information gathering tool, mitigating these informational problems. The analysis demonstrates that protests should be observed most frequently where discontent is neither too high nor too low. This calls into question the common assumption in comparative politics that an increase in protests necessarily reflects an increase in discontent or the weakness of a regime.\n",
            "------------------------------------\n",
            "Title :  Health information on the Internet: gold mine or minefield?\n",
            "Author/s :  Tabitha Tonsaker, G. Bartlett, C. Trpkov\n",
            "Venue :  Canadian family physician Medecin de famille canadien\n",
            "year :  2014\n",
            "Abstract :  The Internet has revolutionized the way information is shared and accessed. Information retrieval is easier now than ever before. Since the rise of modern search engines, social networks, and ubiquitous access through devices such as smartphones and tablet or laptop computers, information is\n",
            "------------------------------------\n",
            "Title :  International Society of Neuropathology‐Haarlem Consensus Guidelines for Nervous System Tumor Classification and Grading\n",
            "Author/s :  D. Louis, A. Perry, P. Burger, D. Ellison, G. Reifenberger, A. von Deimling, K. Aldape, D. Brat, V. Collins, C. Eberhart, D. Figarella-Branger, G. Fuller, F. Giangaspero, C. Giannini, C. Hawkins, P. Kleihues, A. Korshunov, J. Kros, M. Beatriz Lopes, H. Ng, H. Ohgaki, W. Paulus, T. Pietsch, M. Rosenblum, E. Rushing, F. Soylemezoğlu, O. Wiestler, P. Wesseling\n",
            "Venue :  Brain Pathology\n",
            "year :  2014\n",
            "Abstract :  Major discoveries in the biology of nervous system tumors have raised the question of how non‐histological data such as molecular information can be incorporated into the next World Health Organization (WHO) classification of central nervous system tumors. To address this question, a meeting of neuropathologists with expertise in molecular diagnosis was held in Haarlem, the Netherlands, under the sponsorship of the International Society of Neuropathology (ISN). Prior to the meeting, participants solicited input from clinical colleagues in diverse neuro‐oncological specialties. The present “white paper” catalogs the recommendations of the meeting, at which a consensus was reached that incorporation of molecular information into the next WHO classification should follow a set of provided “ISN‐Haarlem” guidelines. Salient recommendations include that (i) diagnostic entities should be defined as narrowly as possible to optimize interobserver reproducibility, clinicopathological predictions and therapeutic planning; (ii) diagnoses should be “layered” with histologic classification, WHO grade and molecular information listed below an “integrated diagnosis”; (iii) determinations should be made for each tumor entity as to whether molecular information is required, suggested or not needed for its definition; (iv) some pediatric entities should be separated from their adult counterparts; (v) input for guiding decisions regarding tumor classification should be solicited from experts in complementary disciplines of neuro‐oncology; and (iv) entity‐specific molecular testing and reporting formats should be followed in diagnostic reports. It is hoped that these guidelines will facilitate the forthcoming update of the fourth edition of the WHO classification of central nervous system tumors.\n",
            "------------------------------------\n",
            "Title :  Tuning parameter selection in high dimensional penalized likelihood\n",
            "Author/s :  Yingying Fan, C. Tang\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Determining how to select the tuning parameter appropriately is essential in penalized likelihood methods for high dimensional data analysis. We examine this problem in the setting of penalized likelihood methods for generalized linear models, where the dimensionality of covariates p is allowed to increase exponentially with the sample size n. We propose to select the tuning parameter by optimizing the generalized information criterion with an appropriate model complexity penalty. To ensure that we consistently identify the true model, a range for the model complexity penalty is identified in the generlized information criterion. We find that this model complexity penalty should diverge at the rate of some power of log (p) depending on the tail probability behaviour of the response variables. This reveals that using the Akaike information criterion or Bayes information criterion to select the tuning parameter may not be adequate for consistently identifying the true model. On the basis of our theoretical study, we propose a uniform choice of the model complexity penalty and show that the approach proposed consistently identifies the true model among candidate models with asymptotic probability 1. We justify the performance of the procedure proposed by numerical simulations and a gene expression data analysis.\n",
            "------------------------------------\n",
            "Title :  On the Rise of FinTechs – Credit Scoring Using Digital Footprints\n",
            "Author/s :  M. Puri, Tobias Berg, Valentin Burg, Ana Gombović\n",
            "Venue :  The Review of financial studies\n",
            "year :  2018\n",
            "Abstract :  \n",
            " We analyze the information content of a digital footprint—that is, information that users leave online simply by accessing or registering on a Web site—for predicting consumer default. We show that even simple, easily accessible variables from a digital footprint match the information content of credit bureau scores. A digital footprint complements rather than substitutes for credit bureau information and affects access to credit and reduces default rates. We discuss the implications for financial intermediaries’ business models, access to credit for the unbanked, and the behavior of consumers, firms, and regulators in the digital sphere. (JEL G20, G21, G29)\n",
            "------------------------------------\n",
            "Title :  Social media and political communication: a social media analytics framework\n",
            "Author/s :  Stefan Stieglitz, Linh Dang-Xuan\n",
            "Venue :  Social Network Analysis and Mining\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Emotions, Partisanship, and Misperceptions: How Anger and Anxiety Moderate the Effect of Partisan Bias on Susceptibility to Political Misinformation\n",
            "Author/s :  Brian E. Weeks\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Citizens are frequently misinformed about political issues and candidates but the circumstances under which inaccurate beliefs emerge are not fully understood. This experimental study demonstrates that the independent experience of two emotions, anger and anxiety, in part determines whether citizens consider misinformation in a partisan or open-minded fashion. Anger encourages partisan, motivated evaluation of uncorrected misinformation that results in beliefs consistent with the supported political party, while anxiety at times promotes initial beliefs based less on partisanship and more on the information environment. However, exposure to corrections improves belief accuracy, regardless of emotion or partisanship. The results indicate that the unique experience of anger and anxiety can affect the accuracy of political beliefs by strengthening or attenuating the influence of partisanship\n",
            "------------------------------------\n",
            "Title :  Unmet care needs of advanced cancer patients and their informal caregivers: a systematic review\n",
            "Author/s :  Tao Wang, A. Molassiotis, B. Chung, J. Tan\n",
            "Venue :  BMC Palliative Care\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information network or social network?: the structure of the twitter follow graph\n",
            "Author/s :  Seth A. Myers, Aneesh Sharma, Pankaj Gupta, Jimmy J. Lin\n",
            "Venue :  The Web Conference\n",
            "year :  2014\n",
            "Abstract :  In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.\n",
            "------------------------------------\n",
            "Title :  Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation\n",
            "Author/s :  Guosheng Lin, Chunhua Shen, Anton van dan Hengel, I. Reid\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2015\n",
            "Abstract :  Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information, specifically, we explore 'patch-patch' context between image regions, and 'patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-overunion score of 78:0 on the challenging PASCAL VOC 2012 dataset.\n",
            "------------------------------------\n",
            "Title :  Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks\n",
            "Author/s :  P. Bashivan, I. Rish, M. Yeasin, N. Codella\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2015\n",
            "Abstract :  One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.\n",
            "------------------------------------\n",
            "Title :  On the Use of Neuropyhsiological Tools in IS Research: Developing a Research Agenda for NeuroIS\n",
            "Author/s :  A. Dimoka, R. Banker, I. Benbasat, Fred D. Davis, A. Dennis, D. Gefen, Alok Gupta, A. Ischebeck, P. Kenning, P. Pavlou, G. Müller-Putz, R. Riedl, J. Brocke, B. Weber\n",
            "Venue :  MIS Q.\n",
            "year :  2012\n",
            "Abstract :  This article discusses the role of commonly used neurophysiological tools such as psychophysiological tools (e.g., EKG, eye tracking) and neuroimaging tools (e.g., fMRI, EEG) in Information Systems research. There is heated interest now in the social sciences in capturing presumably objective data directly from the human body, and this interest in neurophysiological tools has also been gaining momentum in IS research (termed NeuroIS). This article first reviews commonly used neurophysiological tools with regard to their major strengths and weaknesses. It then discusses several promising application areas and research questions where IS researchers can benefit from the use of neurophysiological data. The proposed research topics are presented within three thematic areas: (1) development and use of systems, (2) IS strategy and business outcomes, and (3) group work and decision support. The article concludes with recommendations on how to use neurophysiological tools in IS research along with a set of practical suggestions for developing a research agenda for NeuroIS and establishing NeuroIS as a viable subfield in the IS literature.\n",
            "------------------------------------\n",
            "Title :  Digital Imaging and Communications in Medicine (DICOM)\n",
            "Author/s :  O. Pianykh\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Building Member Attachment in Online Communities: Applying Theories of Group Identity and Interpersonal Bonds\n",
            "Author/s :  Yuqing Ren, F. M. Harper, Sara Drenner, L. Terveen, S. Kiesler, J. Riedl, R. Kraut\n",
            "Venue :  MIS Q.\n",
            "year :  2012\n",
            "Abstract :  Online communities are increasingly important to organizations and the general public, but there is little theoretically based research on what makes some online communities more successful than others. In this article, we apply theory from the field of social psychology to understand how online communities develop member attachment, an important dimension of community success. We implemented and empirically tested two sets of community features for building member attachment by strengthening either group identity or interpersonal bonds. To increase identity-based attachment, we gave members information about group activities and intergroup competition, and tools for group-level communication. To increase bond-based attachment, we gave members information about the activities of individual members and interpersonal similarity, and tools for interpersonal communication. Results from a six-month field experiment show that participants' visit frequency and self-reported attachment increased in both conditions. Community features intended to foster identity-based attachment had stronger effects than features intended to foster bond-based attachment. Participants in the identity condition with access to group profiles and repeated exposure to their group's activities visited their community twice as frequently as participants in other conditions. The new features also had stronger effects on newcomers than on old-timers. This research illustrates how theory from the social science literature can be applied to gain a more systematic understanding of online communities and how theory-inspired features can improve their success.\n",
            "------------------------------------\n",
            "Title :  Overview of the CLEF eHealth Evaluation Lab 2016\n",
            "Author/s :  L. Kelly, L. Goeuriot, H. Suominen, Aurélie Névéol, João Palotti, G. Zuccon\n",
            "Venue :  Conference and Labs of the Evaluation Forum\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Implementing genomic medicine in the clinic: the future is here\n",
            "Author/s :  T. Manolio, R. Chisholm, B. Ozenberger, D. Roden, Marc S. Williams, R. Wilson, D. Bick, E. Bottinger, M. Brilliant, C. Eng, K. Frazer, B. Korf, D. Ledbetter, J. Lupski, C. Marsh, D. Mrazek, M. Murray, P. O’Donnell, D. Rader, M. Relling, A. Shuldiner, D. Valle, R. Weinshilboum, E. Green, G. Ginsburg\n",
            "Venue :  Genetics in Medicine\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Bayesian Persuasion and Information Design\n",
            "Author/s :  Emir Kamenica\n",
            "Venue :  Annual Review of Economics\n",
            "year :  2019\n",
            "Abstract :  A school may improve its students’ job outcomes if it issues only coarse grades. Google can reduce congestion on roads by giving drivers noisy information about the state of traffic. A social planner might raise everyone's welfare by providing only partial information about solvency of banks. All of this can happen even when everyone is fully rational and understands the data-generating process. Each of these examples raises questions of what is the (socially or privately) optimal information that should be revealed. In this article, I review the literature that answers such questions.\n",
            "------------------------------------\n",
            "Title :  A survey of transfer learning\n",
            "Author/s :  Karl R. Weiss, T. Khoshgoftaar, Dingding Wang\n",
            "Venue :  Journal of Big Data\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Do Managers Always Know Better? Relative Accuracy of Management and Analyst Forecasts\n",
            "Author/s :  Amy P. Hutton, L. Lee, Susan Z. Shu\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  We examine the relative accuracy of management and analyst forecasts of annual EPS. We predict and find that analysts’ information advantage resides at the macroeconomic level. They provide more accurate earnings forecasts than management when a firm's fortunes move in concert with macroeconomic factors such as Gross Domestic Product and energy costs. In contrast, we predict and find that management's information advantage resides at the firm level. Their forecasts are more accurate than analysts’ when management's actions, which affect reported earnings, are difficult to anticipate by outsiders, such as when the firm's inventories are abnormally high or the firm has excess capacity or is experiencing a loss. Although analysts are commonly viewed as industry specialists, we fail to find evidence that analysts have an information advantage over managers at the industry level. The two have comparable abilities to forecast earnings for firms with revenues or earnings that are more synchronous with their industries.\n",
            "------------------------------------\n",
            "Title :  Connecting users across social media sites: a behavioral-modeling approach\n",
            "Author/s :  R. Zafarani, Huan Liu\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2013\n",
            "Abstract :  People use various social media for different purposes. The information on an individual site is often incomplete. When sources of complementary information are integrated, a better profile of a user can be built to improve online services such as verifying online information. To integrate these sources of information, it is necessary to identify individuals across social media sites. This paper aims to address the cross-media user identification problem. We introduce a methodology (MOBIUS) for finding a mapping among identities of individuals across social media sites. It consists of three key components: the first component identifies users' unique behavioral patterns that lead to information redundancies across sites; the second component constructs features that exploit information redundancies due to these behavioral patterns; and the third component employs machine learning for effective user identification. We formally define the cross-media user identification problem and show that MOBIUS is effective in identifying users across social media sites. This study paves the way for analysis and mining across social media sites, and facilitates the creation of novel online services across sites.\n",
            "------------------------------------\n",
            "Title :  Sociality Through Social Network Sites\n",
            "Author/s :  N. Ellison, D. Boyd\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This chapter reports authoritative insights into one of the most significant developments related to social interaction – social network sites – and offers an analytic framework for exploring these new sites, while underscoring the centrality of social interaction since the Internet's earliest days, such as through email. Social network sites (SNSs) presented several characteristics that made it possible for individuals to easily update their profiles. The implicit role of communication and information sharing has become the driving motivator for participation. The concept of ‘Web 2.0’ was an industry-driven phenomenon, hyped by the news media and by business analysts alike. Social network sites emerged out of the Web 2.0 and social media phenomena, mixing new technologies and older computer-mediated communication practices infused by tech industry ideals. Server-level data offer a unique opportunity to access elaborated behavioural data about what people are doing on SNSs.\n",
            "------------------------------------\n",
            "Title :  Eight Ways to Promote Generative Learning\n",
            "Author/s :  Logan Fiorella, R. Mayer\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  HMDB 4.0: the human metabolome database for 2018\n",
            "Author/s :  D. Wishart, Y. D. Feunang, A. Marcu, Anchi Guo, Kevin Y. H. Liang, R. Vázquez-Fresno, Tanvir Sajed, Daniel Johnson, Carin Li, N. Karu, Zinat Sayeeda, Elvis J. Lo, Nazanin Assempour, M. Berjanskii, Sandeep Singhal, David Arndt, Yongjie Liang, Hasan Badran, J. Grant, Arnau Serra-Cayuela, Yifeng Liu, R. Mandal, V. Neveu, Allison Pon, Craig K. Knox, Michael Wilson, C. Manach, A. Scalbert\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2017\n",
            "Abstract :  Abstract The Human Metabolome Database or HMDB (www.hmdb.ca) is a web-enabled metabolomic database containing comprehensive information about human metabolites along with their biological roles, physiological concentrations, disease associations, chemical reactions, metabolic pathways, and reference spectra. First described in 2007, the HMDB is now considered the standard metabolomic resource for human metabolic studies. Over the past decade the HMDB has continued to grow and evolve in response to emerging needs for metabolomics researchers and continuing changes in web standards. This year's update, HMDB 4.0, represents the most significant upgrade to the database in its history. For instance, the number of fully annotated metabolites has increased by nearly threefold, the number of experimental spectra has grown by almost fourfold and the number of illustrated metabolic pathways has grown by a factor of almost 60. Significant improvements have also been made to the HMDB’s chemical taxonomy, chemical ontology, spectral viewing, and spectral/text searching tools. A great deal of brand new data has also been added to HMDB 4.0. This includes large quantities of predicted MS/MS and GC–MS reference spectral data as well as predicted (physiologically feasible) metabolite structures to facilitate novel metabolite identification. Additional information on metabolite-SNP interactions and the influence of drugs on metabolite levels (pharmacometabolomics) has also been added. Many other important improvements in the content, the interface, and the performance of the HMDB website have been made and these should greatly enhance its ease of use and its potential applications in nutrition, biochemistry, clinical chemistry, clinical genetics, medicine, and metabolomics science.\n",
            "------------------------------------\n",
            "Title :  Increasing Accountability Through User-Interface Design Artifacts: A New Approach to Addressing the Problem of Access-Policy Violations\n",
            "Author/s :  Anthony Vance, P. Lowry, D. Eggett\n",
            "Venue :  MIS Q.\n",
            "year :  2015\n",
            "Abstract :  Access-policy violations are a growing problem with substantial costs for organizations. Although training programs and sanctions have been suggested as a means of reducing these violations, evidence shows the problem persists. It is thus imperative to identify additional ways to reduce access-policy violations, especially for systems providing broad access to data. We use accountability theory to develop four user-interface (UI) design artifacts that raise users' accountability perceptions within systems and in turn decrease access-policy violations. To test our model, we uniquely applied the scenario-based factorial survey method to various graphical manipulations of a records system containing sensitive information at a large organization with over 300 end users who use the system daily. We show that the UI design artifacts corresponding to four submanipulations of accountability can raise accountability and reduce access policy violation intentions. Our findings have several theoretical and practical implications for increasing accountability using UI design. Moreover, we are the first to extend the scenario-based factorial survey method to test design artifacts. This method provides the ability to use more design manipulations and to test with fewer users than is required in traditional experimentation and research on human--computer interaction. We also provide bootstrapping tests of mediation and moderation and demonstrate how to analyze fixed and random effects within the factorial survey method optimally.\n",
            "------------------------------------\n",
            "Title :  Information Asymmetry in Management Research: Past Accomplishments and Future Opportunities\n",
            "Author/s :  D. Bergh, D. Ketchen, Ilaria Orlandi, P. Heugens, B. Boyd\n",
            "Venue :  Journal of Management\n",
            "year :  2018\n",
            "Abstract :  Information asymmetry is a condition wherein one party in a relationship has more or better information than another. The information asymmetry concept is widely diffused throughout management research, and its existence is a core assumption within leading theories on organizations. Despite information asymmetry’s central role, however, there have been no systematic reviews of the management literature using the concept. As a result, there is no established level of knowledge of information asymmetry as a management concept, nor is there a unified basis for directing future research leveraging the concept. In response, we review 223 relevant articles from leading management journals and develop a framework for organizing and assessing information asymmetry research. We consolidate understanding of information asymmetry’s meaning, conceptual applications, roles in different theoretical models, antecedents, and how focal actors’ self-interests influence the selection of mechanisms for managing it. Further, we highlight opportunities for extensions to core management theories and specify research prospects within several management subfields. Overall, the framework can help guide researchers as they work to advance understanding of one of the management field’s most ubiquitous concepts.\n",
            "------------------------------------\n",
            "Title :  Critical Realism and Affordances: Theorizing IT-Associated Organizational Change Processes\n",
            "Author/s :  O. Volkoff, D. Strong\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Convincing arguments for using critical realism as an underpinning for theories of IT-associated organizational change have appeared in the Information Systems literature. A central task in developing such theories is to uncover the generative mechanisms by which IT is implicated in organizational change processes, but to do so, we must explain how critical realism's concept of generative mechanisms applies in an IS context. Similarly, convincing arguments have been made for using Gibson's (1986) affordance theory from ecological psychology for developing theories of IT-associated organizational change, but this effort has been hampered due to insufficient attention to the ontological status of affordances. In this paper, we argue that affordances are the generative mechanisms we need to specify and explain how affordances are a specific type of generative mechanism. We use the core principles of critical realism to argue how affordances arise in the real domain from the relation between the complex assemblages of organizations and of IT artifacts, how affordances are actualized over time by organizational actors, and how these actualizations lead to the various effects we observe in the empirical domain. After presenting these arguments, we reanalyze two published cases in the literature, those of ACRO and Autoworks, to illustrate how affordance-based theories informed by critical realism enhance our ability to explain IT-associated organizational change. These examples show how researchers using this approach should proceed, and how managers can use these ideas to diagnose and address IT implementation problems.\n",
            "------------------------------------\n",
            "Title :  Twitcident: fighting fire with information from social web streams\n",
            "Author/s :  F. Abel, C. Hauff, G. Houben, R.J.P. Stronkman, Ke Tao\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  In this paper, we present Twitcident, a framework and Web-based system for filtering, searching and analyzing information about real-world incidents or crises. Twitcident connects to emergency broadcasting services and automatically starts tracking and filtering information from Social Web streams (Twitter) when a new incident occurs. It enriches the semantics of streamed Twitter messages to profile incidents and to continuously improve and adapt the information filtering to the current temporal context. Faceted search and analytical tools allow users to retrieve particular information fragments and overview and analyze the current situation as reported on the Social Web. Demo: http://wis.ewi.tudelft.nl/twitcident/\n",
            "------------------------------------\n",
            "Title :  An integrated map of genetic variation from 1,092 human genomes\n",
            "Author/s :  Gil A. David M. Richard M. Gonçalo R. David R. Aravind McVean Altshuler (Co-Chair) Durbin (Co-Chair) Abec, G. McVean, David M. Richard M. Gonçalo R. David R. Aravinda Andrew  Altshuler (Co-Chair) Durbin (Co-Chair) Abecasis Be, David M. Altshuler (Co-Chair), Richard M. Durbin (Co-Chair), G. Abecasis, D. Bentley, Aravinda Chakravarti, Andrew G. Clark, Peter Donnelly, Evan E. Eichler, P. Flicek, S. Gabriel, R. Gibbs, E. Green, M. Hurles, B. Knoppers, J. Korbel, Eric S. Lander, Charles Lee, H. Lehrach, E. Mardis, G. Marth, G. McVean, Deborah A. Nickerson, Jeanette P. Schmidt, S. Sherry, Jun Wang, Richard K. Wilson, Richard A. Huyen Christie Sandra Lora Donna Jeff Min Jun X Gibbs (Principal Investigator) Dinh Kovar Lee Lewi, Richard A. Huyen Christie Sandra Lora Donna Jeff Min Gibbs (Principal Investigator) Dinh Kovar Lee Lewi, Richard A. Gibbs (Principal Investigator), H. Dinh, C. Kovar, Sandra Lee, Lora Lewis, D. Muzny, Jeff Reid, Min Wang, Jun Xiaodong Xiaosen Min Hui Xin Guoqing Jingxiang Yin Wang (Principal Investigator) Fang Guo Jian Jiang , Jun Wang (Principal Investigator), Xiaodong Fang, Xiaosen Guo, Min Jian, Hui Jiang, Xin Jin, Guoqing Li, Jingxiang Li, Yingrui Li, Zhuo Li, Xinyu Liu, Yao Lu, Xuedi Ma, Zheng Su, S. Tai, Meifang Tang, Bo Wang, Guangbiao Wang, Honglong Wu, Renhua Wu, Ye Yin, Wenwei Zhang, Jiao Zhao, Meiru Zhao, Xiaole Zheng, Yan Zhou, Eric S. David M. Stacey B. Namrata Lander (Principal Investigator) Altshuler Gabriel , Eric S. Lander (Principal Investigator), D. Altshuler, Stacey B. Gabriel (Co-Chair), N. Gupta, Paul Laura Rasko Richard E. Xiangqun Flicek (Principal Investigator) Clarke Leinonen Sm, Paul Flicek (Principal Investigator), Laura Clarke, R. Leinonen, Richard E. Smith, Xiangqun Zheng-Bradley, David R. Russell Sean Terena Zoya Bentley (Principal Investigator) Grocock Humphray , David R. Bentley (Principal Investigator), R. Grocock, S. Humphray, Terena James, Z. Kingsbury, Hans Ralf Marcus W. Vyacheslav S. Tatiana A. Matthias F Lehrach (Principal Investigator) Sudbrak (Project , Hans Lehrach (Principal Investigator), Ralf Sudbrak (Project Leader), Marcus W. Albrecht, V. Amstislavskiy, T. Borodina, M. Lienhard, F. Mertes, M. Sultan, B. Timmermann, M. Yaspo, Stephen T. Sherry (Principal Investigator), Gil A. McVean (Principal Investigator), Elaine R. Richard K. Lucinda Robert George M. Mardis (Co-Principal Investigator) (Co-Chair) Wils, Elaine R. Mardis (Co-Principal Investigator) (Co-Chair), Richard K. Wilson (Co-Principal Investigator), L. Fulton, R. Fulton, G. Weinstock, Richard M. Senduran John Petr Thomas M. Anja Shane James M Durbin (Principal Investigator) Balasubramaniam Bu, Richard M. Durbin (Principal Investigator), Senduran Balasubramaniam, J. Burton, Petr Danecek, Thomas M. Keane, Anja Kolb-Kokocinski, Shane A. McCarthy, J. Stalker, Michael A. Quail, Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Adam  Schmidt (Principal Investigator) Davies Gollub Web, Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Schmidt (Principal Investigator) Davies Gollub Web, Jeanette P. Schmidt (Principal Investigator), C. J. Davies, J. Gollub, Teresa A. Webster, Brant Wong, Yiping Zhan, Adam Auton (Principal Investigator), Richard A. Fuli Matthew Danny Uday S. James Donna Uma Jeff Gibbs (Principal Investigator) Yu (Project Leader), Fuli Yu (Project Leader), M. Bainbridge, Danny Challis, Uday S. Evani, James Lu, U. Nagaswamy, A. Sabo, Yi Wang, Jin Yu, Jun Lachlan J. M. Lin Xiaosen Xin Guoqing Qibin Yingru Wang (Principal Investigator) Coin Fang Guo Jin Li, L. Coin, L. Fang, Qibin Li, Zhenyu Li, Haoxiang Lin, Binghang Liu, Ruibang Luo, Nan Qin, Haojing Shao, Bingqiang Wang, Yinlong Xie, C. Ye, Chang Yu, Fan Zhang, Hancheng Zheng, Hongmei Zhu, Gabor T. Erik P. Deniz Wan-Ping Wen Alistair N. Jiantao  Marth (Principal Investigator) Garrison Kural Lee , Gabor T. Marth (Principal Investigator), Erik P Garrison, Deniz Kural, Wan-Ping Lee, Wen Fung Leong, Alistair N. Ward, Jiantao Wu, Mengyao Zhang, Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) Griffin Hsieh Mills S, Charles Lee (Principal Investigator), Lauren Griffin, Chih-heng Hsieh, R. Mills, Xinghua Shi, Marcin von Grotthuss, Chengsheng Zhang, Mark J. Mark A. David M. Eric Gaurav Mauricio O. Guille Daly (Principal Investigator) DePristo (Project Le, Mark J. Daly (Principal Investigator), Mark A. DePristo (Project Leader), E. Banks, G. Bhatia, Mauricio O. Carneiro, Guillermo del Angel, G. Genovese, R. Handsaker, C. Hartl, S. Mccarroll, J. Nemesh, R. Poplin, Stephen F. Schaffner, Khalid Shakir, Seungtai C. Jayon Vladimir Yoon (Principal Investigator) Lihm Makarov, Seungtai C. Yoon (Principal Investigator), J. Lihm, Vladimir Makarov, Hanjun Wook Ki Jin (Principal Investigator) Kim Cheol Kim, Hanjun Jin (Principal Investigator), Wook Kim, Ki Cheol Kim, Jan O. Tobias Korbel (Principal Investigator) Rausch, Jan O. Korbel (Principal Investigator), T. Rausch, Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin, Kathryn Beal, Fiona Cunningham, Javier Herrero, W. McLaren, G. Ritchie, Andrew G. Srikanth Alon Juan L. Clark (Principal Investigator) Gottipati Keinan Ro, Andrew G. Clark (Principal Investigator), S. Gottipati, Alon Keinan, J. Rodriguez-Flores, Pardis C. Sharon R. Shervin Ridhi Sabeti (Principal Investigator) Grossman Tabrizi T, Pardis C. Sabeti (Principal Investigator), Sharon R. Grossman, S. Tabrizi, Ridhi Tariyal, David N. Edward V. Peter D. Cooper (Principal Investigator) Ball Stenson, David N. Cooper (Principal Investigator), E. Ball, P. Stenson, David R. Bret Markus R. Tony Michael Sean Scott Lisa Joh Bentley (Principal Investigator) Barnes Bauer Keir, Bret Barnes, Markus Bauer, R. Keira Cheetham, Tony Cox, Michael Eberle, Scott D. Kahn, Lisa J. Murray, John Peden, Richard Shaw, Kai Ye (Principal Investigator), Mark A. Miriam K. Jerilyn A. Batzer (Principal Investigator) Konkel Walker, Mark A. Batzer (Principal Investigator), Miriam K. Konkel, Jerilyn A. Walker, Daniel G. Monkol MacArthur (Principal Investigator) Lek, Daniel G. MacArthur (Principal Investigator), M. Lek, Vyacheslav S. Ralf Sudbrak (Project Leader) Amstislavskiy Herwig, Sudbrak (Project Leader), Ralf Herwig, Mark D. Shriver (Principal Investigator), Carlos D. Jake K. Francisco M. Simon Eimear E. Jeffrey M. Bustamante (Principal Investigator) Byrnes De La V, Carlos D. Bustamante (Principal Investigator), J. Byrnes, F. M. De La Vega, S. Gravel, E. Kenny, J. Kidd, P. Lacroute, Brian K. Maples, A. Moreno-Estrada, Fouad Zakharia, Eran Yael Halperin (Principal Investigator) Baran, Eran Halperin (Principal Investigator), Yael Baran, David W. Alexis Nils Tyler Ahmet A. Shripad A. Kevin Craig (Principal Investigator) Christoforides Home, David W. Craig (Principal Investigator), Alexis Christoforides, Nils Homer, Tyler Izatt, Ahmet A. Kurdoglu, Shripad A. Sinari, Kevin Squire, Stephen T. Chunlin Sherry (Principal Investigator) Xiao, C. Xiao, Jonathan Vineet Kenny Sebat (Principal Investigator) Bafna Ye, Jonathan Sebat (Principal Investigator), V. Bafna, Kenny Q. Ye, Esteban G. Ryan D. Christopher R. Burchard (Principal Investigator) Hernandez (Princ, Esteban G. Burchard (Principal Investigator), Ryan D. Hernandez (Principal Investigator), C. Gignoux, David Sol J. W. Haussler (Principal Investigator) Katzman James Ke, David Haussler (Principal Investigator), Sol Katzman, W. James Kent, B. Howie, Andres Ruiz-Linares (Principal Investigator), Emmanouil T. Tuuli Dermitzakis (Principal Investigator) Lappalainen, Emmanouil T. Dermitzakis (Principal Investigator), Tuuli Lappalainen, Scott E. Xinyue Ankit Luke J. Devine (Principal Investigator) Liu Maroo Tallon, Scott E. Devine (Principal Investigator), Xinyue Liu, A. Maroo, Luke J. Tallon, Jeffrey A. Leslie P. Rosenfeld (Principal Investigator) Michelson, Jeffrey A. Rosenfeld (Principal Investigator), L. P. Michelson, Gonçalo R. Hyun Paul Andrea Abigail Tom Fabio Francesco Ch Abecasis (Principal Investigator) (Co-Chair) Min K, Gonçalo R. Abecasis (Principal Investigator) (Co-Chair), Hyun Min Kang (Project Leader), Paul Anderson, A. Angius, A. Bigham, T. Blackwell, F. Busonero, F. Cucca, C. Fuchsberger, Chris Jones, G. Jun, Yun Li, R. Lyons, Andrea Maschio, E. Porcu, F. Reinier, Serena Sanna, David Schlessinger, C. Sidore, Adrian Tan, Mary Kate Trost, Philip Alan Awadalla (Principal Investigator) Hodgkinson, Philip Awadalla (Principal Investigator), A. Hodgkinson, Gerton Gil A. Jonathan L. Simon Claire Olivier Anjali Zam Lunter (Principal Investigator) McVean (Principal , Gerton Lunter (Principal Investigator), Gil A. McVean (Principal Investigator) (Co-Chair), Jonathan L. Marchini (Principal Investigator), Simon Myers (Principal Investigator), C. Churchhouse, Olivier Delaneau, Anjali Gupta-Hinch, Z. Iqbal, I. Mathieson, A. Rimmer, Dionysia K. Xifara, Taras K. Oleksyk (Principal Investigator), Yunxin Xiaoming Momiao Fu (Principal Investigator) Liu Xiong, Yunxin Fu (Principal Investigator), Xiaoming Liu, Momiao Xiong, Lynn David Jinchuan Jorde (Principal Investigator) Witherspoon Xing, Lynn Jorde (Principal Investigator), D. Witherspoon, Jinchuan Xing, Evan E. Brian L. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) Browning (Princip, Evan E. Eichler (Principal Investigator), Brian L. Browning (Principal Investigator), Can Alkan, Iman Hajirasouliha, F. Hormozdiari, Arthur Ko, P. Sudmant, Elaine R. Ken Asif Li David Daniel C. Michael D. John W.  Mardis (Co-Principal Investigator) Chen Chinwalla , Elaine R. Mardis (Co-Principal Investigator), Ken Chen, A. Chinwalla, L. Ding, D. Dooling, D. Koboldt, M. McLellan, J. Wallis, M. Wendl, Qunyuan Zhang, Richard M. Matthew E. Chris Cornelis A. Qasim Senduran Yua Durbin (Principal Investigator) Hurles (Principal , Matthew E. Hurles (Principal Investigator), Chris Tyler-Smith (Principal Investigator), C. A. Albers, Q. Ayub, Yuan Chen, A. Coffey, V. Colonna, N. Huang, L. Jostins, Heng Li, A. Scally, Klaudia Walter, Yali Xue, Yujun Zhang, Mark B. Alexej Suganthi Jieming Declan Yao Lukas Arif O Gerstein (Principal Investigator) Abyzov Balasubra, Mark B. Gerstein (Principal Investigator), Alexej Abyzov, S. Balasubramanian, Jieming Chen, Declan Clarke, Yao Fu, L. Habegger, A. Harmanci, Mike Jin, Ekta Khurana, Xinmeng Jasmine Mu, Cristina Sisu, Yingrui Ruibang Hongmei Charles Lauren Chih-Heng Ryan E. X Li Luo Zhu Lee (Principal Investigator) (Co-Chair), Yingrui Ruibang Hongmei Li Luo Zhu, Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) (Co-Chair) Griffin Hs, Charles Lee (Principal Investigator) (Co-Chair), Gabor T. Erik P. Deniz Wan-Ping Alistair N. Jiantao Meng Marth (Principal Investigator) Garrison Kural Lee , Steven A. David M. Eric Guillermo Giulio Robert E. Chris  McCarroll (Project Leader) Altshuler Banks del Ang, Steven A. McCarroll (Project Leader), Jeremiah D. Degenhardt, Paul Laura Richard E. Xiangqun Flicek (Principal Investigator) Clarke Smith Zheng, Jan O. Tobias Adrian M. Korbel (Principal Investigator) (Co-Chair) Rausch , Jan O. Korbel (Principal Investigator) (Co-Chair), A. Stütz, David R. Bret R. Michael Sean Scott Lisa Richard Bentley (Principal Investigator) Barnes Keira Chee, David W. Nils Craig (Principal Investigator) Homer, Deanna Chunlin Church Xiao, D. Church, Jonathan Vineet Jacob J. Kenny Sebat (Principal Investigator) Bafna Michaelson Ye, J. Michaelson, Gerton Gil A. Zamin Lunter (Principal Investigator) McVean (Principal , David Jinchuan Witherspoon Xing, Evan E. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) (Co-Chair) Alkan , Evan E. Eichler (Principal Investigator) (Co-Chair), Ken Asif Li Michael D. John W. Chen Chinwalla Ding McLellan Wallis, Matthew E. Ben Heng Sarah J. Zemin Aylwyn Klaudia Yujun Hurles (Principal Investigator) (Co-Chair) Blackbu, Matthew E. Hurles (Principal Investigator) (Co-Chair), B. Blackburne, S. Lindsay, Z. Ning, Mark B. Alexej Jieming Declan Ekta Xinmeng Cristina Gerstein (Principal Investigator) Abyzov Chen Clar, Mark B. Gerstein (Principal Investigator), Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj, Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj, Richard A. Gibbs (Principal Investigator) (Co-Chair), Xiaosen Yingrui Renhua Guo Li Wu, Gabor T. Erik P. Wen Alistair N. Marth (Principal Investigator) (Co-Chair) Garrison, Gabor T. Marth (Principal Investigator) (Co-Chair), Guillermo Mark A. Stacey B. Namrata Chris Ryan E. del Angel DePristo Gabriel Gupta Hartl Poplin, M. DePristo, Andrew G. Juan L. Clark (Principal Investigator) Rodriguez-Flores, Carlos D. Simon Bustamante (Principal Investigator) Gravel, David W. Alexis Nils Tyler Craig (Principal Investigator) Christoforides Home, Gonçalo R. Hyun Abecasis (Principal Investigator) Min Kang, Gonçalo R. Abecasis (Principal Investigator), Hyun Min Kang, Elaine R. David Lucinda Robert Daniel C. Mardis (Principal Investigator) Dooling Fulton Ful, Elaine R. Mardis (Principal Investigator), Richard M. Senduran Thomas M. Shane James Durbin (Principal Investigator) Balasubramaniam Ke, Mark B. Suganthi Lukas Gerstein (Principal Investigator) Balasubramanian , Erik P. Richard A. Matthew Donna Fuli Jin Guillermo Rob Garrison Gibbs (Principal Investigator) Bainbridge, Richard A. Matthew Donna Fuli Jin Gibbs (Principal Investigator) Bainbridge Muzny Yu, Fuli Yu, Guillermo Robert E. del Angel Handsaker, Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin, Carlos D. Francisco M. Bustamante (Principal Investigator) De La Vega, David W. Ahmet A. Craig (Principal Investigator) Kurdoglu, Chris Yuan Vincenza Adam Jennifer Yali Tyler-Smith (Principal Investigator) (Co-Chair) Ch, Chris Tyler-Smith (Principal Investigator) (Co-Chair), Adam Frankish, Jennifer Harrow, Mark B. Alexej Suganthi Jieming Declan Yao Arif O. Mike Gerstein (Principal Investigator) (Co-Chair) Abyzo, Mark B. Gerstein (Principal Investigator) (Co-Chair), Richard A. Gerald Walker Divya Christie Donna Jeff Jun Xia Gibbs (Principal Investigator) Fowler Hale Kalra K, Richard A. Gerald Walker Divya Christie Donna Jeff Gibbs (Principal Investigator) Fowler Hale Kalra K, Gerald Fowler, Walker Hale, D. Kalra, Jun Xiaosen Guoqing Yingrui Xiaole Wang (Principal Investigator) Guo Li Li Zheng, Paul Laura Jonathan Gavin Eugene Rasko William M. Rajes Flicek (Principal Investigator) (Co-Chair) Clarke , Paul Flicek (Principal Investigator) (Co-Chair), Laura Clarke (Project Leader), Jonathan A. Barker, G. Kelman, Eugene Kulesha, Rajesh Radhakrishnan, Asier Roa, Dmitriy Smirnov, Ian Streeter, I. Toneva, Brendan Vaughan, David R. Tony Sean Scott Bentley (Principal Investigator) Cox Humphray Kahn, Ralf Marcus W. Matthias Sudbrak (Project Leader) Albrecht Lienhard, David W. Tyler Ahmet A. Craig (Principal Investigator) Izatt Kurdoglu, Stephen T. Victor Zinaida Dimitriy Nathan Chao Deanna Robe Sherry (Principal Investigator) (Co-Chair) Ananiev, Stephen T. Sherry (Principal Investigator) (Co-Chair), Victor Ananiev, Zinaida Belaia, Dimitriy Beloslyudtsev, Nathan Bouk, Chao Chen, Robert Cohen, Charles Cook, John Garner, T. Hefferon, M. Kimelman, Chunlei Liu, John Lopez, Peter Meric, Chris O’Sullivan, Yuri Ostapchuk, Lon Phan, Sergiy Ponomarov, Valerie Schneider, Eugene Shekhtman, Karl Sirotkin, D. Slotta, Hua Zhang, Can Arthur Alkan Ko, Aravinda Bartha M. Gonçalo R. Kathleen C. Christine Esteban Chakravarti (Co-Chair) Knoppers (Co-Chair) Abecasi, Aravinda Chakravarti (Co-Chair), Bartha M. Knoppers (Co-Chair), G. Abecasis, K. Barnes, Christine Beiswanger, Esteban G. Burchard, C. Bustamante, Hongyu Cai, H. Cao, R. Durbin, Neda Gharani, R. Gibbs, B. Henn, Danielle Jones, L. Jorde, J. Kaye, A. Kent\n",
            "Venue :  Nature\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Survey on Truth Discovery\n",
            "Author/s :  Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, Jiawei Han\n",
            "Venue :  SKDD\n",
            "year :  2015\n",
            "Abstract :  Thanks to information explosion, data for the objects of interest can be collected from increasingly more sources. However, for the same object, there usually exist conflicts among the collected multi-source information. To tackle this challenge, truth discovery, which integrates multi-source noisy information by estimating the reliability of each source, has emerged as a hot topic. Several truth discovery methods have been proposed for various scenarios, and they have been successfully applied in diverse application domains. In this survey, we focus on providing a comprehensive overview of truth discovery methods, and summarizing them from different aspects. We also discuss some future directions of truth discovery research. We hope that this survey will promote a better understanding of the current progress on truth discovery, and offer some guidelines on how to apply these approaches in application domains.\n",
            "------------------------------------\n",
            "Title :  Security Challenges for the Public Cloud\n",
            "Author/s :  K. Ren, Cong Wang, Qian Wang\n",
            "Venue :  IEEE Internet Computing\n",
            "year :  2012\n",
            "Abstract :  Cloud computing represents today's most exciting computing paradigm shift in information technology. However, security and privacy are perceived as primary obstacles to its wide adoption. Here, the authors outline several critical security challenges and motivate further investigation of security solutions for a trustworthy public cloud environment.\n",
            "------------------------------------\n",
            "Title :  Distributed robotic sensor networks: An information-theoretic approach\n",
            "Author/s :  Brian J. Julian, M. Angermann, M. Schwager, D. Rus\n",
            "Venue :  Int. J. Robotics Res.\n",
            "year :  2012\n",
            "Abstract :  In this paper we present an information-theoretic approach to distributively control multiple robots equipped with sensors to infer the state of an environment. The robots iteratively estimate the environment state using a sequential Bayesian filter, while continuously moving along the gradient of mutual information to maximize the informativeness of the observations provided by their sensors. The gradient-based controller is proven to be convergent between observations and, in its most general form, locally optimal. However, the computational complexity of the general form is shown to be intractable, and thus non-parametric methods are incorporated to allow the controller to scale with respect to the number of robots. For decentralized operation, both the sequential Bayesian filter and the gradient-based controller use a novel consensus-based algorithm to approximate the robots’ joint measurement probabilities, even when the network diameter, the maximum in/out degree, and the number of robots are unknown. The approach is validated in two separate hardware experiments each using five quadrotor flying robots, and scalability is emphasized in simulations using 100 robots.\n",
            "------------------------------------\n",
            "Title :  A guide for the utilization of Health Insurance Review and Assessment Service National Patient Samples\n",
            "Author/s :  L. Kim, Jee-Ae Kim, Sanghyun Kim\n",
            "Venue :  Epidemiology and Health\n",
            "year :  2014\n",
            "Abstract :  The claims data of the Health Insurance Review and Assessment Service (HIRA) is an important source of information for healthcare service research. The claims data of HIRA is collected when healthcare service providers submit a claim to HIRA to be reimbursed for a service that they provided to patients. To improve the accessibility of healthcare service researchers to claims data of HIRA, HIRA has developed the Patient Samples which are extracted using a stratified randomized sampling method. The Patient Samples of HIRA consist of five tables: a table for general information (Table 20) containing socio-demographic information such as gender, age and medical aid, indicators for inpatient and outpatient services; a table for specific information on healthcare services provided (Table 30); a table for diagnostic information (Table 40); a table for outpatient prescriptions (Table 53) and a table for information on healthcare service providers (Table of providers). Researchers who are interested in using the Patient Sample data for research can apply via HIRA’s website (https://www.hira.or.kr).\n",
            "------------------------------------\n",
            "Title :  Research Note - Effects of Individual Self-Protection, Industry Self-Regulation, and Government Regulation on Privacy Concerns: A Study of Location-Based Services\n",
            "Author/s :  Heng Xu, H. Teo, B. Tan, Ritu Agarwal\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This study seeks to clarify the nature of control in the context of information privacy to generate insights into the effects of different privacy assurance approaches on context-specific concerns for information privacy. We theorize that such effects are exhibited through mediation by perceived control over personal information and develop arguments in support of the interaction effects involving different privacy assurance approaches (individual self-protection, industry self-regulation, and government legislation). We test the research model in the context of location-based services using data obtained from 178 individuals in Singapore. In general, the results support our core assertion that perceived control over personal information is a key factor affecting context-specific concerns for information privacy. In addition to enhancing our theoretical understanding of the link between control and privacy concerns, these findings have important implications for service providers and consumers as well as for regulatory bodies and technology developers.\n",
            "------------------------------------\n",
            "Title :  Total Variation Spatial Regularization for Sparse Hyperspectral Unmixing\n",
            "Author/s :  Marian-Daniel Iordache, J. Bioucas-Dias, A. Plaza\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2012\n",
            "Abstract :  Spectral unmixing aims at estimating the fractional abundances of pure spectral signatures (also called endmembers) in each mixed pixel collected by a remote sensing hyperspectral imaging instrument. In recent work, the linear spectral unmixing problem has been approached in semisupervised fashion as a sparse regression one, under the assumption that the observed image signatures can be expressed as linear combinations of pure spectra, known a priori and available in a library. It happens, however, that sparse unmixing focuses on analyzing the hyperspectral data without incorporating spatial information. In this paper, we include the total variation (TV) regularization to the classical sparse regression formulation, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Our experimental results, conducted with both simulated and real hyperspectral data sets, indicate the potential of including spatial information (through the TV term) on sparse unmixing formulations for improved characterization of mixed pixels in hyperspectral imagery.\n",
            "------------------------------------\n",
            "Title :  Experimentally induced innovations lead to persistent culture via conformity in wild birds\n",
            "Author/s :  L. Aplin, D. Farine, J. Morand‐Ferron, A. Cockburn, A. Thornton, B. Sheldon\n",
            "Venue :  Nature\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Echo Chambers: Emotional Contagion and Group Polarization on Facebook\n",
            "Author/s :  Michela Del Vicario, G. Vivaldo, Alessandro Bessi, Fabiana Zollo, A. Scala, G. Caldarelli, W. Quattrociocchi\n",
            "Venue :  Scientific Reports\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  \"Best practice\" for patient-centered communication: a narrative review.\n",
            "Author/s :  A. King, R. Hoppe\n",
            "Venue :  Journal of Graduate Medical Education\n",
            "year :  2013\n",
            "Abstract :  BACKGROUND\n",
            "Communicating with patients has long been identified as an important physician competency. More recently, there is a growing consensus regarding the components that define physician-patient communication. There continues to be emphasis on both the need to teach and to assess the communication skills of physicians.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This narrative review aims to summarize the work that has been conducted in physician-patient communication that supports the efficacy of good communications skills. This work may also help to define the physician-patient communication skills that need to be taught and assessed.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "A review of the literature shows it contains impressive evidence supporting positive associations between physician communication behaviors and positive patient outcomes, such as patient recall, patient understanding, and patient adherence to therapy. There is a consensus about what constitutes \"best practice\" for physician communication in medical encounters: (1) fostering the relationship, (2) gathering information, (3) providing information, (4) making decisions, (5) responding to emotions, and (6) enabling disease- and treatment-related behavior.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Evidence supports the importance of communication skills as a dimension of physician competence. Effort to enhance teaching of communication skills to medical trainees likely will require significant changes in instruction at undergraduate and graduate levels, as well as changes in assessing the developing communication skills of physicians. An added critical dimension is faculty understanding of the importance of communication skills, and their commitment to helping trainees develop those skills.\n",
            "------------------------------------\n",
            "Title :  The Pen Is Mightier Than the Keyboard\n",
            "Author/s :  Pam Mueller, Daniel M. Oppenheimer\n",
            "Venue :  Psychology Science\n",
            "year :  2014\n",
            "Abstract :  Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students’ capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers’ tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning.\n",
            "------------------------------------\n",
            "Title :  Online Survival Analysis Software to Assess the Prognostic Value of Biomarkers Using Transcriptomic Data in Non-Small-Cell Lung Cancer\n",
            "Author/s :  B. Győrffy, P. Surowiak, J. Budczies, A. Lánczky\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  In the last decade, optimized treatment for non-small cell lung cancer had lead to improved prognosis, but the overall survival is still very short. To further understand the molecular basis of the disease we have to identify biomarkers related to survival. Here we present the development of an online tool suitable for the real-time meta-analysis of published lung cancer microarray datasets to identify biomarkers related to survival. We searched the caBIG, GEO and TCGA repositories to identify samples with published gene expression data and survival information. Univariate and multivariate Cox regression analysis, Kaplan-Meier survival plot with hazard ratio and logrank P value are calculated and plotted in R. The complete analysis tool can be accessed online at: www.kmplot.com/lung. All together 1,715 samples of ten independent datasets were integrated into the system. As a demonstration, we used the tool to validate 21 previously published survival associated biomarkers. Of these, survival was best predicted by CDK1 (p<1E-16), CD24 (p<1E-16) and CADM1 (p = 7E-12) in adenocarcinomas and by CCNE1 (p = 2.3E-09) and VEGF (p = 3.3E-10) in all NSCLC patients. Additional genes significantly correlated to survival include RAD51, CDKN2A, OPN, EZH2, ANXA3, ADAM28 and ERCC1. In summary, we established an integrated database and an online tool capable of uni- and multivariate analysis for in silico validation of new biomarker candidates in non-small cell lung cancer.\n",
            "------------------------------------\n",
            "Title :  RRED Indices: Reduced Reference Entropic Differencing for Image Quality Assessment\n",
            "Author/s :  R. Soundararajan, A. Bovik\n",
            "Venue :  IEEE Transactions on Image Processing\n",
            "year :  2012\n",
            "Abstract :  We study the problem of automatic “reduced-reference” image quality assessment (QA) algorithms from the point of view of image information change. Such changes are measured between the reference- and natural-image approximations of the distorted image. Algorithms that measure differences between the entropies of wavelet coefficients of reference and distorted images, as perceived by humans, are designed. The algorithms differ in the data on which the entropy difference is calculated and on the amount of information from the reference that is required for quality computation, ranging from almost full information to almost no information from the reference. A special case of these is algorithms that require just a single number from the reference for QA. The algorithms are shown to correlate very well with subjective quality scores, as demonstrated on the Laboratory for Image and Video Engineering Image Quality Assessment Database and the Tampere Image Database. Performance degradation, as the amount of information is reduced, is also studied.\n",
            "------------------------------------\n",
            "Title :  Detecting Rumors from Microblogs with Recurrent Neural Networks\n",
            "Author/s :  Jing Ma, Wei Gao, P. Mitra, Sejeong Kwon, B. Jansen, Kam-Fai Wong, M. Cha\n",
            "Venue :  International Joint Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  Microblogging platforms are an ideal place for spreading rumors and automatically debunking rumors is a crucial problem. To detect rumors, existing approaches have relied on hand-crafted features for employing machine learning algorithms that require daunting manual effort. Upon facing a dubious claim, people dispute its truthfulness by posting various cues over time, which generates long-distance dependencies of evidence. This paper presents a novel method that learns continuous representations of microblog events for identifying rumors. The proposed model is based on recurrent neural networks (RNN) for learning the hidden representations that capture the variation of contextual information of relevant posts over time. Experimental results on datasets from two real-world microblog platforms demonstrate that (1) the RNN method outperforms state-of-the-art rumor detection models that use hand-crafted features; (2) performance of the RNN-based algorithm is further improved via sophisticated recurrent units and extra hidden layers; (3) RNN-based method detects rumors more quickly and accurately than existing techniques, including the leading online rumor debunking services.\n",
            "------------------------------------\n",
            "Title :  Natural Language Processing in Radiology: A Systematic Review.\n",
            "Author/s :  E. Pons, Loes M M Braun, M. Hunink, J. Kors\n",
            "Venue :  Radiology\n",
            "year :  2016\n",
            "Abstract :  Radiological reporting has generated large quantities of digital content within the electronic health record, which is potentially a valuable source of information for improving clinical care and supporting research. Although radiology reports are stored for communication and documentation of diagnostic imaging, harnessing their potential requires efficient and automated information extraction: they exist mainly as free-text clinical narrative, from which it is a major challenge to obtain structured data. Natural language processing (NLP) provides techniques that aid the conversion of text into a structured representation, and thus enables computers to derive meaning from human (ie, natural language) input. Used on radiology reports, NLP techniques enable automatic identification and extraction of information. By exploring the various purposes for their use, this review examines how radiology benefits from NLP. A systematic literature search identified 67 relevant publications describing NLP methods that support practical applications in radiology. This review takes a close look at the individual studies in terms of tasks (ie, the extracted information), the NLP methodology and tools used, and their application purpose and performance results. Additionally, limitations, future challenges, and requirements for advancing NLP in radiology will be discussed.\n",
            "------------------------------------\n",
            "Title :  Magnon transistor for all-magnon data processing\n",
            "Author/s :  A. Chumak, A. Serga, B. Hillebrands\n",
            "Venue :  Nature Communications\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  An Introduction to Information Retrieval\n",
            "Author/s :  S. Ceri, A. Bozzon, Marco Brambilla, Emanuele Della Valle, P. Fraternali, S. Quarteroni\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information loss\n",
            "Author/s :  W. Unruh, R. Wald\n",
            "Venue :  Reports on progress in physics. Physical Society\n",
            "year :  2017\n",
            "Abstract :  The complete gravitational collapse of a body in general relativity will result in the formation of a black hole. Although the black hole is classically stable, quantum particle creation processes will result in the emission of Hawking radiation to infinity and corresponding mass loss of the black hole, eventually resulting in the complete evaporation of the black hole. Semiclassical arguments strongly suggest that, in the process of black hole formation and evaporation, a pure quantum state will evolve to a mixed state, i.e. there will be ‘information loss’. There has been considerable controversy over this issue for more than 40 years. In this review, we present the arguments in favor of information loss, and analyze some of the counter-arguments and alternative possibilities.\n",
            "------------------------------------\n",
            "Title :  Supplier Encroachment under Asymmetric Information\n",
            "Author/s :  Z. Li, S. Gilbert, Guoming Lai\n",
            "Venue :  Management Sciences\n",
            "year :  2012\n",
            "Abstract :  Prior literature has shown that, for a symmetric information setting, supplier encroachment into a reseller's market can mitigate double marginalization and benefit both the supplier and the reseller. This paper extends the investigation of supplier encroachment to the environment where the reseller might be better informed than the supplier. We find that the launch of the supplier's direct channel can result in costly signaling behavior on the part of the reseller, in which he reduces his order quantity when the market size is small. Such a downward order distortion can amplify double marginalization. As a result, in addition to the “win--win” and “win--lose” outcomes for the supplier and the reseller, supplier encroachment can also lead to “lose--lose” and “lose--win” outcomes, particularly when the reseller has a significant efficiency advantage in the selling process and the prior probability of a large market is low. We further explore the implications of those findings for information management in supply chains. Complementing the conventional understanding, we show that with the ability to encroach, the supplier may prefer to sell to either a better informed or an uninformed reseller in different scenarios. On the other hand, as a result of a supplier developing encroachment capability, a reseller either may choose not to develop an advanced informational capability or may become more willing to find a means of credibly sharing his information. \n",
            " \n",
            "This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  Toward Massive, Ultrareliable, and Low-Latency Wireless Communication With Short Packets\n",
            "Author/s :  G. Durisi, T. Koch, P. Popovski\n",
            "Venue :  Proceedings of the IEEE\n",
            "year :  2015\n",
            "Abstract :  Most of the recent advances in the design of high-speed wireless systems are based on information-theoretic principles that demonstrate how to efficiently transmit long data packets. However, the upcoming wireless systems, notably the fifth-generation (5G) system, will need to support novel traffic types that use short packets. For example, short packets represent the most common form of traffic generated by sensors and other devices involved in machine-to-machine (M2M) communications. Furthermore, there are emerging applications in which small packets are expected to carry critical information that should be received with low latency and ultrahigh reliability. Current wireless systems are not designed to support short-packet transmissions. For example, the design of current systems relies on the assumption that the metadata (control information) is of negligible size compared to the actual information payload. Hence, transmitting metadata using heuristic methods does not affect the overall system performance. However, when the packets are short, metadata may be of the same size as the payload, and the conventional methods to transmit it may be highly suboptimal. In this paper, we review recent advances in information theory, which provide the theoretical principles that govern the transmission of short packets. We then apply these principles to three exemplary scenarios (the two-way channel, the downlink broadcast channel, and the uplink random access channel), thereby illustrating how the transmission of control information can be optimized when the packets are short. The insights brought by these examples suggest that new principles are needed for the design of wireless protocols supporting short packets. These principles will have a direct impact on the system design.\n",
            "------------------------------------\n",
            "Title :  Explanatory Factors of Integrated Sustainability and Financial Reporting\n",
            "Author/s :  José-Valeriano Frías-Aceituno, Lázaro Rodríguez‐Ariza, I. García‐Sánchez\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  The complexity of the business world has led to growing demands being made of companies regarding the information provided on their financial performance, corporate governance and contribution to developing sustainability. In response, some leading companies have begun to publish integrated reporting, in the form of a document providing a coherent summary of this information, thus facilitating stakeholder engagement. \n",
            " \n",
            "This paper examines the validity of the hypotheses of the theories of agency and of signalling, and analyses the political costs and those borne by owners in voluntarily developing this new type of business document. More specifically, in order to determine their prevalence among the suggested reasons for these paradigms, we analyse the effect of industry concentration, together with other factors, in the development of integrated reporting. \n",
            " \n",
            "The analysis of a non-balanced sample of 1590 international companies for the years 2008–2010, in which a logistic regression methodology is applied to panel data, reveals the negative impact of industry concentration on the development of a more pluralist report, simultaneously taking into account stakeholders, sustainability and the long-term viewpoint, as well as questions of responsible investment, business ethics and transparency. Copyright © 2012 John Wiley & Sons, Ltd and ERP Environment\n",
            "------------------------------------\n",
            "Title :  miRBase: from microRNA sequences to function\n",
            "Author/s :  Ana Kozomara, Maria Birgaoanu, S. Griffiths-Jones\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2018\n",
            "Abstract :  Abstract miRBase catalogs, names and distributes microRNA gene sequences. The latest release of miRBase (v22) contains microRNA sequences from 271 organisms: 38 589 hairpin precursors and 48 860 mature microRNAs. We describe improvements to the database and website to provide more information about the quality of microRNA gene annotations, and the cellular functions of their products. We have collected 1493 small RNA deep sequencing datasets and mapped a total of 5.5 billion reads to microRNA sequences. The read mapping patterns provide strong support for the validity of between 20% and 65% of microRNA annotations in different well-studied animal genomes, and evidence for the removal of >200 sequences from the database. To improve the availability of microRNA functional information, we are disseminating Gene Ontology terms annotated against miRBase sequences. We have also used a text-mining approach to search for microRNA gene names in the full-text of open access articles. Over 500 000 sentences from 18 542 papers contain microRNA names. We score these sentences for functional information and link them with 12 519 microRNA entries. The sentences themselves, and word clouds built from them, provide effective summaries of the functional information about specific microRNAs. miRBase is publicly and freely available at http://mirbase.org/.\n",
            "------------------------------------\n",
            "Title :  Learning to Explain: An Information-Theoretic Perspective on Model Interpretation\n",
            "Author/s :  Jianbo Chen, Le Song, M. Wainwright, Michael I. Jordan\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2018\n",
            "Abstract :  We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.\n",
            "------------------------------------\n",
            "Title :  HMDB 4.0: the human metabolome database for 2018\n",
            "Author/s :  D. Wishart, Y. D. Feunang, A. Marcu, Anchi Guo, Kevin Y. H. Liang, R. Vázquez-Fresno, Tanvir Sajed, Daniel Johnson, Carin Li, N. Karu, Zinat Sayeeda, Elvis J. Lo, Nazanin Assempour, M. Berjanskii, Sandeep Singhal, David Arndt, Yongjie Liang, Hasan Badran, J. Grant, Arnau Serra-Cayuela, Yifeng Liu, R. Mandal, V. Neveu, Allison Pon, Craig K. Knox, Michael Wilson, C. Manach, A. Scalbert\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2017\n",
            "Abstract :  Abstract The Human Metabolome Database or HMDB (www.hmdb.ca) is a web-enabled metabolomic database containing comprehensive information about human metabolites along with their biological roles, physiological concentrations, disease associations, chemical reactions, metabolic pathways, and reference spectra. First described in 2007, the HMDB is now considered the standard metabolomic resource for human metabolic studies. Over the past decade the HMDB has continued to grow and evolve in response to emerging needs for metabolomics researchers and continuing changes in web standards. This year's update, HMDB 4.0, represents the most significant upgrade to the database in its history. For instance, the number of fully annotated metabolites has increased by nearly threefold, the number of experimental spectra has grown by almost fourfold and the number of illustrated metabolic pathways has grown by a factor of almost 60. Significant improvements have also been made to the HMDB’s chemical taxonomy, chemical ontology, spectral viewing, and spectral/text searching tools. A great deal of brand new data has also been added to HMDB 4.0. This includes large quantities of predicted MS/MS and GC–MS reference spectral data as well as predicted (physiologically feasible) metabolite structures to facilitate novel metabolite identification. Additional information on metabolite-SNP interactions and the influence of drugs on metabolite levels (pharmacometabolomics) has also been added. Many other important improvements in the content, the interface, and the performance of the HMDB website have been made and these should greatly enhance its ease of use and its potential applications in nutrition, biochemistry, clinical chemistry, clinical genetics, medicine, and metabolomics science.\n",
            "------------------------------------\n",
            "Title :  Deformable Medical Image Registration: A Survey\n",
            "Author/s :  A. Sotiras, C. Davatzikos, N. Paragios\n",
            "Venue :  IEEE Transactions on Medical Imaging\n",
            "year :  2013\n",
            "Abstract :  Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner.\n",
            "------------------------------------\n",
            "Title :  Semi-Supervised Hashing for Large-Scale Search\n",
            "Author/s :  Jun Wang, Sanjiv Kumar, Shih-Fu Chang\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2012\n",
            "Abstract :  Hashing-based approximate nearest neighbor (ANN) search in huge databases has become popular due to its computational and memory efficiency. The popular hashing methods, e.g., Locality Sensitive Hashing and Spectral Hashing, construct hash functions based on random or principal projections. The resulting hashes are either not very accurate or are inefficient. Moreover, these methods are designed for a given metric similarity. On the contrary, semantic similarity is usually given in terms of pairwise labels of samples. There exist supervised hashing methods that can handle such semantic similarity, but they are prone to overfitting when labeled data are small or noisy. In this work, we propose a semi-supervised hashing (SSH) framework that minimizes empirical error over the labeled set and an information theoretic regularizer over both labeled and unlabeled sets. Based on this framework, we present three different semi-supervised hashing methods, including orthogonal hashing, nonorthogonal hashing, and sequential hashing. Particularly, the sequential hashing method generates robust codes in which each hash function is designed to correct the errors made by the previous ones. We further show that the sequential learning paradigm can be extended to unsupervised domains where no labeled pairs are available. Extensive experiments on four large datasets (up to 80 million samples) demonstrate the superior performance of the proposed SSH methods over state-of-the-art supervised and unsupervised hashing techniques.\n",
            "------------------------------------\n",
            "Title :  At Least Bias Is Bipartisan: A Meta-Analytic Comparison of Partisan Bias in Liberals and Conservatives\n",
            "Author/s :  P. Ditto, Brittany S. Liu, Cory J. Clark, S. Wojcik, Eric Chen, R. Grady, Jared B. Celniker, Joanne F. Zinger\n",
            "Venue :  Perspectives on Psychological Science\n",
            "year :  2017\n",
            "Abstract :  Both liberals and conservatives accuse their political opponents of partisan bias, but is there empirical evidence that one side of the political aisle is indeed more biased than the other? To address this question, we meta-analyzed the results of 51 experimental studies, involving over 18,000 participants, that examined one form of partisan bias—the tendency to evaluate otherwise identical information more favorably when it supports one’s political beliefs or allegiances than when it challenges those beliefs or allegiances. Two hypotheses based on previous literature were tested: an asymmetry hypothesis (predicting greater partisan bias in conservatives than in liberals) and a symmetry hypothesis (predicting equal levels of partisan bias in liberals and conservatives). Mean overall partisan bias was robust (r = .245), and there was strong support for the symmetry hypothesis: Liberals (r = .235) and conservatives (r = .255) showed no difference in mean levels of bias across studies. Moderator analyses reveal this pattern to be consistent across a number of different methodological variations and political topics. Implications of the current findings for the ongoing ideological symmetry debate and the role of partisan bias in scientific discourse and political conflict are discussed.\n",
            "------------------------------------\n",
            "Title :  Mining high utility itemsets without candidate generation\n",
            "Author/s :  Mengchi Liu, Jun-Feng Qu\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2012\n",
            "Abstract :  High utility itemsets refer to the sets of items with high utility like profit in a database, and efficient mining of high utility itemsets plays a crucial role in many real-life applications and is an important research issue in data mining area. To identify high utility itemsets, most existing algorithms first generate candidate itemsets by overestimating their utilities, and subsequently compute the exact utilities of these candidates. These algorithms incur the problem that a very large number of candidates are generated, but most of the candidates are found out to be not high utility after their exact utilities are computed. In this paper, we propose an algorithm, called HUI-Miner (High Utility Itemset Miner), for high utility itemset mining. HUI-Miner uses a novel structure, called utility-list, to store both the utility information about an itemset and the heuristic information for pruning the search space of HUI-Miner. By avoiding the costly generation and utility computation of numerous candidate itemsets, HUI-Miner can efficiently mine high utility itemsets from the utility-lists constructed from a mined database. We compared HUI-Miner with the state-of-the-art algorithms on various databases, and experimental results show that HUI-Miner outperforms these algorithms in terms of both running time and memory consumption.\n",
            "------------------------------------\n",
            "Title :  Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions\n",
            "Author/s :  Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2017\n",
            "Abstract :  \n",
            " \n",
            " Distant supervision for relation extraction is an efficient method to scale relation extraction to very large corpora which contains thousands of relations. However, the existing approaches have flaws on selecting valid instances and lack of background knowledge about the entities. In this paper, we propose a sentence-level attention model to select the valid instances, which makes full use of the supervision information from knowledge bases. And we extract entity descriptions from Freebase and Wikipedia pages to supplement background knowledge for our task. The background knowledge not only provides more information for predicting relations, but also brings better entity representations for the attention module. We conduct three experiments on a widely used dataset and the experimental results show that our approach outperforms all the baseline systems significantly.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Inefficient Hiring in Entry-Level Labor Markets\n",
            "Author/s :  Amanda Pallais\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Hiring inexperienced workers generates information about their abilities. If this information is public, workers obtain its benefits. If workers cannot compensate firms for hiring them, firms will hire too few inexperienced workers. I determine the effects of hiring workers and revealing more information about their abilities through a field experiment in an online marketplace. I hired 952 randomly-selected workers, giving them either detailed or coarse public evaluations. Both hiring workers and providing more detailed evaluations substantially improved workers' subsequent employment outcomes. Under plausible assumptions, the experiment's market-level benefits exceeded its cost, suggesting that some experimental workers had been inefficiently unemployed.\n",
            "------------------------------------\n",
            "Title :  Humans use directed and random exploration to solve the explore-exploit dilemma.\n",
            "Author/s :  Robert C. Wilson, A. Geana, J. M. White, Elliot A. Ludvig, J. Cohen\n",
            "Venue :  Journal of experimental psychology. General\n",
            "year :  2014\n",
            "Abstract :  All adaptive organisms face the fundamental tradeoff between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration). Theory suggests at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. In this work we investigated the extent to which humans use these two strategies. In our \"Horizon task,\" participants made explore-exploit decisions in two contexts that differed in the number of choices that they would make in the future (the time horizon). Participants were allowed to make either a single choice in each game (horizon 1), or 6 sequential choices (horizon 6), giving them more opportunity to explore. By modeling the behavior in these two conditions, we were able to measure exploration-related changes in decision making and quantify the contributions of the two strategies to behavior. We found that participants were more information seeking and had higher decision noise with the longer horizon, suggesting that humans use both strategies to solve the exploration-exploitation dilemma. We thus conclude that both information seeking and choice variability can be controlled and put to use in the service of exploration.\n",
            "------------------------------------\n",
            "Title :  Best Care at Lower Cost: The Path to Continuously Learning Health Care in America\n",
            "Author/s :  M. Smith, R. Saunders, Leigh Stuckhardt, J. McGinnis\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  America's health care system has become too complex and costly to continue business as usual. Best Care at Lower Cost explains that inefficiencies, an overwhelming amount of data, and other economic and quality barriers hinder progress in improving health and threaten the nation's economic stability and global competitiveness. According to this report, the knowledge and tools exist to put the health system on the right course to achieve continuous improvement and better quality care at a lower cost. The costs of the system's current inefficiency underscore the urgent need for a systemwide transformation. About 30 percent of health spending in 2009--roughly $750 billion--was wasted on unnecessary services, excessive administrative costs, fraud, and other problems. Moreover, inefficiencies cause needless suffering. By one estimate, roughly 75,000 deaths might have been averted in 2005 if every state had delivered care at the quality level of the best performing state. This report states that the way health care providers currently train, practice, and learn new information cannot keep pace with the flood of research discoveries and technological advances. About 75 million Americans have more than one chronic condition, requiring coordination among multiple specialists and therapies, which can increase the potential for miscommunication, misdiagnosis, potentially conflicting interventions, and dangerous drug interactions. Best Care at Lower Cost emphasizes that a better use of data is a critical element of a continuously improving health system, such as mobile technologies and electronic health records that offer significant potential to capture and share health data better. In order for this to occur, the National Coordinator for Health Information Technology, IT developers, and standard-setting organizations should ensure that these systems are robust and interoperable. Clinicians and care organizations should fully adopt these technologies, and patients should be encouraged to use tools, such as personal health information portals, to actively engage in their care. This book is a call to action that will guide health care providers; administrators; caregivers; policy makers; health professionals; federal, state, and local government agencies; private and public health organizations; and educational institutions.... Download ebook, read file pdf The Path to Continuously Learning Health Care in America\n",
            "------------------------------------\n",
            "Title :  PhosphoSitePlus, 2014: mutations, PTMs and recalibrations\n",
            "Author/s :  P. Hornbeck, Bin Zhang, Beth Murray, J. Kornhauser, V. Latham, E. Skrzypek\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2014\n",
            "Abstract :  PhosphoSitePlus® (PSP, http://www.phosphosite.org/), a knowledgebase dedicated to mammalian post-translational modifications (PTMs), contains over 330 000 non-redundant PTMs, including phospho, acetyl, ubiquityl and methyl groups. Over 95% of the sites are from mass spectrometry (MS) experiments. In order to improve data reliability, early MS data have been reanalyzed, applying a common standard of analysis across over 1 000 000 spectra. Site assignments with P > 0.05 were filtered out. Two new downloads are available from PSP. The ‘Regulatory sites’ dataset includes curated information about modification sites that regulate downstream cellular processes, molecular functions and protein-protein interactions. The ‘PTMVar’ dataset, an intersect of missense mutations and PTMs from PSP, identifies over 25 000 PTMVars (PTMs Impacted by Variants) that can rewire signaling pathways. The PTMVar data include missense mutations from UniPROTKB, TCGA and other sources that cause over 2000 diseases or syndromes (MIM) and polymorphisms, or are associated with hundreds of cancers. PTMVars include 18 548 phosphorlyation sites, 3412 ubiquitylation sites, 2316 acetylation sites, 685 methylation sites and 245 succinylation sites.\n",
            "------------------------------------\n",
            "Title :  Design Guidelines for Spatial Modulation\n",
            "Author/s :  Ping Yang, M. Renzo, Yue Xiao, Shaoqian Li, L. Hanzo\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2015\n",
            "Abstract :  A new class of low-complexity, yet energy-efficient Multiple-Input Multiple-Output (MIMO) transmission techniques, namely, the family of Spatial Modulation (SM) aided MIMOs (SM-MIMO), has emerged. These systems are capable of exploiting the spatial dimensions (i.e., the antenna indices) as an additional dimension invoked for transmitting information, apart from the traditional Amplitude and Phase Modulation (APM). SM is capable of efficiently operating in diverse MIMO configurations in the context of future communication systems. It constitutes a promising transmission candidate for large-scale MIMO design and for the indoor optical wireless communication while relying on a single-Radio Frequency (RF) chain. Moreover, SM may be also viewed as an entirely new hybrid modulation scheme, which is still in its infancy. This paper aims for providing a general survey of the SM design framework as well as of its intrinsic limits. In particular, we focus our attention on the associated transceiver design, on spatial constellation optimization, on link adaptation techniques, on distributed/cooperative protocol design issues, and on their meritorious variants.\n",
            "------------------------------------\n",
            "Title :  Practical extraction of disaster-relevant information from social media\n",
            "Author/s :  Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, P. Meier\n",
            "Venue :  The Web Conference\n",
            "year :  2013\n",
            "Abstract :  During times of disasters online users generate a significant amount of data, some of which are extremely valuable for relief efforts. In this paper, we study the nature of social-media content generated during two different natural disasters. We also train a model based on conditional random fields to extract valuable information from such content. We evaluate our techniques over our two datasets through a set of carefully designed experiments. We also test our methods over a non-disaster dataset to show that our extraction model is useful for extracting information from socially-generated content in general.\n",
            "------------------------------------\n",
            "Title :  Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne\n",
            "Author/s :  James Allan, W. Bruce Croft, Alistair Moffat, M. Sanderson\n",
            "Venue :  SIGF\n",
            "year :  2012\n",
            "Abstract :  During a three-day workshop in February 2012, 45 Information Retrieval researchers met to discuss long-range challenges and opportunities within the field. The result of the workshop is a diverse set of research directions, project ideas, and challenge areas. This report describes the workshop format, provides summaries of broad themes that emerged, includes brief descriptions of all the ideas, and provides detailed discussion of six proposals that were voted \"most interesting\" by the participants. Key themes include the need to: move beyond ranked lists of documents to support richer dialog and presentation, represent the context of search and searchers, provide richer support for information seeking, enable retrieval of a wide range of structured and unstructured content, and develop new evaluation methodologies.\n",
            "------------------------------------\n",
            "Title :  Enabling Flexibility in Process-Aware Information Systems: Challenges, Methods, Technologies\n",
            "Author/s :  M. Reichert, B. Weber\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  In todays dynamic business world, the success of a company increasingly depends on its ability to react to changes in its environment in a quick and flexible way. Companies have therefore identified process agility as a competitive advantage to address business trends like increasing product and service variability or faster time to market, and to ensure business IT alignment. Along this trend, a new generation of information systems has emergedso-called process-aware information systems (PAIS), like workflow management systems, case handling tools, and service orchestration engines. With this book, Reichert and Weber address these flexibility needs and provide an overview of PAIS with a strong focus on methods and technologies fostering flexibility for all phases of the process lifecycle (i.e., modeling, configuration, execution and evolution). Their presentation is divided into six parts. Part I starts with an introduction of fundamental PAIS concepts and establishes the context of process flexibility in the light of practical scenarios. Part II focuses on flexibility support for pre-specified processes, the currently predominant paradigm in the field of business process management (BPM). Part III details flexibility support for loosely specified processes, which only partially specify the process model at build-time, while decisions regarding the exact specification of certain model parts are deferred to the run-time. Part IV deals with user- and data-driven processes, which aim at a tight integration of processes and data, and hence enable an increased flexibility compared to traditional PAIS. Part V introduces existing technologies and systems for the realization of a flexible PAIS. Finally, Part VI summarizes the main ideas of this book and gives an outlook on advanced flexibility issues. The bookstarget groups include researchers, PhD students and Master students in the field of information systems. After reading the book, they will better understand PAIS flexibility aspects. To support the easy use as a textbook, a series of exercises is provided at the end of each chapter and slides and further teaching material are available on the books web site www.flexible-processes.com. Professionals specializing in business process management (BPM) who want to obtain a good understanding of flexibility challenges in BPM and state-of-the-art solutions will also benefit from the presentations of open source as well as commercial process management systems and related practical scenarios.\n",
            "------------------------------------\n",
            "Title :  Suspense and Surprise\n",
            "Author/s :  Jeffrey C. Ely, A. Frankel, Emir Kamenica\n",
            "Venue :  Journal of Political Economy\n",
            "year :  2015\n",
            "Abstract :  We model demand for noninstrumental information, drawing on the idea that people derive entertainment utility from suspense and surprise. A period has more suspense if the variance of the next period’s beliefs is greater. A period has more surprise if the current belief is further from the last period’s belief. Under these definitions, we analyze the optimal way to reveal information over time so as to maximize expected suspense or surprise experienced by a Bayesian audience. We apply our results to the design of mystery novels, political primaries, casinos, game shows, auctions, and sports.\n",
            "------------------------------------\n",
            "Title :  Health-Related Internet Use by Children and Adolescents: Systematic Review\n",
            "Author/s :  Eunhee Park, M. Kwon\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2018\n",
            "Abstract :  Background The internet is widely used by children and adolescents, who generally have a high level of competency with technology. Thus, the internet has become a great resource for supporting youth self-care and health-related services. However, few studies have explored adolescents’ internet use for health-related matters. Objective The objective of this systematic literature review was to examine the phenomenon of children and adolescents’ health-related internet use and to identify gaps in the research. Methods A total of 19 studies were selected from a search of major electronic databases: PubMed, Cumulative Index of Nursing and Allied Health Literature, and PsycINFO using the following search terms: “health-related internet use,” “eHealth,” “Internet use for health-related purpose,” “Web-based resource,” “health information seeking,” and “online resource,” combined with “child,” “adolescent,” “student,” “youth,” and “teen.” The children’s and adolescents’ ages were limited to 24 years and younger. The search was conducted from September 2015 to October 2017. The studies identified to contain youth (<24 years) health-related internet use were all published in peer-reviewed journals in the past 10 years; these studies examined general internet use seeking health care services, resources, information, or using the internet for health promotion and self-care. Studies were excluded if they explored the role of the internet as a modality for surveys, recruitment, or searching for relevant literature without specifically aiming to study participants’ health-related internet use; focused solely on quality assurance for specific websites; or were designed to test a specific internet-based intervention. Results Interesting patterns in adolescents’ health-related internet use, such as seeking preventative health care and specific information about medical issues, were identified. Quantitative studies reported rates of the internet use and access among youth, and the purpose and patterns of health-related internet use among youth were identified. A major objective of health-related internet use is to gain information, but there are inconsistencies in adolescents’ perceptions of health-related internet use. Conclusions This study’s findings provide important information on how youth seek information and related support systems for their health care on the internet. The conceptual and methodological limitations of the identified studies, such as the lack of a theoretical background and unrepresentative samples, are discussed, and gaps within the studies are identified for future research. This review also suggests important features for potential Web-based health interventions for children and adolescents.\n",
            "------------------------------------\n",
            "Title :  Integrated information theory of consciousness: an updated account.\n",
            "Author/s :  G. Tononi\n",
            "Venue :  Archives Italiennes de Biologie\n",
            "year :  2012\n",
            "Abstract :  This article presents an updated account of integrated information theory of consciousness (liT) and some of its implications. /IT stems from thought experiments that lead to phenomenological axioms (existence, compositionality, information, integration, exclusion) and corresponding ontological postulates. The information axiom asserts that every experience is spec~fic - it is what it is by differing in its particular way from a large repertoire of alternatives. The integration axiom asserts that each experience is unified- it cannot be reduced to independent components. The exclusion axiom asserts that every experience is definite - it is limited to particular things and not others and flows at a particular speed and resolution. /IT formalizes these intuitions with postulates. The information postulate states that only \"differences that make a difference\" from the intrinsic perpective of a system matter: a mechanism generates cause-effect information if its present state has selective past causes and selective future effects within a system. The integration postulate states that only information that is irreducible matters: mechanisms generate integrated information only to the extent that the information they generate cannot be partitioned into that generated within independent components. The exclusion postulate states that only maxima of integrated information matter: a mechanism specifies only one maximally irreducible set of past causes and future effects - a concept. A complex is a set of elements specifying a maximally irreducible constellation of concepts, where the maximum is evaluated over elements and at the optimal spatiatemporal scale. Its concepts specify a maximally integrated conceptual information structure or quale, which is identical with an experience. Finally, changes in information integration upon exposure to the environment reflect a system's ability to match the causal structure of the world. After introducing an updated definition of information integration and related quantities, the article presents some theoretical considerations about the relationship between information and causation and about the relational structure of concepts within a qua/e. It also explores the relationship between the temporal grain size of information integration and the dynamic of metastable states in the corticothalamic complex. Finally, it summarizes how liT accounts for empirical findings about the neural substrate of consciousness, and how various aspects of phenomenology may in principle be addressed in terms of the geometry of information integration.\n",
            "------------------------------------\n",
            "Title :  High-speed spelling with a noninvasive brain–computer interface\n",
            "Author/s :  Xiaogang Chen, Yijun Wang, M. Nakanishi, Xiaorong Gao, T. Jung, Shangkai Gao\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance Brain–computer interface (BCI) technology provides a new communication channel. However, current applications have been severely limited by low communication speed. This study reports a noninvasive brain speller that achieved a multifold increase in information transfer rate compared with other existing systems. Based on extremely precise coding of frequency and phase in single-trial steady-state visual evoked potentials, this study developed a new joint frequency-phase modulation method and a user-specific decoding algorithm to implement synchronous modulation and demodulation of electroencephalograms. The resulting speller obtained high spelling rates up to 60 characters (∼12 words) per minute. The proposed methodological framework of high-speed BCI can lead to numerous applications in both patients with motor disabilities and healthy people. The past 20 years have witnessed unprecedented progress in brain–computer interfaces (BCIs). However, low communication rates remain key obstacles to BCI-based communication in humans. This study presents an electroencephalogram-based BCI speller that can achieve information transfer rates (ITRs) up to 5.32 bits per second, the highest ITRs reported in BCI spellers using either noninvasive or invasive methods. Based on extremely high consistency of frequency and phase observed between visual flickering signals and the elicited single-trial steady-state visual evoked potentials, this study developed a synchronous modulation and demodulation paradigm to implement the speller. Specifically, this study proposed a new joint frequency-phase modulation method to tag 40 characters with 0.5-s-long flickering signals and developed a user-specific target identification algorithm using individual calibration data. The speller achieved high ITRs in online spelling tasks. This study demonstrates that BCIs can provide a truly naturalistic high-speed communication channel using noninvasively recorded brain activities.\n",
            "------------------------------------\n",
            "Title :  Health literacy -- a heterogeneous phenomenon: a literature review.\n",
            "Author/s :  L. Mårtensson, G. Hensing\n",
            "Venue :  Scandinavian Journal of Caring Sciences\n",
            "year :  2012\n",
            "Abstract :  BACKGROUND AND AIM\n",
            "A growing responsibility on the part of individuals to make decisions in health issues implies the need of access to health information and personal skills to comprehend the information. Health literacy comprises skills in obtaining, understanding and acting on information about health issues in ways that promote and maintain health. A lack of health literacy may have effects at both the individual and societal levels. There are thus reasons for health care professionals to gain a comprehensive understanding of health literacy. The aim of this review was to explore how health literacy is described in the scientific literature and to give a synthesis of its different meanings.\n",
            "\n",
            "\n",
            "METHODS\n",
            "The review was based on approximately 200 scientific articles published 2000-2008. The analysis process was inspired by the methods of narrative literature review.\n",
            "\n",
            "\n",
            "FINDINGS AND CONCLUSIONS\n",
            "Two different approaches to health literacy became visible, one in which health literacy is expressed as a polarized phenomenon, focusing on the extremes of low and high health literacy. The definitions of health literacy in this approach are characterized by a functional understanding, pointing out certain basic skills needed to understand health information. The other approach represents a complex understanding of health literacy, acknowledging a broadness of skills in interaction with the social and cultural contexts, which means that an individual's health literacy may fluctuate from one day to another according to the context. The complex approach stresses the interactive and critical skills needed to use information or knowledge as a basis for appropriate health decisions. We conclude that health literacy is a heterogeneous phenomenon that has significance for both the individual and society. Future research will aim at the development of assessments that capture the broadness of skills and agents characteristic for health literacy as a complex phenomenon.\n",
            "------------------------------------\n",
            "Title :  Neural Evidence for a Distinction between Short-term Memory and the Focus of Attention\n",
            "Author/s :  J. Lewis-Peacock, A. Drysdale, K. Oberauer, B. Postle\n",
            "Venue :  Journal of Cognitive Neuroscience\n",
            "year :  2012\n",
            "Abstract :  It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.\n",
            "------------------------------------\n",
            "Title :  Wireless Information and Power Transfer With Full Duplex Relaying\n",
            "Author/s :  C. Zhong, H. Suraweera, G. Zheng, I. Krikidis, Zhaoyang Zhang\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2014\n",
            "Abstract :  We consider a dual-hop full-duplex relaying system, where the energy constrained relay node is powered by radio frequency signals from the source using the time-switching architecture, both the amplify-and-forward and decode-and-forward relaying protocols are studied. Specifically, we provide an analytical characterization of the achievable throughput of three different communication modes, namely, instantaneous transmission, delay-constrained transmission, and delay tolerant transmission. In addition, the optimal time split is studied for different transmission modes. Our results reveal that, when the time split is optimized, the full-duplex relaying could substantially boost the system throughput compared to the conventional half-duplex relaying architecture for all three transmission modes. In addition, it is shown that the instantaneous transmission mode attains the highest throughput. However, compared to the delay-constrained transmission mode, the throughput gap is rather small. Unlike the instantaneous time split optimization which requires instantaneous channel state information, the optimal time split in the delay-constrained transmission mode depends only on the statistics of the channel, hence, is suitable for practical implementations.\n",
            "------------------------------------\n",
            "Title :  Structure-based prediction of protein-protein interactions on a genome-wide scale\n",
            "Author/s :  Q. Zhang, D. Petrey, L. Deng, Liao Qiang, Yu Shi, Chan Aye Thu, B. Bisikirska, C. Lefebvre, D. Accili, T. Hunter, T. Maniatis, A. Califano, B. Honig\n",
            "Venue :  Nature\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms\n",
            "Author/s :  K. Crawford, J. Schultz\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The rise of “big data” analytics in the private sector poses new challenges for privacy advocates. Unlike previous computational models that exploit personally identifiable information (PII) directly, such as behavioral targeting, big data has exploded the definition of PII to make many more sources of data personally identifiable. By analyzing primarily metadata, such as a set of predictive or aggregated findings without displaying or distributing the originating data, big data approaches often operate outside of current privacy protections (Rubinstein 2013; Tene and Polonetsky 2012), effectively marginalizing regulatory schema. Big data presents substantial privacy concerns – risks of bias or discrimination based on the inappropriate generation of personal data – a risk we call “predictive privacy harm.” Predictive analysis and categorization can pose a genuine threat to individuals, especially when it is performed without their knowledge or consent. While not necessarily a harm that falls within the conventional “invasion of privacy” boundaries, such harms still center on an individual’s relationship with data about her. Big data approaches need not rely on having a person’s PII directly: a combination of techniques from social network analysis, interpreting online behaviors and predictive modeling can create a detailed, intimate picture with a high degree of accuracy. Furthermore, harms can still result when such techniques are done poorly, rendering an inaccurate picture that nonetheless is used to impact on a person’s life and livelihood. In considering how to respond to evolving big data practices, we began by examining the existing rights that individuals have to see and review records pertaining to them in areas such as health and credit information. But it is clear that these existing systems are inadequate to meet current big data challenges. Fair Information Privacy Practices and other notice-and-choice regimes fail to protect against predictive privacy risks in part because individuals are rarely aware of how their individual data is being used to their detriment, what determinations are being made about them, and because at various points in big data processes, the relationship between predictive privacy harms and originating PII may be complicated by multiple technical processes and the involvement of third parties. Thus, past privacy regulations and rights are ill equipped to face current and future big data challenges.We propose a new approach to mitigating predictive privacy harms – that of a right to procedural data due process. In the Anglo-American legal tradition, procedural due process prohibits the government from depriving an individual’s rights to life, liberty, or property without affording her access to certain basic procedural components of the adjudication process – including the rights to review and contest the evidence at issue, the right to appeal any adverse decision, the right to know the allegations presented and be heard on the issues they raise. Procedural due process also serves as an enforcer of separation of powers, prohibiting those who write laws from also adjudicating them.While some current privacy regimes offer nominal due process-like mechanisms in relation to closely defined types of data, these rarely include all of the necessary components to guarantee fair outcomes and arguably do not apply to many kinds of big data systems (Terry 2012). A more rigorous framework is needed, particularly given the inherent analytical assumptions and methodological biases built into many big data systems (boyd and Crawford 2012). Building on previous thinking about due process for public administrative computer systems (Steinbock 2005; Citron 2010), we argue that individuals who are privately and often secretly “judged” by big data should have similar rights to those judged by the courts with respect to how their personal data has been used in such adjudications. Using procedural due process principles, we analogize a system of regulation that would provide such rights against private big data actors.\n",
            "------------------------------------\n",
            "Title :  News, Politics, and Negativity\n",
            "Author/s :  S. Soroka, S. McAdams\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Work in political communication has discussed the ongoing predominance of negative news, but has offered few convincing accounts for this focus. A growing body of literature shows that humans regularly pay more attention to negative information than to positive information, however. This article argues that we should view the nature of news content in part as a consequence of this asymmetry bias observed in human behavior. A psychophysiological experiment capturing viewers’ reactions to actual news content shows that negative news elicits stronger and more sustained reactions than does positive news. Results are discussed as they pertain to political behavior and communication, and to politics and political institutions more generally.\n",
            "------------------------------------\n",
            "Title :  Situation Awareness Misconceptions and Misunderstandings\n",
            "Author/s :  M. Endsley\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Situation awareness (SA) has become a widely used construct within the human factors community, the focus of considerable research over the past 25 years. This research has been used to drive the development of advanced information displays, the design of automated systems, information fusion algorithms, and new training approaches for improving SA in individuals and teams. In recent years, a number of papers criticized the Endsley model of SA on various grounds. I review those criticisms here and show them to be based on misunderstandings of the model. I also review several new models of SA, including situated SA, distributed SA, and sensemaking, in light of this discussion and show how they compare to existing models of SA in individuals and teams.\n",
            "------------------------------------\n",
            "Title :  How can i improve my app? Classifying user reviews for software maintenance and evolution\n",
            "Author/s :  Sebastiano Panichella, Andrea Di Sorbo, Emitza Guzman, C. A. Visaggio, G. Canfora, H. Gall\n",
            "Venue :  IEEE International Conference on Software Maintenance and Evolution\n",
            "year :  2015\n",
            "Abstract :  App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings. These platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. Previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. In this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) Natural Language Processing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify app reviews into the proposed categories. We show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).\n",
            "------------------------------------\n",
            "Title :  Character-Aware Neural Language Models\n",
            "Author/s :  Yoon Kim, Yacine Jernite, D. Sontag, Alexander M. Rush\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Geo-indistinguishability: differential privacy for location-based systems\n",
            "Author/s :  M. Andrés, N. E. Bordenabe, K. Chatzikokolakis, C. Palamidessi\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2012\n",
            "Abstract :  The growing popularity of location-based systems, allowing unknown/untrusted servers to easily collect huge amounts of information regarding users' location, has recently started raising serious privacy concerns. In this paper we introduce geoind, a formal notion of privacy for location-based systems that protects the user's exact location, while allowing approximate information -- typically needed to obtain a certain desired service -- to be released. This privacy definition formalizes the intuitive notion of protecting the user's location within a radius $r$ with a level of privacy that depends on r, and corresponds to a generalized version of the well-known concept of differential privacy. Furthermore, we present a mechanism for achieving geoind by adding controlled random noise to the user's location. We describe how to use our mechanism to enhance LBS applications with geo-indistinguishability guarantees without compromising the quality of the application results. Finally, we compare state-of-the-art mechanisms from the literature with ours. It turns out that, among all mechanisms independent of the prior, our mechanism offers the best privacy guarantees.\n",
            "------------------------------------\n",
            "Title :  Understanding Employee Responses to Stressful Information Security Requirements: A Coping Perspective\n",
            "Author/s :  J. D'Arcy, Tejaswini C. Herath, Mindy K. Shoss\n",
            "Venue :  Journal of Management Information Systems\n",
            "year :  2014\n",
            "Abstract :  We use coping theory to explore an underlying relationship between employee stress caused by burdensome, complex, and ambiguous information security requirements (termed \"security-related stress\" or SRS) and deliberate information security policy (ISP) violations. Results from a survey of 539 employee users suggest that SRS engenders an emotion-focused coping response in the form of moral disengagement from ISP violations, which in turn increases one's susceptibility to this behavior. Our multidimensional view of SRS—comprised of security-related overload, complexity, and uncertainty—offers a new perspective on the workplace environment factors that foster noncompliant user behavior and inspire cognitive rationalizations of such behavior. The study extends technostress research to the information systems security domain and provides a theoretical framework for the influence of SRS on user behavior. For practitioners, the results highlight the incidence of SRS in organizations and suggest potential mechanisms to counter the stressful effects of information security requirements.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Classification of Hyperspectral Data Using Loopy Belief Propagation and Active Learning\n",
            "Author/s :  Jun Li, J. Bioucas-Dias, A. Plaza\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2013\n",
            "Abstract :  In this paper, we propose a new framework for spectral-spatial classification of hyperspectral image data. The proposed approach serves as an engine in the context of which active learning algorithms can exploit both spatial and spectral information simultaneously. An important contribution of our paper is the fact that we exploit the marginal probability distribution which uses the whole information in the hyperspectral data. We learn such distributions from both the spectral and spatial information contained in the original hyperspectral data using loopy belief propagation. The adopted probabilistic model is a discriminative random field in which the association potential is a multinomial logistic regression classifier and the interaction potential is a Markov random field multilevel logistic prior. Our experimental results with hyperspectral data sets collected using the National Aeronautics and Space Administration's Airborne Visible Infrared Imaging Spectrometer and the Reflective Optics System Imaging Spectrometer system indicate that the proposed framework provides state-of-the-art performance when compared to other similar developments.\n",
            "------------------------------------\n",
            "Title :  Conditional Adversarial Domain Adaptation\n",
            "Author/s :  Mingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I. Jordan\n",
            "Venue :  Neural Information Processing Systems\n",
            "year :  2017\n",
            "Abstract :  Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may struggle to align different domains of multimodal distributions that are native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. Experiments testify that the proposed approach exceeds the state-of-the-art results on five benchmark datasets.\n",
            "------------------------------------\n",
            "Title :  Evaluating Behaviorally-Motivated Policy: Experimental Evidence from the Lightbulb Market\n",
            "Author/s :  H. Allcott, Dmitry Taubinsky\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Imperfect information and inattention to energy costs are important potential motivations for energy efficiency standards and subsidies. We evaluate these motivations in the lightbulb market using a theoretical model and two randomized experiments. We derive welfare effects as functions of reduced-form sufficient statistics capturing economic and psychological parameters, which we estimate using a novel within-subject information disclosure experiment. The main results suggest that moderate subsidies for energy-efficient lightbulbs may increase welfare, but informational and attentional biases alone do not justify a ban on incandescent lightbulbs. Our results and techniques generate broader methodological insights into welfare analysis with misoptimizing consumers. (JEL D12, D83, H21, H31, L67, Q41, Q48)\n",
            "------------------------------------\n",
            "Title :  Analyst Information Discovery and Interpretation Roles: A Topic Modeling Approach\n",
            "Author/s :  Allen H. Huang, Reuven Lehavy, Amy Y. Zang, Rong Zheng\n",
            "Venue :  Management Sciences\n",
            "year :  2016\n",
            "Abstract :  This study examines analyst information intermediary roles using a textual analysis of analyst reports and corporate disclosures. We employ a topic modeling methodology from computational linguistic research to compare the thematic content of a large sample of analyst reports issued promptly after earnings conference calls with the content of the calls themselves. We show that analysts discuss exclusive topics beyond those from conference calls and interpret topics from conference calls. In addition, we find that investors place a greater value on new information in analyst reports when managers face greater incentives to withhold value-relevant information. Analyst interpretation is particularly valuable when the processing costs of conference call information increase. Finally, we document that investors react to analyst report content that simply confirms managers’ conference call discussions. Overall, our study shows that analysts play the information intermediary roles by discovering information beyond corporate disclosures and by clarifying and confirming corporate disclosures.\n",
            "------------------------------------\n",
            "Title :  Throughput Optimization for Massive MIMO Systems Powered by Wireless Energy Transfer\n",
            "Author/s :  Gang Yang, Chin Keong Ho, Rui Zhang, Y. Guan\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2014\n",
            "Abstract :  This paper studies a wireless-energy-transfer (WET) enabled massive multiple-input-multiple-output (MIMO) system (MM) consisting of a hybrid data-and-energy access point (H-AP) and multiple single-antenna users. In the WET-MM system, the H-AP is equipped with a large number M of antennas and functions like a conventional AP in receiving data from users, but additionally supplies wireless power to the users. We consider frame-based transmissions. Each frame is divided into three phases: the uplink channel estimation (CE) phase, the downlink WET phase, as well as the uplink wireless information transmission (WIT) phase. Firstly, users use a fraction of the previously harvested energy to send pilots, while the H-AP estimates the uplink channels and obtains the downlink channels by exploiting channel reciprocity. Next, the H-AP utilizes the channel estimates just obtained to transfer wireless energy to all users in the downlink via energy beamforming. Finally, the users use a portion of the harvested energy to send data to the H-AP simultaneously in the uplink (reserving some harvested energy for sending pilots in the next frame) . To optimize the throughput and ensure rate fairness, we consider the problem of maximizing the minimum rate among all users. In the large-M regime, we obtain the asymptotically optimal solutions and some interesting insights for the optimal design of WET-MM system.\n",
            "------------------------------------\n",
            "Title :  Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks\n",
            "Author/s :  Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-rong Wen, Edward Y. Chang\n",
            "Venue :  Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year :  2018\n",
            "Abstract :  With the revival of neural networks, many studies try to adapt powerful sequential neural models, ıe Recurrent Neural Networks (RNN), to sequential recommendation. RNN-based networks encode historical interaction records into a hidden state vector. Although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. It is difficult to capture fine-grained user preference from the interaction sequence. Furthermore, the latent vector representation is usually hard to understand and explain. To address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. Our model integrates the RNN-based networks with Key-Value Memory Network (KV-MN). We further incorporate knowledge base (KB) information to enhance the semantic representation of KV-MN. RNN-based models are good at capturing sequential user preference, while knowledge-enhanced KV-MNs are good at capturing attribute-level user preference. By using a hybrid of RNNs and KV-MNs, it is expected to be endowed with both benefits from these two components. The sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. With the incorporation of KB information, our model is also highly interpretable. To our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale KB information.\n",
            "------------------------------------\n",
            "Title :  Why Information Grows: The Evolution of Order, from Atoms to Economies\n",
            "Author/s :  César A. Hidalgo\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Prologue: The Eternal War Introduction: From Atoms to People to Economics PART I Bits in Atoms Chapter 1. The Secret to Time Travel Chapter 2. The Body of the Meaningless Chapter 3. The Eternal Anomaly PART II Crystallized Imagination Chapter 4. Out of Our Heads! Chapter 5. Amplifiers PART III The Quantization of Knowhow Chapter 6. This Time, It's Personal Chapter 7. Links Are Not Free Chapter 8. In Links We Trust PART IV The Complexity of the Economy Chapter 9. The Evolution of Economic Complexity Chapter 10. The Sixth Substance Chapter 11. The Marriage of Knowledge, Knowhow, and Information PART V Epilogue Chapter 12. The Evolution of Physical Order, from Atoms to Economics Acknowledgments: Bleeding Words Notes Index\n",
            "------------------------------------\n",
            "Title :  Context-Dependent Sentiment Analysis in User-Generated Videos\n",
            "Author/s :  Soujanya Poria, E. Cambria, Devamanyu Hazarika, Navonil Majumder, Amir Zadeh, Louis-Philippe Morency\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2017\n",
            "Abstract :  Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.\n",
            "------------------------------------\n",
            "Title :  Privacy, Security and Trust in Cloud Computing\n",
            "Author/s :  Siani Pearson\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Model Cards for Model Reporting\n",
            "Author/s :  Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, B. Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, Timnit Gebru\n",
            "Venue :  FAT\n",
            "year :  2018\n",
            "Abstract :  Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.\n",
            "------------------------------------\n",
            "Title :  Access to Management and the Informativeness of Analyst Research\n",
            "Author/s :  T. C. Green, Russell Jame, S. Markov, Musa Subasi\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We examine whether access to management at broker-hosted investor conferences leads to more informative research by analysts. We find analyst recommendation changes have larger immediate price impacts when the analyst׳s firm has a conference-hosting relation with the company. The effect increases with hosting frequency and is strongest in the days following the conference. Conference-hosting brokers also issue more informative, accurate, and timely earnings forecasts than non-hosts. Our findings suggest that access to management remains an important source of analysts׳ informational advantage in the post-Regulation Fair Disclosure world.\n",
            "------------------------------------\n",
            "Title :  Observing the operational significance of discord consumption\n",
            "Author/s :  M. Gu, H. Chrzanowski, S. Assad, T. Symul, K. Modi, T. Ralph, V. Vedral, P. Lam\n",
            "Venue :  Nature Physics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  RefSeq: an update on mammalian reference sequences\n",
            "Author/s :  K. Pruitt, Garth R. Brown, S. Hiatt, F. Thibaud-Nissen, Alex Astashyn, O. Ermolaeva, C. Farrell, Jennifer Hart, M. Landrum, Kelly M. McGarvey, M. R. Murphy, N. O'Leary, S. Pujar, B. Rajput, S. H. Rangwala, Lillian D. Riddick, Andrei Shkeda, Hanzhen Sun, P. Tamez, R. E. Tully, Craig Wallin, David Webb, Janet Weber, Wendy Wu, Michael DiCuccio, P. Kitts, D. Maglott, Terence D. Murphy, J. Ostell\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  The National Center for Biotechnology Information (NCBI) Reference Sequence (RefSeq) database is a collection of annotated genomic, transcript and protein sequence records derived from data in public sequence archives and from computation, curation and collaboration (http://www.ncbi.nlm.nih.gov/refseq/). We report here on growth of the mammalian and human subsets, changes to NCBI’s eukaryotic annotation pipeline and modifications affecting transcript and protein records. Recent changes to NCBI’s eukaryotic genome annotation pipeline provide higher throughput, and the addition of RNAseq data to the pipeline results in a significant expansion of the number of transcripts and novel exons annotated on mammalian RefSeq genomes. Recent annotation changes include reporting supporting evidence for transcript records, modification of exon feature annotation and the addition of a structured report of gene and sequence attributes of biological interest. We also describe a revised protein annotation policy for alternatively spliced transcripts with more divergent predicted proteins and we summarize the current status of the RefSeqGene project.\n",
            "------------------------------------\n",
            "Title :  Information geometry\n",
            "Author/s :  S. Amari\n",
            "Venue :  Japanese journal of mathematics\n",
            "year :  2021\n",
            "Abstract :  Information geometry has emerged from the study of the invariant structure in families of probability distributions. This invariance uniquely determines a second-order symmetric tensor g and third-order symmetric tensor T in a manifold of probability distributions. A pair of these tensors ( g, T ) defines a Riemannian metric and a pair of affine connections which together preserve the metric. Information geometry involves studying a Riemannian manifold having a pair of dual affine connections. Such a structure also arises from an asymmetric divergence function and affine differential geometry. A dually flat Riemannian manifold is particularly useful for various applications, because a generalized Pythagorean theorem and projection theorem hold. The Wasserstein distance gives another important geometry on probability distributions, which is non-invariant but responsible for the metric properties of a sample space. I attempt to construct information geometry of the entropy-regularized Wasserstein distance.\n",
            "------------------------------------\n",
            "Title :  Leveraging Digital Technologies: How Information Quality Leads to Localized Capabilities and Customer Service Performance\n",
            "Author/s :  P. Setia, V. Venkatesh, Supreet Joglekar\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  With the growing recognition of the customer's role in service creation and delivery, there is an increased impetus on building customer-centric organizations. Digital technologies play a key role in such organizations. Prior research studying digital business strategies has largely focused on building production-side competencies and there has been little focus on customer-side digital business strategies to leverage these technologies. We propose a theory to understand the effectiveness of a customer-side digital business strategy focused on localized dynamics--here, a firm's customer service units (CSUs). Specifically, we use a capabilities perspective to propose digital design as an antecedent to two customer service capabilities--namely, customer orientation capability and customer response capability--across a firm's CSUs. These two capabilities will help a firm to locally sense and respond to customer needs, respectively. Information quality from the digital design of the CSU is proposed as the antecedent to the two capabilities. Proposed capability-building dynamics are tested using data collected from multiple respondents across 170 branches of a large bank. Findings suggest that the impacts of information quality in capability-building are contingent on the local process characteristics. We offer implications for a firm's customer-side digital business strategy and present new areas for future examination of such strategies.\n",
            "------------------------------------\n",
            "Title :  Cascaded Recurrent Neural Networks for Hyperspectral Image Classification\n",
            "Author/s :  Renlong Hang, Qingshan Liu, D. Hong, Pedram Ghamisi\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2017\n",
            "Abstract :  By considering the spectral signature as a sequence, recurrent neural networks (RNNs) have been successfully used to learn discriminative features from hyperspectral images (HSIs) recently. However, most of these models only input the whole spectral bands into RNNs directly, which may not fully explore the specific properties of HSIs. In this paper, we propose a cascaded RNN model using gated recurrent units to explore the redundant and complementary information of HSIs. It mainly consists of two RNN layers. The first RNN layer is used to eliminate redundant information between adjacent spectral bands, while the second RNN layer aims to learn the complementary information from nonadjacent spectral bands. To improve the discriminative ability of the learned features, we design two strategies for the proposed model. Besides, considering the rich spatial information contained in HSIs, we further extend the proposed model to its spectral–spatial counterpart by incorporating some convolutional layers. To test the effectiveness of our proposed models, we conduct experiments on two widely used HSIs. The experimental results show that our proposed models can achieve better results than the compared models.\n",
            "------------------------------------\n",
            "Title :  Enhanced LSTM for Natural Language Inference\n",
            "Author/s :  Qian Chen, Xiao-Dan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, D. Inkpen\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2016\n",
            "Abstract :  Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result—it further improves the performance even when added to the already very strong model.\n",
            "------------------------------------\n",
            "Title :  How Much Position Information Do Convolutional Neural Networks Encode?\n",
            "Author/s :  Md. Amirul Islam, Sen Jia, Neil D. B. Bruce\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2020\n",
            "Abstract :  In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.\n",
            "------------------------------------\n",
            "Title :  Understanding Online Purchase Decision Making: The Effects of Unconscious Thought, Information Quality, and Information Quantity\n",
            "Author/s :  Jie Gao, Cheng Zhang, Ke Wang, Sulin Ba\n",
            "Venue :  Decision Support Systems\n",
            "year :  2012\n",
            "Abstract :  The prosperity of online shopping has led e-commerce vendors to provide increasingly rich information, particularly for experience products, to enhance consumers' shopping experience and satisfaction. However, there is little awareness that consumers may not be able to process all the information available because of human beings' limited information processing capacity. Online shoppers could be easily confused when facing rich information, particularly when the amount of information greatly exceeds their processing capacity. In contrast to previous research which has focused on the formatting of information or user interfaces to solve the information overload problem, this study explores a new solution based on the role of unconscious thought. Integrating information processing theory and the unconscious thought theory, the current study examines the different roles of information quantity, information quality and thought mode in consumers' decision satisfaction, in the presence of rich information. Our results show that unconscious thought moderates the relationship between information quality and consumer satisfaction towards their decision making when shopping experience products online, and is thus worthy of special attention in the design of e-commerce websites. The study contributes to both unconscious thought theory and information processing theory by exploring the interaction effect of the quantity and quality of information with thought mode in affecting the quality of purchasing decisions.\n",
            "------------------------------------\n",
            "Title :  Online Social Networks: Threats and Solutions\n",
            "Author/s :  Michael Fire, Roy Goldschmidt, Y. Elovici\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2013\n",
            "Abstract :  Many online social network (OSN) users are unaware of the numerous security risks that exist in these networks, including privacy violations, identity theft, and sexual harassment, just to name a few. According to recent studies, OSN users readily expose personal and private details about themselves, such as relationship status, date of birth, school name, email address, phone number, and even home address. This information, if put into the wrong hands, can be used to harm users both in the virtual world and in the real world. These risks become even more severe when the users are children. In this paper, we present a thorough review of the different security and privacy risks, which threaten the well-being of OSN users in general, and children in particular. In addition, we present an overview of existing solutions that can provide better protection, security, and privacy for OSN users. We also offer simple-to-implement recommendations for OSN users, which can improve their security and privacy when using these platforms. Furthermore, we suggest future research directions.\n",
            "------------------------------------\n",
            "Title :  Information provision for stroke patients and their caregivers.\n",
            "Author/s :  A. Forster, L. Brown, Jane Smith, A. House, P. Knapp, John Wright, John B. Young\n",
            "Venue :  Cochrane Database of Systematic Reviews\n",
            "year :  2012\n",
            "Abstract :  BACKGROUND\n",
            "Research shows that stroke patients and their families are dissatisfied with the information provided and have a poor understanding of stroke and associated issues.\n",
            "\n",
            "\n",
            "OBJECTIVES\n",
            "To assess the effectiveness of information provision strategies in improving the outcome for stroke patients or their identified caregivers, or both.\n",
            "\n",
            "\n",
            "SEARCH METHODS\n",
            "For this update we searched the Cochrane Stroke Group Trials Register (June 2012), the Cochrane Central Register of Controlled trials (CENTRAL), the Cochrane Database of Systematic Reviews (CDSR), the Database of Abstracts of Reviews of Effects (DARE), the NHS Economic Evaluation Database (EED), and the Health Technology Assessment (HTA) Database (The Cochrane Library June, 2012), MEDLINE (1966 to June 2012), EMBASE (1980 to June 2012), CINAHL (1982 to June 2012) and PsycINFO (1974 to June 2012). We also searched ongoing trials registers, scanned bibliographies of relevant articles and books and contacted researchers.\n",
            "\n",
            "\n",
            "SELECTION CRITERIA\n",
            "Randomised trials involving patients or carers of patients with a clinical diagnosis of stroke or transient ischaemic attack (TIA) where an information intervention was compared with standard care, or where information and another therapy were compared with the other therapy alone.\n",
            "\n",
            "\n",
            "DATA COLLECTION AND ANALYSIS\n",
            "Two review authors independently assessed trial eligibility and methodological quality and extracted data. Primary outcomes were knowledge about stroke and stroke services, and impact on mood.\n",
            "\n",
            "\n",
            "MAIN RESULTS\n",
            "We have added four new trials to this update. This review now includes 21 trials involving 2289 patient and 1290 carer participants. Nine trials evaluated a passive and 12 trials an active information intervention. Meta-analyses showed a significant effect in favour of the intervention on patient knowledge (standardised mean difference (SMD) 0.29, 95% confidence interval (CI) 0.12 to 0.46, P < 0.001), carer knowledge (SMD 0.74, 95% CI 0.06 to 1.43, P = 0.03), one aspect of patient satisfaction (odds ratio (OR) 2.07, 95% CI 1.33 to 3.23, P = 0.001), and patient depression scores (mean difference (MD) -0.52, 95% CI -0.93 to -0.10, P = 0.01). There was no significant effect (P > 0.05) on number of cases of anxiety or depression in patients, carer mood or satisfaction, or death. Qualitative analyses found no strong evidence of an effect on other outcomes. Post-hoc subgroup analyses showed that active information had a significantly greater effect than passive information on patient mood but not on other outcomes.\n",
            "\n",
            "\n",
            "AUTHORS' CONCLUSIONS\n",
            "There is evidence that information improves patient and carer knowledge of stroke, aspects of patient satisfaction, and reduces patient depression scores. However, the reduction in depression scores was small and may not be clinically significant. Although the best way to provide information is still unclear there is some evidence that strategies that actively involve patients and carers and include planned follow-up for clarification and reinforcement have a greater effect on patient mood.\n",
            "------------------------------------\n",
            "Title :  Attention Augmented Convolutional Networks\n",
            "Author/s :  Irwan Bello, Barret Zoph, Ashish Vaswani, Jonathon Shlens, Quoc V. Le\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2019\n",
            "Abstract :  Convolutional networks have enjoyed much success in many computer vision applications. The convolution operation however has a significant weakness in that it only operates on a local neighbourhood, thus missing global information. Self-attention, on the other hand, has emerged as a recent advance to capture long range interactions, but has mostly been applied to sequence modeling and generative modeling tasks. In this paper, we propose to augment convolutional networks with self-attention by concatenating convolutional feature maps with a set of feature maps produced via a novel relative self-attention mechanism. In particular, we extend previous work on relative self-attention over sequences to images and discuss a memory efficient implementation. Unlike Squeeze-and-Excitation, which performs attention over the channels and ignores spatial information, our self-attention mechanism attends jointly to both features and spatial locations while preserving translation equivariance. We find that Attention Augmentation leads to consistent improvements in image classification on ImageNet and object detection on COCO across many different models and scales, including ResNets and a state-of-the art mobile constrained network, while keeping the number of parameters similar. In particular, our method achieves a 1.3% top-1 accuracy improvement on ImageNet classification over a ResNet50 baseline and outperforms other attention mechanisms for images such as Squeeze-and-Excitation. It also achieves an improvement of 1.4 AP in COCO Object Detection on top of a RetinaNet baseline.\n",
            "------------------------------------\n",
            "Title :  The Impact of Social Media on Panic During the COVID-19 Pandemic in Iraqi Kurdistan: Online Questionnaire Study\n",
            "Author/s :  A. Ahmad, H. Murad\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background In the first few months of 2020, information and news reports about the coronavirus disease (COVID-19) were rapidly published and shared on social media and social networking sites. While the field of infodemiology has studied information patterns on the Web and in social media for at least 18 years, the COVID-19 pandemic has been referred to as the first social media infodemic. However, there is limited evidence about whether and how the social media infodemic has spread panic and affected the mental health of social media users. Objective The aim of this study is to determine how social media affects self-reported mental health and the spread of panic about COVID-19 in the Kurdistan Region of Iraq. Methods To carry out this study, an online questionnaire was prepared and conducted in Iraqi Kurdistan, and a total of 516 social media users were sampled. This study deployed a content analysis method for data analysis. Correspondingly, data were analyzed using SPSS software. Results Participants reported that social media has a significant impact on spreading fear and panic related to the COVID-19 outbreak in Iraqi Kurdistan, with a potential negative influence on people’s mental health and psychological well-being. Facebook was the most used social media network for spreading panic about the COVID-19 outbreak in Iraq. We found a significant positive statistical correlation between self-reported social media use and the spread of panic related to COVID-19 (R=.8701). Our results showed that the majority of youths aged 18-35 years are facing psychological anxiety. Conclusions During lockdown, people are using social media platforms to gain information about COVID-19. The nature of the impact of social media panic among people varies depending on an individual's gender, age, and level of education. Social media has played a key role in spreading anxiety about the COVID-19 outbreak in Iraqi Kurdistan.\n",
            "------------------------------------\n",
            "Title :  Can Twitter Help Predict Firm-Level Earnings and Stock Returns?\n",
            "Author/s :  Eli Bartov, Lucile Faurel, Partha Mohanram\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  ABSTRACT: Prior research has examined how companies exploit Twitter in communicating with investors, and whether Twitter activity predicts the stock market as a whole. We test whether opinions of individuals tweeted just prior to a firm's earnings announcement predict its earnings and announcement returns. Using a broad sample from 2009 to 2012, we find that the aggregate opinion from individual tweets successfully predicts a firm's forthcoming quarterly earnings and announcement returns. These results hold for tweets that convey original information, as well as tweets that disseminate existing information, and are stronger for tweets providing information directly related to firm fundamentals and stock trading. Importantly, our results hold even after controlling for concurrent information or opinion from traditional media sources, and are stronger for firms in weaker information environments. Our findings highlight the importance of considering the aggregate opinion from individual tweets when assessing...\n",
            "------------------------------------\n",
            "Title :  Knowing when to doubt: developing a critical stance when learning from others.\n",
            "Author/s :  Candice M. Mills\n",
            "Venue :  Developmental Psychology\n",
            "year :  2013\n",
            "Abstract :  Children may be biased toward accepting information as true, but the fact remains that children are exposed to misinformation from many sources, and mastering the intricacies of doubt is necessary. The current article examines this issue, focusing on understanding developmental changes and consistencies in children's ability to take a critical stance toward information. Research reviewed includes studies of children's ability to detect ignorance, inaccuracy, incompetence, deception, and distortion. Particular emphasis is placed on what this research indicates about how children are reasoning about when to trust and when to doubt. The remainder of the article proposes a framework to evaluate preexisting research and encourage further research, closing with a discussion of several other overarching questions that should be considered to develop a model to explain developmental, individual, and situational differences in children's ability to evaluate information.\n",
            "------------------------------------\n",
            "Title :  Anxious politics : democratic citizenship in a threatening world\n",
            "Author/s :  B. Albertson, S. Gadarian\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  1. Anxiety in public life 2. What's your worry? Finding and creating anxiety in the American public 3. Anxiety, immigration, and the search for information 4. Don't worry, be trusting? The effect of anxiety on political trust 5. The politics of anxiety: anxiety's role on public opinion 6. Anxiety and democratic citizenship.\n",
            "------------------------------------\n",
            "Title :  Active inference and epistemic value\n",
            "Author/s :  Karl J. Friston, Francesco Rigoli, D. Ognibene, C. Mathys, Thomas H. B. FitzGerald, G. Pezzulo\n",
            "Venue :  Cognitive neuroscience\n",
            "year :  2015\n",
            "Abstract :  We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.\n",
            "------------------------------------\n",
            "Title :  International Society of Neuropathology‐Haarlem Consensus Guidelines for Nervous System Tumor Classification and Grading\n",
            "Author/s :  D. Louis, A. Perry, P. Burger, D. Ellison, G. Reifenberger, A. von Deimling, K. Aldape, D. Brat, V. Collins, C. Eberhart, D. Figarella-Branger, G. Fuller, F. Giangaspero, C. Giannini, C. Hawkins, P. Kleihues, A. Korshunov, J. Kros, M. Beatriz Lopes, H. Ng, H. Ohgaki, W. Paulus, T. Pietsch, M. Rosenblum, E. Rushing, F. Soylemezoğlu, O. Wiestler, P. Wesseling\n",
            "Venue :  Brain Pathology\n",
            "year :  2014\n",
            "Abstract :  Major discoveries in the biology of nervous system tumors have raised the question of how non‐histological data such as molecular information can be incorporated into the next World Health Organization (WHO) classification of central nervous system tumors. To address this question, a meeting of neuropathologists with expertise in molecular diagnosis was held in Haarlem, the Netherlands, under the sponsorship of the International Society of Neuropathology (ISN). Prior to the meeting, participants solicited input from clinical colleagues in diverse neuro‐oncological specialties. The present “white paper” catalogs the recommendations of the meeting, at which a consensus was reached that incorporation of molecular information into the next WHO classification should follow a set of provided “ISN‐Haarlem” guidelines. Salient recommendations include that (i) diagnostic entities should be defined as narrowly as possible to optimize interobserver reproducibility, clinicopathological predictions and therapeutic planning; (ii) diagnoses should be “layered” with histologic classification, WHO grade and molecular information listed below an “integrated diagnosis”; (iii) determinations should be made for each tumor entity as to whether molecular information is required, suggested or not needed for its definition; (iv) some pediatric entities should be separated from their adult counterparts; (v) input for guiding decisions regarding tumor classification should be solicited from experts in complementary disciplines of neuro‐oncology; and (iv) entity‐specific molecular testing and reporting formats should be followed in diagnostic reports. It is hoped that these guidelines will facilitate the forthcoming update of the fourth edition of the WHO classification of central nervous system tumors.\n",
            "------------------------------------\n",
            "Title :  Eavesdropping on heterospecific alarm calls: from mechanisms to consequences\n",
            "Author/s :  R. Magrath, T. Haff, Pamela M. Fallow, A. Radford\n",
            "Venue :  Biological Reviews of The Cambridge Philosophical Society\n",
            "year :  2015\n",
            "Abstract :  Animals often gather information from other species by eavesdropping on signals intended for others. We review the extent, benefits, mechanisms, and ecological and evolutionary consequences of eavesdropping on other species' alarm calls. Eavesdropping has been shown experimentally in about 70 vertebrate species, and can entail closely or distantly related species. The benefits of eavesdropping include prompting immediate anti‐predator responses, indirect enhancement of foraging or changed habitat use, and learning about predators. Eavesdropping on heterospecifics can provide more eyes looking for danger, complementary information to that from conspecifics, and potentially information at reduced cost. The response to heterospecific calls can be unlearned or learned. Unlearned responses occur when heterospecific calls have acoustic features similar to that used to recognize conspecific calls, or acoustic properties such as harsh sounds that prompt attention and may allow recognition or facilitate learning. Learning to recognize heterospecific alarm calls is probably essential to allow recognition of the diversity of alarm calls, but the evidence is largely indirect. The value of eavesdropping on different species is affected by problems of signal interception and the relevance of heterospecific alarm calls to the listener. These constraints on eavesdropping will affect how information flows among species and thus affect community function. Some species are ‘keystone’ information producers, while others largely seek information, and these differences probably affect the formation and function of mixed‐species groups. Eavesdroppers might also integrate alarm calls from multiple species to extract relevant and reliable information. Eavesdropping appears to set the stage for the evolution of interspecific deception and communication, and potentially affects communication within species. Overall, we now know that eavesdropping on heterospecific alarm calls is an important source of information for many species across the globe, and there are ample opportunities for research on mechanisms, fitness consequences and implications for community function and signalling evolution.\n",
            "------------------------------------\n",
            "Title :  Censoring Representations with an Adversary\n",
            "Author/s :  Harrison Edwards, A. Storkey\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2015\n",
            "Abstract :  In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model.\n",
            "------------------------------------\n",
            "Title :  A review of volunteered geographic information quality assessment methods\n",
            "Author/s :  Hansi Senaratne, A. Mobasheri, A. Ali, C. Capineri, M. Haklay\n",
            "Venue :  International Journal of Geographical Information Science\n",
            "year :  2017\n",
            "Abstract :  ABSTRACT With the ubiquity of advanced web technologies and location-sensing hand held devices, citizens regardless of their knowledge or expertise, are able to produce spatial information. This phenomenon is known as volunteered geographic information (VGI). During the past decade VGI has been used as a data source supporting a wide range of services, such as environmental monitoring, events reporting, human movement analysis, disaster management, etc. However, these volunteer-contributed data also come with varying quality. Reasons for this are: data is produced by heterogeneous contributors, using various technologies and tools, having different level of details and precision, serving heterogeneous purposes, and a lack of gatekeepers. Crowd-sourcing, social, and geographic approaches have been proposed and later followed to develop appropriate methods to assess the quality measures and indicators of VGI. In this article, we review various quality measures and indicators for selected types of VGI and existing quality assessment methods. As an outcome, the article presents a classification of VGI with current methods utilized to assess the quality of selected types of VGI. Through these findings, we introduce data mining as an additional approach for quality handling in VGI.\n",
            "------------------------------------\n",
            "Title :  Determinants of patient choice of healthcare providers: a scoping review\n",
            "Author/s :  A. Victoor, D. Delnoij, R. Friele, J. Rademakers\n",
            "Venue :  BMC Health Services Research\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Pileup per particle identification\n",
            "Author/s :  D. Bertolini, P. Harris, M. Low, N. Tran\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A quantum memory for orbital angular momentum photonic qubits\n",
            "Author/s :  A. Nicolas, L. Veissier, L. Giner, E. Giacobino, D. Maxein, J. Laurat\n",
            "Venue :  Nature Photonics\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Concentration of Measure Inequalities in Information Theory, Communications, and Coding\n",
            "Author/s :  M. Raginsky, I. Sason\n",
            "Venue :  Foundations and Trends in Communications and Information Theory\n",
            "year :  2012\n",
            "Abstract :  Concentration inequalities have been the subject of exciting developments during the last two decades, and have been intensively studied and used as a powerful tool in various areas. These include convex geometry, functional analysis, statistical physics, mathematical statistics, pure and applied probability theory, information theory, theoretical computer science, learning theory, and dynamical systems. Concentration of Measure Inequalities in Information Theory, Communications, and Coding focuses on some of the key modern mathematical tools that are used for the derivation of concentration inequalities, on their links to information theory, and on their various applications to communications and coding. In addition to being a survey, this monograph also includes various new recent results derived by the authors. This third edition of the bestselling book introduces the reader to the martingale method and the Efron-Stein-Steele inequalities in completely new sections. A new application of lossless source coding with side information is described in detail. Finally, the references have been updated and ones included that have been published since the original publication. Concentration of Measure Inequalities in Information Theory, Communications, and Coding is essential reading for all researchers and scientists in information theory and coding.\n",
            "------------------------------------\n",
            "Title :  Variational Lossy Autoencoder\n",
            "Author/s :  Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, J. Schulman, Ilya Sutskever, P. Abbeel\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2016\n",
            "Abstract :  Representation learning seeks to expose certain aspects of observed data in a learned representation that's amenable to downstream tasks like classification. For instance, a good representation for 2D images might be one that describes only global structure and discards information about detailed texture. In this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE model allows us to have control over what the global latent code can learn and , by designing the architecture accordingly, we can force the global latent code to discard irrelevant information such as texture in 2D images, and hence the VAE only \"autoencodes\" data in a lossy fashion. In addition, by leveraging autoregressive models as both prior distribution $p(z)$ and decoding distribution $p(x|z)$, we can greatly improve generative modeling performance of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and Caltech-101 Silhouettes density estimation tasks.\n",
            "------------------------------------\n",
            "Title :  Incentives for Information Production in Markets Where Prices Affect Real Investment\n",
            "Author/s :  James Dow, Itay Goldstein, A. Guembel\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  We analyze information production incentives for traders in financial markets, when firms condition investment decisions on information revealed through stock prices. We show that traders’ private value of information about a firm’s investment project increases with the ex ante likelihood the project will be undertaken. This generates an informational amplification effect of shocks to firm value. Information production by traders may exhibit strategic complementarities for projects that would not be undertaken in the absence of positive news from the stock market. A small decline in fundamentals can lead to a market breakdown where information production ceases, and investment and firm value collapse. Our theory sheds light on how productivity shocks are amplified over the business cycle.\n",
            "------------------------------------\n",
            "Title :  Enhancing wireless information and power transfer by exploiting multi-antenna techniques\n",
            "Author/s :  Xiaoming Chen, Zhaoyang Zhang, Hsiao-Hwa Chen, Huazi Zhang\n",
            "Venue :  IEEE Communications Magazine\n",
            "year :  2015\n",
            "Abstract :  This article reviews an emerging wireless information and power transfer (WIPT) technique with an emphasis on its performance enhancement employing multi-antenna techniques. Compared to traditional wireless information transmission, WIPT faces numerous challenges. First, it is more susceptible to channel fading and path loss, resulting in a much shorter power transfer distance. Second, it gives rise to the issue of how to balance spectral efficiency for information transmission and energy efficiency for power transfer in order to obtain an optimal tradeoff. Third, there exists a security issue for information transmission in order to improve power transfer efficiency. In this context, multi-antenna techniques, e.g. energy beamforming, are introduced to solve these problems by exploiting spatial degree of freedom. This article provides a tutorial on various aspects of multi-antenna based WIPT techniques, with a focus on tackling the challenges by parameter optimization and protocol design. In particular, we investigate the WIPT tradeoffs based on two typical multi-antenna techniques: the limited feedback multi-antenna technique for short-distance transfer; and the large-scale multiple-input multiple-output (LS-MIMO, also known as massive MIMO) technique for long-distance transfer. Finally, simulation results validate the effectiveness of the proposed schemes.\n",
            "------------------------------------\n",
            "Title :  The Effect of Information Communication Technology Interventions on Reducing Social Isolation in the Elderly: A Systematic Review\n",
            "Author/s :  Yi-Ru Regina Chen, P. Schulz\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2016\n",
            "Abstract :  Background The aging of the population is an inexorable change that challenges governments and societies in every developed country. Based on clinical and empirical data, social isolation is found to be prevalent among elderly people, and it has negative consequences on the elderly’s psychological and physical health. Targeting social isolation has become a focus area for policy and practice. Evidence indicates that contemporary information and communication technologies (ICT) have the potential to prevent or reduce the social isolation of elderly people via various mechanisms. Objective This systematic review explored the effects of ICT interventions on reducing social isolation of the elderly. Methods Relevant electronic databases (PsycINFO, PubMed, MEDLINE, EBSCO, SSCI, Communication Studies: a SAGE Full-Text Collection, Communication & Mass Media Complete, Association for Computing Machinery (ACM) Digital Library, and IEEE Xplore) were systematically searched using a unified strategy to identify quantitative and qualitative studies on the effectiveness of ICT-mediated social isolation interventions for elderly people published in English between 2002 and 2015. Narrative synthesis was performed to interpret the results of the identified studies, and their quality was also appraised. Results Twenty-five publications were included in the review. Four of them were evaluated as rigorous research. Most studies measured the effectiveness of ICT by measuring specific dimensions rather than social isolation in general. ICT use was consistently found to affect social support, social connectedness, and social isolation in general positively. The results for loneliness were inconclusive. Even though most were positive, some studies found a nonsignificant or negative impact. More importantly, the positive effect of ICT use on social connectedness and social support seemed to be short-term and did not last for more than six months after the intervention. The results for self-esteem and control over one’s life were consistent but generally nonsignificant. ICT was found to alleviate the elderly’s social isolation through four mechanisms: connecting to the outside world, gaining social support, engaging in activities of interests, and boosting self-confidence. Conclusions More well-designed studies that contain a minimum risk of research bias are needed to draw conclusions on the effectiveness of ICT interventions for elderly people in reducing their perceived social isolation as a multidimensional concept. The results of this review suggest that ICT could be an effective tool to tackle social isolation among the elderly. However, it is not suitable for every senior alike. Future research should identify who among elderly people can most benefit from ICT use in reducing social isolation. Research on other types of ICT (eg, mobile phone–based instant messaging apps) should be conducted to promote understanding and practice of ICT-based social-isolation interventions for elderly people.\n",
            "------------------------------------\n",
            "Title :  Re-examining the Unified Theory of Acceptance and Use of Technology (UTAUT): Towards a Revised Theoretical Model\n",
            "Author/s :  Yogesh Kumar Dwivedi, N. Rana, A. Jeyaraj, Marc Clement, Michael D. Williams\n",
            "Venue :  Inf. Syst. Frontiers\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Existing data sources for clinical epidemiology: The Danish National Database of Reimbursed Prescriptions\n",
            "Author/s :  S. A. Jóhannesdóttir, E. Horváth-Puhó, V. Ehrenstein, M. Schmidt, L. Pedersen, H. Sørensen\n",
            "Venue :  Clinical Epidemiology\n",
            "year :  2012\n",
            "Abstract :  The Danish health care system provides partial reimbursement of most prescription medications in Denmark. The dispensation of prescription medications is registered in administrative databases. Each time a prescription is redeemed at a pharmacy, an electronic record is generated with information related to the user, prescriber, the pharmacy, and the dispensed drug. The National Health Service gathers this information for administration of the drug reimbursement plan. Recently, this information became the basis for the establishment of a new research database, the Danish National Database of Reimbursed Prescriptions (DNDRP). In this paper, we review the content, coverage, quality, linkage, access, and research possibilities of this new database. The database encompasses the reimbursement records of all reimbursed drugs sold in community pharmacies and hospital-based outpatient pharmacies in Denmark since 2004. On average, approximately 3.5 million users are recorded in the database each year. During the coverage period, the number of annual prescription redemptions increased by 15%. Most dispensed prescriptions are in the categories “alimentary tract and metabolism”, “cardiovascular system”, “nervous system”, and “respiratory system”. Individuals are identified by the unique central personal registration (CPR) number assigned to all persons born in or immigrating to Denmark. The new database fully complies with Denmark’s Act on Processing of Personal Data, while avoiding additional restrictions imposed on data use at the Danish National Prescription Registry, administered by Statistics Denmark. Most importantly, CPR numbers are reversibly encrypted, which allows re-identification of drug users; furthermore, the data access is possible outside the servers of Statistics Denmark. These features open additional opportunities for international collaboration, validation studies, studies on adverse drug effects requiring review of medical records, studies involving contact to general practitioners, and linkage of prescription data to other clinical and research databases. The DNDRP thus is a valuable data source for pharmacoepidemiological research.\n",
            "------------------------------------\n",
            "Title :  Unified Theory of Acceptance and Use of Technology: A Synthesis and the Road Ahead\n",
            "Author/s :  V. Venkatesh, J. Thong, Xin Xu\n",
            "Venue :  Journal of the AIS\n",
            "year :  2016\n",
            "Abstract :  The unified theory of acceptance and use of technology (UTAUT) is a little over a decade old and has been used extensively in information systems (IS) and other fields, as the large number of citations to the original paper that introduced the theory evidences. In this paper, we review and synthesize the IS literature on UTAUT from September 2003 until December 2014, perform a theoretical analysis of UTAUT and its extensions, and chart an agenda for research going forward. Based on Weber’s (2012) framework of theory evaluation, we examined UTAUT and its extensions along two sets of quality dimensions; namely, the parts of a theory and the theory as a whole. While our review identifies many merits to UTAUT, we also found that the progress related to this theory has hampered further theoretical development in research into technology acceptance and use. To chart an agenda for research that will enable significant future work, we analyze the theoretical contributions of UTAUT using Whetten’s (2009) notion of cross-context theorizing. Our analysis reveals several limitations that lead us to propose a multi-level framework that can serve as the theoretical foundation for future research. Specifically, this framework integrates the notion of research context and cross-context theorizing with the theory evaluation framework to: (1) synthesize the existing UTAUT extensions across both the dimensions and the levels of the research context and (2) highlight promising research directions. We conclude with recommendations for future UTAUT-related research using the proposed framework.\n",
            "------------------------------------\n",
            "Title :  Intelligent Device-to-Device Communication in the Internet of Things\n",
            "Author/s :  O. Bello, S. Zeadally\n",
            "Venue :  IEEE Systems Journal\n",
            "year :  2016\n",
            "Abstract :  Analogous to the way humans use the Internet, devices will be the main users in the Internet of Things (IoT) ecosystem. Therefore, device-to-device (D2D) communication is expected to be an intrinsic part of the IoT. Devices will communicate with each other autonomously without any centralized control and collaborate to gather, share, and forward information in a multihop manner. The ability to gather relevant information in real time is key to leveraging the value of the IoT as such information will be transformed into intelligence, which will facilitate the creation of an intelligent environment. Ultimately, the quality of the information gathered depends on how smart the devices are. In addition, these communicating devices will operate with different networking standards, may experience intermittent connectivity with each other, and many of them will be resource constrained. These characteristics open up several networking challenges that traditional routing protocols cannot solve. Consequently, devices will require intelligent routing protocols in order to achieve intelligent D2D communication. We present an overview of how intelligent D2D communication can be achieved in the IoT ecosystem. In particular, we focus on how state-of-the-art routing algorithms can achieve intelligent D2D communication in the IoT.\n",
            "------------------------------------\n",
            "Title :  Coronavirus-Related Health Literacy: A Cross-Sectional Study in Adults during the COVID-19 Infodemic in Germany\n",
            "Author/s :  O. Okan, T. Bollweg, E. Berens, K. Hurrelmann, U. Bauer, D. Schaeffer\n",
            "Venue :  International Journal of Environmental Research and Public Health\n",
            "year :  2020\n",
            "Abstract :  There is an “infodemic” associated with the COVID-19 pandemic—an overabundance of valid and invalid information. Health literacy is the ability to access, understand, appraise, and apply health information, making it crucial for navigating coronavirus and COVID-19 information environments. A cross-sectional representative study of participants ≥ 16 years in Germany was conducted using an online survey. A coronavirus-related health literacy measure was developed (HLS-COVID-Q22). Internal consistency was very high (α = 0.940; ρ = 0.891) and construct validity suggests a sufficient model fit, making HLS-COVID-Q22 a feasible tool for assessing coronavirus-related health literacy in population surveys. While 49.9% of our sample had sufficient levels of coronavirus-related health literacy, 50.1% had “problematic” (15.2%) or “inadequate” (34.9%) levels. Although the overall level of health literacy is high, a vast number of participants report difficulties dealing with coronavirus and COVID-19 information. The participants felt well informed about coronavirus, but 47.8% reported having difficulties judging whether they could trust media information on COVID-19. Confusion about coronavirus information was significantly higher among those who had lower health literacy. This calls for targeted public information campaigns and promotion of population-based health literacy for better navigation of information environments during the infodemic, identification of disinformation, and decision-making based on reliable and trustworthy information.\n",
            "------------------------------------\n",
            "Title :  A Review and Clarification of the Terms “holistic,” “configural,” and “relational” in the Face Perception Literature\n",
            "Author/s :  D. Piepers, Rachel A Robbins\n",
            "Venue :  Front. Psychology\n",
            "year :  2012\n",
            "Abstract :  It is widely agreed that the human face is processed differently from other objects. However there is a lack of consensus on what is meant by a wide array of terms used to describe this “special” face processing (e.g., holistic and configural) and the perceptually relevant information within a face (e.g., relational properties and configuration). This paper will review existing models of holistic/configural processing, discuss how they differ from one another conceptually, and review the wide variety of measures used to tap into these concepts. In general we favor a model where holistic processing of a face includes some or all of the interrelations between features and has separate coding for features. However, some aspects of the model remain unclear. We propose the use of moving faces as a way of clarifying what types of information are included in the holistic representation of a face.\n",
            "------------------------------------\n",
            "Title :  Coordination with Flexible Information Acquisition\n",
            "Author/s :  Ming-yu Yang\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We study flexible information acquisition in a coordination game. “Flexible” acquisition means that players choose not only how much but also what kind of information to acquire. Information acquisition has a cost proportional to reduction of entropy. Hence, players will collect the information most relevant to their welfare but can be rationally inattentive to other aspects of the fundamental. When information is cheap, this flexibility enables players to acquire information that makes efficient coordination possible, which also leads to multiple equilibria. This result contrasts with the global game literature, where information structure is less flexible and cheap information leads to a unique equilibrium with inefficient coordination.\n",
            "------------------------------------\n",
            "Title :  FPGA based Real time 'secure' body temperature monitoring suitable for WBSN 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing\n",
            "Author/s :  M. Rao, T. Newe, I. Grout, E. Lewis, Avijit Mathur\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In wireless body sensor networks (WBSNs), sensors continuously monitor human physiological activities using medical sensors, for example; blood pressure, body temperature and electrocardiography (ECG). A WBSN can be used to develop a patient monitoring system. The traditional body sensor networks (BSNs) have limited hardware resources in terms of computational capabilities, data processing speed, memory and battery life. Also these BSNs are generally not suitable for the implementation of security mechanisms, reason is that, implementation of security mechanisms require relatively more hardware resources because of the complexity of their algorithms. To get rid of these limitations a Field Programmable Gate Array (FPGA) device is suitable because of its flexible architecture and high performance features. In this paper an FPGA based experimental framework is investigated to implement real time body temperature monitoring with reliable data transmission, using data integrity verification. This data integrity check is very important for patient monitoring systems as unreliable data could lead the healthcare professionals to make an incorrect diagnosis concerning patients health. The data integrity verification is achieved using newly selected cryptographic hash function called, SHA-3 (Secure Hash Algorithm-3). To the best of authors knowledge, all previously published FPGA based WBSNs implementations did not implemented any security mechanisms to secure physiological data, so this work is the first contribution regarding it.\n",
            "------------------------------------\n",
            "Title :  Business Process Management: A Comprehensive Survey\n",
            "Author/s :  Wil M.P. van der Aalst\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Business Process Management (BPM) research resulted in a plethora of methods, techniques, and tools to support the design, enactment, management, and analysis of operational business processes. This survey aims to structure these results and provide an overview of the state-of-the-art in BPM. In BPM the concept of a process model is fundamental. Process models may be used to configure information systems, but may also be used to analyze, understand, and improve the processes they describe. Hence, the introduction of BPM technology has both managerial and technical ramifications and may enable significant productivity improvements, cost savings, and flow-time reductions. The practical relevance of BPM and rapid developments over the last decade justify a comprehensive survey.\n",
            "------------------------------------\n",
            "Title :  Next-generation phenotyping of electronic health records\n",
            "Author/s :  G. Hripcsak, D. Albers\n",
            "Venue :  J. Am. Medical Informatics Assoc.\n",
            "year :  2012\n",
            "Abstract :  The national adoption of electronic health records (EHR) promises to make an unprecedented amount of data available for clinical research, but the data are complex, inaccurate, and frequently missing, and the record reflects complex processes aside from the patient's physiological state. We believe that the path forward requires studying the EHR as an object of interest in itself, and that new models, learning from data, and collaboration will lead to efficient use of the valuable information currently locked in health records.\n",
            "------------------------------------\n",
            "Title :  The impact of website quality on customer satisfaction and purchase intention: perceived playfulness and perceived flow as mediators\n",
            "Author/s :  Chia-Lin Hsu, Kuo-Chien Chang, Mu-Chen Chen\n",
            "Venue :  Inf. Syst. E Bus. Manag.\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Mobile Data Offloading through Opportunistic Communications and Social Participation\n",
            "Author/s :  B. Han, Pan Hui, V. S. A. Kumar, M. Marathe, Jianhua Shao, A. Srinivasan\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these algorithms for both synthetic and real-world mobility traces. For example, the Heuristic algorithm can offload mobile data traffic by up to 73.66 percent for a real-world mobility trace. Moreover, to investigate the feasibility of opportunistic communications for mobile phones, we implement a proof-of-concept prototype, called Opp-off, on Nokia N900 smartphones, which utilizes their Bluetooth interface for device/service discovery and content transfer.\n",
            "------------------------------------\n",
            "Title :  Digital Twin—The Simulation Aspect\n",
            "Author/s :  S. Boschert, R. Rosen\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Characterization techniques for nanoparticles: comparison and complementarity upon studying nanoparticle properties.\n",
            "Author/s :  S. Mourdikoudis, R. M. Pallares, N. Thanh\n",
            "Venue :  Nanoscale\n",
            "year :  2018\n",
            "Abstract :  Nanostructures have attracted huge interest as a rapidly growing class of materials for many applications. Several techniques have been used to characterize the size, crystal structure, elemental composition and a variety of other physical properties of nanoparticles. In several cases, there are physical properties that can be evaluated by more than one technique. Different strengths and limitations of each technique complicate the choice of the most suitable method, while often a combinatorial characterization approach is needed. In addition, given that the significance of nanoparticles in basic research and applications is constantly increasing, it is necessary that researchers from separate fields overcome the challenges in the reproducible and reliable characterization of nanomaterials, after their synthesis and further process (e.g. annealing) stages. The principal objective of this review is to summarize the present knowledge on the use, advances, advantages and weaknesses of a large number of experimental techniques that are available for the characterization of nanoparticles. Different characterization techniques are classified according to the concept/group of the technique used, the information they can provide, or the materials that they are destined for. We describe the main characteristics of the techniques and their operation principles and we give various examples of their use, presenting them in a comparative mode, when possible, in relation to the property studied in each case.\n",
            "------------------------------------\n",
            "Title :  DGIdb 3.0: a redesign and expansion of the drug–gene interaction database\n",
            "Author/s :  Kelsy C. Cotto, A. Wagner, Yang-Yang Feng, Susanna Kiwala, Adam C. Coffman, Gregory C. Spies, Alexander T. Wollam, N. Spies, O. Griffith, M. Griffith\n",
            "Venue :  Nucleic Acids Research\n",
            "year :  2017\n",
            "Abstract :  Abstract The drug–gene interaction database (DGIdb, www.dgidb.org) consolidates, organizes and presents drug–gene interactions and gene druggability information from papers, databases and web resources. DGIdb normalizes content from 30 disparate sources and allows for user-friendly advanced browsing, searching and filtering for ease of access through an intuitive web user interface, application programming interface (API) and public cloud-based server image. DGIdb v3.0 represents a major update of the database. Nine of the previously included 24 sources were updated. Six new resources were added, bringing the total number of sources to 30. These updates and additions of sources have cumulatively resulted in 56 309 interaction claims. This has also substantially expanded the comprehensive catalogue of druggable genes and anti-neoplastic drug–gene interactions included in the DGIdb. Along with these content updates, v3.0 has received a major overhaul of its codebase, including an updated user interface, preset interaction search filters, consolidation of interaction information into interaction groups, greatly improved search response times and upgrading the underlying web application framework. In addition, the expanded API features new endpoints which allow users to extract more detailed information about queried drugs, genes and drug–gene interactions, including listings of PubMed IDs, interaction type and other interaction metadata.\n",
            "------------------------------------\n",
            "Title :  Brain rhythms and neural syntax: implications for efficient coding of cognitive content and neuropsychiatric disease.\n",
            "Author/s :  G. Buzsáki, Brendon O. Watson\n",
            "Venue :  Dialogues in Clinical Neuroscience\n",
            "year :  2012\n",
            "Abstract :  The perpetual activity of the cerebral cortex is largely supported by the variety of oscillations the brain generates, spanning a number of frequencies and anatomical locations, as well as behavioral correlates. First, we review findings from animal studies showing that most forms of brain rhythms are inhibition-based, producing rhythmic volleys of inhibitory inputs to principal cell populations, thereby providing alternating temporal windows of relatively reduced and enhanced excitability in neuronal networks. These inhibition-based mechanisms offer natural temporal frames to group or “chunk” neuronal activity into cell assemblies and sequences of assemblies, with more complex multi-oscillation interactions creating syntactical rules for the effective exchange of information among cortical networks. We then review recent studies in human psychiatric patients demonstrating a variety alterations in neural oscillations across all major psychiatric diseases, and suggest possible future research directions and treatment approaches based on the fundamental properties of brain rhythms.\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "from semanticscholar import SemanticScholar\n",
        "sch = SemanticScholar()\n",
        "resultsFromSemantic = []\n",
        "results = sch.search_paper('Information Retrival',year=\"2012-2023\")\n",
        "\n",
        "def authorFormat(authors):\n",
        "  authorList = []\n",
        "  for author in authors:\n",
        "    authorList.append(author.name)\n",
        "  \n",
        "  authorSentence = \", \".join(authorList)\n",
        "  return authorSentence\n",
        "\n",
        "\n",
        "for item in results:\n",
        "  print(\"Title : \",item.title)\n",
        "  print(\"Author/s : \",authorFormat(item.authors))\n",
        "  print(\"Venue : \",item.venue)\n",
        "  print(\"year : \",item.year)\n",
        "  print(\"Abstract : \",item.abstract)\n",
        "  print(36*\"-\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ3V7Cguwql_"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twitter_scraper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "DjeUEftq2FIW",
        "outputId": "a6733015-e891-4a64-8abb-79bf9239a6c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twitter_scraper\n",
            "  Downloading twitter_scraper-0.4.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting MechanicalSoup\n",
            "  Downloading MechanicalSoup-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.8/dist-packages (from twitter_scraper) (0.10.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from MechanicalSoup->twitter_scraper) (2.25.1)\n",
            "Collecting beautifulsoup4>=4.7\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from MechanicalSoup->twitter_scraper) (4.9.2)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.0.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (0.0.1)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (2.1.1)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.19.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.1.1)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (2.0.0)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.26.14)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (8.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (6.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (2022.12.7)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (10.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=5.0 in /usr/local/lib/python3.8/dist-packages (from fake-useragent->requests-html->twitter_scraper) (5.10.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyquery->requests-html->twitter_scraper) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->twitter_scraper) (3.12.1)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, MechanicalSoup, twitter_scraper\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed MechanicalSoup-1.2.0 beautifulsoup4-4.11.2 soupsieve-2.3.2.post1 twitter_scraper-0.4.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "XGhxVMz_wqmA",
        "outputId": "d9de6206-ef88-413d-c142-99febafc5b98"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-830bb8c7c500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You code here (Please add comments in the code):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitter_scraper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#AccheDin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/twitter_scraper/modules/tweets.py\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(query, pages)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mpages\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/twitter_scraper/modules/tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[0;34m(pages)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 html = HTML(\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"items_html\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bunk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 )\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "from twitter_scraper import get_tweets\n",
        "for tweet in get_tweets('#AccheDin', pages=1):\n",
        "     print(tweet['text'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}