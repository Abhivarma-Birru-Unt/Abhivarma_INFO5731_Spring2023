{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhivarma-Birru-Unt/Abhivarma_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023_Abhivarma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_IxAhYrwql5"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdii6UZwql7"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIpIcpqTwql8"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "E9UTlS0Dwql8",
        "outputId": "ee57ca14-e638-403f-a412-46d19dd67f3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nHere we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\\nWe choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\\n\\nHere we scrape only the basic comment users have mentioned and the respective star rating they have given.\\nThese allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\\n\\nWe collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\\n\\nSTEPS:\\n1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\\n2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\\n3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\\n4. Iterate each page dynamically until we get atleast 1000 reviews of the product\\n5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \\n6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\\n7. Print or Display the dataframe to get the respective reviews.\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Here we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\n",
        "We choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\n",
        "\n",
        "Here we scrape only the basic comment users have mentioned and the respective star rating they have given.\n",
        "These allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\n",
        "\n",
        "We collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\n",
        "\n",
        "STEPS:\n",
        "1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\n",
        "2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\n",
        "3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\n",
        "4. Iterate each page dynamically until we get atleast 1000 reviews of the product\n",
        "5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \n",
        "6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\n",
        "7. Print or Display the dataframe to get the respective reviews.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGRL5c6wql9"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jjrDdfv-wql-",
        "outputId": "7db832c7-58d2-4542-ccfd-bd9b7d99ea7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Comment Rating\n",
              "0               Fabulous!      5\n",
              "1     Best in the market!      5\n",
              "2                Terrific      5\n",
              "3               Fabulous!      5\n",
              "4             Really Nice      4\n",
              "...                   ...    ...\n",
              "1195               Super!      5\n",
              "1196              Awesome      5\n",
              "1197               Super!      5\n",
              "1198            Wonderful      4\n",
              "1199            Must buy!      5\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb33f1df-870e-4ae8-92ba-70fb71fabd8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terrific</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>Must buy!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb33f1df-870e-4ae8-92ba-70fb71fabd8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb33f1df-870e-4ae8-92ba-70fb71fabd8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb33f1df-870e-4ae8-92ba-70fb71fabd8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "reviewTextHeading = [] # This list stores the generic main heading of the review\n",
        "reviewRating =[] #List to star rratings of the reviews\n",
        "for page in range(120): #loop over 120 times to get atleast 1000 reviews\n",
        "  linkToFlipkart = \"https://www.flipkart.com/apple-iphone-xr-product-red-64-gb-includes-earpods-power-adapter/product-reviews/itmf9z7zhydhtbn5?pid=MOBF9Z7ZRWGTX3FA&lid=LSTMOBF9Z7ZRWGTX3FAWC8NB0&marketplace=FLIPKART\"+ str(page)  #use the flipkart link of iphone xr\n",
        "  specificPage = requests.get(linkToFlipkart)\n",
        "  soup = BeautifulSoup(specificPage.text,'html.parser')\n",
        "  mainReviewOfProduct=soup.find_all(class_ = '_2-N8zT') #classname which holds the content of main heading of the review\n",
        "  reviewCommentOfProduct = soup.find_all(class_='_3LWZlK _1BLPMq') #classname which holds the star rating of the review\n",
        "  for mainReview, commentOfReview in zip(mainReviewOfProduct, reviewCommentOfProduct):\n",
        "      reviewTextHeading.append(mainReview.text)  #append into the list of review headings\n",
        "      reviewRating.append(commentOfReview.text)  #append star rating into the list of starRating\n",
        "\n",
        "dataFrameOfRating = pd.DataFrame(list(zip(reviewTextHeading, reviewRating)),columns=[\"Comment\",\"Rating\"])\n",
        "dataFrameOfRating"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataFrameOfRating.to_csv('iphoneXRRating.csv', index=False)\n",
        "dataFrameOfRating.sort_values(\"Rating\",ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "clNYst_MDr2Q",
        "outputId": "d690eff9-4d3c-4dba-938b-4d65f0966231"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Comment Rating\n",
              "0              Fabulous!      5\n",
              "761  Best in the market!      5\n",
              "743            Fabulous!      5\n",
              "745               Super!      5\n",
              "746              Awesome      5\n",
              "..                   ...    ...\n",
              "188            Wonderful      4\n",
              "964          Really Nice      4\n",
              "688            Wonderful      4\n",
              "958            Wonderful      4\n",
              "534          Really Nice      4\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86c8ab51-a1db-4e4d-88a4-c8c4fbd59529\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86c8ab51-a1db-4e4d-88a4-c8c4fbd59529')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86c8ab51-a1db-4e4d-88a4-c8c4fbd59529 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86c8ab51-a1db-4e4d-88a4-c8c4fbd59529');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyR97nQKwql-"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install semanticscholar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RVWUgbUpCu",
        "outputId": "1c76fa37-4bc3-469a-c832-9e1c9f615c3f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: semanticscholar in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (8.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPVluKOxwql_",
        "outputId": "ae5ee34f-0769-4707-e287-fd3753287a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Abstract :  Viral products and ideas are intuitively understood to grow through a person-to-person diffusion process analogous to the spread of an infectious disease; however, until recently it has been prohibitively difficult to directly observe purportedly viral events, and thus to rigorously quantify or characterize their structural properties. Here we propose a formal measure of what we label “structural virality” that interpolates between two conceptual extremes: content that gains its popularity through a single, large broadcast and that which grows through multiple generations with any one individual directly responsible for only a fraction of the total adoption. We use this notion of structural virality to analyze a unique data set of a billion diffusion events on Twitter, including the propagation of news stories, videos, images, and petitions. We find that across all domains and all sizes of events, online diffusion is characterized by surprising structural diversity; that is, popular events regularly grow via both broadcast and viral mechanisms, as well as essentially all conceivable combinations of the two. Nevertheless, we find that structural virality is typically low, and remains so independent of size, suggesting that popularity is largely driven by the size of the largest broadcast. Finally, we attempt to replicate these findings with a model of contagion characterized by a low infection rate spreading on a scale-free network. We find that although several of our empirical findings are consistent with such a model, it fails to replicate the observed diversity of structural virality, thereby suggesting new directions for future modeling efforts. This paper was accepted by Lorin Hitt, information systems.\n",
            "------------------------------------\n",
            "Title :  Distributed Event-Triggered Control for Multi-Agent Systems\n",
            "Author/s :  D. Dimarogonas, Emilio Frazzoli, K. Johansson\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2012\n",
            "Abstract :  Event-driven strategies for multi-agent systems are motivated by the future use of embedded microprocessors with limited resources that will gather information and actuate the individual agent controller updates. The controller updates considered here are event-driven, depending on the ratio of a certain measurement error with respect to the norm of a function of the state, and are applied to a first order agreement problem. A centralized formulation is considered first and then its distributed counterpart, in which agents require knowledge only of their neighbors' states for the controller implementation. The results are then extended to a self-triggered setup, where each agent computes its next update time at the previous one, without having to keep track of the state error that triggers the actuation between two consecutive update instants. The results are illustrated through simulation examples.\n",
            "------------------------------------\n",
            "Title :  The Supply Chain Has No Clothes: Technology Adoption of Blockchain for Supply Chain Transparency\n",
            "Author/s :  Kristoffer Francisco, David Swanson\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Blockchain technology, popularized by Bitcoin cryptocurrency, is characterized as an open-source, decentralized, distributed database for storing transaction information. Rather than relying on centralized intermediaries (e.g., banks) this technology allows two parties to transact directly using duplicate, linked ledgers called blockchains. This makes transactions considerably more transparent than those provided by centralized systems. As a result, transactions are executed without relying on explicit trust [of a third party], but on the distributed trust based on the consensus of the network (i.e., other blockchain users). Applying this technology to improve supply chain transparency has many possibilities. Every product has a long and storied history. However, much of this history is presently obscured. Often, when negative practices are exposed, they quickly escalate to scandalous, and financially crippling proportions. There are many recent examples, such as the exposure of child labor upstream in the manufacturing process and the unethical use of rainforest resources. Blockchain may bring supply chain transparency to a new level, but presently academic and managerial adoption of blockchain technologies is limited by our understanding. To address this issue, this research uses the Unified Theory of Acceptance and Use of Technology (UTAUT) and the concept of technology innovation adoption as a foundational framework for supply chain traceability. A conceptual model is developed and the research culminates with supply chain implications of blockchain that are inspired by theory and literature review.\n",
            "------------------------------------\n",
            "Title :  Accurate information transmission through dynamic biochemical signaling networks\n",
            "Author/s :  Jangir Selimkhanov, Brooks Taylor, Jason Yao, A. Pilko, J. Albeck, A. Hoffmann, L. Tsimring, R. Wollman\n",
            "Venue :  Science\n",
            "year :  2014\n",
            "Abstract :  Stochasticity inherent to biochemical reactions (intrinsic noise) and variability in cellular states (extrinsic noise) degrade information transmitted through signaling networks. We analyzed the ability of temporal signal modulation—that is, dynamics—to reduce noise-induced information loss. In the extracellular signal–regulated kinase (ERK), calcium (Ca2+), and nuclear factor kappa-B (NF-κB) pathways, response dynamics resulted in significantly greater information transmission capacities compared to nondynamic responses. Theoretical analysis demonstrated that signaling dynamics has a key role in overcoming extrinsic noise. Experimental measurements of information transmission in the ERK network under varying signal-to-noise levels confirmed our predictions and showed that signaling dynamics mitigate, and can potentially eliminate, extrinsic noise–induced information loss. By curbing the information-degrading effects of cell-to-cell variability, dynamic responses substantially increase the accuracy of biochemical signaling networks. Signaling dynamics increase the information transmission capacity of biochemical signaling pathways. Dynamic signals enhance information transfer Cells need to process information about their external environment reliably to survive. However, variation, or noise, in biochemical reactions, or in the states of individual cells, make it hard for a cell to detect concentration, rather than just the presence or absence of an activating ligand. Selimkhanov et al. show that cellular signaling circuits get around this problem by continually monitoring signals over time. Such dynamic responses in cultured human cells more effectively distinguish signals from noise and thus avoid loss of information transmitted to the cell from external signals. Science, this issue p. 1370\n",
            "------------------------------------\n",
            "Title :  FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\n",
            "Author/s :  Caner Hazirbas, Lingni Ma, Csaba Domokos, D. Cremers\n",
            "Venue :  Asian Conference on Computer Vision\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Unsafe exposure analysis of mobile in-app advertisements\n",
            "Author/s :  Michael C. Grace, Wu Zhou, Xuxian Jiang, A. Sadeghi\n",
            "Venue :  Wireless Network Security\n",
            "year :  2012\n",
            "Abstract :  In recent years, there has been explosive growth in smartphone sales, which is accompanied with the availability of a huge number of smartphone applications (or simply apps). End users or consumers are attracted by the many interesting features offered by these devices and the associated apps. The developers of these apps are also benefited by the prospect of financial compensation, either by selling their apps directly or by embedding one of the many ad libraries available on smartphone platforms. In this paper, we focus on potential privacy and security risks posed by these embedded or in-app advertisement libraries (henceforth \"ad libraries,\" for brevity). To this end, we study the popular Android platform and collect 100,000 apps from the official Android Market in March-May, 2011. Among these apps, we identify 100 representative in-app ad libraries (embedded in 52.1% of them) and further develop a system called AdRisk to systematically identify potential risks. In particular, we first decouple the embedded ad libraries from host apps and then apply our system to statically examine the ad libraries, ranging from whether they will upload privacy-sensitive information to remote (ad) servers or whether they will download untrusted code from remote servers. Our results show that most existing ad libraries collect private information: some of them may be used for legitimate targeting purposes (i.e., the user's location) while others are hard to justify by invasively collecting the information such as the user's call logs, phone number, browser bookmarks, or even the list of installed apps on the phone. Moreover, additional ones go a step further by making use of an unsafe mechanism to directly fetch and run code from the Internet, which immediately leads to serious security risks. Our investigation indicates the symbiotic relationship between embedded ad libraries and host apps is one main reason behind these exposed risks. These results clearly show the need for better regulating the way ad libraries are integrated in Android apps.\n",
            "------------------------------------\n",
            "Title :  A Review of Facebook Research in the Social Sciences\n",
            "Author/s :  R. Wilson, S. Gosling, Lindsay T. Graham\n",
            "Venue :  Perspectives on Psychological Science\n",
            "year :  2012\n",
            "Abstract :  With over 800 million active users, Facebook is changing the way hundreds of millions of people relate to one another and share information. A rapidly growing body of research has accompanied the meteoric rise of Facebook as social scientists assess the impact of Facebook on social life. In addition, researchers have recognized the utility of Facebook as a novel tool to observe behavior in a naturalistic setting, test hypotheses, and recruit participants. However, research on Facebook emanates from a wide variety of disciplines, with results being published in a broad range of journals and conference proceedings, making it difficult to keep track of various findings. And because Facebook is a relatively recent phenomenon, uncertainty still exists about the most effective ways to do Facebook research. To address these issues, the authors conducted a comprehensive literature search, identifying 412 relevant articles, which were sorted into 5 categories: descriptive analysis of users, motivations for using Facebook, identity presentation, the role of Facebook in social interactions, and privacy and information disclosure. The literature review serves as the foundation from which to assess current findings and offer recommendations to the field for future research on Facebook and online social networks more broadly.\n",
            "------------------------------------\n",
            "Title :  Social media and vaccine hesitancy: new updates for the era of COVID-19 and globalized infectious diseases\n",
            "Author/s :  N. Puri, E. Coomes, H. Haghbayan, K. Gunaratne\n",
            "Venue :  Human Vaccines & Immunotherapeutics\n",
            "year :  2020\n",
            "Abstract :  ABSTRACT Despite major advances in vaccination over the past century, resurgence of vaccine-preventable illnesses has led the World Health Organization to identify vaccine hesitancy as a major threat to global health. Vaccine hesitancy may be fueled by health information obtained from a variety of sources, including new media such as the Internet and social media platforms. As access to technology has improved, social media has attained global penetrance. In contrast to traditional media, social media allow individuals to rapidly create and share content globally without editorial oversight. Users may self-select content streams, contributing to ideological isolation. As such, there are considerable public health concerns raised by anti-vaccination messaging on such platforms and the consequent potential for downstream vaccine hesitancy, including the compromise of public confidence in future vaccine development for novel pathogens, such as SARS-CoV-2 for the prevention of COVID-19. In this review, we discuss the current position of social media platforms in propagating vaccine hesitancy and explore next steps in how social media may be used to improve health literacy and foster public trust in vaccination.\n",
            "------------------------------------\n",
            "Title :  What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author/s :  Alexis Conneau, Germán Kruszewski, Guillaume Lample, Loïc Barrault, Marco Baroni\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2018\n",
            "Abstract :  Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title :  Information propagation in the Bitcoin network\n",
            "Author/s :  Christian Decker, Roger Wattenhofer\n",
            "Venue :  IEEE P2P 2013 Proceedings\n",
            "year :  2013\n",
            "Abstract :  Bitcoin is a digital currency that unlike traditional currencies does not rely on a centralized authority. Instead Bitcoin relies on a network of volunteers that collectively implement a replicated ledger and verify transactions. In this paper we analyze how Bitcoin uses a multi-hop broadcast to propagate transactions and blocks through the network to update the ledger replicas. We then use the gathered information to verify the conjecture that the propagation delay in the network is the primary cause for blockchain forks. Blockchain forks should be avoided as they are symptomatic for inconsistencies among the replicas in the network. We then show what can be achieved by pushing the current protocol to its limit with unilateral changes to the client's behavior.\n",
            "------------------------------------\n",
            "Title :  COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author/s :  Cristina M. Pulido, Beatriz Villarejo-Carballido, Gisela Redondo-Sama, Aitor Gómez\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title :  Translation techniques in cross-language information retrieval\n",
            "Author/s :  Dong Zhou, M. Truran, T. Brailsford, V. Wade, H. Ashman\n",
            "Venue :  CSUR\n",
            "year :  2012\n",
            "Abstract :  Cross-language information retrieval (CLIR) is an active sub-domain of information retrieval (IR). Like IR, CLIR is centered on the search for documents and for information contained within those documents. Unlike IR, CLIR must reconcile queries and documents that are written in different languages. The usual solution to this mismatch involves translating the query and/or the documents before performing the search. Translation is therefore a pivotal activity for CLIR engines. Over the last 15 years, the CLIR community has developed a wide range of techniques and models supporting free text translation. This article presents an overview of those techniques, with a special emphasis on recent developments.\n",
            "------------------------------------\n",
            "Title :  Digital Economics\n",
            "Author/s :  Avi Goldfarb, Catherine Tucker\n",
            "Venue :  Journal of Economic Literature\n",
            "year :  2017\n",
            "Abstract :  Digital technology is the representation of information in bits. This technology has reduced the cost of storage, computation, and transmission of data. Research on digital economics examines whether and how digital technology changes economic activity. In this review, we emphasize the reduction in five distinct economic costs associated with digital economic activity: search costs, replication costs, transportation costs, tracking costs, and verification costs. (JEL D24, D83, L86, O33, R41)\n",
            "------------------------------------\n",
            "Title :  Geographical tracking and mapping of coronavirus disease COVID-19/severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) epidemic and associated events around the world: how 21st century GIS technologies are supporting the global fight against outbreaks and epidemics\n",
            "Author/s :  M. N. Kamel Boulos, E. Geraghty\n",
            "Venue :  International Journal of Health Geographics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Primer in BERTology: What We Know About How BERT Works\n",
            "Author/s :  Anna Rogers, Olga Kovaleva, Anna Rumshisky\n",
            "Venue :  Transactions of the Association for Computational Linguistics\n",
            "year :  2020\n",
            "Abstract :  Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.\n",
            "------------------------------------\n",
            "Title :  Science vs Conspiracy: Collective Narratives in the Age of Misinformation\n",
            "Author/s :  Alessandro Bessi, Mauro Coletto, G. Davidescu, A. Scala, G. Caldarelli, W. Quattrociocchi\n",
            "Venue :  PLoS ONE\n",
            "year :  2014\n",
            "Abstract :  The large availability of user provided contents on online social media facilitates people aggregation around shared beliefs, interests, worldviews and narratives. In spite of the enthusiastic rhetoric about the so called collective intelligence unsubstantiated rumors and conspiracy theories—e.g., chemtrails, reptilians or the Illuminati—are pervasive in online social networks (OSN). In this work we study, on a sample of 1.2 million of individuals, how information related to very distinct narratives—i.e. main stream scientific and conspiracy news—are consumed and shape communities on Facebook. Our results show that polarized communities emerge around distinct types of contents and usual consumers of conspiracy news result to be more focused and self-contained on their specific contents. To test potential biases induced by the continued exposure to unsubstantiated rumors on users’ content selection, we conclude our analysis measuring how users respond to 4,709 troll information—i.e. parodistic and sarcastic imitation of conspiracy theories. We find that 77.92% of likes and 80.86% of comments are from users usually interacting with conspiracy stories.\n",
            "------------------------------------\n",
            "Title :  Guidance Regarding Methods for De-identification of Protected Health Information in Accordance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule\n",
            "Author/s :  B. Fitzgerald\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Guidance Regarding Methods for De-identification of Protected Health Information in Accordance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule This page provides guidance about methods and approaches to achieve de-identification in accordance with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Privacy Rule. The guidance explains and answers questions regarding the two methods that can be used to satisfy the Privacy Rule’s de-identification standard: Expert Determination and Safe Harbor . This guidance is intended to assist covered entities to understand what is de-identification, the general process by which de-identified information is created, and the options available for performing de-identification.\n",
            "------------------------------------\n",
            "Title :  Age of Information: An Introduction and Survey\n",
            "Author/s :  R. Yates, Yin Sun, D. Brown, S. Kaul, E. Modiano, S. Ulukus\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2020\n",
            "Abstract :  We summarize recent contributions in the broad area of age of information (AoI). In particular, we describe the current state of the art in the design and optimization of low-latency cyberphysical systems and applications in which sources send time-stamped status updates to interested recipients. These applications desire status updates at the recipients to be as timely as possible; however, this is typically constrained by limited system resources. We describe AoI timeliness metrics and present general methods of AoI evaluation analysis that are applicable to a wide variety of sources and systems. Starting from elementary single-server queues, we apply these AoI methods to a range of increasingly complex systems, including energy harvesting sensors transmitting over noisy channels, parallel server systems, queueing networks, and various single-hop and multi-hop wireless networks. We also explore how update age is related to MMSE methods of sampling, estimation and control of stochastic processes. The paper concludes with a review of efforts to employ age optimization in cyberphysical applications.\n",
            "------------------------------------\n",
            "Title :  miRBase: annotating high confidence microRNAs using deep sequencing data\n",
            "Author/s :  Ana Kozomara, S. Griffiths-Jones\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  We describe an update of the miRBase database (http://www.mirbase.org/), the primary microRNA sequence repository. The latest miRBase release (v20, June 2013) contains 24 521 microRNA loci from 206 species, processed to produce 30 424 mature microRNA products. The rate of deposition of novel microRNAs and the number of researchers involved in their discovery continue to increase, driven largely by small RNA deep sequencing experiments. In the face of these increases, and a range of microRNA annotation methods and criteria, maintaining the quality of the microRNA sequence data set is a significant challenge. Here, we describe recent developments of the miRBase database to address this issue. In particular, we describe the collation and use of deep sequencing data sets to assign levels of confidence to miRBase entries. We now provide a high confidence subset of miRBase entries, based on the pattern of mapped reads. The high confidence microRNA data set is available alongside the complete microRNA collection at http://www.mirbase.org/. We also describe embedding microRNA-specific Wikipedia pages on the miRBase website to encourage the microRNA community to contribute and share textual and functional information.\n",
            "------------------------------------\n",
            "Title :  Sensor Mania! The Internet of Things, Wearable Computing, Objective Metrics, and the Quantified Self 2.0\n",
            "Author/s :  M. Swan\n",
            "Venue :  J. Sens. Actuator Networks\n",
            "year :  2012\n",
            "Abstract :  The number of devices on the Internet exceeded the number of people on the Internet in 2008, and is estimated to reach 50 billion in 2020. A wide-ranging Internet of Things (IOT) ecosystem is emerging to support the process of connecting real-world objects like buildings, roads, household appliances, and human bodies to the Internet via sensors and microprocessor chips that record and transmit data such as sound waves, temperature, movement, and other variables. The explosion in Internet-connected sensors means that new classes of technical capability and application are being created. More granular 24/7 quantified monitoring is leading to a deeper understanding of the internal and external worlds encountered by humans. New data literacy behaviors such as correlation assessment, anomaly detection, and high-frequency data processing are developing as humans adapt to the different kinds of data flows enabled by the IOT. The IOT ecosystem has four critical functional steps: data creation, information generation, meaning-making, and action-taking. This paper provides a comprehensive review of the current and rapidly emerging ecosystem of the Internet of Things (IOT).\n",
            "------------------------------------\n",
            "Title :  Predicting information credibility in time-sensitive social media\n",
            "Author/s :  Carlos Castillo, Marcelo Mendoza, Bárbara Poblete\n",
            "Venue :  Internet Research\n",
            "year :  2013\n",
            "Abstract :  Purpose – Twitter is a popular microblogging service which has proven, in recent years, its potential for propagating news and information about developing events. The purpose of this paper is to focus on the analysis of information credibility on Twitter. The purpose of our research is to establish if an automatic discovery process of relevant and credible news events can be achieved. Design/methodology/approach – The paper follows a supervised learning approach for the task of automatic classification of credible news events. A first classifier decides if an information cascade corresponds to a newsworthy event. Then a second classifier decides if this cascade can be considered credible or not. The paper undertakes this effort training over a significant amount of labeled data, obtained using crowdsourcing tools. The paper validates these classifiers under two settings: the first, a sample of automatically detected Twitter “trends” in English, and second, the paper tests how well this model transfers to...\n",
            "------------------------------------\n",
            "Title :  Mandatory IFRS Adoption and Financial Statement Comparability\n",
            "Author/s :  François Brochet, Alan D. Jagolinzer, Edward J. Riedl\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This study examines whether mandatory adoption of International Financial Reporting Standards (IFRS) leads to capital market benefits through enhanced financial statement comparability. UK domestic standards are considered very similar to IFRS (Bae et al. 2008), suggesting any capital market benefits observed for UK-domiciled firms are more likely attributable to improvements in comparability (i.e., better precision of across-firm information) than to changes in information quality specific to the firm (i.e., core information quality). If IFRS adoption improves financial statement comparability, we predict this should reduce insiders’ ability to benefit from private information. Consistent with these expectations, we find that abnormal returns to insider purchases ― used to proxy for private information ― are reduced following IFRS adoption. Similar results obtain across numerous subsamples and proxies used to isolate IFRS effects attributable to comparability. Together, the findings are consistent with mandatory IFRS adoption improving comparability and thus leading to capital market benefits by reducing insiders’ ability to exploit private information.\n",
            "------------------------------------\n",
            "Title :  Gene Regulatory Network Inference from Single-Cell Data Using Multivariate Information Measures\n",
            "Author/s :  Thalia E. Chan, M. Stumpf, A. Babtie\n",
            "Venue :  bioRxiv\n",
            "year :  2017\n",
            "Abstract :  While single-cell gene expression experiments present new challenges for data processing, the cell-to-cell variability observed also reveals statistical relationships that can be used by information theory. Here, we use multivariate information theory to explore the statistical dependencies between triplets of genes in single-cell gene expression datasets. We develop PIDC, a fast, efficient algorithm that uses partial information decomposition (PID) to identify regulatory relationships between genes. We thoroughly evaluate the performance of our algorithm and demonstrate that the higher order information captured by PIDC allows it to outperform pairwise mutual information-based algorithms when recovering true relationships present in simulated data. We also infer gene regulatory networks from three experimental single-cell data sets and illustrate how network context, choices made during analysis, and sources of variability affect network inference. PIDC tutorials and open-source software for estimating PID are available here: https://github.com/Tchanders/network_inference_tutorials. PIDC should facilitate the identification of putative functional relationships and mechanistic hypotheses from single-cell transcriptomic data.\n",
            "------------------------------------\n",
            "Title :  Social networks predict patch discovery in a wild population of songbirds\n",
            "Author/s :  L. Aplin, D. Farine, J. Morand‐Ferron, B. Sheldon\n",
            "Venue :  Proceedings of the Royal Society B: Biological Sciences\n",
            "year :  2012\n",
            "Abstract :  Animals use social information in a wide variety of contexts. Its extensive use by individuals to locate food patches has been documented in a number of species, and various mechanisms of discovery have been identified. However, less is known about whether individuals differ in their access to, and use of, social information to find food. We measured the social network of a wild population of three sympatric tit species (family Paridae) and then recorded individual discovery of novel food patches. By using recently developed methods for network-based diffusion analysis, we show that order of arrival at new food patches was predicted by social associations. Models based only on group searching did not explain this relationship. Furthermore, network position was correlated with likelihood of patch discovery, with central individuals more likely to locate and use novel foraging patches than those with limited social connections. These results demonstrate the utility of social network analysis as a method to investigate social information use, and suggest that the greater probability of receiving social information about new foraging patches confers a benefit on more socially connected individuals.\n",
            "------------------------------------\n",
            "Title :  What to Expect When the Unexpected Happens: Social Media Communications Across Crises\n",
            "Author/s :  Alexandra Olteanu, Sarah Vieweg, Carlos Castillo\n",
            "Venue :  Conference on Computer Supported Cooperative Work\n",
            "year :  2015\n",
            "Abstract :  The use of social media to communicate timely information during crisis situations has become a common practice in recent years. In particular, the one-to-many nature of Twitter has created an opportunity for stakeholders to disseminate crisis-relevant messages, and to access vast amounts of information they may not otherwise have. Our goal is to understand what affected populations, response agencies and other stakeholders can expect-and not expect-from these data in various types of disaster situations. Anecdotal evidence suggests that different types of crises elicit different reactions from Twitter users, but we have yet to see whether this is in fact the case. In this paper, we investigate several crises-including natural hazards and human-induced disasters-in a systematic manner and with a consistent methodology. This leads to insights about the prevalence of different information types and sources across a variety of crisis situations.\n",
            "------------------------------------\n",
            "Title :  Table of Pharmacogenomic Biomarkers in Drug Labeling\n",
            "Author/s :  \n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Pharmacogenomics can play an important role in identifying responders and non-responders to medications, avoiding adverse events, and optimizing drug dose. Drug ÙH labeling may contain information on genomic biomarkers and can describe: ? Drug exposure and clinical response variabilityeling ? Risk for adverse events ? Genotype-specific dosing strationl Ther ? Mechanisms of drug actionstrationl Ther ? Polymorphic drug target and disposition genes The table below lists FDA-approved drugs with pharmacogenomic information in their labeling. The labeling for some, but not all, of the products includes specific actions to be taken based on the biomarker information. Pharmacogenomic information can appear in different sections of the labeling depending on the actions. For more ÙH information, please refer to the appropriate labeling guidance. Biomarkers in the table include but are not limited to germ-line or somatic gene variants, functional deficiencies, expression changes, and chromosomal abnormalities; selected protein biomarkers that are used to select patients for treatment are also included. This table does not include non-human genetic biomarkers (e.g., microbial variants that influence sensitivity to antibiotics),; or biomarkers that are used solely for diagnostic purposes (e.g., for genetic diseases) unless they are linked to drug activity or used to identify a specific subset in whom prescribing information differs.\n",
            "------------------------------------\n",
            "Title :  Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author/s :  G. Schryen\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Intelligent Reflecting Surface Aided MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer\n",
            "Author/s :  Cunhua Pan, Hong Ren, Kezhi Wang, M. Elkashlan, A. Nallanathan, Jiangzhou Wang, L. Hanzo\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2019\n",
            "Abstract :  An intelligent reflecting surface (IRS) is invoked for enhancing the energy harvesting performance of a simultaneous wireless information and power transfer (SWIPT) aided system. Specifically, an IRS-assisted SWIPT system is considered, where a multi-antenna aided base station (BS) communicates with several multi-antenna assisted information receivers (IRs), while guaranteeing the energy harvesting requirement of the energy receivers (ERs). To maximize the weighted sum rate (WSR) of IRs, the transmit precoding (TPC) matrices of the BS and passive phase shift matrix of the IRS should be jointly optimized. To tackle this challenging optimization problem, we first adopt the classic block coordinate descent (BCD) algorithm for decoupling the original optimization problem into several subproblems and alternately optimize the TPC matrices and the phase shift matrix. For each subproblem, we provide a low-complexity iterative algorithm, which is guaranteed to converge to the Karush-Kuhn-Tucker (KKT) point of each subproblem. The BCD algorithm is rigorously proved to converge to the KKT point of the original problem. We also conceive a feasibility checking method to study its feasibility. Our extensive simulation results confirm that employing IRSs in SWIPT beneficially enhances the system performance and the proposed BCD algorithm converges rapidly, which is appealing for practical applications.\n",
            "------------------------------------\n",
            "Title :  Some Simple Economics of Crowdfunding\n",
            "Author/s :  A. Agrawal, Christian Catalini, Avi Goldfarb\n",
            "Venue :  Innovation Policy and the Economy\n",
            "year :  2013\n",
            "Abstract :  It is not surprising that the financing of early-stage creative projects and ventures is typically geographically localized since these types of funding decisions are usually predicated on personal relationships and due diligence requiring face-to-face interactions in response to high levels of risk, uncertainty, and information asymmetry. So, to economists, the recent rise of crowdfunding—raising capital from many people through an online platform—which offers little opportunity for careful due diligence and involves not only friends and family but also many strangers from near and far, is initially startling. On the eve of launching equity-based crowdfunding, a new market for early-stage finance in the United States, we provide a preliminary exploration of its underlying economics. We highlight the extent to which economic theory, in particular transaction costs, reputation, and market design, can explain the rise of nonequity crowdfunding and offer a framework for speculating on how equity-based crowdfunding may unfold. We conclude by articulating open questions related to how crowdfunding may affect social welfare and the rate and direction of innovation.\n",
            "------------------------------------\n",
            "Title :  Scalable and Secure Sharing of Personal Health Records in Cloud Computing Using Attribute-Based Encryption\n",
            "Author/s :  Ming Li, Shucheng Yu, Yao Zheng, K. Ren, W. Lou\n",
            "Venue :  IEEE Transactions on Parallel and Distributed Systems\n",
            "year :  2013\n",
            "Abstract :  Personal health record (PHR) is an emerging patient-centric model of health information exchange, which is often outsourced to be stored at a third party, such as cloud providers. However, there have been wide privacy concerns as personal health information could be exposed to those third party servers and to unauthorized parties. To assure the patients' control over access to their own PHRs, it is a promising method to encrypt the PHRs before outsourcing. Yet, issues such as risks of privacy exposure, scalability in key management, flexible access, and efficient user revocation, have remained the most important challenges toward achieving fine-grained, cryptographically enforced data access control. In this paper, we propose a novel patient-centric framework and a suite of mechanisms for data access control to PHRs stored in semitrusted servers. To achieve fine-grained and scalable data access control for PHRs, we leverage attribute-based encryption (ABE) techniques to encrypt each patient's PHR file. Different from previous works in secure data outsourcing, we focus on the multiple data owner scenario, and divide the users in the PHR system into multiple security domains that greatly reduces the key management complexity for owners and users. A high degree of patient privacy is guaranteed simultaneously by exploiting multiauthority ABE. Our scheme also enables dynamic modification of access policies or file attributes, supports efficient on-demand user/attribute revocation and break-glass access under emergency scenarios. Extensive analytical and experimental results are presented which show the security, scalability, and efficiency of our proposed scheme.\n",
            "------------------------------------\n",
            "Title :  Localization algorithms of Wireless Sensor Networks: a survey\n",
            "Author/s :  Guangjie Han, Huihui Xu, T. Duong, Jinfang Jiang, T. Hara\n",
            "Venue :  Telecommunications Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  PEGASIS : Power-Efficient Gathering in Sensor Information Systems\n",
            "Author/s :  A. Sankaliya\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Sensor network consisting of nodes with limited battery power and wireless communications are deployed to collect useful information from the field. The main idea in PEGASIS is for each node to receive from and transmit to close neighbors and take turns being the leader for transmission to the BS. This approach distributes the energy load evenly among the sensor nodes in the network. Sensor nodes are randomly deployed in the sensor field, and therefore, the i th node is at a random location. The nodes will be organized to form a chain, which can either be accomplished by the sensor nodes themselves using a greedy algorithm. The algorithm to resolve the unbalanced energy consumption problem caused by long distance data transmission of some nodes in a chain formed by the greedy algorithm.\n",
            "------------------------------------\n",
            "Title :  A Survey on Network Embedding\n",
            "Author/s :  Peng Cui, Xiao Wang, J. Pei, Wenwu Zhu\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2017\n",
            "Abstract :  Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.\n",
            "------------------------------------\n",
            "Title :  Cognitive Load Theory: Implications for medical education: AMEE Guide No. 86\n",
            "Author/s :  John Q. Young, J. V. van Merrienboer, S. Durning, O. ten Cate\n",
            "Venue :  Medical Teacher\n",
            "year :  2014\n",
            "Abstract :  Abstract Cognitive Load Theory (CLT) builds upon established models of human memory that include the subsystems of sensory, working and long-term memory. Working memory (WM) can only process a limited number of information elements at any given time. This constraint creates a “bottleneck” for learning. CLT identifies three types of cognitive load that impact WM: intrinsic load (associated with performing essential aspects of the task), extraneous load (associated with non-essential aspects of the task) and germane load (associated with the deliberate use of cognitive strategies that facilitate learning). When the cognitive load associated with a task exceeds the learner’s WM capacity, performance and learning is impaired. To facilitate learning, CLT researchers have developed instructional techniques that decrease extraneous load (e.g. worked examples), titrate intrinsic load to the developmental stage of the learner (e.g. simplify task without decontextualizing) and ensure that unused WM capacity is dedicated to germane load, i.e. cognitive learning strategies. A number of instructional techniques have been empirically tested. As learners’ progress, curricula must also attend to the expertise-reversal effect. Instructional techniques that facilitate learning among early learners may not help and may even interfere with learning among more advanced learners. CLT has particular relevance to medical education because many of the professional activities to be learned require the simultaneous integration of multiple and varied sets of knowledge, skills and behaviors at a specific time and place. These activities possess high “element interactivity” and therefore impose a cognitive load that may surpass the WM capacity of the learner. Applications to various medical education settings (classroom, workplace and self-directed learning) are explored.\n",
            "------------------------------------\n",
            "Title :  Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts\n",
            "Author/s :  C. D. Santos, M. Gatti\n",
            "Venue :  International Conference on Computational Linguistics\n",
            "year :  2014\n",
            "Abstract :  Sentiment analysis of short texts such as single sentences and Twitter messages is challenging because of the limited contextual information that they normally contain. Effectively solving this task requires strategies that combine the small text content with prior knowledge and use more than just bag-of-words. In this work we propose a new deep convolutional neural network that exploits from characterto sentence-level information to perform sentiment analysis of short texts. We apply our approach for two corpora of two different domains: the Stanford Sentiment Treebank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentiment corpus (STS), which contains Twitter messages. For the SSTb corpus, our approach achieves state-of-the-art results for single sentence sentiment prediction in both binary positive/negative classification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy. For the STS corpus, our approach achieves a sentiment prediction accuracy of 86.4%.\n",
            "------------------------------------\n",
            "Title :  A social diffusion model of misinformation and disinformation for understanding human information behaviour\n",
            "Author/s :  N. Karlova, K. Fisher\n",
            "Venue :  Information Research\n",
            "year :  2013\n",
            "Abstract :  Introduction. People enjoy sharing information, even when they do not believe it. Thus, misinformation (inaccurate information) and disinformation (deceptive information) diffuse throughout social networks, as misinforming and disinforming are varieties of information behaviour. Social media have made such diffusion easier and faster. Many information behaviour models, however, suggest a normative model of information as true, accurate, complete, despite the ubiquity of misinformation and disinformation. Analysis. Misinformation and disinformation are defined and we show how they extend the concept of information through their informativeness. Table 1 summarizes the features of information, misinformation, and disinformation. Figure 1 illustrates the social diffusion process by which misinforming and disinforming function as types of information behaviour. Conclusion. Misinformation and disinformation are closely linked to information literacy, especially in terms of how they are diffused and shared and how people use both cues to credibility and cues to deception to make judgements. Misinformation and disinformation present both challenges and opportunities for individuals, businesses, and governments. Future work in immersive, 3D virtual worlds takes a naturalistic approach to understand the principal elements of cues to misinformation and disinformation.\n",
            "------------------------------------\n",
            "Title :  Thalamus plays a central role in ongoing cortical functioning\n",
            "Author/s :  S. Sherman\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Constrained Nonnegative Matrix Factorization for Image Representation\n",
            "Author/s :  Haifeng Liu, Zhaohui Wu, Xuelong Li, Deng Cai, Thomas S. Huang\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2012\n",
            "Abstract :  Nonnegative matrix factorization (NMF) is a popular technique for finding parts-based, linear representations of nonnegative data. It has been successfully applied in a wide range of applications such as pattern recognition, information retrieval, and computer vision. However, NMF is essentially an unsupervised method and cannot make use of label information. In this paper, we propose a novel semi-supervised matrix decomposition method, called Constrained Nonnegative Matrix Factorization (CNMF), which incorporates the label information as additional constraints. Specifically, we show how explicitly combining label information improves the discriminating power of the resulting matrix decomposition. We explore the proposed CNMF method with two cost function formulations and provide the corresponding update solutions for the optimization problems. Empirical experiments demonstrate the effectiveness of our novel algorithm in comparison to the state-of-the-art approaches through a set of evaluations based on real-world applications.\n",
            "------------------------------------\n",
            "Title :  Semantic Image Synthesis With Spatially-Adaptive Normalization\n",
            "Author/s :  Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.\n",
            "------------------------------------\n",
            "Title :  The Black Box Society: The Secret Algorithms That Control Money and Information\n",
            "Author/s :  Frank A. Pasquale\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Every day, corporations are connecting the dots about our personal behaviorsilently scrutinizing clues left behind by our work habits and Internet use. The data compiled and portraits created are incredibly detailed, to the point of being invasive. But who connects the dots about what firms are doing with this information? The Black Box Society argues that we all need to be able to do soand to set limits on how big data affects our lives. Hidden algorithms can make (or ruin) reputations, decide the destiny of entrepreneurs, or even devastate an entire economy. Shrouded in secrecy and complexity, decisions at major Silicon Valley and Wall Street firms were long assumed to be neutral and technical. But leaks, whistleblowers, and legal disputes have shed new light on automated judgment. Self-serving and reckless behavior is surprisingly common, and easy to hide in code protected by legal and real secrecy. Even after billions of dollars of fines have been levied, underfunded regulators may have only scratched the surface of this troubling behavior. Frank Pasquale exposes how powerful interests abuse secrecy for profit and explains ways to rein them in. Demanding transparency is only the first step. An intelligible society would assure that key decisions of its most important firms are fair, nondiscriminatory, and open to criticism. Silicon Valley and Wall Street need to accept as much accountability as they impose on others.\n",
            "------------------------------------\n",
            "Title :  Inferring gene regulatory networks from gene expression data by path consistency algorithm based on conditional mutual information\n",
            "Author/s :  Xiujun Zhang, Xingming Zhao, Kun He, Lehui Lu, Yongwei Cao, Jingdong Liu, Jin-Kao Hao, Zhiping Liu, Luonan Chen\n",
            "Venue :  Bioinform.\n",
            "year :  2012\n",
            "Abstract :  MOTIVATION\n",
            "Reconstruction of gene regulatory networks (GRNs), which explicitly represent the causality of developmental or regulatory process, is of utmost interest and has become a challenging computational problem for understanding the complex regulatory mechanisms in cellular systems. However, all existing methods of inferring GRNs from gene expression profiles have their strengths and weaknesses. In particular, many properties of GRNs, such as topology sparseness and non-linear dependence, are generally in regulation mechanism but seldom are taken into account simultaneously in one computational method.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "In this work, we present a novel method for inferring GRNs from gene expression data considering the non-linear dependence and topological structure of GRNs by employing path consistency algorithm (PCA) based on conditional mutual information (CMI). In this algorithm, the conditional dependence between a pair of genes is represented by the CMI between them. With the general hypothesis of Gaussian distribution underlying gene expression data, CMI between a pair of genes is computed by a concise formula involving the covariance matrices of the related gene expression profiles. The method is validated on the benchmark GRNs from the DREAM challenge and the widely used SOS DNA repair network in Escherichia coli. The cross-validation results confirmed the effectiveness of our method (PCA-CMI), which outperforms significantly other previous methods. Besides its high accuracy, our method is able to distinguish direct (or causal) interactions from indirect associations.\n",
            "\n",
            "\n",
            "AVAILABILITY\n",
            "All the source data and code are available at: http://csb.shu.edu.cn/subweb/grn.htm.\n",
            "\n",
            "\n",
            "CONTACT\n",
            "lnchen@sibs.ac.cn; zpliu@sibs.ac.cn\n",
            "\n",
            "\n",
            "SUPPLEMENTARY INFORMATION\n",
            "Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title :  Quantum resource theories\n",
            "Author/s :  E. Chitambar, G. Gour\n",
            "Venue :  Reviews of Modern Physics\n",
            "year :  2018\n",
            "Abstract :  Quantum resource theories (QRTs) offer a highly versatile and powerful framework for studying different phenomena in quantum physics. From quantum entanglement to quantum computation, resource theories can be used to quantify a desirable quantum effect, develop new protocols for its detection, and identify processes that optimize its use for a given application. Particularly, QRTs revolutionize the way we think about familiar properties of physical systems like entanglement, elevating them from just being interesting from a fundamental point of view to being useful in performing practical tasks. The basic methodology of a general QRT involves partitioning all quantum states into two groups, one consisting of free states and the other consisting of resource states. Accompanying the set of free states is a collection of free quantum operations arising from natural restrictions on physical systems, and that consists of all the physical processes allowed by the resource theory and which acts invariantly on the set of free states. The QRT then studies what information processing tasks become possible using the restricted operations. Despite the large degree of freedom in how one defines the free states and free operations, unexpected similarities emerge among different QRTs in terms of resource measures and resource convertibility. As a result, objects that appear quite distinct on the surface, such as entanglement and quantum reference frames, appear to have great similarity on a deeper structural level. In this article we review the general framework of a quantum resource theory, focusing on common structural features, operational tasks, and resource measures. To illustrate these concepts, an overview is provided on some of the more commonly studied QRTs in the literature.\n",
            "------------------------------------\n",
            "Title :  A survey on information visualization: recent advances and challenges\n",
            "Author/s :  Shixia Liu, Weiwei Cui, Yingcai Wu, Mengchen Liu\n",
            "Venue :  The Visual Computer\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A Theoretical Framework for Conversational Search\n",
            "Author/s :  Filip Radlinski, Nick Craswell\n",
            "Venue :  Conference on Human Information Interaction and Retrieval\n",
            "year :  2017\n",
            "Abstract :  This paper studies conversational approaches to information retrieval, presenting a theory and model of information interaction in a chat setting. In particular, we consider the question of what properties would be desirable for a conversational information retrieval system so that the system can allow users to answer a variety of information needs in a natural and efficient manner. We study past work on human conversations, and propose a small set of properties that taken together could measure the extent to which a system is conversational. Following this, we present a theoretical model of a conversational system that implements the properties. We describe how this system could be implemented, making the action space of an conversational search agent explicit. Our analysis of this model shows that while theoretical, the model could be practically implemented to satisfy the desirable properties presented. In doing so, we show that the properties are also feasible.\n",
            "------------------------------------\n",
            "Title :  Is This Review Believable? A Study of Factors Affecting the Credibility of Online Consumer Reviews from an ELM Perspective\n",
            "Author/s :  Cindy Man-Yee Cheung, C. Sia, Kevin K. Y. Kuan\n",
            "Venue :  Journal of the AIS\n",
            "year :  2012\n",
            "Abstract :  With the ever-increasing popularity of online consumer reviews, understanding what makes an online review believable has attracted increased attention from both academics and practitioners. Drawing on the elaboration likelihood model (ELM), this study examines four information cues used to evaluate the credibility of online reviews: Argument quality, source credibility, review consistency, and review sidedness, under different levels of involvement and expertise. We conducted an online survey that involved users of Epinions.com, a popular online consumer review website, to test the research model empirically. Consistent with previous research, the results reveal that argument quality, a central cue, was the primary factor affecting review credibility. Participants also relied on peripheral cues such as source credibility, review consistency, and review sidedness when evaluating online consumer reviews. Review sidedness had a stronger impact on review credibility when the recipient had a low involvement level and a high expertise level. However, the other interaction effects were not significant. We discuss the theoretical and practical implications of these results.\n",
            "------------------------------------\n",
            "Title :  Harvest-Then-Cooperate: Wireless-Powered Cooperative Communications\n",
            "Author/s :  H. Chen, Yonghui Li, J. L. Rebelatto, B. Filho, B. Vucetic\n",
            "Venue :  IEEE Transactions on Signal Processing\n",
            "year :  2014\n",
            "Abstract :  In this paper, we consider a wireless-powered cooperative communication network consisting of one hybrid access-point (AP), one source, and one relay. In contrast to conventional cooperative networks, the source and relay in the considered network have no embedded energy supply. They need to rely on the energy harvested from the signals broadcasted by the AP for their cooperative information transmission. Based on this three-node reference model, we propose a harvest-then-cooperate (HTC) protocol, in which the source and relay harvest energy from the AP in the downlink and work cooperatively in the uplink for the source's information transmission. Considering a delay-limited transmission mode, the approximate closed-form expression for the average throughput of the proposed protocol is derived over Rayleigh fading channels. Subsequently, this analysis is extended to the multi-relay scenario, where the approximate throughput of the HTC protocol with two popular relay selection schemes is derived. The asymptotic analyses for the throughput performance of the considered schemes at high signal-to-noise radio are also provided. All theoretical results are validated by numerical simulations. The impacts of the system parameters, such as time allocation, relay number, and relay position, on the throughput performance are extensively investigated.\n",
            "------------------------------------\n",
            "Title :  The effect of electronic word of mouth on brand image and purchase intention\n",
            "Author/s :  M. Jalilvand, Neda Samiei\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Purpose – Word‐of‐mouth (WOM) has been recognized as one of the most influential resources of information transmission. Advances in information technology and the emergence of online social network sites have changed the way information is transmitted. This phenomenon impacts consumers as this easily accessible information could greatly affect the consumption decision. The purpose of this paper is to examine the extent to which e‐WOM among consumers can influence brand image and purchase intention in the automobile industry.Design/methodology/approach – Measurement items are adapted from existing scales found in the marketing literature. Academic colleagues reviewed the items for face validity and readability. The scales are evaluated for reliability, convergent validity, and discriminant validity using data collected in a survey of Iran Khodro's prospective customers in Iran. A structural equation modeling procedure is applied to the examination of the influences of e‐WOM on brand image and purchase inte...\n",
            "------------------------------------\n",
            "Title :  Towards Actualizing the Value Potential of Korea Health Insurance Review and Assessment (HIRA) Data as a Resource for Health Research: Strengths, Limitations, Applications, and Strategies for Optimal Use of HIRA Data\n",
            "Author/s :  Jee-Ae Kim, Seokjun Yoon, L. Kim, Dong Sook Kim\n",
            "Venue :  Journal of Korean medical science\n",
            "year :  2017\n",
            "Abstract :  Health Insurance and Review Assessment (HIRA) in South Korea, also called National Health Insurance (NHI) data, is a repository of claims data collected in the process of reimbursing healthcare providers. Under the universal coverage system, having fee-for-services covering all citizens in South Korea, HIRA contains comprehensive and rich information pertaining to healthcare services such as treatments, pharmaceuticals, procedures, and diagnoses for almost 50 million beneficiaries. This corpus of HIRA data, which constitutes a large repository of data in the healthcare sector, has enormous potential to create value in several ways: enhancing the efficiency of the healthcare delivery system without compromising quality of care; adding supporting evidence for a given intervention; and providing the information needed to prevent (or monitor) adverse events. In order to actualize this potential, HIRA data need to actively be utilized for research. Thus understanding this data would greatly enhance this potential. We introduce HIRA data as an important source for health research and provide guidelines for researchers who are currently utilizing HIRA, or interested in doing so, to answer their research questions. We present the characteristics and structure of HIRA data. We discuss strengths and limitations that should be considered in conducting research with HIRA data and suggest strategies for optimal utilization of HIRA data by reviewing published research using HIRA data.\n",
            "------------------------------------\n",
            "Title :  A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques\n",
            "Author/s :  M. Allahyari, Seyedamin Pouriyeh, Mehdi Assefi, Saied Safaei, Elizabeth D. Trippe, Juan B. Gutiérrez, K. Kochut\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  The amount of text that is generated every day is increasing dramatically. This tremendous volume of mostly unstructured text cannot be simply processed and perceived by computers. Therefore, efficient and effective techniques and algorithms are required to discover useful patterns. Text mining is the task of extracting meaningful information from text, which has gained significant attentions in recent years. In this paper, we describe several of the most fundamental text mining tasks and techniques including text pre-processing, classification and clustering. Additionally, we briefly explain text mining in biomedical and health care domains.\n",
            "------------------------------------\n",
            "Title :  Cortical information flow during flexible sensorimotor decisions\n",
            "Author/s :  M. Siegel, T. J. Buschman, E. Miller\n",
            "Venue :  Science\n",
            "year :  2015\n",
            "Abstract :  Signal flow during sensorimotor choices Little is known about the flow of task signals across the brain. Siegel et al. simultaneously recorded from multiple units in the sensory, parietal, prefrontal, and motor cortex while monkeys were cued to perform one among two possible simple tasks. The proportion of neurons coding for stimuli, cues, tasks, and choices, and their response latency, varied across regions. Parietal and prefrontal brain regions encoded task information and choices with the same latency. Interestingly, all brain areas encoded all types of information. However, they differed functionally according to the proportions of neurons and their response latency. Science, this issue p. 1352 A dynamic network of cortical areas processing similar information but to different degrees is explored. During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.\n",
            "------------------------------------\n",
            "Title :  Internet use by pregnant women seeking pregnancy-related information: a systematic review\n",
            "Author/s :  P. Sayakhot, M. Carolan-Olah\n",
            "Venue :  BMC Pregnancy and Childbirth\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Twisted photons: new quantum perspectives in high dimensions\n",
            "Author/s :  Manuel Erhard, R. Fickler, M. Krenn, A. Zeilinger\n",
            "Venue :  Light: Science & Applications\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs\n",
            "Author/s :  Vishwanath A. Sindagi, Vishal M. Patel\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  We present a novel method called Contextual Pyramid CNN (CP-CNN) for generating high-quality crowd density and count estimation by explicitly incorporating global and local contextual information of crowd images. The proposed CP-CNN consists of four modules: Global Context Estimator (GCE), Local Context Estimator (LCE), Density Map Estimator (DME) and a Fusion-CNN (F-CNN). GCE is a VGG-16 based CNN that encodes global context and it is trained to classify input images into different density classes, whereas LCE is another CNN that encodes local context information and it is trained to perform patch-wise classification of input images into different density classes. DME is a multi-column architecture-based CNN that aims to generate high-dimensional feature maps from the input image which are fused with the contextual information estimated by GCE and LCE using F-CNN. To generate high resolution and high-quality density maps, F-CNN uses a set of convolutional and fractionally-strided convolutional layers and it is trained along with the DME in an end-to-end fashion using a combination of adversarial loss and pixellevel Euclidean loss. Extensive experiments on highly challenging datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Research Note - The Impact of External Word-of-Mouth Sources on Retailer Sales of High-Involvement Products\n",
            "Author/s :  B. Gu, Jaehong Park, Prabhudev Konana\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  Online word-of-mouth (WOM) such as consumer opinions, user experiences, and product reviews has become a major information source in consumer purchase decisions. Prior research on online WOM effect has focused mostly on low-involvement products such as books or CDs. For these products, retailer-hosted (internal) WOM is shown to influence sales overwhelmingly. Numerous surveys, however, suggest consumers often conduct pre-purchase searches for high-involvement products (e.g., digital cameras) and visit external WOM websites during the search process. In this study, we analyze the relative impact of external and internal WOMs on retailer sales for high-involvement products using a panel of sales and WOM data for 148 digital cameras from Amazon.com and three external WOM websites (Cnet, DpReview, and Epinions) over a four-month period. The results suggest that a retailer's internal WOM has a limited influence on its sales of high-involvement products, while external WOM sources have a significant impact on the retailer's sales. The findings imply that external WOM sources play an important role in the information search process.\n",
            "------------------------------------\n",
            "Title :  What's skill got to do with it?: Information literacy skills and self-views of ability among first-year college students\n",
            "Author/s :  M. Gross, D. Latham\n",
            "Venue :  J. Assoc. Inf. Sci. Technol.\n",
            "year :  2012\n",
            "Abstract :  This study replicates a previous study based on work in psychology, which demonstrates that students who score as below proficient in information literacy (IL) skills have a miscalibrated self-view of their ability. Simply stated, these students tend to believe that they have above-average IL skills, when, in fact, an objective test of their ability indicates that they are below-proficient in terms of their actual skills. This investigation was part of an Institute of Museum and Library Services-funded project and includes demographic data about participants, their scores on an objective test of their information literacy skills, and self-estimates of their ability. Findings support previous research that indicates many students come to college without proficient IL skills, that students with below-proficient IL skills have inflated views of their ability, and that this miscalibration can also be expressed by students who test as proficient. Implications for research and practice are discussed. © 2012 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title :  Physical Layer Security for Next Generation Wireless Networks: Theories, Technologies, and Challenges\n",
            "Author/s :  Yiliang Liu, Hsiao-Hwa Chen, Liangmin Wang\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2017\n",
            "Abstract :  Physical layer security (PHY-security) takes the advantages of channel randomness nature of transmission media to achieve communication confidentiality and authentication. Wiretap coding and signal processing technologies are expected to play vital roles in this new security mechanism. PHY-security has attracted a lot of attention due to its unique features and the fact that our daily life relies heavily on wireless communications for sensitive and private information transmissions. Compared to conventional cryptography that works to ensure all involved entities to load proper and authenticated cryptographic information, PHY-security technologies perform security functions without considering about how those security protocols are executed. In other words, it does not require to implement any extra security schemes or algorithms on other layers above the physical layer. This survey introduces the fundamental theories of PHY-security, covering confidentiality and authentication, and provides an overview on the state-of-the-art works on PHY-security technologies that can provide secure communications in wireless systems, along with the discussions on challenges and their proposed solutions. Furthermore, at the end of this paper, the open issues are identified as our future research directions.\n",
            "------------------------------------\n",
            "Title :  An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author/s :  Daniel Russo, Benjamin Van Roy\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2014\n",
            "Abstract :  We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title :  Diversity is All You Need: Learning Skills without a Reward Function\n",
            "Author/s :  Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, S. Levine\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2018\n",
            "Abstract :  Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN (\"Diversity is All You Need\"), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. In these environments, some of the learned skills correspond to solving the task, and each skill that solves the task does so in a distinct manner. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning\n",
            "------------------------------------\n",
            "Title :  Preparing for Life in a Digital Age: The IEA International Computer and Information Literacy Study International Report\n",
            "Author/s :  J. Fraillon, J. Ainley, Wolfram Schulz, Tim Friedman, E. Gebhardt\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Ability to use information and communication technologies (ICT) is an imperative for effective participation in todays digital age. Schools worldwide are responding to the need to provide young people with that ability. But how effective are they in this regard? The IEA International Computer and Information Literacy Study (ICILS) responded to this question by studying the extent to which young people have developed computer and information literacy (CIL), which is defined as the ability to use computers to investigate, create and communicate with others at home, school, the workplace and in society.The study was conducted under the auspices of the International Association for the Evaluation of Educational Achievement (IEA) and builds on a series of earlier IEA studies focusing on ICT in education.Data were gathered from almost 60,000 Grade 8 students in more than 3,300 schools from 21 education systems. This information was augmented by data from almost 35,000 teachers in those schools and by contextual data collected from school ICT-coordinators, school principals and the ICILS national research centers.The IEA ICILS team systematically investigated differences among the participating countries in students CIL outcomes, how participating countries were providing CIL-related education and how confident teachers were in using ICT in their pedagogical practice. The team also explored differences within and across countries with respect to relationships between CIL education outcomes and student characteristics and school contexts.In general, the study findings presented in this international report challenge the notion of young people as digital natives with a self-developed capacity to use digital technology. The large variations in CIL proficiency within and across the ICILS countries suggest it is naive to expect young people to develop CIL in the absence of coherent learning programs. Findings also indicate that system- and school-level planning needs to focus on increasing teacher expertise in using ICT for pedagogical purposes if such programs are to have the desired effect.The report furthermore presents an empirically derived scale and description of CIL learning that educational stakeholders can reference when deliberating about CIL education and use to monitor change in CIL over time.\n",
            "------------------------------------\n",
            "Title :  Should Banks' Stress Test Results Be Disclosed? An Analysis of the Costs and Benefits\n",
            "Author/s :  Itay Goldstein, H. Sapra\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Stress tests have become an important component of the supervisory toolkit. However, the extent of disclosure of stress-test results remains controversial. We argue that while stress tests uncover unique information to outsiders – because banks operate in second-best environments with multiple imperfections – there are potential endogenous costs associated with such disclosure.First, disclosure might interfere with the operation of the interbank market and the risk sharing provided in this market. Second, while disclosure might improve price efficiency and hence market discipline, it might also induce sub-optimal behavior in banks. Third, disclosure might induce ex post market externalities that lead to excessive and inefficient reaction to public news. Fourth, disclosure might also reduce traders incentives to gather information, which reduces market discipline because it hampers the ability of supervisors to learn from market data for their regulatory actions.Overall, we believe that disclosure of stress-test results is beneficial because it promotes financial stability. However, in promoting financial stability, such disclosures may exacerbate bank-specific inefficiencies. We provide some guidance on how such inefficiencies could be minimized.\n",
            "------------------------------------\n",
            "Title :  Permutation Entropy and Its Main Biomedical and Econophysics Applications: A Review\n",
            "Author/s :  M. Zanin, L. Zunino, O. Rosso, D. Papo\n",
            "Venue :  Entropy\n",
            "year :  2012\n",
            "Abstract :  Entropy is a powerful tool for the analysis of time series, as it allows describing the probability distributions of the possible state of a system, and therefore the information encoded in it. Nevertheless, important information may be codified also in the temporal dynamics, an aspect which is not usually taken into account. The idea of calculating entropy based on permutation patterns (that is, permutations defined by the order relations among values of a time series) has received a lot of attention in the last years, especially for the understanding of complex and chaotic systems. Permutation entropy directly accounts for the temporal information contained in the time series; furthermore, it has the quality of simplicity, robustness and very low computational cost. To celebrate the tenth anniversary of the original work, here we analyze the theoretical foundations of the permutation entropy, as well as the main recent applications to the analysis of economical markets and to the understanding of biomedical systems.\n",
            "------------------------------------\n",
            "Title :  Dynamic consent: a patient interface for twenty-first century research networks\n",
            "Author/s :  J. Kaye, E. Whitley, David Lund, M. Morrison, H. Teare, Karen Melham\n",
            "Venue :  European Journal of Human Genetics\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Deep supervised learning for hyperspectral data classification through convolutional neural networks\n",
            "Author/s :  K. Makantasis, K. Karantzalos, A. Doulamis, N. Doulamis\n",
            "Venue :  IEEE International Geoscience and Remote Sensing Symposium\n",
            "year :  2015\n",
            "Abstract :  Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  Health information on the Internet: gold mine or minefield?\n",
            "Author/s :  Tabitha Tonsaker, G. Bartlett, C. Trpkov\n",
            "Venue :  Canadian family physician Medecin de famille canadien\n",
            "year :  2014\n",
            "Abstract :  The Internet has revolutionized the way information is shared and accessed. Information retrieval is easier now than ever before. Since the rise of modern search engines, social networks, and ubiquitous access through devices such as smartphones and tablet or laptop computers, information is\n",
            "------------------------------------\n",
            "Title :  FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack\n",
            "Author/s :  Y. Yarom, K. Falkner\n",
            "Venue :  USENIX Security Symposium\n",
            "year :  2014\n",
            "Abstract :  Sharing memory pages between non-trusting processes is a common method of reducing the memory footprint of multi-tenanted systems. In this paper we demonstrate that, due to a weakness in the Intel X86 processors, page sharing exposes processes to information leaks. We present FLUSH+RELOAD, a cache side-channel attack technique that exploits this weakness to monitor access to memory lines in shared pages. Unlike previous cache side-channel attacks, FLUSH+RELOAD targets the Last-Level Cache (i.e. L3 on processors with three cache levels). Consequently, the attack program and the victim do not need to share the execution core. \n",
            " \n",
            "We demonstrate the efficacy of the FLUSH+RELOAD attack by using it to extract the private encryption keys from a victim program running GnuPG 1.4.13. We tested the attack both between two unrelated processes in a single operating system and between processes running in separate virtual machines. On average, the attack is able to recover 96.7% of the bits of the secret key by observing a single signature or decryption round.\n",
            "------------------------------------\n",
            "Title :  Activities at the Universal Protein Resource (UniProt)\n",
            "Author/s :  R. Apweiler, A. Bateman, M. Martin, C. O’Donovan, M. Magrane, Y. Alam-Faruque, E. Alpi, R. Antunes, J. Arganiska, E. Casanova, B. Bely, M. Bingley, C. Bonilla, R. Britto, B. Bursteinas, W. Chan, G. Chavali, Elena Cibrián-Uhalte, A. D. Silva, M. D. Giorgi, Tunca Dogan, F. Fazzini, P. Gane, Lg Castro, P. Garmiri, E. Hatton-Ellis, R. Hieta, R. Huntley, D. Legge, W. Liu, J. Luo, Alistair MacDougall, P. Mutowo, Andrew Nightingale, S. Orchard, K. Pichler, D. Poggioli, S. Pundir, L. Pureza, G. Qi, S. Rosanoff, Rabie Saidi, T. Sawford, A. Shypitsyna, E. Turner, Volynkin, T. Wardell, X. Watkins, H. Zellner, M. Corbett, M. Donnelly, P. V. Rensburg, M. Goujon, H. McWilliam, R. Lopez, I. Xenarios, L. Bougueleret, A. Bridge, S. Poux, N. Redaschi, L. Aimo, A. Auchincloss, K. Axelsen, Parit Bansal, Delphine Baratin, P. Binz, M. Blatter, B. Boeckmann, Jerven T. Bolleman, E. Boutet, L. Breuza, C. Casal-Casas, E. D. Castro, L. Cerutti, E. Coudert, Béatrice A. Cuche, M. Doche, D. Dornevil, Severine Duvaud, A. Estreicher, L. Famiglietti, M. Feuermann, E. Gasteiger, S. Gehant, Gerritsen, A. Gos, N. Gruaz-Gumowski, U. Hinz, C. Hulo, J. James, F. Jungo, G. Keller, Lara, P. Lemercier, J. Lew, D. Lieberherr, T. Lombardot, X. Martin, P. Masson, A. Morgat, T. Neto, S. Paesano, I. Pedruzzi, S. Pilbout, Monica Pozzato, Manuela Pruess, C. Rivoire, B. Roechert, Michel Schneider, C. Sigrist, K. Sonesson, S. Staehli, A. Stutz, S. Sundaram, M. Tognolli, L. Verbregue, A. Veuthey, Cathy H. Wu, C. Arighi, L. Arminski, Chuming Chen, Youhai H. Chen, J. Garavelli, Hongzhan Huang, K. Laiho, P. McGarvey, D. Natale, Baris E. Suzek, C. R. Vinayaka, Q. Wang, Y. Wang, L. Yeh, Yerramalla, J. Zhang\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to provide the scientific community with a comprehensive, high-quality and freely accessible resource of protein sequences and functional annotation. It integrates, interprets and standardizes data from literature and numerous resources to achieve the most comprehensive catalog possible of protein information. The central activities are the biocuration of the UniProt Knowledgebase and the dissemination of these data through our Web site and web services. UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR). UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.\n",
            "------------------------------------\n",
            "Title :  The Duality of Technology: Rethinking the Concept of Technology in Organizations\n",
            "Author/s :  W. Orlikowski\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This paper develops a new theoretical model with which to examine the interaction between technology and organizations. Early research studies assumed technology to be an objective, external force that would have deterministic impacts on organizational properties such as structure. Later researchers focused on the human aspect of technology, seeing it as the outcome of strategic choice and social action. This paper suggests that either view is incomplete, and proposes a reconceptualization of technology that takes both perspectives into account. A theoretical model—the structurational model of technology—is built on the basis of this new conceptualization, and its workings explored through discussion of a field study of information technology. The paper suggests that the reformulation of the technology concept and the structurational model of technology allow a deeper and more dialectical understanding of the interaction between technology and organizations. This understanding provides insight into the limits and opportunities of human choice, technology development and use, and organizational design. Implications for future research of the new concept of technology and the structurational model of technology are discussed.\n",
            "------------------------------------\n",
            "Title :  Collateral Crises\n",
            "Author/s :  Gary B. Gorton, G. Ordonez\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Short-term collateralized debt, such as demand deposits and money market instruments - private money, is efficient if agents are willing to lend without producing costly information about the collateral backing the debt. When the economy relies on such informationally-insensitive debt, firms with low quality collateral can borrow, generating a credit boom and an increase in output and consumption. Financial fragility builds up over time as information about counter-parties decays. A crisis occurs when a small shock then causes a large change in the information environment. Agents suddenly have incentives to produce information, asymmetric information becomes a threat and there is a decline in output and consumption. A social planner would produce more information than private agents, but would not always want to eliminate fragility.\n",
            "------------------------------------\n",
            "Title :  The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics\n",
            "Author/s :  D. Ivanov, A. Dolgui, B. Sokolov\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2018\n",
            "Abstract :  The impact of digitalisation and Industry 4.0 on the ripple effect and disruption risk control analytics in the supply chain (SC) is studied. The research framework combines the results from two isolated areas, i.e. the impact of digitalisation on SC management (SCM) and the impact of SCM on the ripple effect control. To the best of our knowledge, this is the first study that connects business, information, engineering and analytics perspectives on digitalisation and SC risks. This paper does not pretend to be encyclopedic, but rather analyses recent literature and case-studies seeking to bring the discussion further with the help of a conceptual framework for researching the relationships between digitalisation and SC disruptions risks. In addition, it emerges with an SC risk analytics framework. It analyses perspectives and future transformations that can be expected in transition towards cyber-physical SCs. With these two frameworks, this study contributes to the literature by answering the questions of (1) what relations exist between big data analytics, Industry 4.0, additive manufacturing, advanced trace & tracking systems and SC disruption risks; (2) how digitalisation can contribute to enhancing ripple effect control; and (3) what digital technology-based extensions can trigger the developments towards SC risk analytics.\n",
            "------------------------------------\n",
            "Title :  Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author/s :  Christopher Courtney, Supradeep Dutta, Yong Li\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title :  Eliciting Expert Knowledge in Conservation Science\n",
            "Author/s :  T. Martin, M. Burgman, F. Fidler, P. Kuhnert, S. Low-Choy, M. McBride, K. Mengersen\n",
            "Venue :  Conservation Biology\n",
            "year :  2012\n",
            "Abstract :  Abstract:  Expert knowledge is used widely in the science and practice of conservation because of the complexity of problems, relative lack of data, and the imminent nature of many conservation decisions. Expert knowledge is substantive information on a particular topic that is not widely known by others. An expert is someone who holds this knowledge and who is often deferred to in its interpretation. We refer to predictions by experts of what may happen in a particular context as expert judgments. In general, an expert‐elicitation approach consists of five steps: deciding how information will be used, determining what to elicit, designing the elicitation process, performing the elicitation, and translating the elicited information into quantitative statements that can be used in a model or directly to make decisions. This last step is known as encoding. Some of the considerations in eliciting expert knowledge include determining how to work with multiple experts and how to combine multiple judgments, minimizing bias in the elicited information, and verifying the accuracy of expert information. We highlight structured elicitation techniques that, if adopted, will improve the accuracy and information content of expert judgment and ensure uncertainty is captured accurately. We suggest four aspects of an expert elicitation exercise be examined to determine its comprehensiveness and effectiveness: study design and context, elicitation design, elicitation method, and elicitation output. Just as the reliability of empirical data depends on the rigor with which it was acquired so too does that of expert knowledge.\n",
            "------------------------------------\n",
            "Title :  Deep supervised learning for hyperspectral data classification through convolutional neural networks\n",
            "Author/s :  K. Makantasis, K. Karantzalos, A. Doulamis, N. Doulamis\n",
            "Venue :  IEEE International Geoscience and Remote Sensing Symposium\n",
            "year :  2015\n",
            "Abstract :  Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  Ignorance, Debt and Financial Crises +\n",
            "Author/s :  Tri Vi Dang, Gary B. Gorton, Bengt Holmstrom\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  In this paper we provide a theory of money markets and private money. We show that preserving symmetric ignorance in liquidity provision is welfare maximizing and strictly dominates symmetric or even perfect information. A key property for the functioning of money markets is when agents have no need to ask questions and no incentive to produce private information about the value of the security. Debt is the optimal private money because it is least information acquisition sensitive. Bad public news (shock) about the fundamentals of assets that back debt can cause information-insensitive debt to become information-acquisition sensitive. The expected value of debt drops, but to prevent endogenous adverse selection agents reduce the amount of trade below the expected value of debt. The shock is amplified, leading to a financial crisis.\n",
            "------------------------------------\n",
            "Title :  Health information on the Internet: gold mine or minefield?\n",
            "Author/s :  Tabitha Tonsaker, G. Bartlett, C. Trpkov\n",
            "Venue :  Canadian family physician Medecin de famille canadien\n",
            "year :  2014\n",
            "Abstract :  The Internet has revolutionized the way information is shared and accessed. Information retrieval is easier now than ever before. Since the rise of modern search engines, social networks, and ubiquitous access through devices such as smartphones and tablet or laptop computers, information is\n",
            "------------------------------------\n",
            "Title :  Collateral Crises\n",
            "Author/s :  Gary B. Gorton, G. Ordonez\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Short-term collateralized debt, such as demand deposits and money market instruments - private money, is efficient if agents are willing to lend without producing costly information about the collateral backing the debt. When the economy relies on such informationally-insensitive debt, firms with low quality collateral can borrow, generating a credit boom and an increase in output and consumption. Financial fragility builds up over time as information about counter-parties decays. A crisis occurs when a small shock then causes a large change in the information environment. Agents suddenly have incentives to produce information, asymmetric information becomes a threat and there is a decline in output and consumption. A social planner would produce more information than private agents, but would not always want to eliminate fragility.\n",
            "------------------------------------\n",
            "Title :  The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics\n",
            "Author/s :  D. Ivanov, A. Dolgui, B. Sokolov\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2018\n",
            "Abstract :  The impact of digitalisation and Industry 4.0 on the ripple effect and disruption risk control analytics in the supply chain (SC) is studied. The research framework combines the results from two isolated areas, i.e. the impact of digitalisation on SC management (SCM) and the impact of SCM on the ripple effect control. To the best of our knowledge, this is the first study that connects business, information, engineering and analytics perspectives on digitalisation and SC risks. This paper does not pretend to be encyclopedic, but rather analyses recent literature and case-studies seeking to bring the discussion further with the help of a conceptual framework for researching the relationships between digitalisation and SC disruptions risks. In addition, it emerges with an SC risk analytics framework. It analyses perspectives and future transformations that can be expected in transition towards cyber-physical SCs. With these two frameworks, this study contributes to the literature by answering the questions of (1) what relations exist between big data analytics, Industry 4.0, additive manufacturing, advanced trace & tracking systems and SC disruption risks; (2) how digitalisation can contribute to enhancing ripple effect control; and (3) what digital technology-based extensions can trigger the developments towards SC risk analytics.\n",
            "------------------------------------\n",
            "Title :  What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author/s :  Alexis Conneau, Germán Kruszewski, Guillaume Lample, Loïc Barrault, Marco Baroni\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2018\n",
            "Abstract :  Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title :  Variable selection with stepwise and best subset approaches.\n",
            "Author/s :  Wentao Bao\n",
            "Venue :  Annals of Translational Medicine\n",
            "year :  2016\n",
            "Abstract :  While purposeful selection is performed partly by software and partly by hand, the stepwise and best subset approaches are automatically performed by software. Two R functions stepAIC() and bestglm() are well designed for stepwise and best subset regression, respectively. The stepAIC() function begins with a full or null model, and methods for stepwise regression can be specified in the direction argument with character values \"forward\", \"backward\" and \"both\". The bestglm() function begins with a data frame containing explanatory variables and response variables. The response variable should be in the last column. Varieties of goodness-of-fit criteria can be specified in the IC argument. The Bayesian information criterion (BIC) usually results in more parsimonious model than the Akaike information criterion.\n",
            "------------------------------------\n",
            "Title :  Electronic Health Records: Then, Now, and in the Future.\n",
            "Author/s :  R. Evans\n",
            "Venue :  Yearbook of medical informatics\n",
            "year :  2016\n",
            "Abstract :  OBJECTIVES\n",
            "Describe the state of Electronic Health Records (EHRs) in 1992 and their evolution by 2015 and where EHRs are expected to be in 25 years. Further to discuss the expectations for EHRs in 1992 and explore which of them were realized and what events accelerated or disrupted/derailed how EHRs evolved.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Literature search based on \"Electronic Health Record\", \"Medical Record\", and \"Medical Chart\" using Medline, Google, Wikipedia Medical, and Cochrane Libraries resulted in an initial review of 2,356 abstracts and other information in papers and books. Additional papers and books were identified through the review of references cited in the initial review.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "By 1992, hardware had become more affordable, powerful, and compact and the use of personal computers, local area networks, and the Internet provided faster and easier access to medical information. EHRs were initially developed and used at academic medical facilities but since most have been replaced by large vendor EHRs. While EHR use has increased and clinicians are being prepared to practice in an EHR-mediated world, technical issues have been overshadowed by procedural, professional, social, political, and especially ethical issues as well as the need for compliance with standards and information security. There have been enormous advancements that have taken place, but many of the early expectations for EHRs have not been realized and current EHRs still do not meet the needs of today's rapidly changing healthcare environment.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The current use of EHRs initiated by new technology would have been hard to foresee. Current and new EHR technology will help to provide international standards for interoperable applications that use health, social, economic, behavioral, and environmental data to communicate, interpret, and act intelligently upon complex healthcare information to foster precision medicine and a learning health system.\n",
            "------------------------------------\n",
            "Title :  The effect of electronic word of mouth on brand image and purchase intention\n",
            "Author/s :  M. Jalilvand, Neda Samiei\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Purpose – Word‐of‐mouth (WOM) has been recognized as one of the most influential resources of information transmission. Advances in information technology and the emergence of online social network sites have changed the way information is transmitted. This phenomenon impacts consumers as this easily accessible information could greatly affect the consumption decision. The purpose of this paper is to examine the extent to which e‐WOM among consumers can influence brand image and purchase intention in the automobile industry.Design/methodology/approach – Measurement items are adapted from existing scales found in the marketing literature. Academic colleagues reviewed the items for face validity and readability. The scales are evaluated for reliability, convergent validity, and discriminant validity using data collected in a survey of Iran Khodro's prospective customers in Iran. A structural equation modeling procedure is applied to the examination of the influences of e‐WOM on brand image and purchase inte...\n",
            "------------------------------------\n",
            "Title :  Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author/s :  Christopher Courtney, Supradeep Dutta, Yong Li\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title :  Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports\n",
            "Author/s :  Jian Zhou, Hongyu Zhang, D. Lo\n",
            "Venue :  International Conference on Software Engineering\n",
            "year :  2012\n",
            "Abstract :  For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.\n",
            "------------------------------------\n",
            "Title :  Eliciting Expert Knowledge in Conservation Science\n",
            "Author/s :  T. Martin, M. Burgman, F. Fidler, P. Kuhnert, S. Low-Choy, M. McBride, K. Mengersen\n",
            "Venue :  Conservation Biology\n",
            "year :  2012\n",
            "Abstract :  Abstract:  Expert knowledge is used widely in the science and practice of conservation because of the complexity of problems, relative lack of data, and the imminent nature of many conservation decisions. Expert knowledge is substantive information on a particular topic that is not widely known by others. An expert is someone who holds this knowledge and who is often deferred to in its interpretation. We refer to predictions by experts of what may happen in a particular context as expert judgments. In general, an expert‐elicitation approach consists of five steps: deciding how information will be used, determining what to elicit, designing the elicitation process, performing the elicitation, and translating the elicited information into quantitative statements that can be used in a model or directly to make decisions. This last step is known as encoding. Some of the considerations in eliciting expert knowledge include determining how to work with multiple experts and how to combine multiple judgments, minimizing bias in the elicited information, and verifying the accuracy of expert information. We highlight structured elicitation techniques that, if adopted, will improve the accuracy and information content of expert judgment and ensure uncertainty is captured accurately. We suggest four aspects of an expert elicitation exercise be examined to determine its comprehensiveness and effectiveness: study design and context, elicitation design, elicitation method, and elicitation output. Just as the reliability of empirical data depends on the rigor with which it was acquired so too does that of expert knowledge.\n",
            "------------------------------------\n",
            "Title :  Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\n",
            "Author/s :  Wei Shen, Jianyong Wang, Jiawei Han\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2015\n",
            "Abstract :  The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research. Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. Potential applications include information extraction, information retrieval, and knowledge base population. However, this task is challenging due to name variations and entity ambiguity. In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.\n",
            "------------------------------------\n",
            "Title :  Silent Listeners: The Evolution of Privacy and Disclosure on Facebook\n",
            "Author/s :  F. Stutzman, R. Gross, A. Acquisti\n",
            "Venue :  Journal of Privacy and Confidentiality\n",
            "year :  2013\n",
            "Abstract :  Over the past decade, social network sites have experienced dramatic growth in popularity, reaching most demographics and providing new opportunities for interaction and socialization. Through this growth, users have been challenged to manage novel privacy concerns and balance nuanced trade-offs between disclosing and withholding personal information. To date, however, no study has documented how privacy and disclosure evolved on social network sites over an extended period of time. In this manuscript we use profile data from a longitudinal panel of 5,076 Facebook users to understand how their privacy and disclosure behavior changed between 2005---the early days of the network---and 2011. Our analysis highlights three contrasting trends. First, over time Facebook users in our dataset exhibited increasingly privacy-seeking behavior, progressively decreasing the amount of personal data shared publicly with unconnected profiles in the same network. However, and second, changes implemented by Facebook near the end of the period of time under our observation arrested or in some cases inverted that trend. Third, the amount and scope of personal information that Facebook users revealed privately to other connected profiles actually increased over time---and because of that, so did disclosures to ``silent listeners'' on the network: Facebook itself, third-party apps, and (indirectly) advertisers. These findings highlight the tension between privacy choices as expressions of individual subjective preferences, and the role of the environment in shaping those choices.\n",
            "------------------------------------\n",
            "Title :  An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author/s :  Daniel Russo, Benjamin Van Roy\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2014\n",
            "Abstract :  We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title :  Trust-Aware Recommender Systems\n",
            "Author/s :  Mohammad Ali Abbasi, J. Tang\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Recommender systems are an effective solution to the information overload problem, specially in the online world where we are constantly faced with inordinately many choices. These systems try to find the items such as books or movies that match best with users’ preferences. Based on the different approaches to finding the items of interests to users, we can classify the recommender systems into three major groups. First, content based recommender systems use content information to make a recommendation. For example, such systems might recommend a romantic movie to a user that showed interest in romantic movies in her profile. Second, collaborative filtering recommender systems rely only on the past behavior of the users such as their previous transactions or ratings. By comparing this information, a collaborative filtering recommender system finds new items or users to users. In order to address the cold-start problem and fend off various types of attacks, the third class of recommender systems, namely trust-aware recommender systems, is proposed. These systems use social media and trust information to make a recommendation, which is shown to be promising in improving the accuracy of the recommendations. In this chapter, we give an overview of state-of-theart recommender systems with a focus on trust-aware recommender systems. In particular, we describe the ways that trust information can help to improve the quality of the recommendations. In the rest of the chapter, we introduce recommender systems, then trust in social media, and next trust-aware recommender systems. Trust-Aware Recommender Systems 3 1.1 Recommender Systems With the development of Web 2.0, information has increased at an unprecedented rate which aggravates the severity of the information overload problem for online users. For example, a search for “smartphone” returns 1,664,253 results in Amazon products or a search for “best movies to watch” in Google videos returns about 219,000,000 results. Due to the information overload problem, the decision-making process becomes perplexing when one is exposed to excessive information [58, 55, 19, 1]. Therefore, with the rapidly growing amount of available information and digital items on the web, it is necessary to use tools to filter this information in order to find items that are more likely to be of interest to the users. One can use search engines to overcome the information overload problem. In this case, the user has to refine the search terms or has to pick more specific query terms to narrow down the results. Another solution to overcome the information overload problem is to use top-k recommendations. In this approach, the system keeps a list of the most popular items and utilizes the list to recommend items to the user. For example, Ted is a website that uses this technique to recommend items to users. It can be seen in Figure 1.1, users can sort items bases on the different approaches such as overall popularity (most viewed), popularity in the past week (most emailed this week), or popularity in the past month (most popular this month) among others. Similar to search engines, top-k items are not usually customized based on users’ preferences and interest. In particulate, a top-k-item system returns the same list of items to people with different preferences. Therefore, customization is the major problem associated with these two approaches. Recommender systems are introduced to tackle the information overload, and the customization problem. Recommender systems are a subclass of information filtering systems that consider users’ preferences and recommended items that match with users’ preferences and interests [23]. These systems have become extremely common in recent years and are applied in a variety of applications including recommending products, social links, and digital items. The most popular ones are probably movies, music, news, books, and products in general [58, 70, 19, 26, 60]. Further, recommender systems are frequently used on recommending social links such as recommending people to follow on Twitter, befriend on social networks or dating sites [67, 37]. Furthermore, these systems are also used to accurately estimate the degree to which a particular user (from now on termed the target user) will like a particular item (the target item) [73]. Based on the type of data that recommender systems use, we can classify 1http://www.amazon.com 2https://www.google.com/#q=best+movies+to+watch&safe=active&tbm=vid 3http://www.ted.com/ 4 Trust-Aware Recommender Systems FIGURE 1.1: Ted.com uses a top-k item recommendation approach to rank items them into two major classes: content-based and collaborative filtering based recommender systems [76, 60]. Content-based recommendation systems use items’ features and characteristics to rank the items based on the user’s preferences. Collaborative filtering recommendation systems rely on the user’s past behavior e.g., purchases or ratings, to find similar users or items and utilize this information in order to find the items of interests to the user. In general, recommender systems are utility functions that predict the rating of item i from the item set I for user u from the user set U in the form of U × I → R, where rui is the rating of the item i for the given user u. The task of recommender systems is to predict user u’s rating for the given item i for which rui is unknown and use r̂ui to represent the predicted rating. The ratings, ru,i, can be any real number but often ratings are integers in the range [1, 5]. We use R to show all of the ratings. In real-world recommender systems, only a few users rate the items of interests (this number for many recommender system is less than 1%). Matrix 1.1 shows an example of a rating matrix with missing values. The goal of recommender systems is to predict these missing values. R =  5 2 3 4 3 4 2 2 5 3 5 5 3  (1.1) Trust-Aware Recommender Systems 5 Algorithm 1 Content-based recommendation 1: Describe the items that may be recommended. 2: Create a profile of the user that describes the types of items the user likes 3: Compare items to the user profile to determine what to recommend. The profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user. 1.1.1 Content-based Recommendation Content-based recommender systems uses items’ and users’ features to create a profile for each item or user. For example, movie profile might include attributes such as gender, participating actors, director, and office box popularity. User profile includes demographic information and users’s interests [28]. These systems use supervised machine learning to induce a classifier that can discriminate between items likely to be of interest to the user and those likely to be uninteresting [52, 5, 49]. The recommender recommends an item to a user based on a description of the item and a profile of the users’ interests. Algorithm 1 shows the main steps of a content-based recommendation. We usually use vector space model to represent users’ and items’ features. In this model, every item or user is represented as a vector. i = (t1, t2, ..., tn) (1.2) where tj is the frequency of term j in item i. To model users or items more accurately, instead of frequency we can use tf-idf which can be calculated as follows: tft,i = ft,i max{fz,i : z ∈ i} idft = log N nt (1.3) wt,i = tft,i × idft (1.4) where ft,i is the frequency of term t in item i, max{fz,i : z ∈ i} is the maximum term frequency in item i, N is the total number of items, nt is the number of items where term t appears. tft,i denotes the frequency of term t in item i, and idft denotes the inverse document frequency of term t, which inversely correlates with the number of items, that term t is appeared in their descriptions. The similarity between user u and item i can be calculated using Equation 1.5. sim(u, i) = ∑ t∈T wt,uwt,i √∑ t∈T w 2 t,u √∑ t∈T w 2 t,i (1.5) where T indicates the set of terms that appeared in item and user description. 6 Trust-Aware Recommender Systems 1.1.2 Collaborative Filtering (CF) Collaborative filtering is the process of filtering the information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc [69]. Collaborative filtering systems use the user’s past behavior, and recommend items that match their taste. Collaborative filtering recommender systems can be classified into memory-based and model-based collaborative filtering. In memory-based approach we predict the missing ratings based on similarity between users or items. In model-based approach, we use given user-item ratings to construct a model and use the model to predict missing ratings. We’ll give a detailed description of these two approaches in the following sections. The main advantage of this method is that the recommender system does not need to have any information about the users and content of the items to recommend. User-item ratings are the only information the system needs to operate. The following are assumptions for collaborative filtering systems [76]: • Users with similar ratings on some items are more likely to have similar ratings on future items, and • Items with similar ratings in the past are more likely to have similar ratings in the future. Figure 1.2 illustrates this approach for a small set of users and movies. The goal is recommending a new movie to Jack. In the first step, the system finds three other users that have similar movie taste as Jack’s. The next step it looks for other movies that these users liked. All three of them liked “Once Upon a Time in the West”, and two of them liked “Spider man”. Therefore, the top recommendation would be “Once Upon a Time in the West”. 1.1.2.1 Memory-based Collaborative Filtering In a memory-based approach, the recommender system aims to predict the missing ratings based on either similarity\n",
            "------------------------------------\n",
            "Title :  Information Frictions in Trade\n",
            "Author/s :  Treb Allen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  It is costly to learn about market conditions elsewhere, especially in developing countries. This paper examines how such information frictions affect trade. Using data on regional agricultural trade in the Philippines, I first document a number of observed patterns in trade flows and prices that suggest the presence of information frictions. I then incorporate information frictions into a perfect competition trade model by embedding a process whereby heterogeneous producers engage in a costly sequential search process to determine where to sell their produce. I show that introducing information frictions reconciles the theory with the observed patterns in the data. Structural estimation of the model finds that information frictions are quantitatively important: roughly half the observed regional price dispersion is due to information frictions. Furthermore, incorporating information frictions improves the out‐of‐sample predictive power of the model.\n",
            "------------------------------------\n",
            "Title :  Quantum resource theories\n",
            "Author/s :  E. Chitambar, G. Gour\n",
            "Venue :  Reviews of Modern Physics\n",
            "year :  2018\n",
            "Abstract :  Quantum resource theories (QRTs) offer a highly versatile and powerful framework for studying different phenomena in quantum physics. From quantum entanglement to quantum computation, resource theories can be used to quantify a desirable quantum effect, develop new protocols for its detection, and identify processes that optimize its use for a given application. Particularly, QRTs revolutionize the way we think about familiar properties of physical systems like entanglement, elevating them from just being interesting from a fundamental point of view to being useful in performing practical tasks. The basic methodology of a general QRT involves partitioning all quantum states into two groups, one consisting of free states and the other consisting of resource states. Accompanying the set of free states is a collection of free quantum operations arising from natural restrictions on physical systems, and that consists of all the physical processes allowed by the resource theory and which acts invariantly on the set of free states. The QRT then studies what information processing tasks become possible using the restricted operations. Despite the large degree of freedom in how one defines the free states and free operations, unexpected similarities emerge among different QRTs in terms of resource measures and resource convertibility. As a result, objects that appear quite distinct on the surface, such as entanglement and quantum reference frames, appear to have great similarity on a deeper structural level. In this article we review the general framework of a quantum resource theory, focusing on common structural features, operational tasks, and resource measures. To illustrate these concepts, an overview is provided on some of the more commonly studied QRTs in the literature.\n",
            "------------------------------------\n",
            "Title :  Sampling-based robotic information gathering algorithms\n",
            "Author/s :  G. Hollinger, G. Sukhatme\n",
            "Venue :  Int. J. Robotics Res.\n",
            "year :  2014\n",
            "Abstract :  We propose three sampling-based motion planning algorithms for generating informative mobile robot trajectories. The goal is to find a trajectory that maximizes an information quality metric (e.g. variance reduction, information gain, or mutual information) and also falls within a pre-specified budget constraint (e.g. fuel, energy, or time). Prior algorithms have employed combinatorial optimization techniques to solve these problems, but existing techniques are typically restricted to discrete domains and often scale poorly in the size of the problem. Our proposed rapidly exploring information gathering (RIG) algorithms combine ideas from sampling-based motion planning with branch and bound techniques to achieve efficient information gathering in continuous space with motion constraints. We provide analysis of the asymptotic optimality of our algorithms, and we present several conservative pruning strategies for modular, submodular, and time-varying information objectives. We demonstrate that our proposed techniques find optimal solutions more quickly than existing combinatorial solvers, and we provide a proof-of-concept field implementation on an autonomous surface vehicle performing a wireless signal strength monitoring task in a lake.\n",
            "------------------------------------\n",
            "Title :  Deep Learning: Methods and Applications\n",
            "Author/s :  L. Deng, Dong Yu\n",
            "Venue :  Foundations and Trends® in Signal Processing\n",
            "year :  2014\n",
            "Abstract :  This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.\n",
            "------------------------------------\n",
            "Title :  Adapting to Artificial Intelligence: Radiologists and Pathologists as Information Specialists.\n",
            "Author/s :  S. Jha, E. Topol\n",
            "Venue :  JAMA\n",
            "year :  2016\n",
            "Abstract :  Artificial intelligence—the mimicking of human cognition by computers—was once a fable in science fiction but is becoming reality in medicine. The combination of big data and artificial intelligence, referred to by some as the fourth industrial revolution,1 will change radiology and pathology along with other medical specialties. Although reports of radiologists and pathologists being replaced by computers seem exaggerated,2 these specialties must plan strategically for a future in which artificial intelligence is part of the health care workforce. Radiologists have always revered machines and technology. In 1960, Lusted predicted “an electronic scannercomputer to examine chest photofluorograms, to separate the clearly normal chest films from the abnormal chest films.”3 Lusted further suggested that “the abnormal chest films would be marked for later study by the radiologists.”3 Lusted’s intuitions were prescient: interpreting radiographs is pattern recognition; computers can recognize patterns and may be helpful because some roentgenographic analyses can be automated. Nearly 60 years after Lusted’s prediction, Enlitic, a technology company in Silicon Valley, inputted images of normal radiographs and radiographs with fractures into a computerized database.4 Using deep learning, a refined version of artificial neural networks, the\n",
            "------------------------------------\n",
            "Title :  You are facing the Mona Lisa: spot localization using PHY layer information\n",
            "Author/s :  Souvik Sen, B. Radunovic, Romit Roy Choudhury, T. Minka\n",
            "Venue :  ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services\n",
            "year :  2012\n",
            "Abstract :  This paper explores the viability of precise indoor localization using physical layer information in WiFi systems. We find evidence that channel responses from multiple OFDM subcarriers can be a promising location signature. While these signatures certainly vary over time and environmental mobility, we notice that their core structure preserves certain properties that are amenable to localization. We attempt to harness these opportunities through a functional system called PinLoc, implemented on off-the-shelf Intel 5300 cards. We evaluate the system in a busy engineering building, a crowded student center, a cafeteria, and at the Duke University museum, and demonstrate localization accuracies in the granularity of 1m x 1m boxes, called \"spots\". Results from 100 spots show that PinLoc is able to localize users to the correct spot with 89% mean accuracy, while incurring less than 6% false positives. We believe this is an important step forward, compared to the best indoor localization schemes of today, such as Horus.\n",
            "------------------------------------\n",
            "Title :  Information propagation in the Bitcoin network\n",
            "Author/s :  Christian Decker, Roger Wattenhofer\n",
            "Venue :  IEEE P2P 2013 Proceedings\n",
            "year :  2013\n",
            "Abstract :  Bitcoin is a digital currency that unlike traditional currencies does not rely on a centralized authority. Instead Bitcoin relies on a network of volunteers that collectively implement a replicated ledger and verify transactions. In this paper we analyze how Bitcoin uses a multi-hop broadcast to propagate transactions and blocks through the network to update the ledger replicas. We then use the gathered information to verify the conjecture that the propagation delay in the network is the primary cause for blockchain forks. Blockchain forks should be avoided as they are symptomatic for inconsistencies among the replicas in the network. We then show what can be achieved by pushing the current protocol to its limit with unilateral changes to the client's behavior.\n",
            "------------------------------------\n",
            "Title :  Quantum discord as resource for remote state preparation\n",
            "Author/s :  B. Dakić, Yannick Ole Lipp, Xiao-song Ma, M. Ringbauer, S. Kropatschek, S. Barz, T. Paterek, V. Vedral, A. Zeilinger, Č. Brukner, P. Walther\n",
            "Venue :  Nature Physics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Sensing as a service model for smart cities supported by Internet of Things\n",
            "Author/s :  Charith Perera, A. Zaslavsky, P. Christen, Dimitrios Georgakopoulos\n",
            "Venue :  Transactions on Emerging Telecommunications Technologies\n",
            "year :  2013\n",
            "Abstract :  The world population is growing at a rapid pace. Towns and cities are accommodating half of the world's population thereby creating tremendous pressure on every aspect of urban living. Cities are known to have large concentration of resources and facilities. Such environments attract people from rural areas. However, unprecedented attraction has now become an overwhelming issue for city governance and politics. The enormous pressure towards efficient city management has triggered various Smart City initiatives by both government and private sector businesses to invest in information and communication technologies to find sustainable solutions to the growing issues. The Internet of Things (IoT) has also gained significant attention over the past decade. IoT envisions to connect billions of sensors to the Internet and expects to use them for efficient and effective resource management in Smart Cities. Today, infrastructure, platforms and software applications are offered as services using cloud technologies. In this paper, we explore the concept of sensing as a service and how it fits with the IoT. Our objective is to investigate the concept of sensing as a service model in technological, economical and social perspectives and identify the major open challenges and issues. Copyright © 2013 John Wiley & Sons, Ltd.\n",
            "------------------------------------\n",
            "Title :  Mobile health\n",
            "Author/s :  A. Monteiro\n",
            "Venue :  Radiologia Brasileira\n",
            "year :  2014\n",
            "Abstract :  Radiol Bras. 2014 Mar/Abr;47(2):IX mHealth, or mobile health is a term associated with the daily practice of medicine and public health supported by mobile devices such as cell phones and tablets. It is an universal trend of convergence of all patients’ information and images, data banks as source of information, academic social networks, specialized remote support systems and alike, as a support to the medical practice and to the teaching of medicine. Additionally there is the possibility of access by patients to their reports, tests results and schedules. However, other low-cost technologies are available, such as Raspberry Pi, a credit-card-sized computer developed in the United Kingdom by the Raspberry Pi Foundation. Such project was aimed at facilitating and encouraging the teaching of computer sciences for children in that country, and involving the study of computer techniques, methods and tools, processes automation and development of solutions based on the use of digital processing. The suc-\n",
            "------------------------------------\n",
            "Title :  An Empirical Analysis of the Quality of Corporate Financial Disclosure\n",
            "Author/s :  S. Singhvi, H. Desai\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  IN A free enterprise system, variations in corporate disclosure practices are likely to result since corporations are managed by groups which have varying managerial philosophies and wide discretion in connection with disclosing information to the investing public. The quality of corporate disclosure influences to a great extent the quality of investment decisions made by investors. This study attempts to identify some of the characteristics of corporations in the United States which are associated with, and the probable implications of, the quality of corporate disclosure.\n",
            "------------------------------------\n",
            "Title :  Information, Role Models and Perceived Returns to Education Experimental Evidence from Madagascar\n",
            "Author/s :  T. Nguyen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This brief summarizes the information, role models and perceived returns to education experimental evidence from Madagascar. This paper shows that increasing perceived returns to education strengthens incentives for schooling when agents underestimate the actual returns. The author conducted a field experiment in Madagascar to study alternative ways to provide additional information about the returns to education: simply providing statistics versus using a role model, an actual person sharing his and her success story. Some argue that role models may be more effective than providing statistics to a largely illiterate population. However, this proposition depends on how households update their beliefs based on the information the role model brings. Motivated by a model of belief formation, the author randomly assigns schools to the role model intervention, the statistics intervention, or a combination of both. The author fined that providing statistics reduced the large gap between perceived returns and the statistics provided. As a result, it improved average test scores by 0.2 standard deviations. For those whose initial perceived returns were below the statistics, test scores improved by 0.37 standard deviations. Student attendance in statistics schools is also 3.5 percentage points higher than attendance in schools without statistics. Consistent with the theory, seeing a role model of poor background has a larger impact on poor children's test scores than seeing someone of rich background. Combining a role model with statistics leads to smaller treatment effects than statistics alone, also consistent with the theory. The key implication of my results is that households lack information, but are able to process new information and change their decisions in a sophisticated manner.\n",
            "------------------------------------\n",
            "Title :  Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers\n",
            "Author/s :  G. Ateniese, L. Mancini, A. Spognardi, Antonio Villani, Domenico Vitali, G. Felici\n",
            "Venue :  Int. J. Secur. Networks\n",
            "year :  2013\n",
            "Abstract :  Machine Learning (ML) algorithms are used to train computers to perform a variety of complex tasks and improve with experience. Computers learn how to recognize patterns, make unintended decisions, or react to a dynamic environment. Certain trained machines may be more effective than others because they are based on more suitable ML algorithms or because they were trained through superior training sets. Although ML algorithms are known and publicly released, training sets may not be reasonably ascertainable and, indeed, may be guarded as trade secrets. While much research has been performed about the privacy of the elements of training sets, in this paper we focus our attention on ML classifiers and on the statistical information that can be unconsciously or maliciously revealed from them. We show that it is possible to infer unexpected but useful information from ML classifiers. In particular, we build a novel meta-classifier and train it to hack other classifiers, obtaining meaningful information about their training sets. This kind of information leakage can be exploited, for example, by a vendor to build more effective classifiers or to simply acquire trade secrets from a competitor's apparatus, potentially violating its intellectual property rights.\n",
            "------------------------------------\n",
            "Title :  Automatic detection of rumor on Sina Weibo\n",
            "Author/s :  Fan Yang, Yang Liu, Xiaohui Yu, Min Yang\n",
            "Venue :  MDS '12\n",
            "year :  2012\n",
            "Abstract :  The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter, the world's largest micro-blogging platform, as the premise of research. In this work, we shift the premise and study the problem of information credibility on Sina Weibo, China's leading micro-blogging service provider. With eight times more users than Twitter, Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone, and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments, the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs, and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification, and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge, this is the first study on rumor analysis and detection on Sina Weibo.\n",
            "------------------------------------\n",
            "Title :  Seeking and sharing health information online: comparing search engines and social media\n",
            "Author/s :  M. Choudhury, M. Morris, Ryen W. White\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2014\n",
            "Abstract :  Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
            "------------------------------------\n",
            "Title :  Crowdsourcing, Citizen Science or Volunteered Geographic Information? The Current State of Crowdsourced Geographic Information\n",
            "Author/s :  L. See, P. Mooney, G. Foody, L. Bastin, A. Comber, J. Estima, S. Fritz, N. Kerle, B. Jiang, Mari Laakso, Hai-Ying Liu, G. Milcinski, Matej Niksic, M. Painho, Andrea Pődör, A. Raimond, M. Rutzinger\n",
            "Venue :  ISPRS Int. J. Geo Inf.\n",
            "year :  2016\n",
            "Abstract :  Citizens are increasingly becoming an important source of geographic information, sometimes entering domains that had until recently been the exclusive realm of authoritative agencies. This activity has a very diverse character as it can, amongst other things, be active or passive, involve spatial or aspatial data and the data provided can be variable in terms of key attributes such as format, description and quality. Unsurprisingly, therefore, there are a variety of terms used to describe data arising from citizens. In this article, the expressions used to describe citizen sensing of geographic information are reviewed and their use over time explored, prior to categorizing them and highlighting key issues in the current state of the subject. The latter involved a review of ~100 Internet sites with particular focus on their thematic topic, the nature of the data and issues such as incentives for contributors. This review suggests that most sites involve active rather than passive contribution, with citizens typically motivated by the desire to aid a worthy cause, often receiving little training. As such, this article provides a snapshot of the role of citizens in crowdsourcing geographic information and a guide to the current status of this rapidly emerging and evolving subject.\n",
            "------------------------------------\n",
            "Title :  VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback\n",
            "Author/s :  Ruining He, Julian McAuley\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " Modern recommender systems model people and items by discovering or `teasing apart' the underlying dimensions that encode the properties of items and users' preferences toward them. Critically, such dimensions are uncovered based on user feedback, often in implicit form (such as purchase histories, browsing logs, etc.); in addition, some recommender systems make use of side information, such as product attributes, temporal information, or review text.However one important feature that is typically ignored by existing personalized recommendation and ranking methods is the visual appearance of the items being considered. In this paper we propose a scalable factorization model to incorporate visual signals into predictors of people's opinions, which we apply to a selection of large, real-world datasets. We make use of visual features extracted from product images using (pre-trained) deep networks, on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people's feedback. This not only leads to significantly more accurate personalized ranking methods, but also helps to alleviate cold start issues, and qualitatively to analyze the visual dimensions that influence people's opinions.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Banks as Secret Keepers\n",
            "Author/s :  Tri Vi Dang, Gary B. Gorton, B. Holmström, G. Ordonez\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Banks are optimally opaque institutions. They produce debt for use as a transaction medium (bank money), which requires that information about the backing assets - loans - not be revealed, so that bank money does not fluctuate in value, reducing the efficiency of trade. This need for opacity conflicts with the production of information about investment projects, needed for allocative efficiency. Intermediaries exist to hide such information, so banks select portfolios of information-insensitive assets. For the economy as a whole, firms endogenously separate into bank finance and capital market/stock market finance depending on the cost of producing information about their projects.\n",
            "------------------------------------\n",
            "Title :  Unique in the shopping mall: On the reidentifiability of credit card metadata\n",
            "Author/s :  Y. de Montjoye, Laura Radaelli, V. Singh, A. Pentland\n",
            "Venue :  Science\n",
            "year :  2015\n",
            "Abstract :  Large-scale data sets of human behavior have the potential to fundamentally transform the way we fight diseases, design cities, or perform research. Metadata, however, contain sensitive information. Understanding the privacy of these data sets is key to their broad use and, ultimately, their impact. We study 3 months of credit card records for 1.1 million people and show that four spatiotemporal points are enough to uniquely reidentify 90% of individuals. We show that knowing the price of a transaction increases the risk of reidentification by 22%, on average. Finally, we show that even data sets that provide coarse information at any or all of the dimensions provide little anonymity and that women are more reidentifiable than men in credit card metadata.\n",
            "------------------------------------\n",
            "Title :  FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\n",
            "Author/s :  Caner Hazirbas, Lingni Ma, Csaba Domokos, D. Cremers\n",
            "Venue :  Asian Conference on Computer Vision\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Visualization and analysis of gene expression in tissue sections by spatial transcriptomics\n",
            "Author/s :  P. Ståhl, Fredrik Salmén, S. Vickovic, Anna Lundmark, J. F. Navarro, J. Magnusson, S. Giacomello, Michaela Asp, J. Westholm, M. Huss, A. Mollbrink, S. Linnarsson, S. Codeluppi, Å. Borg, F. Pontén, P. Costea, P. Sahlén, J. Mulder, O. Bergmann, J. Lundeberg, J. Frisén\n",
            "Venue :  Science\n",
            "year :  2016\n",
            "Abstract :  Spatial structure of RNA expression RNA-seq and similar methods can record gene expression within and among cells. Current methods typically lose positional information and many require arduous single-cell isolation and sequencing. Ståhl et al. have developed a way of measuring the spatial distribution of transcripts by annealing fixed brain or cancer tissue samples directly to bar-coded reverse transcriptase primers, performing reverse transcription followed by sequencing and computational reconstruction, and they can do so for multiple genes. Science, this issue p. 78 A new technique allows visualization and quantitative analysis of the spatially resolved transcriptome across individual tissue sections. Analysis of the pattern of proteins or messengerRNAs (mRNAs) in histological tissue sections is a cornerstone in biomedical research and diagnostics. This typically involves the visualization of a few proteins or expressed genes at a time. We have devised a strategy, which we call “spatial transcriptomics,” that allows visualization and quantitative analysis of the transcriptome with spatial resolution in individual tissue sections. By positioning histological sections on arrayed reverse transcription primers with unique positional barcodes, we demonstrate high-quality RNA-sequencing data with maintained two-dimensional positional information from the mouse brain and human breast cancer. Spatial transcriptomics provides quantitative gene expression data and visualization of the distribution of mRNAs within tissue sections and enables novel types of bioinformatics analyses, valuable in research and diagnostics.\n",
            "------------------------------------\n",
            "Title :  CSI Phase Fingerprinting for Indoor Localization With a Deep Learning Approach\n",
            "Author/s :  Xuyu Wang, Lingjun Gao, S. Mao\n",
            "Venue :  IEEE Internet of Things Journal\n",
            "year :  2016\n",
            "Abstract :  With the increasing demand of location-based services, indoor localization based on fingerprinting has become an increasingly important technique due to its high accuracy and low hardware requirement. In this paper, we propose PhaseFi, a fingerprinting system for indoor localization with calibrated channel state information (CSI) phase information. In PhaseFi, the raw phase information is first extracted from the multiple antennas and multiple subcarriers of the IEEE 802.11n network interface card by accessing the modified device driver. Then a linear transformation is applied to extract the calibrated phase information, which we prove to have a bounded variance. For the offline stage, we design a deep network with three hidden layers to train the calibrated phase data, and employ the weights of the deep network to represent fingerprints. A greedy learning algorithm is incorporated to train the weights layer-by-layer to reduce computational complexity, where a subnetwork between two consecutive layers forms a restricted Boltzmann machine. In the online stage, we use a probabilistic method based on the radial basis function for online location estimation. The proposed PhaseFi scheme is implemented and validated with extensive experiments in two representation indoor environments. It is shown to outperform three benchmark schemes based on CSI or received signal strength in both scenarios.\n",
            "------------------------------------\n",
            "Title :  The Limits of Price Discrimination\n",
            "Author/s :  D. Bergemann, Benjamin A. Brooks, S. Morris\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  We analyze the welfare consequences of a monopolist having additional information about consumers' tastes, beyond the prior distribution; the additional information can be used to charge different prices to different segments of the market, i.e., carry out \"third degree price discrimination.\" We show that the segmentation and pricing induced by the additional information can achieve every combination of consumer and producer surplus such that: (i) consumer surplus is non-negative, (ii) producer surplus is at least as high as profits under the uniform monopoly price, and (iii) total surplus does not exceed the efficient gains from trade. As well as characterizing the welfare impact of price discrimination, we examine the limits of how prices and quantities can change under price discrimination. We also examine the limits of price discrimination in richer environments with quantity discrimination and limited ability to segment the market.\n",
            "------------------------------------\n",
            "Title :  Collaborative filtering recommender systems\n",
            "Author/s :  M. Nilashi, Karamollah Bagherifard, O. Ibrahim, H. Alizadeh, L. Nojeem, Nazanin Roozegar\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recommender Systems are software tools and techniques for suggesting items to users by considering their preferences in an automated fashion. The suggestions provided are aimed at support users in various decision- making processes. Technically, recommender system has their origins in different fields such as Information Retrieval (IR), text classification, machine learning and Decision Support Systems (DSS). Recommender systems are used to address the Information Overload (IO) problem by recommending potentially interesting or useful items to users. They have proven to be worthy tools for online users to deal with the IO and have become one of the most popular and powerful tools in E-commerce. Many existing recommender systems rely on the Collaborative Filtering (CF) and have been extensively used in E-commerce .They have proven to be very effective with powerful techniques in many famous E-commerce companies. This study presents an overview of the field of recommender systems with current generation of recommendation methods and examines comprehensively CF systems with its algorithms.\n",
            "------------------------------------\n",
            "Title :  Replacing the Soft-Decision FEC Limit Paradigm in the Design of Optical Communication Systems*\n",
            "Author/s :  A. Alvarado, E. Agrell, D. Lavery, R. Maher, P. Bayvel\n",
            "Venue :  Journal of Lightwave Technology\n",
            "year :  2015\n",
            "Abstract :  The FEC limit paradigm is the prevalent practice for designing optical communication systems to attain a certain bit error rate (BER) without forward error correction (FEC). This practice assumes that there is an FEC code that will reduce the BER after decoding to the desired level. In this paper, we challenge this practice and show that the concept of a channel-independent FEC limit is invalid for soft-decision bit-wise decoding. It is shown that for low code rates and high-order modulation formats, the use of the soft-decision FEC limit paradigm can underestimate the spectral efficiencies by up to 20%. A better predictor for the BER after decoding is the generalized mutual information, which is shown to give consistent post-FEC BER predictions across different channel conditions and modulation formats. Extensive optical full-field simulations and experiments are carried out in both the linear and nonlinear transmission regimes to confirm the theoretical analysis.\n",
            "------------------------------------\n",
            "Title :  Motivated numeracy and enlightened self-government\n",
            "Author/s :  D. Kahan, E. Peters, Erica Dawson, P. Slovic\n",
            "Venue :  Behavioural Public Policy\n",
            "year :  2017\n",
            "Abstract :  Abstract Why does public conflict over societal risks persist in the face of compelling and widely accessible scientific evidence? We conducted an experiment to probe two alternative answers: the ‘science comprehension thesis’ (SCT), which identifies defects in the public's knowledge and reasoning capacities as the source of such controversies; and the ‘identity-protective cognition thesis’ (ICT), which treats cultural conflict as disabling the faculties that members of the public use to make sense of decision-relevant science. In our experiment, we presented subjects with a difficult problem that turned on their ability to draw valid causal inferences from empirical data. As expected, subjects highest in numeracy – a measure of the ability and disposition to make use of quantitative information – did substantially better than less numerate ones when the data were presented as results from a study of a new skin rash treatment. Also as expected, subjects’ responses became politically polarized – and even less accurate – when the same data were presented as results from the study of a gun control ban. But contrary to the prediction of SCT, such polarization did not abate among subjects highest in numeracy; instead, it increased. This outcome supported ICT, which predicted that more numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlooks. We discuss the theoretical and practical significance of these findings.\n",
            "------------------------------------\n",
            "Title :  Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\n",
            "Author/s :  Jun Liu, Amir Shahroudy, Dong Xu, G. Wang\n",
            "Venue :  European Conference on Computer Vision\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Mobile devices in medicine: a survey of how medical students, residents, and faculty use smartphones and other mobile devices to find information.\n",
            "Author/s :  J. Boruff, D. Storie\n",
            "Venue :  Journal of the Medical Library Association\n",
            "year :  2014\n",
            "Abstract :  OBJECTIVES\n",
            "The research investigated the extent to which students, residents, and faculty members in Canadian medical faculties use mobile devices, such as smartphones (e.g., iPhone, Android, Blackberry) and tablet computers (e.g., iPad), to answer clinical questions and find medical information. The results of this study will inform how health libraries can effectively support mobile technology and collections.\n",
            "\n",
            "\n",
            "METHODS\n",
            "An electronic survey was distributed by medical librarians at four Canadian universities to medical students, residents, and faculty members via departmental email discussion lists, personal contacts, and relevant websites. It investigated the types of information sought, facilitators to mobile device use in medical information seeking, barriers to access, support needs, familiarity with institutionally licensed resources, and most frequently used resources.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The survey of 1,210 respondents indicated widespread use of smartphones and tablets in clinical settings in 4 Canadian universities. Third- and fourth-year undergraduate students (i.e., those in their clinical clerkships) and medical residents, compared to other graduate students and faculty, used their mobile devices more often, used them for a broader range of activities, and purchased more resources for their devices.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Technological and intellectual barriers do not seem to prevent medical trainees and faculty from regularly using mobile devices for their medical information searches; however, barriers to access and lack of awareness might keep them from using reliable, library-licensed resources.\n",
            "\n",
            "\n",
            "IMPLICATIONS\n",
            "Libraries should focus on providing access to a smaller number of highly used mobile resources instead of a huge collection until library-licensed mobile resources have streamlined authentication processes.\n",
            "------------------------------------\n",
            "Title :  Functional correlates of the lateral and medial entorhinal cortex: objects, path integration and local–global reference frames\n",
            "Author/s :  J. Knierim, J. P. Neunuebel, Sachin S. Deshmukh\n",
            "Venue :  Philosophical Transactions of the Royal Society B: Biological Sciences\n",
            "year :  2014\n",
            "Abstract :  The hippocampus receives its major cortical input from the medial entorhinal cortex (MEC) and the lateral entorhinal cortex (LEC). It is commonly believed that the MEC provides spatial input to the hippocampus, whereas the LEC provides non-spatial input. We review new data which suggest that this simple dichotomy between ‘where’ versus ‘what’ needs revision. We propose a refinement of this model, which is more complex than the simple spatial–non-spatial dichotomy. MEC is proposed to be involved in path integration computations based on a global frame of reference, primarily using internally generated, self-motion cues and external input about environmental boundaries and scenes; it provides the hippocampus with a coordinate system that underlies the spatial context of an experience. LEC is proposed to process information about individual items and locations based on a local frame of reference, primarily using external sensory input; it provides the hippocampus with information about the content of an experience.\n",
            "------------------------------------\n",
            "Title :  Quality of the Finnish Hospital Discharge Register: A systematic review\n",
            "Author/s :  R. Sund\n",
            "Venue :  Scandinavian Journal of Public Health\n",
            "year :  2012\n",
            "Abstract :  Aims: The Finnish Hospital Discharge Register (FHDR) is one of the oldest individual level hospital discharge registers and has been intensively used for research purposes. The aim of this study was to gather information concerning the quality of FHDR into one place in terms of a systematic review of validation studies that compare data to external information. Methods: Several reference databases were searched for validity articles published until January 2012. For each included study, focus of validation, register years examined, number of compared observations, external source(s) of data, summary of validation results, and conclusions concerning the validity of FHDR were extracted. Results: In total, 32 different studies comparing FHDR data to external information were identified. Most of the studies examined validity in the case of vascular disease, mental disorders or injuries. More than 95% of discharges could be identified from the register. Positive predictive value (PPV) for common diagnoses was between 75 and 99%. Conclusions: Completeness and accuracy in the register seem to vary from satisfactory to very good in the register as long as the recognised limitations are taking into account. Poor recording of subsidiary diagnoses and secondary operations and other rarely used items are the most obvious limitations in validity, but do not compromise the value of data in FHDR in being used in studies that are not feasible to conduct otherwise.\n",
            "------------------------------------\n",
            "Title :  Preparing and conducting interviews to collect data.\n",
            "Author/s :  O. Doody, M. Noonan\n",
            "Venue :  Nurse Researcher\n",
            "year :  2013\n",
            "Abstract :  AIM\n",
            "To describe three styles of interviews and discuss issues regarding planning and conducting interviews.\n",
            "\n",
            "\n",
            "BACKGROUND\n",
            "Interviews are probably the approach most used to collect data in studies. They are particularly useful in uncovering the story behind a participant's experiences. Researchers can follow a line of questions to gain information about a topic, or further explore responses or findings. But the researcher needs to plan and decide the format of the interview before collecting data.\n",
            "\n",
            "\n",
            "REVIEW METHODS\n",
            "The authors included papers on structured, unstructured and semi-structured interviews published in a peer-reviewed joumrnal and in English.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Interviews are one of the most common metods of data collection in qualitative research. However they require the researcher to have a sound understanding of their use and appropriateness. The ability to conduct interviews is one that develops over time and to aid the researcher in developing their interview skills they should consult with other researchers, seeking comments and advice and, critically, to appraise audio recordings.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "This article aims to support students who are undertaking research modules as part of their academic studies, writing a research proposal or novice researchers who are about to use interviews as a means of data collection.\n",
            "\n",
            "\n",
            "IMPLICATIONS FOR RESEARCH/PRACTICE\n",
            "To conduct a successful interview, researchers need to develop their interview technique, choose the right method and carefully plan for all aspects of the process.\n",
            "------------------------------------\n",
            "Title :  Infoglut: How Too Much Information Is Changing the Way We Think and Know\n",
            "Author/s :  M. Andrejevic\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Today, more mediated information is available to more people than at any other time in human history. New and revitalized sense-making strategies multiply in response to the challenges of \"cutting through the clutter\" of competing narratives and taming the avalanche of information. Data miners, \"sentiment analysts,\" and decision markets offer to help bodies of data \"speak for themselves\"making sense of their own patterns so we dont have to. Neuromarketers and body language experts promise to peer behind peoples words to see what their brains are really thinking and feeling. New forms of information processing promise to displace the need for expertise and even comprehensionat least for those with access to the data. Infoglut explores the connections between these wide-ranging sense-making strategies for an era of information overload and \"big data,\" and the new forms of control they enable. Andrejevic critiques the popular embrace of deconstructive debunkery, calling into question the post-truth, post-narrative, and post-comprehension politics it underwrites, and tracing a way beyond them.\n",
            "------------------------------------\n",
            "Title :  What it will take to achieve the as-yet-unfulfilled promises of health information technology.\n",
            "Author/s :  A. Kellermann, Spencer S. Jones\n",
            "Venue :  Health Affairs\n",
            "year :  2013\n",
            "Abstract :  A team of RAND Corporation researchers projected in 2005 that rapid adoption of health information technology (IT) could save the United States more than $81 billion annually. Seven years later the empirical data on the technology's impact on health care efficiency and safety are mixed, and annual health care expenditures in the United States have grown by $800 billion. In our view, the disappointing performance of health IT to date can be largely attributed to several factors: sluggish adoption of health IT systems, coupled with the choice of systems that are neither interoperable nor easy to use; and the failure of health care providers and institutions to reengineer care processes to reap the full benefits of health IT. We believe that the original promise of health IT can be met if the systems are redesigned to address these flaws by creating more-standardized systems that are easier to use, are truly interoperable, and afford patients more access to and control over their health data. Providers must do their part by reengineering care processes to take full advantage of efficiencies offered by health IT, in the context of redesigned payment models that favor value over volume.\n",
            "------------------------------------\n",
            "Title :  How Technology Is Changing Work and Organizations\n",
            "Author/s :  W. Cascio, Ramiro Montealegre\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four ...\n",
            "------------------------------------\n",
            "Title :  Characterizing the Propagation of Situational Information in Social Media During COVID-19 Epidemic: A Case Study on Weibo\n",
            "Author/s :  Lifang Li, Qingpeng Zhang, Xiao Wang, J. Zhang, Tao Wang, Tian-Lu Gao, Wei Duan, K. Tsoi, Fei-yue Wang\n",
            "Venue :  IEEE Transactions on Computational Social Systems\n",
            "year :  2020\n",
            "Abstract :  During the ongoing outbreak of coronavirus disease (COVID-19), people use social media to acquire and exchange various types of information at a historic and unprecedented scale. Only the situational information are valuable for the public and authorities to response to the epidemic. Therefore, it is important to identify such situational information and to understand how it is being propagated on social media, so that appropriate information publishing strategies can be informed for the COVID-19 epidemic. This article sought to fill this gap by harnessing Weibo data and natural language processing techniques to classify the COVID-19-related information into seven types of situational information. We found specific features in predicting the reposted amount of each type of information. The results provide data-driven insights into the information need and public attention.\n",
            "------------------------------------\n",
            "Title :  Some Hesitant Fuzzy Aggregation Operators with Their Application in Group Decision Making\n",
            "Author/s :  M. Xia, Zeshui Xu, Na Chen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Pyramid Attention Network for Semantic Segmentation\n",
            "Author/s :  Hanchao Li, Pengfei Xiong, Jie An, Lingxue Wang\n",
            "Venue :  British Machine Vision Conference\n",
            "year :  2018\n",
            "Abstract :  A Pyramid Attention Network(PAN) is proposed to exploit the impact of global contextual information in semantic segmentation. Different from most existing works, we combine attention mechanism and spatial pyramid to extract precise dense features for pixel labeling instead of complicated dilated convolution and artificially designed decoder networks. Specifically, we introduce a Feature Pyramid Attention module to perform spatial pyramid attention structure on high-level output and combining global pooling to learn a better feature representation, and a Global Attention Upsample module on each decoder layer to provide global context as a guidance of low-level features to select category localization details. The proposed approach achieves state-of-the-art performance on PASCAL VOC 2012 and Cityscapes benchmarks with a new record of mIoU accuracy 84.0% on PASCAL VOC 2012, while training without COCO dataset.\n",
            "------------------------------------\n",
            "Title :  DeViSE: A Deep Visual-Semantic Embedding Model\n",
            "Author/s :  Andrea Frome, G. Corrado, Jonathon Shlens, Samy Bengio, J. Dean, M. Ranzato, Tomas Mikolov\n",
            "Venue :  NIPS\n",
            "year :  2013\n",
            "Abstract :  Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.\n",
            "------------------------------------\n",
            "Title :  Addressing the Personalization-Privacy Paradox: An Empirical Assessment from a Field Experiment on Smartphone Users\n",
            "Author/s :  J. Sutanto, Elia Palme, Chuan-Hoo Tan, C. Phang\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Privacy has been an enduring concern associated with commercial information technology (IT) applications, in particular regarding the issue of personalization. IT-enabled personalization, while potentially making the user computing experience more gratifying, often relies heavily on the user's personal information to deliver individualized services, which raises the user's privacy concerns. We term the tension between personalization and privacy, which follows from marketers exploiting consumers' data to offer personalized product information, the personalization--privacy paradox. To better understand this paradox, we build on the theoretical lenses of uses and gratification theory and information boundary theory to conceptualize the extent to which privacy impacts the process and content gratifications derived from personalization, and how an IT solution can be designed to alleviate privacy concerns. \n",
            " \n",
            "Set in the context of personalized advertising applications for smartphones, we propose and prototype an IT solution, referred to as a personalized, privacy-safe application, that retains users' information locally on their smartphones while still providing them with personalized product messages. We validated this solution through a field experiment by benchmarking it against two more conventional applications: a base nonpersonalized application that broadcasts non-personalized product information to users, and a personalized, nonprivacy safe application that transmits user information to a central marketer's server. The results show that (compared to the non-personalized application), while personalized, privacy-safe or not increased application usage (reflecting process gratification), it was only when it was privacy-safe that users saved product messages (reflecting content gratification) more frequently. Follow-up surveys corroborated these nuanced findings and further revealed the users' psychological states, which explained our field experiment results. We found that saving advertisements for content gratification led to a perceived intrusion of information boundary that made users reluctant to do so. Overall our proposed IT solution, which delivers a personalized service but avoids transmitting users' personal information to third parties, reduces users' perceptions that their information boundaries are being intruded upon, thus mitigating the personalization--privacy paradox and increasing both process and content gratification.\n",
            "------------------------------------\n",
            "Title :  Weighted-permutation entropy: a complexity measure for time series incorporating amplitude information.\n",
            "Author/s :  Bilal H. Fadlallah, Badong Chen, A. Keil, J. Príncipe\n",
            "Venue :  Physical review. E, Statistical, nonlinear, and soft matter physics\n",
            "year :  2013\n",
            "Abstract :  Permutation entropy (PE) has been recently suggested as a novel measure to characterize the complexity of nonlinear time series. In this paper, we propose a simple method to address some of PE's limitations, mainly its inability to differentiate between distinct patterns of a certain motif and the sensitivity of patterns close to the noise floor. The method relies on the fact that patterns may be too disparate in amplitudes and variances and proceeds by assigning weights for each extracted vector when computing the relative frequencies associated with every motif. Simulations were conducted over synthetic and real data for a weighting scheme inspired by the variance of each pattern. Results show better robustness and stability in the presence of higher levels of noise, in addition to a distinctive ability to extract complexity information from data with spiky features or having abrupt changes in magnitude.\n",
            "------------------------------------\n",
            "Title :  Quantum technologies with hybrid systems\n",
            "Author/s :  G. Kurizki, P. Bertet, Y. Kubo, K. Mølmer, D. Petrosyan, P. Rabl, J. Schmiedmayer\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  An extensively pursued current direction of research in physics aims at the development of practical technologies that exploit the effects of quantum mechanics. As part of this ongoing effort, devices for quantum information processing, secure communication, and high-precision sensing are being implemented with diverse systems, ranging from photons, atoms, and spins to mesoscopic superconducting and nanomechanical structures. Their physical properties make some of these systems better suited than others for specific tasks; thus, photons are well suited for transmitting quantum information, weakly interacting spins can serve as long-lived quantum memories, and superconducting elements can rapidly process information encoded in their quantum states. A central goal of the envisaged quantum technologies is to develop devices that can simultaneously perform several of these tasks, namely, reliably store, process, and transmit quantum information. Hybrid quantum systems composed of different physical components with complementary functionalities may provide precisely such multitasking capabilities. This article reviews some of the driving theoretical ideas and first experimental realizations of hybrid quantum systems and the opportunities and challenges they present and offers a glance at the near- and long-term perspectives of this fascinating and rapidly expanding field.\n",
            "------------------------------------\n",
            "Title :  Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty.\n",
            "Author/s :  G. Baele, P. Lemey, T. Bedford, A. Rambaut, M. Suchard, A. Alekseyenko\n",
            "Venue :  Molecular biology and evolution\n",
            "year :  2012\n",
            "Abstract :  Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.\n",
            "------------------------------------\n",
            "Title :  Spectral-Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network\n",
            "Author/s :  Ying Li, Haokui Zhang, Qiang Shen\n",
            "Venue :  Remote Sensing\n",
            "year :  2017\n",
            "Abstract :  Recent research has shown that using spectral–spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral–spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral–spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods—namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods—on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.\n",
            "------------------------------------\n",
            "Title :  Better reporting of interventions: template for intervention description and replication (TIDieR) checklist and guide\n",
            "Author/s :  T. Hoffmann, P. Glasziou, I. Boutron, R. Milne, R. Perera, D. Moher, D. Altman, V. Barbour, H. Macdonald, M. Johnston, S. Lamb, M. Dixon-Woods, P. McCulloch, J. Wyatt, A. Chan, S. Michie\n",
            "Venue :  BMJ : British Medical Journal\n",
            "year :  2014\n",
            "Abstract :  Without a complete published description of interventions, clinicians and patients cannot reliably implement interventions that are shown to be useful, and other researchers cannot replicate or build on research findings. The quality of description of interventions in publications, however, is remarkably poor. To improve the completeness of reporting, and ultimately the replicability, of interventions, an international group of experts and stakeholders developed the Template for Intervention Description and Replication (TIDieR) checklist and guide. The process involved a literature review for relevant checklists and research, a Delphi survey of an international panel of experts to guide item selection, and a face to face panel meeting. The resultant 12 item TIDieR checklist (brief name, why, what (materials), what (procedure), who provided, how, where, when and how much, tailoring, modifications, how well (planned), how well (actual)) is an extension of the CONSORT 2010 statement (item 5) and the SPIRIT 2013 statement (item 11). While the emphasis of the checklist is on trials, the guidance is intended to apply across all evaluative study designs. This paper presents the TIDieR checklist and guide, with an explanation and elaboration for each item, and examples of good reporting. The TIDieR checklist and guide should improve the reporting of interventions and make it easier for authors to structure accounts of their interventions, reviewers and editors to assess the descriptions, and readers to use the information.\n",
            "------------------------------------\n",
            "Title :  Bayesian Persuasion and Information Design\n",
            "Author/s :  Emir Kamenica\n",
            "Venue :  Annual Review of Economics\n",
            "year :  2019\n",
            "Abstract :  A school may improve its students’ job outcomes if it issues only coarse grades. Google can reduce congestion on roads by giving drivers noisy information about the state of traffic. A social planner might raise everyone's welfare by providing only partial information about solvency of banks. All of this can happen even when everyone is fully rational and understands the data-generating process. Each of these examples raises questions of what is the (socially or privately) optimal information that should be revealed. In this article, I review the literature that answers such questions.\n",
            "------------------------------------\n",
            "Title :  Why did my car just do that? Explaining semi-autonomous driving actions to improve driver understanding, trust, and performance\n",
            "Author/s :  Jeamin Koo, Jungsuk Kwac, Wendy Ju, M. Steinert, L. Leifer, C. Nass\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  NEQR: a novel enhanced quantum representation of digital images\n",
            "Author/s :  Yi Zhang, Kai Lu, Yinghui Gao, Mo Wang\n",
            "Venue :  Quantum Information Processing\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Digital Divide\n",
            "Author/s :  Peter A. Chow-White, Betty Ackah, Philippa R. Adams\n",
            "Venue :  Oxford Bibliographies Online Datasets\n",
            "year :  2018\n",
            "Abstract :  the Internet for older people by Peter Millward Focussing upon the elderly, this article utilises data discovered as researcher for Age Concern in Wigan (U.K.) and examines the feelings of older people toward the Internet. It explores the reasons why some clients and volunteers choose to use the Internet, whilst others do not, relating these perspectives to the organisations, alongside broader national (U.K.) and EU, commitments to reduce the digital divide. The article argues that for the elderly Internet usability is based upon more than availability of technology. Instead a lack of Web skills among the elderly leads to an opinion that information and communication technologies are for the young, leading to a long-term damage lack of interest in using the Internet.\n",
            "------------------------------------\n",
            "Title :  Immediate Psychological Responses and Associated Factors during the Initial Stage of the 2019 Coronavirus Disease (COVID-19) Epidemic among the General Population in China\n",
            "Author/s :  Cuiyan Wang, R. Pan, Xiaoyang Wan, Yilin Tan, Linkang Xu, C. Ho, R. Ho\n",
            "Venue :  International Journal of Environmental Research and Public Health\n",
            "year :  2020\n",
            "Abstract :  Background: The 2019 coronavirus disease (COVID-19) epidemic is a public health emergency of international concern and poses a challenge to psychological resilience. Research data are needed to develop evidence-driven strategies to reduce adverse psychological impacts and psychiatric symptoms during the epidemic. The aim of this study was to survey the general public in China to better understand their levels of psychological impact, anxiety, depression, and stress during the initial stage of the COVID-19 outbreak. The data will be used for future reference. Methods: From 31 January to 2 February 2020, we conducted an online survey using snowball sampling techniques. The online survey collected information on demographic data, physical symptoms in the past 14 days, contact history with COVID-19, knowledge and concerns about COVID-19, precautionary measures against COVID-19, and additional information required with respect to COVID-19. Psychological impact was assessed by the Impact of Event Scale-Revised (IES-R), and mental health status was assessed by the Depression, Anxiety and Stress Scale (DASS-21). Results: This study included 1210 respondents from 194 cities in China. In total, 53.8% of respondents rated the psychological impact of the outbreak as moderate or severe; 16.5% reported moderate to severe depressive symptoms; 28.8% reported moderate to severe anxiety symptoms; and 8.1% reported moderate to severe stress levels. Most respondents spent 20–24 h per day at home (84.7%); were worried about their family members contracting COVID-19 (75.2%); and were satisfied with the amount of health information available (75.1%). Female gender, student status, specific physical symptoms (e.g., myalgia, dizziness, coryza), and poor self-rated health status were significantly associated with a greater psychological impact of the outbreak and higher levels of stress, anxiety, and depression (p < 0.05). Specific up-to-date and accurate health information (e.g., treatment, local outbreak situation) and particular precautionary measures (e.g., hand hygiene, wearing a mask) were associated with a lower psychological impact of the outbreak and lower levels of stress, anxiety, and depression (p < 0.05). Conclusions: During the initial phase of the COVID-19 outbreak in China, more than half of the respondents rated the psychological impact as moderate-to-severe, and about one-third reported moderate-to-severe anxiety. Our findings identify factors associated with a lower level of psychological impact and better mental health status that can be used to formulate psychological interventions to improve the mental health of vulnerable groups during the COVID-19 epidemic.\n",
            "------------------------------------\n",
            "Title :  Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author/s :  G. Schryen\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Assessing the Probability of Bankruptcy\n",
            "Author/s :  Jarom Heaps\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Knowing whether or not a company is financial stable has always been a top concern for analysts and money managers. This paper compares the effectiveness of default prediction using two different types of measures: accounting and market based. Accounting measures have been the most popular even though, according to theory, a market based measure reflects all available information. Theory goes as far to say that accounting measures can add no incremental value to a market based measure. In my research I found that accounting based measures can be effective in their predictive power; the market-based measure (BSM) results were much more difficult to estimate within the limits of this research project.\n",
            "------------------------------------\n",
            "Title :  Multimodal Data Fusion: An Overview of Methods, Challenges, and Prospects\n",
            "Author/s :  D. Lahat, T. Adalı, C. Jutten\n",
            "Venue :  Proceedings of the IEEE\n",
            "year :  2015\n",
            "Abstract :  In various disciplines, information about the same phenomenon can be acquired from different types of detectors, at different conditions, in multiple experiments or subjects, among others. We use the term “modality” for each such acquisition framework. Due to the rich characteristics of natural phenomena, it is rare that a single modality provides complete knowledge of the phenomenon of interest. The increasing availability of several modalities reporting on the same system introduces new degrees of freedom, which raise questions beyond those related to exploiting each modality separately. As we argue, many of these questions, or “challenges,” are common to multiple domains. This paper deals with two key issues: “why we need data fusion” and “how we perform it.” The first issue is motivated by numerous examples in science and technology, followed by a mathematical framework that showcases some of the benefits that data fusion provides. In order to address the second issue, “diversity” is introduced as a key concept, and a number of data-driven solutions based on matrix and tensor decompositions are discussed, emphasizing how they account for diversity across the data sets. The aim of this paper is to provide the reader, regardless of his or her community of origin, with a taste of the vastness of the field, the prospects, and the opportunities that it holds.\n",
            "------------------------------------\n",
            "Title :  Social Media, Knowledge Sharing, and Innovation: Toward a Theory of Communication Visibility\n",
            "Author/s :  P. Leonardi\n",
            "Venue :  Information systems research\n",
            "year :  2014\n",
            "Abstract :  This paper offers a theory of communication visibility based on a field study of the implementation of a new enterprise social networking site in a large financial services organization. The emerging theory suggests that once invisible communication occurring between others in the organization becomes visible for third parties, those third parties could improve their metaknowledge i.e., knowledge of who knows what and who knows whom. Communication visibility, in this case made possible by the enterprise social networking site, leads to enhanced awareness of who knows what and whom through two interrelated mechanisms: message transparency and network translucence. Seeing the contents of other's messages helps third-party observers make inferences about coworkers' knowledge. Tangentially, seeing the structure of coworkers' communication networks helps third-party observers make inferences about those with whom coworkers regularly communicate. The emerging theory further suggests that enhanced metaknowledge can lead to more innovative products and services and less knowledge duplication if employees learn to work in new ways. By learning vicariously rather than through experience, workers can more effectively recombine existing ideas into new ideas and avoid duplicating work. Moreover, they can begin to proactively aggregate information perceived daily rather than engaging in reactive search after confronting a problem. I discuss the important implications of this emerging theory of communication visibility for work in the knowledge economy.\n",
            "------------------------------------\n",
            "Title :  Positioning and Presenting Design Science Research for Maximum Impact\n",
            "Author/s :  S. Gregor, A. Hevner\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Design science research (DSR) has staked its rightful ground as an important and legitimate Information Systems (IS) research paradigm. We contend that DSR has yet to attain its full potential impact on the development and use of information systems due to gaps in the understanding and application of DSR concepts and methods. This essay aims to help researchers (1) appreciate the levels of artifact abstractions that may be DSR contributions, (2) identify appropriate ways of consuming and producing knowledge when they are preparing journal articles or other scholarly works, (3) understand and position the knowledge contributions of their research projects, and (4) structure a DSR article so that it emphasizes significant contributions to the knowledge base. Our focal contribution is the DSR knowledge contribution framework with two dimensions based on the existing state of knowledge in both the problem and solution domains for the research opportunity under study. In addition, we propose a DSR communication schema with similarities to more conventional publication patterns, but which substitutes the description of the DSR artifact in place of a traditional results section. We evaluate the DSR contribution framework and the DSR communication schema via examinations of DSR exemplar publications.\n",
            "------------------------------------\n",
            "Title :  What Does BERT Look at? An Analysis of BERT’s Attention\n",
            "Author/s :  Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning\n",
            "Venue :  BlackboxNLP@ACL\n",
            "year :  2019\n",
            "Abstract :  Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\n",
            "------------------------------------\n",
            "Title :  Influence of fake news in Twitter during the 2016 US presidential election\n",
            "Author/s :  A. Bovet, H. Makse\n",
            "Venue :  Nature Communications\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  News Recommendations from Social Media Opinion Leaders: Effects on Media Trust and Information Seeking\n",
            "Author/s :  J. Turcotte, Chance York, Jacob Irving, Rosanne M. Scholl, Raymond J. Pingree\n",
            "Venue :  J. Comput. Mediat. Commun.\n",
            "year :  2015\n",
            "Abstract :  Polls show a strong decline in public trust of traditional news outlets; however, social media offers new avenues for receiving news content. This experiment used the Facebook API to manipulate whether a news story appeared to have been posted on Facebook by one of the respondent's real-life Facebook friends. Results show that social media recommendations improve levels of media trust, and also make people want to follow more news from that particular media outlet in the future. Moreover, these effects are amplified when the real-life friend sharing the story on social media is perceived as an opinion leader. Implications for democracy and the news business are discussed.\n",
            "------------------------------------\n",
            "Title :  What is big data? A consensual definition and a review of key research topics\n",
            "Author/s :  Andrea De Mauro, Marco Greco, M. Grimaldi\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Although Big Data is a trending buzzword in both academia and the industry, its meaning is still shrouded by much conceptual vagueness. The term is used to describe a wide range of concepts: from the technological ability to store, aggregate, and process data, to the cultural shift that is pervasively invading business and society, both drowning in information overload. The lack of a formal definition has led research to evolve into multiple and inconsistent paths. Furthermore, the existing ambiguity among researchers and practitioners undermines an efficient development of the subject. In this paper we have reviewed the existing literature on Big Data and analyzed its previous definitions in order to pursue two results: first, to provide a summary of the key research areas related to the phenomenon, identifying emerging trends and suggesting opportunities for future development; second, to provide a consensual definition for Big Data, by synthesizing common themes of existing works and patterns in previous definitions.\n",
            "------------------------------------\n",
            "Title :  Misleading Health-Related Information Promoted Through Video-Based Social Media: Anorexia on YouTube\n",
            "Author/s :  S. Syed-Abdul, L. Fernández-Luque, W. Jian, Yu-chuan Li, S. Crain, M. Hsu, Yao-Chin Wang, Dorjsuren Khandregzen, E. Chuluunbaatar, P. Nguyen, Der-Ming Liou\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Introduction The amount of information being uploaded onto social video platforms, such as YouTube, Vimeo, and Veoh, continues to spiral, making it increasingly difficult to discern reliable health information from misleading content. There are thousands of YouTube videos promoting misleading information about anorexia (eg, anorexia as a healthy lifestyle). Objective The aim of this study was to investigate anorexia-related misinformation disseminated through YouTube videos. Methods We retrieved YouTube videos related to anorexia using the keywords anorexia, anorexia nervosa, proana, and thinspo on October 10, 2011.Three doctors reviewed 140 videos with approximately 11 hours of video content, classifying them as informative, pro-anorexia, or others. By informative we mean content describing the health consequences of anorexia and advice on how to recover from it; by pro-anorexia we mean videos promoting anorexia as a fashion, a source of beauty, and that share tips and methods for becoming and remaining anorexic. The 40 most-viewed videos (20 informative and 20 pro-anorexia videos) were assessed to gauge viewer behavior. Results The interrater agreement of classification was moderate (Fleiss’ kappa=0.5), with 29.3% (n=41) being rated as pro-anorexia, 55.7% (n=78) as informative, and 15.0% (n=21) as others. Pro-anorexia videos were favored 3 times more than informative videos (odds ratio [OR] 3.3, 95% CI 3.3-3.4, P<.001). Conclusions Pro-anorexia information was identified in 29.3% of anorexia-related videos. Pro-anorexia videos are less common than informative videos; however, in proportional terms, pro-anorexia content is more highly favored and rated by its viewers. Efforts should focus on raising awareness, particularly among teenagers, about the trustworthiness of online information about beauty and healthy lifestyles. Health authorities producing videos to combat anorexia should consider involving celebrities and models to reach a wider audience. More research is needed to study the characteristics of pro-anorexia videos in order to develop algorithms that will automatically detect and filter those videos before they become popular.\n",
            "------------------------------------\n",
            "Title :  Signalling Theory and Equilibrium in Strategic Management Research: An Assessment and a Research Agenda\n",
            "Author/s :  D. Bergh, Brian L. Connelly, David J. Ketchen, Jr, Lu M. Shannon\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Actors within organizations commonly must make choices armed with incomplete and asymmetrically distributed information. Signalling theory seeks to explain how individuals are able to do so. This theory's primary predictive mechanism is ‘separating equilibrium’, which occurs when a signal's expectations are confirmed through experience. A content analysis finds that most strategic management signalling theory studies have not fully leveraged separating equilibrium. This presents two possible paths for future research. First, some researchers may wish to incorporate separating equilibrium. We illustrate how doing so can uncover new relationships, generate novel insights, and fortify the theory's application. Others who want to theorize about signals, but not examine separating equilibrium, could integrate ideas from signalling theory with other information perspectives. Here a signal becomes one stimulus among many that corporate actors interpret and act upon. We provide research agendas so strategy scholars can apply signalling theory most effectively to meet their research objectives.\n",
            "------------------------------------\n",
            "Title :  A scoping review of rapid review methods\n",
            "Author/s :  A. Tricco, J. Antony, W. Zarin, L. Strifler, M. Ghassemi, J. Ivory, L. Perrier, B. Hutton, D. Moher, S. Straus\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information Dropout: Learning Optimal Representations Through Noisy Computation\n",
            "Author/s :  A. Achille, Stefano Soatto\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2016\n",
            "Abstract :  The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.\n",
            "------------------------------------\n",
            "Title :  Enhancing patient safety and quality of care by improving the usability of electronic health record systems: recommendations from AMIA.\n",
            "Author/s :  Blackford Middleton, M. Bloomrosen, Mark A. Dente, Bill Hashmat, R. Koppel, J. Overhage, T. Payne, S. Rosenbloom, Charlotte A. Weaver, Jiajie Zhang\n",
            "Venue :  JAMIA Journal of the American Medical Informatics Association\n",
            "year :  2013\n",
            "Abstract :  In response to mounting evidence that use of electronic medical record systems may cause unintended consequences, and even patient harm, the AMIA Board of Directors convened a Task Force on Usability to examine evidence from the literature and make recommendations. This task force was composed of representatives from both academic settings and vendors of electronic health record (EHR) systems. After a careful review of the literature and of vendor experiences with EHR design and implementation, the task force developed 10 recommendations in four areas: (1) human factors health information technology (IT) research, (2) health IT policy, (3) industry recommendations, and (4) recommendations for the clinician end-user of EHR software. These AMIA recommendations are intended to stimulate informed debate, provide a plan to increase understanding of the impact of usability on the effective use of health IT, and lead to safer and higher quality care with the adoption of useful and usable EHR systems.\n",
            "------------------------------------\n",
            "Title :  Open government: connecting vision and voice\n",
            "Author/s :  A. Meijer, D. Curtin, M. Hillebrandt\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  The term open government is often used to describe initiatives of putting government information on the Internet. This conceptualization is too restricted since open government is not only about openness in informational terms (vision) but also about openness in interactive terms (voice). On the basis of an analysis of 103 articles, this article provides insight into the concepts of openness, transparency and participation, their interactions, and the manner in which they have been discussed in the literature. This analysis shows the differences and similarities between economic, political science and legal perspectives on open government and argues that a multidisciplinary approach needs to be taken. The authors conclude that open government is much too important to leave it to the ‘techies’: scientists and practitioners with backgrounds in law, economics, political science and public administration should also get involved to build sound connections between vision and voice that facilitate active citizenship. Points for practitioners This article provides guidelines for the realization of open government: (1) design open government for synergistic or complementary relationships between transparency and participation, (2) design open government for a diverse population, (3) design open government for direct and indirect effects, (4) design open government acknowledging a variety in desirables and (5) design for continuous learning about effects and side-effects. The authors emphasize that a diversified approach to the design of open government will be more fruitful in the long run than merely understanding it in terms of making information publicly available.\n",
            "------------------------------------\n",
            "Title :  Sleep-dependent memory triage: evolving generalization through selective processing\n",
            "Author/s :  R. Stickgold, M. Walker\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  OCNet: Object Context Network for Scene Parsing\n",
            "Author/s :  Yuhui Yuan, Jingdong Wang\n",
            "Venue :  ArXiv\n",
            "year :  2018\n",
            "Abstract :  In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. \n",
            "We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. \n",
            "To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff\n",
            "------------------------------------\n",
            "Title :  A Survey: Digital Image Watermarking Techniques\n",
            "Author/s :  P. Parashar, R. Singh\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Multimedia security is extremely significant concern for the internet technology because of the ease of the duplication, distribution and manipulation of the multimedia data. The digital watermarking is a field of information hiding which hide the crucial information in the original data for protection illegal duplication and distribution of multimedia data. This paper presents a survey on the existing digital image watermarking techniques. The results of various digital image watermarking techniques have been compared on the basis of outputs. In the digital watermarking the secret information are implanted into the original data for protecting the ownership rights of the multimedia data. The image watermarking techniques may divide on the basis of domain like spatial domain or transform domain or on the basis of wavelets. The spatial domain techniques directly work on the pixels and the frequency domain works on the transform coefficients of the image. This survey elaborates the most important methods of spatial domain and transform domain and focuses the merits and demerits of these techniques.\n",
            "------------------------------------\n",
            "Title :  Examining the Role of Social Media in Effective Crisis Management\n",
            "Author/s :  Yan Jin, B. Liu, Lucinda L. Austin\n",
            "Venue :  Communication Research\n",
            "year :  2014\n",
            "Abstract :  Publics increasingly use social media during crises and, consequently, crisis communication professionals need to understand how to strategically optimize these tools. Despite this need, there is scarce theory-grounded research to understand key factors that affect how publics consume crisis information via social media compared to other sources. To fill this gap, an emerging model helps crisis managers understand how publics produce, consume, and/or share crisis information via social media and other sources: the social-mediated crisis communication model (SMCC). This study tests essential components of the SMCC model through a 3 (crisis information form) x 2 (crisis information source) x 2 (crisis origin) mixed-design experiment (N = 338). The findings indicate the key role of crisis origin in affecting publics’ preferred information form (social media, traditional media, or word-of-mouth communication) and source (organization in crisis or third party), which influences how publics anticipate an organization should respond to a crisis and what crisis emotions they are likely to feel when exposed to crisis information.\n",
            "------------------------------------\n",
            "Title :  Adoption of Electronic Health Record Systems among U . S . Non-Federal Acute Care Hospitals : 2008-2015\n",
            "Author/s :  J. Henry, Yuriy Pylypchuk, Talisha Searcy, Vaishali Patel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The adoption and meaningful use of electronic health records (EHRs) are key objectives of the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the Federal Health IT Strategic Plan (1). This brief uses data from the American Hospital Association to describe trends in adoption of EHR technology among non-federal acute care hospitals from 2008 to 2015. It tracks the adoption of Basic EHR systems and the possession of certified EHR technology. Unless otherwise stated, this brief refers to Basic EHR adoption with clinical notes, a measure which represents a minimum use of 10 core functionalities determined to be essential to an EHR system (see Table A1)(2).\n",
            "------------------------------------\n",
            "Title :  The Pulvinar Regulates Information Transmission Between Cortical Areas Based on Attention Demands\n",
            "Author/s :  Y. Saalmann, M. Pinsk, Liang Wang, Xin Li, S. Kastner\n",
            "Venue :  Science\n",
            "year :  2012\n",
            "Abstract :  The Conductor in the Thalamus The pulvinar is the largest thalamic nucleus in the brain but its functions remain unclear. The pulvinar is ideally positioned to synchronize activity across the visual cortex. Saalmann et al. (p. 753) combined diffusion tensor imaging with multi-electrode recordings from three different brain areas in monkeys to probe thalamo-cortical interactions during visual attention. The pulvinar was found to play a vital role in attention by routing behaviorally relevant information across the visual cortex. A region of the thalamus synchronizes neuronal firing in two cortical areas and thus allocates attention. Selective attention mechanisms route behaviorally relevant information through large-scale cortical networks. Although evidence suggests that populations of cortical neurons synchronize their activity to preferentially transmit information about attentional priorities, it is unclear how cortical synchrony across a network is accomplished. Based on its anatomical connectivity with the cortex, we hypothesized that the pulvinar, a thalamic nucleus, regulates cortical synchrony. We mapped pulvino-cortical networks within the visual system, using diffusion tensor imaging, and simultaneously recorded spikes and field potentials from these interconnected network sites in monkeys performing a visuospatial attention task. The pulvinar synchronized activity between interconnected cortical areas according to attentional allocation, suggesting a critical role for the thalamus not only in attentional selection but more generally in regulating information transmission across the visual cortex.\n",
            "------------------------------------\n",
            "Title :  Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks\n",
            "Author/s :  Z. Cai, Zaobo He, Xin Guan, Yingshu Li\n",
            "Venue :  IEEE Transactions on Dependable and Secure Computing\n",
            "year :  2018\n",
            "Abstract :  Releasing social network data could seriously breach user privacy. User profile and friendship relations are inherently private. Unfortunately, sensitive information may be predicted out of released data through data mining techniques. Therefore, sanitizing network data prior to release is necessary. In this paper, we explore how to launch an inference attack exploiting social networks with a mixture of non-sensitive attributes and social relationships. We map this issue to a collective classification problem and propose a collective inference model. In our model, an attacker utilizes user profile and social relationships in a collective manner to predict sensitive information of related victims in a released social network dataset. To protect against such attacks, we propose a data sanitization method collectively manipulating user profile and friendship relations. Besides sanitizing friendship relations, the proposed method can take advantages of various data-manipulating methods. We show that we can easily reduce adversary’s prediction accuracy on sensitive information, while resulting in less accuracy decrease on non-sensitive information towards three social network datasets. This is the first work to employ collective methods involving various data-manipulating methods and social relationships to protect against inference attacks in social networks.\n",
            "------------------------------------\n",
            "Title :  Geographical tracking and mapping of coronavirus disease COVID-19/severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) epidemic and associated events around the world: how 21st century GIS technologies are supporting the global fight against outbreaks and epidemics\n",
            "Author/s :  M. N. Kamel Boulos, E. Geraghty\n",
            "Venue :  International Journal of Health Geographics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Research Note - The Impact of External Word-of-Mouth Sources on Retailer Sales of High-Involvement Products\n",
            "Author/s :  B. Gu, Jaehong Park, Prabhudev Konana\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  Online word-of-mouth (WOM) such as consumer opinions, user experiences, and product reviews has become a major information source in consumer purchase decisions. Prior research on online WOM effect has focused mostly on low-involvement products such as books or CDs. For these products, retailer-hosted (internal) WOM is shown to influence sales overwhelmingly. Numerous surveys, however, suggest consumers often conduct pre-purchase searches for high-involvement products (e.g., digital cameras) and visit external WOM websites during the search process. In this study, we analyze the relative impact of external and internal WOMs on retailer sales for high-involvement products using a panel of sales and WOM data for 148 digital cameras from Amazon.com and three external WOM websites (Cnet, DpReview, and Epinions) over a four-month period. The results suggest that a retailer's internal WOM has a limited influence on its sales of high-involvement products, while external WOM sources have a significant impact on the retailer's sales. The findings imply that external WOM sources play an important role in the information search process.\n",
            "------------------------------------\n",
            "Title :  Dense Trajectories and Motion Boundary Descriptors for Action Recognition\n",
            "Author/s :  Heng Wang, Alexander Kläser, C. Schmid, Cheng-Lin Liu\n",
            "Venue :  International Journal of Computer Vision\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Mobile health 2012\n",
            "Author/s :  Maeve Duggan, Susannah Fox\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Half of smartphone owners use their devices to get health information and one-fifth of smartphone owners have health apps. The results reported here come from a nationwide survey of 3,014 adults living in the United States. Telephone interviews were conducted by landline (1,808) and cell phone (1,206, including 624 without a landline phone). The survey was conducted by Princeton Survey Research Associates International. Interviews were done in English and Spanish by Princeton Data Source from August 7 to September 6, 2012. Statistical results are weighted to correct known demographic discrepancies. The margin of sampling error for the complete set of weighted data is ±2.4 percentage points.\n",
            "------------------------------------\n",
            "Title :  Interactive information complexity\n",
            "Author/s :  M. Braverman\n",
            "Venue :  Symposium on the Theory of Computing\n",
            "year :  2012\n",
            "Abstract :  The primary goal of this paper is to define and study the interactive information complexity of functions. Let f(x,y) be a function, and suppose Alice is given x and Bob is given y. Informally, the interactive information complexity IC(f) of f is the least amount of information Alice and Bob need to reveal to each other to compute f. Previously, information complexity has been defined with respect to a prior distribution on the input pairs (x,y). Our first goal is to give a definition that is independent of the prior distribution. We show that several possible definitions are essentially equivalent.\n",
            " We establish some basic properties of the interactive information complexity IC(f). In particular, we show that IC(f) is equal to the amortized (randomized) communication complexity of f. We also show a direct sum theorem for IC(f) and give the first general connection between information complexity and (non-amortized) communication complexity. This connection implies that a non-trivial exchange of information is required when solving problems that have non-trivial communication complexity.\n",
            " We explore the information complexity of two specific problems - Equality and Disjointness. We show that only a constant amount of information needs to be exchanged when solving Equality with no errors, while solving Disjointness with a constant error probability requires the parties to reveal a linear amount of information to each other.\n",
            "------------------------------------\n",
            "Title :  Convolutional Matrix Factorization for Document Context-Aware Recommendation\n",
            "Author/s :  Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, Hwanjo Yu\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2016\n",
            "Abstract :  Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.\n",
            "------------------------------------\n",
            "Title :  The role of e-learning, the advantages and disadvantages of its adoption in Higher Education.\n",
            "Author/s :  Valentina Arkorful, N. Abaidoo\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study investigates the effectiveness of using e-learning in teaching in tertiary institutions. In institutions of higher education, the issue of utilizing modern information and communication technologies for teaching and learning is very important. This study reviews literature and gives a scholarly background to the study by reviewing some contributions made by various researchers and institutions on the concept of e-learning, particularly its usage in teaching and learning in higher educational institutions. It unveils some views that people and institutions have shared globally on the adoption and integration of e-learning technologies in education through surveys and other observations. It looks at the meaning or definitions of e-learning as given by different researchers and the role that e-learning plays in higher educational institutions in relation to teaching and learning processes, and the advantages and disadvantages of its adoption and implemention.\n",
            "------------------------------------\n",
            "Title :  Generalized Composite Kernel Framework for Hyperspectral Image Classification\n",
            "Author/s :  Jun Li, P. Marpu, A. Plaza, J. Bioucas-Dias, J. Benediktsson\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2013\n",
            "Abstract :  This paper presents a new framework for the development of generalized composite kernel machines for hyperspectral image classification. We construct a new family of generalized composite kernels which exhibit great flexibility when combining the spectral and the spatial information contained in the hyperspectral data, without any weight parameters. The classifier adopted in this work is the multinomial logistic regression, and the spatial information is modeled from extended multiattribute profiles. In order to illustrate the good performance of the proposed framework, support vector machines are also used for evaluation purposes. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible/Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the proposed framework leads to state-of-the-art classification performance in complex analysis scenarios.\n",
            "------------------------------------\n",
            "Title :  Advances in Quantum Cryptography\n",
            "Author/s :  S. Pirandola, U. Andersen, L. Banchi, M. Berta, D. Bunandar, R. Colbeck, D. Englund, T. Gehring, C. Lupo, C. Ottaviani, Jason L. Pereira, M. Razavi, J. S. Shaari, M. Tomamichel, Vladyslav C. Usenko, G. Vallone, P. Villoresi, P. Wallden\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  Quantum cryptography is arguably the fastest growing area in quantum information science. Novel theoretical protocols are designed on a regular basis, security proofs are constantly improving, and experiments are gradually moving from proof-of-principle lab demonstrations to in-field implementations and technological prototypes. In this review, we provide both a general introduction and a state of the art description of the recent advances in the field, both theoretically and experimentally. We start by reviewing protocols of quantum key distribution based on discrete variable systems. Next we consider aspects of device independence, satellite challenges, and high rate protocols based on continuous variable systems. We will then discuss the ultimate limits of point-to-point private communications and how quantum repeaters and networks may overcome these restrictions. Finally, we will discuss some aspects of quantum cryptography beyond standard quantum key distribution, including quantum data locking and quantum digital signatures.\n",
            "------------------------------------\n",
            "Title :  Understanding Online Purchase Decision Making: The Effects of Unconscious Thought, Information Quality, and Information Quantity\n",
            "Author/s :  Jie Gao, Cheng Zhang, Ke Wang, Sulin Ba\n",
            "Venue :  Decision Support Systems\n",
            "year :  2012\n",
            "Abstract :  The prosperity of online shopping has led e-commerce vendors to provide increasingly rich information, particularly for experience products, to enhance consumers' shopping experience and satisfaction. However, there is little awareness that consumers may not be able to process all the information available because of human beings' limited information processing capacity. Online shoppers could be easily confused when facing rich information, particularly when the amount of information greatly exceeds their processing capacity. In contrast to previous research which has focused on the formatting of information or user interfaces to solve the information overload problem, this study explores a new solution based on the role of unconscious thought. Integrating information processing theory and the unconscious thought theory, the current study examines the different roles of information quantity, information quality and thought mode in consumers' decision satisfaction, in the presence of rich information. Our results show that unconscious thought moderates the relationship between information quality and consumer satisfaction towards their decision making when shopping experience products online, and is thus worthy of special attention in the design of e-commerce websites. The study contributes to both unconscious thought theory and information processing theory by exploring the interaction effect of the quantity and quality of information with thought mode in affecting the quality of purchasing decisions.\n",
            "------------------------------------\n",
            "Title :  Fixing a Broken ELBO\n",
            "Author/s :  Alexander A. Alemi, Ben Poole, Ian S. Fischer, Joshua V. Dillon, R. Saurous, K. Murphy\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2017\n",
            "Abstract :  Recent work in unsupervised representation learning has focused on learning deep directed latent-variable models. Fitting these models by maximizing the marginal likelihood or evidence is typically intractable, thus a common approximation is to maximize the evidence lower bound (ELBO) instead. However, maximum likelihood training (whether exact or approximate) does not necessarily result in a good latent representation, as we demonstrate both theoretically and empirically. In particular, we derive variational lower and upper bounds on the mutual information between the input and the latent variable, and use these bounds to derive a rate-distortion curve that characterizes the tradeoff between compression and reconstruction accuracy. Using this framework, we demonstrate that there is a family of models with identical ELBO, but different quantitative and qualitative characteristics. Our framework also suggests a simple new method to ensure that latent variable models with powerful stochastic decoders do not ignore their latent code.\n",
            "------------------------------------\n",
            "Title :  COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author/s :  Cristina M. Pulido, Beatriz Villarejo-Carballido, Gisela Redondo-Sama, Aitor Gómez\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title :  Gene Ontology Consortium: going forward\n",
            "Author/s :  J. Blake, Kim M Rutherford, J. Chan, R. Kishore, P. Sternberg, K. V. Auken, Hans-Michael Müller, J. Done, Yanhong Li\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2014\n",
            "Abstract :  The Gene Ontology (GO; http://www.geneontology.org) is a community-based bioinformatics resource that supplies information about gene product function using ontologies to represent biological knowledge. Here we describe improvements and expansions to several branches of the ontology, as well as updates that have allowed us to more efficiently disseminate the GO and capture feedback from the research community. The Gene Ontology Consortium (GOC) has expanded areas of the ontology such as cilia-related terms, cell-cycle terms and multicellular organism processes. We have also implemented new tools for generating ontology terms based on a set of logical rules making use of templates, and we have made efforts to increase our use of logical definitions. The GOC has a new and improved web site summarizing new developments and documentation, serving as a portal to GO data. Users can perform GO enrichment analysis, and search the GO for terms, annotations to gene products, and associated metadata across multiple species using the all-new AmiGO 2 browser. We encourage and welcome the input of the research community in all biological areas in our continued effort to improve the Gene Ontology.\n",
            "------------------------------------\n",
            "Title :  Information Systems Success Measurement\n",
            "Author/s :  William H. DeLone, E. McLean\n",
            "Venue :  Found. Trends Inf. Syst.\n",
            "year :  2016\n",
            "Abstract :  Researchers and practitioners alike face a daunting challenge when evaluating the \"success\" of information systems. The purpose of this monograph is to deepen, researchers and practitioners, understanding of the complex nature of IS success measurement driven by the constantly changing role and use of information technology. This monograph covers the history of IS success measurement as well as recent trends and future expectations for IS success measurement. The monograph also identifies the critical success factors that drive information system success and provides measurement and evaluation guidance for practitioners. This comprehensive study of IS success measurement is designed to improve measurement practice among researchers and managers.\n",
            "------------------------------------\n",
            "Title :  Prominent Features of Rumor Propagation in Online Social Media\n",
            "Author/s :  Sejeong Kwon, M. Cha, Kyomin Jung, Wei Chen, Yajun Wang\n",
            "Venue :  2013 IEEE 13th International Conference on Data Mining\n",
            "year :  2013\n",
            "Abstract :  The problem of identifying rumors is of practical importance especially in online social networks, since information can diffuse more rapidly and widely than the offline counterpart. In this paper, we identify characteristics of rumors by examining the following three aspects of diffusion: temporal, structural, and linguistic. For the temporal characteristics, we propose a new periodic time series model that considers daily and external shock cycles, where the model demonstrates that rumor likely have fluctuations over time. We also identify key structural and linguistic differences in the spread of rumors and non-rumors. Our selected features classify rumors with high precision and recall in the range of 87% to 92%, that is higher than other states of the arts on rumor classification.\n",
            "------------------------------------\n",
            "Title :  Belief Echoes: The Persistent Effects of Corrected Misinformation\n",
            "Author/s :  Emily A. Thorson\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Across three separate experiments, I find that exposure to negative political information continues to shape attitudes even after the information has been effectively discredited. I call these effects “belief echoes.” Results suggest that belief echoes can be created through an automatic or deliberative process. Belief echoes occur even when the misinformation is corrected immediately, the “gold standard” of journalistic fact-checking. The existence of belief echoes raises ethical concerns about journalists’ and fact-checking organizations’ efforts to publicly correct false claims.\n",
            "------------------------------------\n",
            "Title :  The role of e-learning, the advantages and disadvantages of its adoption in Higher Education.\n",
            "Author/s :  Valentina Arkorful, N. Abaidoo\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study investigates the effectiveness of using e-learning in teaching in tertiary institutions. In institutions of higher education, the issue of utilizing modern information and communication technologies for teaching and learning is very important. This study reviews literature and gives a scholarly background to the study by reviewing some contributions made by various researchers and institutions on the concept of e-learning, particularly its usage in teaching and learning in higher educational institutions. It unveils some views that people and institutions have shared globally on the adoption and integration of e-learning technologies in education through surveys and other observations. It looks at the meaning or definitions of e-learning as given by different researchers and the role that e-learning plays in higher educational institutions in relation to teaching and learning processes, and the advantages and disadvantages of its adoption and implemention.\n",
            "------------------------------------\n",
            "Title :  Social Networks and the Diffusion of User-Generated Content: Evidence from YouTube\n",
            "Author/s :  Anjana Susarla, Jeong-ha Oh, Yong Tan\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This paper is motivated by the success of YouTube, which is attractive to content creators as well as corporations for its potential to rapidly disseminate digital content. The networked structure of interactions on YouTube and the tremendous variation in the success of videos posted online lends itself to an inquiry of the role of social influence. Using a unique data set of video information and user information collected from YouTube, we find that social interactions are influential not only in determining which videos become successful but also on the magnitude of that impact. We also find evidence for a number of mechanisms by which social influence is transmitted, such as (i) a preference for conformity and homophily and (ii) the role of social networks in guiding opinion formation and directing product search and discovery. Econometrically, the problem in identifying social influence is that individuals' choices depend in great part upon the choices of other individuals, referred to as the reflection problem. Another problem in identification is to distinguish between social contagion and user heterogeneity in the diffusion process. Our results are in sharp contrast to earlier models of diffusion, such as the Bass model, that do not distinguish between different social processes that are responsible for the process of diffusion. Our results are robust to potential self-selection according to user tastes, temporal heterogeneity and the reflection problem. Implications for researchers and managers are discussed.\n",
            "------------------------------------\n",
            "Title :  Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author/s :  Christopher Courtney, Supradeep Dutta, Yong Li\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title :  Spectral-Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network\n",
            "Author/s :  Ying Li, Haokui Zhang, Qiang Shen\n",
            "Venue :  Remote Sensing\n",
            "year :  2017\n",
            "Abstract :  Recent research has shown that using spectral–spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral–spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral–spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods—namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods—on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.\n",
            "------------------------------------\n",
            "Title :  Preparing for Life in a Digital Age: The IEA International Computer and Information Literacy Study International Report\n",
            "Author/s :  J. Fraillon, J. Ainley, Wolfram Schulz, Tim Friedman, E. Gebhardt\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Ability to use information and communication technologies (ICT) is an imperative for effective participation in todays digital age. Schools worldwide are responding to the need to provide young people with that ability. But how effective are they in this regard? The IEA International Computer and Information Literacy Study (ICILS) responded to this question by studying the extent to which young people have developed computer and information literacy (CIL), which is defined as the ability to use computers to investigate, create and communicate with others at home, school, the workplace and in society.The study was conducted under the auspices of the International Association for the Evaluation of Educational Achievement (IEA) and builds on a series of earlier IEA studies focusing on ICT in education.Data were gathered from almost 60,000 Grade 8 students in more than 3,300 schools from 21 education systems. This information was augmented by data from almost 35,000 teachers in those schools and by contextual data collected from school ICT-coordinators, school principals and the ICILS national research centers.The IEA ICILS team systematically investigated differences among the participating countries in students CIL outcomes, how participating countries were providing CIL-related education and how confident teachers were in using ICT in their pedagogical practice. The team also explored differences within and across countries with respect to relationships between CIL education outcomes and student characteristics and school contexts.In general, the study findings presented in this international report challenge the notion of young people as digital natives with a self-developed capacity to use digital technology. The large variations in CIL proficiency within and across the ICILS countries suggest it is naive to expect young people to develop CIL in the absence of coherent learning programs. Findings also indicate that system- and school-level planning needs to focus on increasing teacher expertise in using ICT for pedagogical purposes if such programs are to have the desired effect.The report furthermore presents an empirically derived scale and description of CIL learning that educational stakeholders can reference when deliberating about CIL education and use to monitor change in CIL over time.\n",
            "------------------------------------\n",
            "Title :  Should Banks' Stress Test Results Be Disclosed? An Analysis of the Costs and Benefits\n",
            "Author/s :  Itay Goldstein, H. Sapra\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Stress tests have become an important component of the supervisory toolkit. However, the extent of disclosure of stress-test results remains controversial. We argue that while stress tests uncover unique information to outsiders – because banks operate in second-best environments with multiple imperfections – there are potential endogenous costs associated with such disclosure.First, disclosure might interfere with the operation of the interbank market and the risk sharing provided in this market. Second, while disclosure might improve price efficiency and hence market discipline, it might also induce sub-optimal behavior in banks. Third, disclosure might induce ex post market externalities that lead to excessive and inefficient reaction to public news. Fourth, disclosure might also reduce traders incentives to gather information, which reduces market discipline because it hampers the ability of supervisors to learn from market data for their regulatory actions.Overall, we believe that disclosure of stress-test results is beneficial because it promotes financial stability. However, in promoting financial stability, such disclosures may exacerbate bank-specific inefficiencies. We provide some guidance on how such inefficiencies could be minimized.\n",
            "------------------------------------\n",
            "Title :  INSAT-3D vertical profile retrievals at IMDPS, New Delhi : A preliminary evaluation\n",
            "Author/s :  A. K. Mitra, S. Bhan, Anubha Sharma, N. Kaushik, Shailesh Parihar, R. Mahandru, P. K. Kundu\n",
            "Venue :  Mausam\n",
            "year :  2021\n",
            "Abstract :  Successful launch of indigenous geostationary satellite INSAT-3D on 26 July, 2013 with advanced meteorological payloads onboard, has provided a new opportunity to the Indian meteorologists. A new payload, atmospheric sounder, has been launched for the first time in Indian satellite to provide the vertical profiles of temperature and humidity in the atmosphere. It is possible to obtain continuous upper level temperature and moisture profiles with a spatial resolution of 30 × 30 km and temporal resolution of one hour. The INSAT-3D temperature and moisture retrievals derived from routine application of sounder data processing algorithm installed at INSAT Meteorological Data Processing System (IMDPS), New Delhi were compared with collocated GPS sonde observations (GPOB), and National Oceanic and Atmospheric Administration (NOAA) polar orbiting satellites (N-18 and N-19) derived profiles to assess retrieval performance. The INSAT-3D temperature profiles show the positive bias throughout from surface to 30 hPa against the GPOB. The overall temperature between retrivals exhibited a systematic bias error at almost all the levels. Bias ranges from 2 to 4 °C between 1000 to 100 hPa levels. The levels of maximum positive bias, where INSAT-3D values are too warm, are near the surface and 100 hPa. This can be attributed to the inability of the retrieval scheme to precisely locate the change in the lapse rate associated with the tropopause due to general disagreement at higher levels. However, the moisture profiles showed somewhat lower accuracy against the GPOB. INSAT-3D and GPOB derived Total Perceptible Water (TPW) were also compared and showed that correlation of INSAT-3D TPW agree well with GPOB TPW to some extent than the level specific LI.\n",
            "------------------------------------\n",
            "Title :  Advances in Hyperspectral Image Classification: Earth Monitoring with Statistical Learning Methods\n",
            "Author/s :  Gustau Camps-Valls, D. Tuia, L. Bruzzone, J. Benediktsson\n",
            "Venue :  IEEE Signal Processing Magazine\n",
            "year :  2013\n",
            "Abstract :  The technological evolution of optical sensors over the last few decades has provided remote sensing analysts with rich spatial, spectral, and temporal information. In particular, the increase in spectral resolution of hyperspectral images (HSIs) and infrared sounders opens the doors to new application domains and poses new methodological challenges in data analysis. HSIs allow the characterization of objects of interest (e.g., land-cover classes) with unprecedented accuracy, and keeps inventories up to date. Improvements in spectral resolution have called for advances in signal processing and exploitation algorithms. This article focuses on the challenging problem of hyperspectral image classification, which has recently gained in popularity and attracted the interest of other scientific disciplines such as machine learning, image processing, and computer vision. In the remote sensing community, the term classification is used to denote the process that assigns single pixels to a set of classes, while the term segmentation is used for methods aggregating pixels into objects and then assigned to a class.\n",
            "------------------------------------\n",
            "Title :  Quantum technologies with hybrid systems\n",
            "Author/s :  G. Kurizki, P. Bertet, Y. Kubo, K. Mølmer, D. Petrosyan, P. Rabl, J. Schmiedmayer\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  An extensively pursued current direction of research in physics aims at the development of practical technologies that exploit the effects of quantum mechanics. As part of this ongoing effort, devices for quantum information processing, secure communication, and high-precision sensing are being implemented with diverse systems, ranging from photons, atoms, and spins to mesoscopic superconducting and nanomechanical structures. Their physical properties make some of these systems better suited than others for specific tasks; thus, photons are well suited for transmitting quantum information, weakly interacting spins can serve as long-lived quantum memories, and superconducting elements can rapidly process information encoded in their quantum states. A central goal of the envisaged quantum technologies is to develop devices that can simultaneously perform several of these tasks, namely, reliably store, process, and transmit quantum information. Hybrid quantum systems composed of different physical components with complementary functionalities may provide precisely such multitasking capabilities. This article reviews some of the driving theoretical ideas and first experimental realizations of hybrid quantum systems and the opportunities and challenges they present and offers a glance at the near- and long-term perspectives of this fascinating and rapidly expanding field.\n",
            "------------------------------------\n",
            "Title :  STITCH 5: augmenting protein–chemical interaction networks with tissue and affinity data\n",
            "Author/s :  Damian Szklarczyk, Alberto Santos, C. V. Mering, L. Jensen, P. Bork, Michael Kuhn\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  Interactions between proteins and small molecules are an integral part of biological processes in living organisms. Information on these interactions is dispersed over many databases, texts and prediction methods, which makes it difficult to get a comprehensive overview of the available evidence. To address this, we have developed STITCH (‘Search Tool for Interacting Chemicals’) that integrates these disparate data sources for 430 000 chemicals into a single, easy-to-use resource. In addition to the increased scope of the database, we have implemented a new network view that gives the user the ability to view binding affinities of chemicals in the interaction network. This enables the user to get a quick overview of the potential effects of the chemical on its interaction partners. For each organism, STITCH provides a global network; however, not all proteins have the same pattern of spatial expression. Therefore, only a certain subset of interactions can occur simultaneously. In the new, fifth release of STITCH, we have implemented functionality to filter out the proteins and chemicals not associated with a given tissue. The STITCH database can be downloaded in full, accessed programmatically via an extensive API, or searched via a redesigned web interface at http://stitch.embl.de.\n",
            "------------------------------------\n",
            "Title :  Performance Management in the Public Sector\n",
            "Author/s :  Wouter Van Dooren, G. Bouckaert, J. Halligan\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  1. Introduction 2. Defining the Concepts 3. The History of Performance Management 4. Performance Measurement 5. Incorporation of Performance Information 6. The use of Performance Information 7. Users 8. Non-use 9. The Effects of Using Performance Information 10. The Future of Performance Management\n",
            "------------------------------------\n",
            "Title :  Electronic frog eye: Counting crowd using WiFi\n",
            "Author/s :  Wei Xi, Jizhong Zhao, Xiangyang Li, K. Zhao, Shaojie Tang, Xue Liu, Zhiping Jiang\n",
            "Venue :  IEEE Conference on Computer Communications\n",
            "year :  2014\n",
            "Abstract :  Crowd counting, which count or accurately estimate the number of human beings within a region, is critical in many applications, such as guided tour, crowd control and marketing research and analysis. A crowd counting solution should be scalable and be minimally intrusive (i.e., device-free) to users. Image-based solutions are device-free, but cannot work well in a dim or dark environment. Non-image based solutions usually require every human being carrying device, and are inaccurate and unreliable in practice. In this paper, we present FCC, a device-Free Crowd Counting approach based on Channel State Information (CSI). Our design is motivated by our observation that CSI is highly sensitive to environment variation, like a frog eye. We theoretically discuss the relationship between the number of moving people and the variation of wireless channel state. A major challenge in our design of FCC is to find a stable monotonic function to characterize the relationship between the crowd number and various features of CSI. To this end, we propose a metric, the Percentage of nonzero Elements (PEM), in the dilated CSI Matrix. The monotonic relationship can be explicitly formulated by the Grey Verhulst Model, which is used for crowd counting without a labor-intensive site survey. We implement FCC using off-the-shelf IEEE 802.11n devices and evaluate its performance via extensive experiments in typical real-world scenarios. Our results demonstrate that FCC outperforms the state-of-art approaches with much better accuracy, scalability and reliability.\n",
            "------------------------------------\n",
            "Title :  AndroidLeaks: Automatically Detecting Potential Privacy Leaks in Android Applications on a Large Scale\n",
            "Author/s :  Clint Gibler, J. Crussell, Jeremy Erickson, Hao Chen\n",
            "Venue :  Trust and Trustworthy Computing\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  KGAT: Knowledge Graph Attention Network for Recommendation\n",
            "Author/s :  Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2019\n",
            "Abstract :  To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism. We release the codes and datasets at https://github.com/xiangwang1223/knowledge_graph_attention_network.\n",
            "------------------------------------\n",
            "Title :  Coronavirus: the spread of misinformation\n",
            "Author/s :  A. Mian, Shujhat Khan\n",
            "Venue :  BMC Medicine\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The Pulvinar Regulates Information Transmission Between Cortical Areas Based on Attention Demands\n",
            "Author/s :  Y. Saalmann, M. Pinsk, Liang Wang, Xin Li, S. Kastner\n",
            "Venue :  Science\n",
            "year :  2012\n",
            "Abstract :  The Conductor in the Thalamus The pulvinar is the largest thalamic nucleus in the brain but its functions remain unclear. The pulvinar is ideally positioned to synchronize activity across the visual cortex. Saalmann et al. (p. 753) combined diffusion tensor imaging with multi-electrode recordings from three different brain areas in monkeys to probe thalamo-cortical interactions during visual attention. The pulvinar was found to play a vital role in attention by routing behaviorally relevant information across the visual cortex. A region of the thalamus synchronizes neuronal firing in two cortical areas and thus allocates attention. Selective attention mechanisms route behaviorally relevant information through large-scale cortical networks. Although evidence suggests that populations of cortical neurons synchronize their activity to preferentially transmit information about attentional priorities, it is unclear how cortical synchrony across a network is accomplished. Based on its anatomical connectivity with the cortex, we hypothesized that the pulvinar, a thalamic nucleus, regulates cortical synchrony. We mapped pulvino-cortical networks within the visual system, using diffusion tensor imaging, and simultaneously recorded spikes and field potentials from these interconnected network sites in monkeys performing a visuospatial attention task. The pulvinar synchronized activity between interconnected cortical areas according to attentional allocation, suggesting a critical role for the thalamus not only in attentional selection but more generally in regulating information transmission across the visual cortex.\n",
            "------------------------------------\n",
            "Title :  Integrated Risk Information System\n",
            "Author/s :  Ord, Ncea, Irisd\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  EPA's Integrated Risk Information System (IRIS) is a human health assessment program that evaluates information on health effects that may result from exposure to environmental contaminants.\n",
            "------------------------------------\n",
            "Title :  Multimodal learning with deep Boltzmann machines\n",
            "Author/s :  Nitish Srivastava, R. Salakhutdinov\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2012\n",
            "Abstract :  Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.\n",
            "------------------------------------\n",
            "Title :  Visual localization within LIDAR maps for automated urban driving\n",
            "Author/s :  R. W. Wolcott, R. Eustice\n",
            "Venue :  2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
            "year :  2014\n",
            "Abstract :  This paper reports on the problem of map-based visual localization in urban environments for autonomous vehicles. Self-driving cars have become a reality on roadways and are going to be a consumer product in the near future. One of the most significant road-blocks to autonomous vehicles is the prohibitive cost of the sensor suites necessary for localization. The most common sensor on these platforms, a three-dimensional (3D) light detection and ranging (LIDAR) scanner, generates dense point clouds with measures of surface reflectivity-which other state-of-the-art localization methods have shown are capable of centimeter-level accuracy. Alternatively, we seek to obtain comparable localization accuracy with significantly cheaper, commodity cameras. We propose to localize a single monocular camera within a 3D prior ground-map, generated by a survey vehicle equipped with 3D LIDAR scanners. To do so, we exploit a graphics processing unit to generate several synthetic views of our belief environment. We then seek to maximize the normalized mutual information between our real camera measurements and these synthetic views. Results are shown for two different datasets, a 3.0 km and a 1.5 km trajectory, where we also compare against the state-of-the-art in LIDAR map-based localization.\n",
            "------------------------------------\n",
            "Title :  Peningkatan Kemampuan Menulis Teks Deskripsi Siswa Kelas VII SMP Berdasarkan Level Pemula Menggunakan Teknik Retrival Jaringan Semantik\n",
            "Author/s :  Tobias Nggaruaka, A. Hermansyah, Santi Monika\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  Kemampuan menulis teks deskripsi siswa kelas VII SMP YPPGI Geradus Adii Merauke masih rendah. Berdasarkan permasalahan tersebut tujuan penelitian ini adalah meningkatkan kemampuan menulis teks deskripsi dengan menggunakan teknik retrival jaringan semantik. Penelitian ini menggunakan jenis penelitian kualitatif dengan rancangan penelitian tindakan kelas (PTK). Rancangan penelitian yang digunakan meliputi: observasi, analisis, perencanaan, pelaksanaan, refleksi, dan evaluasi. Data penelitian ini adalah berupa data proses dan data hasil penilaian pembelajaran. Data tersebut dikumpulkan dengan menggunakan instrumen penelitian yaitu; hasil pengamatan, wawancara, hasil tindakan, catatan lapangan, dan dokumentasi. Hasil penelitian menunjukkan bahwa pembelajaran pada siklus I pertemuan I dengan presentasi 28,57%. Sedangkan pada pertemuan II siklus I hasil pembelajaran meningkat menjadi 57,14%. Hasil pembelajaran pada siklus II pertemuan I meningkat menjadi 85,71%. Sedangkan pada pertemuan II siklus II meningkat menjadi 100% dengan kriteria ketuntasan minimal.\n",
            "------------------------------------\n",
            "Title :  Controlled-Channel Attacks: Deterministic Side Channels for Untrusted Operating Systems\n",
            "Author/s :  Yuanzhong Xu, Weidong Cui, Marcus Peinado\n",
            "Venue :  IEEE Symposium on Security and Privacy\n",
            "year :  2015\n",
            "Abstract :  The presence of large numbers of security vulnerabilities in popular feature-rich commodity operating systems has inspired a long line of work on excluding these operating systems from the trusted computing base of applications, while retaining many of their benefits. Legacy applications continue to run on the untrusted operating system, while a small hyper visor or trusted hardware prevents the operating system from accessing the applications' memory. In this paper, we introduce controlled-channel attacks, a new type of side-channel attack that allows an untrusted operating system to extract large amounts of sensitive information from protected applications on systems like Overshadow, Ink Tag or Haven. We implement the attacks on Haven and Ink Tag and demonstrate their power by extracting complete text documents and outlines of JPEG images from widely deployed application libraries. Given these attacks, it is unclear if Over shadow's vision of protecting unmodified legacy applications from legacy operating systems running on off-the-shelf hardware is still tenable.\n",
            "------------------------------------\n",
            "Title :  Addressing the Personalization-Privacy Paradox: An Empirical Assessment from a Field Experiment on Smartphone Users\n",
            "Author/s :  J. Sutanto, Elia Palme, Chuan-Hoo Tan, C. Phang\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Privacy has been an enduring concern associated with commercial information technology (IT) applications, in particular regarding the issue of personalization. IT-enabled personalization, while potentially making the user computing experience more gratifying, often relies heavily on the user's personal information to deliver individualized services, which raises the user's privacy concerns. We term the tension between personalization and privacy, which follows from marketers exploiting consumers' data to offer personalized product information, the personalization--privacy paradox. To better understand this paradox, we build on the theoretical lenses of uses and gratification theory and information boundary theory to conceptualize the extent to which privacy impacts the process and content gratifications derived from personalization, and how an IT solution can be designed to alleviate privacy concerns. \n",
            " \n",
            "Set in the context of personalized advertising applications for smartphones, we propose and prototype an IT solution, referred to as a personalized, privacy-safe application, that retains users' information locally on their smartphones while still providing them with personalized product messages. We validated this solution through a field experiment by benchmarking it against two more conventional applications: a base nonpersonalized application that broadcasts non-personalized product information to users, and a personalized, nonprivacy safe application that transmits user information to a central marketer's server. The results show that (compared to the non-personalized application), while personalized, privacy-safe or not increased application usage (reflecting process gratification), it was only when it was privacy-safe that users saved product messages (reflecting content gratification) more frequently. Follow-up surveys corroborated these nuanced findings and further revealed the users' psychological states, which explained our field experiment results. We found that saving advertisements for content gratification led to a perceived intrusion of information boundary that made users reluctant to do so. Overall our proposed IT solution, which delivers a personalized service but avoids transmitting users' personal information to third parties, reduces users' perceptions that their information boundaries are being intruded upon, thus mitigating the personalization--privacy paradox and increasing both process and content gratification.\n",
            "------------------------------------\n",
            "Title :  Why did my car just do that? Explaining semi-autonomous driving actions to improve driver understanding, trust, and performance\n",
            "Author/s :  Jeamin Koo, Jungsuk Kwac, Wendy Ju, M. Steinert, L. Leifer, C. Nass\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Cortical information flow during flexible sensorimotor decisions\n",
            "Author/s :  M. Siegel, T. J. Buschman, E. Miller\n",
            "Venue :  Science\n",
            "year :  2015\n",
            "Abstract :  Signal flow during sensorimotor choices Little is known about the flow of task signals across the brain. Siegel et al. simultaneously recorded from multiple units in the sensory, parietal, prefrontal, and motor cortex while monkeys were cued to perform one among two possible simple tasks. The proportion of neurons coding for stimuli, cues, tasks, and choices, and their response latency, varied across regions. Parietal and prefrontal brain regions encoded task information and choices with the same latency. Interestingly, all brain areas encoded all types of information. However, they differed functionally according to the proportions of neurons and their response latency. Science, this issue p. 1352 A dynamic network of cortical areas processing similar information but to different degrees is explored. During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.\n",
            "------------------------------------\n",
            "Title :  Boardroom Centrality and Firm Performance\n",
            "Author/s :  D. Larcker, Eric C. So, Charles C. Y. Wang\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Firms with central boards of directors earn superior risk-adjusted stock returns. A long (short) position in the most (least) central firms earns average annual returns of 4.68%. Firms with central boards also experience higher future return-on-assets growth and more positive analyst forecast errors. Return prediction, return-on-assets growth, and analyst errors are concentrated among high growth opportunity firms or firms confronting adverse circumstances, consistent with boardroom connections mattering most for firms standing to benefit most from information and resources exchanged through boardroom networks. Overall, our results suggest that director networks provide economic benefits that are not immediately reflected in stock prices.\n",
            "------------------------------------\n",
            "Title :  Decoding neural representational spaces using multivariate pattern analysis.\n",
            "Author/s :  J. Haxby, Andrew C. Connolly, J. S. Guntupalli\n",
            "Venue :  Annual Review of Neuroscience\n",
            "year :  2014\n",
            "Abstract :  A major challenge for systems neuroscience is to break the neural code. Computational algorithms for encoding information into neural activity and extracting information from measured activity afford understanding of how percepts, memories, thought, and knowledge are represented in patterns of brain activity. The past decade and a half has seen significant advances in the development of methods for decoding human neural activity, such as multivariate pattern classification, representational similarity analysis, hyperalignment, and stimulus-model-based encoding and decoding. This article reviews these advances and integrates neural decoding methods into a common framework organized around the concept of high-dimensional representational spaces.\n",
            "------------------------------------\n",
            "Title :  The Evolving Role of the Public Information Officer: An Examination of Social Media in Emergency Management\n",
            "Author/s :  Amanda Lee Hughes, L. Palen\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Abstract This work examines how the introduction of social media has affected the role of the Public Information Officer (PIO)—the public relations component of the National Incident Management System (NIMS). Through analysis of 25 PIO interviews, we examine the work practice of PIOs and find that social media expand not only the scope and type of PIO work activity, but also the “information pathways” that exist between PIOs, the media, and members of the public. We model these changes and examine how the presence of social media challenges previous conceptualizations of PIO work. Lastly, we present a view of how PIO work could be better imagined for the future of emergency management organizations.\n",
            "------------------------------------\n",
            "Title :  Sustainability reports as simulacra? A counter-account of A and A+ GRI reports\n",
            "Author/s :  O. Boiral\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Purpose - – The purpose of this paper is to examine the extent to which sustainability reporting can be viewed as a simulacrum used to camouflage real sustainable-development problems and project an idealized view of the firms' situations. Design/methodology/approach - – The method was based on the content analysis and counter accounting of 23 sustainability reports from firms in the energy and mining sectors which had received application levels of A or A+ from the Global Reporting Initiative (GRI). The information disclosed in some 2,700 pages of reports was structured around 92 GRI indicators and compared with 116 significant news events that clearly addressed the responsibility of these firms in sustainable development problems. Moreover, the 1,258 pictures included in sustainability reports were categorized into recurring themes from an inductive perspective. Findings - – A total of 90 per cent of the significant negative events were not reported, contrary to the principles of balance, completeness and transparency of GRI reports. Moreover, the pictures included in these reports showcase various simulacra clearly disconnected with the impact of business activities. Originality/value - – The paper shows the relevance of the counter accounting approach in assessing the quality of sustainability reports and question the reliability of the GRI's A or A+ application levels. It contributes to debates concerning the transparency of sustainability reports in light of Debord's and Baudrillard's critical perspective. The paper reveals the underexplored role of images in the emergence of several types of simulacra.\n",
            "------------------------------------\n",
            "Title :  An investigation of visibility and flexibility as complements to supply chain analytics: An organizational information processing theory perspective\n",
            "Author/s :  R. Srinivasan, M. Swink\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Many businesses are seeking to develop and exploit analytics capabilities today. Using organizational information processing theory (OIPT), we study demand visibility and supply visibility as foundational resources for analytics capability, and organizational flexibility as a complementary capability. We further examine relationships among these factors under varying conditions of market volatility, a type of environmental uncertainty. The results from our analysis of data from 191 global firms indicate that both demand and supply visibility are associated with the development of analytics capability. In turn, analytics capability is shown to be more strongly associated with operational performance when supply chain organizations also possess organizational flexibility needed to act upon analytics-generated insights quickly and efficiently. Furthermore, the empirical results indicate that analytics capability and organizational flexibility are more valuable as complementary capabilities for firms who operate in volatile markets, rather than in stable ones. These findings extend OIPT to create a better understanding of contemporary applications of information processing technologies, while also providing theoretically grounded guidance to managers in the development of analytics capabilities within their firms. \n",
            " \n",
            "This article is protected by copyright. All rights reserved.\n",
            "------------------------------------\n",
            "Title :  Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment\n",
            "Author/s :  K. Huckvale, José Tomás Prieto, M. Tilney, Pierre Benghozi, J. Car\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The Six Core Elements of Business Process Management\n",
            "Author/s :  M. Rosemann, J. Brocke\n",
            "Venue :  Handbook on Business Process Management\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Ebola, Twitter, and misinformation: a dangerous combination?\n",
            "Author/s :  S. O. Oyeyemi, E. Gabarron, R. Wynn\n",
            "Venue :  BMJ : British Medical Journal\n",
            "year :  2014\n",
            "Abstract :  The recent Ebola outbreak in west Africa has affected countries deeply in need of foreign aid.1 People desperately need correct information on how to prevent and treat Ebola. Despite the poverty, the increasing spread of computers, tablets, and smartphones in the region creates an opportunity for the rapid dissemination of information through the internet and social media, but there is no guarantee that …\n",
            "------------------------------------\n",
            "Title :  Learning to Optimize via Information-Directed Sampling\n",
            "Author/s :  Daniel Russo, Benjamin Van Roy\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  We propose information-directed sampling - a new algorithm for online optimization problems in which a decision-maker must balance between exploration and exploitation while learning from partial feedback. Each action is sampled in a manner that minimizes the ratio between the square of expected single-period regret and a measure of information gain: the mutual information between the optimal action and the next observation. \n",
            " \n",
            "We establish an expected regret bound for information-directed sampling that applies across a very general class of models and scales with the entropy of the optimal action distribution. For the widely studied Bernoulli and linear bandit models, we demonstrate simulation performance surpassing popular approaches, including upper confidence bound algorithms, Thompson sampling, and knowledge gradient. Further, we present simple analytic examples illustrating that information-directed sampling can dramatically outperform upper confidence bound algorithms and Thompson sampling due to the way it measures information gain.\n",
            "------------------------------------\n",
            "Title :  An Overview of Multi-task Learning\n",
            "Author/s :  Yu Zhang, Qiang Yang\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.\n",
            "------------------------------------\n",
            "Title :  A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\n",
            "Author/s :  A. Casali, O. Gosseries, M. Rosanova, M. Boly, S. Sarasso, K. Casali, S. Casarotto, M. Bruno, Steven Laureys, G. Tononi, M. Massimini\n",
            "Venue :  Science Translational Medicine\n",
            "year :  2013\n",
            "Abstract :  A theory-derived index of consciousness, which quantifies the complexity of the brain’s response to a stimulus, measures the level of consciousness in awake, sleeping, anesthetized, and brain-damaged subjects. Quantifying the Unquantifiable Manipulation of consciousness is an everyday medical trick—think anesthesia—but physicians have only the crudest of tools to detect when a person is not aware. The usual question or physical stimulus does not always provide reliable reactions, and a more precise index is needed to avoid, for example, the conclusion that people who have locked-in syndrome (in which they are aware but cannot respond) are unconscious. Here, Casali et al. have extended their previous work on electrical correlates of consciousness to define an electroencephalographic-derived index of human consciousness [the perturbational complexity index (PCI)] that reflects the information content of the brain’s response to a magnetic stimulus. The PCI could allow tracking of consciousness in individual patients. The authors used data already collected from previous experiments, in which they had stimulated people’s brains with transcranial magnetic stimulation. By calculating the likely brain regional sources of the signals and then comparing the unique information in each, the authors derived PCI values. The values ranged from 0.44 to 0.67 in 32 awake healthy people, but fell to 0.18 to 0.28 during nonrapid eye movement (NREM) sleep. Then, to see whether a completely different way of inducing unconsciousness had the same effect on PCI, the authors assessed data from patients given various amounts of the anesthetics midazolam, xenon, and propofol. These agents too caused low “unconscious” values for the PCI: midazolam deep sedation, 0.23 to 0.31; propofol, 0.13 to 0.30; and xenon, 0.12 to 0.31. However, what about patients who suffer brain damage and who exhibit various levels of consciousness by conventional assessment methods? In these people, consciousness varies widely, as does the underlying damage from stroke or trauma. Here, too, the authors found promising results in those who had emerged from coma but were in a vegetative state or minimally conscious state, or exhibited locked-in syndrome. The PCI values from these patients clearly reflected the state of their consciousness, with the six patients in a vegetative state clearly unconscious (0.19 to 0.31), the two with locked-in syndrome clearly aware (0.51 to 0.62), and those in a minimally conscious state showing intermediate values (0.32 to 0.49). The validity of PCI for clinical application will need to be assessed in prospective trials, but it has the advantage of being derived from a simple noninvasive measurement. The new index reported by Casali et al. appears to be a robust measure that distinguishes conscious from unconscious states well enough to be used on an individual basis, a prerequisite for deployment in the clinic. One challenging aspect of the clinical assessment of brain-injured, unresponsive patients is the lack of an objective measure of consciousness that is independent of the subject’s ability to interact with the external environment. Theoretical considerations suggest that consciousness depends on the brain’s ability to support complex activity patterns that are, at once, distributed among interacting cortical areas (integrated) and differentiated in space and time (information-rich). We introduce and test a theory-driven index of the level of consciousness called the perturbational complexity index (PCI). PCI is calculated by (i) perturbing the cortex with transcranial magnetic stimulation (TMS) to engage distributed interactions in the brain (integration) and (ii) compressing the spatiotemporal pattern of these electrocortical responses to measure their algorithmic complexity (information). We test PCI on a large data set of TMS-evoked potentials recorded in healthy subjects during wakefulness, dreaming, nonrapid eye movement sleep, and different levels of sedation induced by anesthetic agents (midazolam, xenon, and propofol), as well as in patients who had emerged from coma (vegetative state, minimally conscious state, and locked-in syndrome). PCI reliably discriminated the level of consciousness in single individuals during wakefulness, sleep, and anesthesia, as well as in patients who had emerged from coma and recovered a minimal level of consciousness. PCI can potentially be used for objective determination of the level of consciousness at the bedside.\n",
            "------------------------------------\n",
            "Title :  InfoVAE: Information Maximizing Variational Autoencoders\n",
            "Author/s :  Shengjia Zhao, Jiaming Song, S. Ermon\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.\n",
            "------------------------------------\n",
            "Title :  The Information . A History , a Theory , a Flood\n",
            "Author/s :  J. Rivera\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The book is full of interesting references to the history of information theory, but unfortunately lacks the theoretical rigor of an academic account of the topic. The reader can find really inspiring stories and draw out powerful insights about what information means, but also finds awkward reflections about its essence and about how the concept should be understood. On the positive side, we can mention the relevance of redundancy in language, a point that is wonderfully explained in the description of the drums' communication language, as well as in the process of breaking cryptographic codes. On the negative side, we should mention the Epilogue and its loose reflection around the meaning of meaning, that ultimately confuses information with knowledge, and thus presents networks and “the internet” as a social agent that “is changing the world”.\n",
            "------------------------------------\n",
            "Title :  Semantic trajectories modeling and analysis\n",
            "Author/s :  C. Parent, S. Spaccapietra, C. Renso, G. Andrienko, N. Andrienko, V. Bogorny, M. Damiani, A. Gkoulalas-Divanis, J. Macêdo, N. Pelekis, Y. Theodoridis, Zhixian Yan\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Focus on movement data has increased as a consequence of the larger availability of such data due to current GPS, GSM, RFID, and sensors techniques. In parallel, interest in movement has shifted from raw movement data analysis to more application-oriented ways of analyzing segments of movement suitable for the specific purposes of the application. This trend has promoted semantically rich trajectories, rather than raw movement, as the core object of interest in mobility studies. This survey provides the definitions of the basic concepts about mobility data, an analysis of the issues in mobility data management, and a survey of the approaches and techniques for: (i) constructing trajectories from movement tracks, (ii) enriching trajectories with semantic information to enable the desired interpretations of movements, and (iii) using data mining to analyze semantic trajectories and extract knowledge about their characteristics, in particular the behavioral patterns of the moving objects. Last but not least, the article surveys the new privacy issues that arise due to the semantic aspects of trajectories.\n",
            "------------------------------------\n",
            "Title :  ERNIE: Enhanced Language Representation with Informative Entities\n",
            "Author/s :  Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2019\n",
            "Abstract :  Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.\n",
            "------------------------------------\n",
            "Title :  Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers\n",
            "Author/s :  G. Ateniese, L. Mancini, A. Spognardi, Antonio Villani, Domenico Vitali, G. Felici\n",
            "Venue :  Int. J. Secur. Networks\n",
            "year :  2013\n",
            "Abstract :  Machine Learning (ML) algorithms are used to train computers to perform a variety of complex tasks and improve with experience. Computers learn how to recognize patterns, make unintended decisions, or react to a dynamic environment. Certain trained machines may be more effective than others because they are based on more suitable ML algorithms or because they were trained through superior training sets. Although ML algorithms are known and publicly released, training sets may not be reasonably ascertainable and, indeed, may be guarded as trade secrets. While much research has been performed about the privacy of the elements of training sets, in this paper we focus our attention on ML classifiers and on the statistical information that can be unconsciously or maliciously revealed from them. We show that it is possible to infer unexpected but useful information from ML classifiers. In particular, we build a novel meta-classifier and train it to hack other classifiers, obtaining meaningful information about their training sets. This kind of information leakage can be exploited, for example, by a vendor to build more effective classifiers or to simply acquire trade secrets from a competitor's apparatus, potentially violating its intellectual property rights.\n",
            "------------------------------------\n",
            "Title :  New Literacies: A Dual-Level Theory of the Changing Nature of Literacy, Instruction, and Assessment\n",
            "Author/s :  D. Leu, C. Kinzer, Julie Coiro, Jill Castek, L. Henry\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Today, the nature of literacy has become deictic. This simple idea carries important implications for literacy theory, research, and instruction that our field must begin to address. Deixis is a term used by linguists (Fillmore, 1966; Murphy, 1986; Traut & Kazzazi, 1996) to define words whose meanings change rapidly as their context changes. Tomorrow, for example, is a deictic term; the meaning of “tomorrow” becomes “today” every 24 hours. The meaning of literacy has also become deictic because we live in an age of rapidly changing information and communication technologies, each of which requires new literacies (Leu, 1997, 2000). Thus, to have been literate yesterday, in a world defined primarily by relatively static book technologies, does not ensure that one is fully literate today where we encounter new technologies such as Google docs, Skype, iMovie, Contribute, Basecamp, Dropbox, Facebook, Google, foursquare, Chrome, educational video games, or thousands of mobile apps. To be literate tomorrow will be defined by even newer technologies that have yet to appear and even newer discourses and social practices that will be created to meet future needs. Thus, when we speak of new literacies, we mean that literacy is not just new today; it becomes new every day of our lives. How should we theorize the new literacies that will define our future, when literacy has become deictic? The answer is important because our concept of literacy defines both who we are and who we shall become. But there is a conundrum here. How can we possibly develop adequate theory when the object that we seek to study is itself ephemeral, continuously being redefined by a changing context? This is an important theoretical challenge that our field has not previously faced. The purpose of this chapter is to advance theory in a world where literacy has become deictic. It suggests that a dual-level theory of New Literacies is a useful approach to theory building in a world where the nature of literacy continuously changes. We begin by making a central point: Social contexts have always shaped both the function and form of literate practices and been shaped by them in return. We discuss the social context of the current period and explain how this has produced new information and communication technologies (ICTs), and the new literacies that these technologies demand. Second, we explore several lowercase new literacies perspectives that are emerging. We argue that a dual-level New Literacies theory is essential to take full advantage of this important and diverse work. Third, we identify a set of principles, drawn from research, that inform an uppercase theory of New Literacies. Then, we present one lowercase theory of new literacies, the new literacies of online research and comprehension, to illustrate how a dual-level theory of New Literacies can inform new literacies research that takes related but different theoretical perspectives. We conclude by considering the implications of a dual-level theory of New Literacies for both research and practice.\n",
            "------------------------------------\n",
            "Title :  Tweeting From Left to Right\n",
            "Author/s :  Pablo Barberá, J. Jost, Jonathan Nagler, Joshua A. Tucker, Richard Bonneau\n",
            "Venue :  Psychology Science\n",
            "year :  2015\n",
            "Abstract :  We estimated ideological preferences of 3.8 million Twitter users and, using a data set of nearly 150 million tweets concerning 12 political and nonpolitical issues, explored whether online communication resembles an “echo chamber” (as a result of selective exposure and ideological segregation) or a “national conversation.” We observed that information was exchanged primarily among individuals with similar ideological preferences in the case of political issues (e.g., 2012 presidential election, 2013 government shutdown) but not many other current events (e.g., 2013 Boston Marathon bombing, 2014 Super Bowl). Discussion of the Newtown shootings in 2012 reflected a dynamic process, beginning as a national conversation before transforming into a polarized exchange. With respect to both political and nonpolitical issues, liberals were more likely than conservatives to engage in cross-ideological dissemination; this is an important asymmetry with respect to the structure of communication that is consistent with psychological theory and research bearing on ideological differences in epistemic, existential, and relational motivation. Overall, we conclude that previous work may have overestimated the degree of ideological segregation in social-media usage.\n",
            "------------------------------------\n",
            "Title :  Cyberchondria: towards a better understanding of excessive health-related Internet use\n",
            "Author/s :  V. Starcevic, D. Berle\n",
            "Venue :  Expert Review of Neurotherapeutics\n",
            "year :  2013\n",
            "Abstract :  Looking for information about symptoms and illnesses on the Internet is common and often serves useful purposes. However, a number of people who are overly distressed or anxious about their health perform excessive or repeated health-related searches on the Internet, only to become more distressed or frightened – a pattern defined here as cyberchondria. This behavior, which can also be construed as a form of reassurance seeking and occurs as a manifestation of health anxiety and hypochondriasis, is the focus of this article. The antecedents of cyberchondria, factors that maintain it and its consequences are examined conceptually and in light of the relatively little research that has been performed so far. Managing cyberchondria poses a challenge, and several approaches as part of the treatment of health anxiety and hypochondriasis are described. The article makes suggestions for further research on cyberchondria.\n",
            "------------------------------------\n",
            "Title :  Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm\n",
            "Author/s :  Mohammed A. Ambusaidi, Xiangjian He, P. Nanda, Zhiyuan Tan\n",
            "Venue :  IEEE transactions on computers\n",
            "year :  2016\n",
            "Abstract :  Redundant and irrelevant features in data have caused a long-term problem in network traffic classification. These features not only slow down the process of classification but also prevent a classifier from making accurate decisions, especially when coping with big data. In this paper, we propose a mutual information based algorithm that analytically selects the optimal feature for classification. This mutual information based feature selection algorithm can handle linearly and nonlinearly dependent data features. Its effectiveness is evaluated in the cases of network intrusion detection. An Intrusion Detection System (IDS), named Least Square Support Vector Machine based IDS (LSSVM-IDS), is built using the features selected by our proposed feature selection algorithm. The performance of LSSVM-IDS is evaluated using three intrusion detection evaluation datasets, namely KDD Cup 99, NSL-KDD and Kyoto 2006+ dataset. The evaluation results show that our feature selection algorithm contributes more critical features for LSSVM-IDS to achieve better accuracy and lower computational cost compared with the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Knowing when to doubt: developing a critical stance when learning from others.\n",
            "Author/s :  Candice M. Mills\n",
            "Venue :  Developmental Psychology\n",
            "year :  2013\n",
            "Abstract :  Children may be biased toward accepting information as true, but the fact remains that children are exposed to misinformation from many sources, and mastering the intricacies of doubt is necessary. The current article examines this issue, focusing on understanding developmental changes and consistencies in children's ability to take a critical stance toward information. Research reviewed includes studies of children's ability to detect ignorance, inaccuracy, incompetence, deception, and distortion. Particular emphasis is placed on what this research indicates about how children are reasoning about when to trust and when to doubt. The remainder of the article proposes a framework to evaluate preexisting research and encourage further research, closing with a discussion of several other overarching questions that should be considered to develop a model to explain developmental, individual, and situational differences in children's ability to evaluate information.\n",
            "------------------------------------\n",
            "Title :  Harvest-Then-Cooperate: Wireless-Powered Cooperative Communications\n",
            "Author/s :  H. Chen, Yonghui Li, J. L. Rebelatto, B. Filho, B. Vucetic\n",
            "Venue :  IEEE Transactions on Signal Processing\n",
            "year :  2014\n",
            "Abstract :  In this paper, we consider a wireless-powered cooperative communication network consisting of one hybrid access-point (AP), one source, and one relay. In contrast to conventional cooperative networks, the source and relay in the considered network have no embedded energy supply. They need to rely on the energy harvested from the signals broadcasted by the AP for their cooperative information transmission. Based on this three-node reference model, we propose a harvest-then-cooperate (HTC) protocol, in which the source and relay harvest energy from the AP in the downlink and work cooperatively in the uplink for the source's information transmission. Considering a delay-limited transmission mode, the approximate closed-form expression for the average throughput of the proposed protocol is derived over Rayleigh fading channels. Subsequently, this analysis is extended to the multi-relay scenario, where the approximate throughput of the HTC protocol with two popular relay selection schemes is derived. The asymptotic analyses for the throughput performance of the considered schemes at high signal-to-noise radio are also provided. All theoretical results are validated by numerical simulations. The impacts of the system parameters, such as time allocation, relay number, and relay position, on the throughput performance are extensively investigated.\n",
            "------------------------------------\n",
            "Title :  Continuous Variable Quantum Information: Gaussian States and Beyond\n",
            "Author/s :  G. Adesso, Sammy Ragy, Antony R. Lee\n",
            "Venue :  Open systems & information dynamics\n",
            "year :  2014\n",
            "Abstract :  The study of Gaussian states has arisen to a privileged position in contin- uous variable quantum information in recent years. This is due to vehemently pursued experimental realisations and a magnificently elegant mathematical framework. In this paper, we provide a brief, and hopefully didactic, exposition of Gaussian state quantum information and its contemporary uses, including sometimes omitted crucial details. After introducing the subject material and outlining the essential toolbox of continuous variable systems, we define the basic notions needed to understand Gaussian states and Gaussian operations. In particular, emphasis is placed on the mathematical structure combining notions of algebra and symplectic geometry fundamental to a complete understanding of Gaussian informatics. Furthermore, we discuss the quantification of different forms of cor- relations (including entanglement and quantum discord) for Gaussian states, paying special attention to recently developed measures. The paper is concluded by succinctly expressing the main Gaussian state limitations and outlining a selection of possible future lines for quantum information processing with continuous variable systems.\n",
            "------------------------------------\n",
            "Title :  ExFuse: Enhancing Feature Fusion for Semantic Segmentation\n",
            "Author/s :  Zhenli Zhang, X. Zhang, Chao Peng, Dazhi Cheng, Jian Sun\n",
            "Venue :  European Conference on Computer Vision\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Spectre Attacks: Exploiting Speculative Execution\n",
            "Author/s :  P. Kocher, Daniel Genkin, D. Gruss, Werner Haas, Michael Hamburg, Moritz Lipp, S. Mangard, Thomas Prescher, Michael Schwarz, Y. Yarom\n",
            "Venue :  IEEE Symposium on Security and Privacy\n",
            "year :  2018\n",
            "Abstract :  Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.\n",
            "------------------------------------\n",
            "Title :  Impact of Online Information on Self-Isolation Intention During the COVID-19 Pandemic: Cross-Sectional Study\n",
            "Author/s :  Ali Farooq, Samuli Laato, A. Islam\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background During the coronavirus disease (COVID-19) pandemic, governments issued movement restrictions and placed areas into quarantine to combat the spread of the disease. In addition, individuals were encouraged to adopt personal health measures such as social isolation. Information regarding the disease and recommended avoidance measures were distributed through a variety of channels including social media, news websites, and emails. Previous research suggests that the vast amount of available information can be confusing, potentially resulting in overconcern and information overload. Objective This study investigates the impact of online information on the individual-level intention to voluntarily self-isolate during the pandemic. Using the protection-motivation theory as a framework, we propose a model outlining the effects of cyberchondria and information overload on individuals’ perceptions and motivations. Methods To test the proposed model, we collected data with an online survey (N=225) and analyzed it using partial least square-structural equation modeling. The effects of social media and living situation were tested through multigroup analysis. Results Cyberchondria and information overload had a significant impact on individuals’ threat and coping perceptions, and through them on self-isolation intention. Among the appraisal constructs, perceived severity (P=.002) and self-efficacy (P=.003) positively impacted self-isolation intention, while response cost (P<.001) affected the intention negatively. Cyberchondria (P=.003) and information overload (P=.003) indirectly affected self-isolation intention through the aforementioned perceptions. Using social media as an information source increased both cyberchondria and information overload. No differences in perceptions were found between people living alone and those living with their families. Conclusions During COVID-19, frequent use of social media contributed to information overload and overconcern among individuals. To boost individuals’ motivation to adopt preventive measures such as self-isolation, actions should focus on lowering individuals’ perceived response costs in addition to informing them about the severity of the situation.\n",
            "------------------------------------\n",
            "Title :  Understanding customers' repeat purchase intentions in B2C e‐commerce: the roles of utilitarian value, hedonic value and perceived risk\n",
            "Author/s :  Chao-Min Chiu, Eric T. G. Wang, Yu-Hui Fang, Hsin-Yi Huang\n",
            "Venue :  Information Systems Journal\n",
            "year :  2014\n",
            "Abstract :  Customer loyalty or repeat purchasing is critical for the survival and success of any store. By focusing on online stores, this study investigates the repeat purchase intention of experienced online buyers based on means‐end chain theory and prospect theory. In the research model, both utilitarian value and hedonic value are hypothesised to affect repeat purchase intention positively. Perceived risk is hypothesised to affect repeat purchase intention negatively and moderate the effects of utilitarian and hedonic values on repeat purchase intention. Utilitarian value is proposed as a formative second‐order construct formed by product offerings, product information, monetary savings and convenience. Hedonic value is also proposed as a formative second‐order construct formed by the six hedonic benefits that have been identified in prior research. Data collected from 782 Yahoo!Kimo customers provide strong support for the research model. The results indicate that both the utilitarian value and hedonic value are positively associated with buyers' repeat purchase intention. A higher level of perceived risk reduces the effect of utilitarian value and increases the effect of hedonic value on repeat purchase intention. Implications for theory and practice and suggestions for future research are provided.\n",
            "------------------------------------\n",
            "Title :  Adoption of Electronic Health Record Systems among U . S . Non-Federal Acute Care Hospitals : 2008-2015\n",
            "Author/s :  J. Henry, Yuriy Pylypchuk, Talisha Searcy, Vaishali Patel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The adoption and meaningful use of electronic health records (EHRs) are key objectives of the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the Federal Health IT Strategic Plan (1). This brief uses data from the American Hospital Association to describe trends in adoption of EHR technology among non-federal acute care hospitals from 2008 to 2015. It tracks the adoption of Basic EHR systems and the possession of certified EHR technology. Unless otherwise stated, this brief refers to Basic EHR adoption with clinical notes, a measure which represents a minimum use of 10 core functionalities determined to be essential to an EHR system (see Table A1)(2).\n",
            "------------------------------------\n",
            "Title :  Hidden factors and hidden topics: understanding rating dimensions with review text\n",
            "Author/s :  Julian McAuley, J. Leskovec\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2013\n",
            "Abstract :  In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.\n",
            "------------------------------------\n",
            "Title :  Credibility ranking of tweets during high impact events\n",
            "Author/s :  Aditi Gupta, P. Kumaraguru\n",
            "Venue :  PSOSM '12\n",
            "year :  2012\n",
            "Abstract :  Twitter has evolved from being a conversation or opinion sharing medium among friends into a platform to share and disseminate information about current events. Events in the real world create a corresponding spur of posts (tweets) on Twitter. Not all content posted on Twitter is trustworthy or useful in providing information about the event. In this paper, we analyzed the credibility of information in tweets corresponding to fourteen high impact news events of 2011 around the globe. From the data we analyzed, on average 30% of total tweets posted about an event contained situational information about the event while 14% was spam. Only 17% of the total tweets posted about the event contained situational awareness information that was credible. Using regression analysis, we identified the important content and sourced based features, which can predict the credibility of information in a tweet. Prominent content based features were number of unique characters, swear words, pronouns, and emoticons in a tweet, and user based features like the number of followers and length of username. We adopted a supervised machine learning and relevance feedback approach using the above features, to rank tweets according to their credibility score. The performance of our ranking algorithm significantly enhanced when we applied re-ranking strategy. Results show that extraction of credible information from Twitter can be automated with high confidence.\n",
            "------------------------------------\n",
            "Title :  The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power\n",
            "Author/s :  Shoshana Zuboff\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  Society is at a turning point. The heady optimism that accompanied the advent of the Internet has gone, replaced with a deep unease as technology, capitalism and an unequal society combine to create the perfect storm. Tech companies are gathering our information online and selling it to the highest bidder, whether government or retailer. In this world of surveillance capitalism, profit depends not only on predicting but modifying our online behaviour. How will this fusion of capitalism and the digital shape the values that define our future?\n",
            "------------------------------------\n",
            "Title :  Recurrent Convolutional Network for Video-Based Person Re-identification\n",
            "Author/s :  Niall McLaughlin, J. M. D. Rincón, P. Miller\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2016\n",
            "Abstract :  In this paper we propose a novel recurrent neural network architecture for video-based person re-identification. Given the video sequence of a person, features are extracted from each frame using a convolutional neural network that incorporates a recurrent final layer, which allows information to flow between time-steps. The features from all timesteps are then combined using temporal pooling to give an overall appearance feature for the complete sequence. The convolutional network, recurrent layer, and temporal pooling layer, are jointly trained to act as a feature extractor for video-based re-identification using a Siamese network architecture. Our approach makes use of colour and optical flow information in order to capture appearance and motion information which is useful for video re-identification. Experiments are conduced on the iLIDS-VID and PRID-2011 datasets to show that this approach outperforms existing methods of video-based re-identification.\n",
            "------------------------------------\n",
            "Title :  TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence of User Trust and of Item Ratings\n",
            "Author/s :  G. Guo, Jie Zhang, N. Yorke-Smith\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " Collaborative filtering suffers from the problems of data sparsity and cold start, which dramatically degrade recommendation performance. To help resolve these issues, we propose TrustSVD, a trust-based matrix factorization technique. By analyzing the social trust data from four real-world data sets, we conclude that not only the explicit but also the implicit influence of both ratings and trust should be taken into consideration in a recommendation model. Hence, we build on top of a state-of-the-art recommendation algorithm SVD++ which inherently involves the explicit and implicit influence of rated items, by further incorporating both the explicit and implicit influence of trusted users on the prediction of items for an active user. To our knowledge, the work reported is the first to extend SVD++ with social trust information. Experimental results on the four data sets demonstrate that our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Content-Aware Point of Interest Recommendation on Location-Based Social Networks\n",
            "Author/s :  Huiji Gao, Jiliang Tang, Xia Hu, Huan Liu\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " The rapid urban expansion has greatly extended the physical boundary of users' living area and developed a large number of POIs (points of interest). POI recommendation is a task that facilitates users' urban exploration and helps them filter uninteresting POIs for decision making. While existing work of POI recommendation on location-based social networks (LBSNs) discovers the spatial, temporal, and social patterns of user check-in behavior, the use of content information has not been systematically studied. The various types of content information available on LBSNs could be related to different aspects of a user's check-in action, providing a unique opportunity for POI recommendation. In this work, we study the content information on LBSNs w.r.t. POI properties, user interests, and sentiment indications. We model the three types of information under a unified POI recommendation framework with the consideration of their relationship to check-in actions. The experimental results exhibit the significance of content information in explaining user behavior, and demonstrate its power to improve POI recommendation performance on LBSNs.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Real-World Evidence - What Is It and What Can It Tell Us?\n",
            "Author/s :  Rachel E. Sherman, S. Anderson, G. D. Dal Pan, Gerry W Gray, T. Gross, Nina L. Hunter, L. LaVange, D. Marinac-Dabic, P. Marks, M. Robb, J. Shuren, R. Temple, J. Woodcock, L. Yue*, R. Califf\n",
            "Venue :  New England Journal of Medicine\n",
            "year :  2016\n",
            "Abstract :  The FDA is developing guidance on the use of “real-world evidence” — health care information from atypical sources, including electronic health records, billing databases, and product and disease registries — to assess the safety and effectiveness of drugs and devices.\n",
            "------------------------------------\n",
            "Title :  Report Cards: The Impact of Providing School and Child Test Scores on Educational Markets\n",
            "Author/s :  Tahir Andrabi, Jishnu Das, A. Khwaja\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This paper studies study the impact of providing school and child test scores on subsequent test scores, prices, and enrollment in markets with multiple public and private providers. A randomly selected half of the sample villages (markets) received report cards. This increased test scores by 0.11 standard deviations, decreased private school fees by 17 percent, and increased primary enrollment by 4.5 percent. Heterogeneity in the treatment impact by initial school quality is consistent with canonical models of asymmetric information. Information provision facilitates better comparisons across providers, improves market efficiency and raises child welfare through higher test scores, higher enrollment, and lower fees.\n",
            "------------------------------------\n",
            "Title :  \"Meaningful Information\" and the Right to Explanation\n",
            "Author/s :  Andrew D. Selbst, Julia E. Powles\n",
            "Venue :  FAT\n",
            "year :  2017\n",
            "Abstract :  There is no single, neat statutory provision labeled the “right to explanation” in Europe’s new General Data Protection Regulation (GDPR). But nor is such a right illusory. \n",
            "Responding to two prominent papers that, in turn, conjure and critique the right to explanation in the context of automated decision-making, we advocate a return to the text of the GDPR. \n",
            "Articles 13-15 provide rights to “meaningful information about the logic involved” in automated decisions. This is a right to explanation, whether one uses the phrase or not. \n",
            "The right to explanation should be interpreted functionally, flexibly, and should, at a minimum, enable a data subject to exercise his or her rights under the GDPR and human rights law.\n",
            "------------------------------------\n",
            "Title :  Replacing the Soft-Decision FEC Limit Paradigm in the Design of Optical Communication Systems*\n",
            "Author/s :  A. Alvarado, E. Agrell, D. Lavery, R. Maher, P. Bayvel\n",
            "Venue :  Journal of Lightwave Technology\n",
            "year :  2015\n",
            "Abstract :  The FEC limit paradigm is the prevalent practice for designing optical communication systems to attain a certain bit error rate (BER) without forward error correction (FEC). This practice assumes that there is an FEC code that will reduce the BER after decoding to the desired level. In this paper, we challenge this practice and show that the concept of a channel-independent FEC limit is invalid for soft-decision bit-wise decoding. It is shown that for low code rates and high-order modulation formats, the use of the soft-decision FEC limit paradigm can underestimate the spectral efficiencies by up to 20%. A better predictor for the BER after decoding is the generalized mutual information, which is shown to give consistent post-FEC BER predictions across different channel conditions and modulation formats. Extensive optical full-field simulations and experiments are carried out in both the linear and nonlinear transmission regimes to confirm the theoretical analysis.\n",
            "------------------------------------\n",
            "Title :  The Impact of IT Capabilities on Firm Performance: The Mediating Roles of Absorptive Capacity and Supply Chain Agility\n",
            "Author/s :  Hefu Liu, Weiling Ke, K. Wei, Zhongsheng Hua\n",
            "Venue :  Decision Support Systems\n",
            "year :  2013\n",
            "Abstract :  Researchers and practitioners regard information technology (IT) as a competitive tool. However, current knowledge on IT capability mechanisms that affect firm performance remains unclear. Based on the dynamic capabilities perspective and the view of a hierarchy of capabilities, this article proposes a model to examine how IT capabilities (i.e., flexible IT infrastructure and IT assimilation) affect firm performance through absorptive capacity and supply chain agility in the supply chain context. Survey data show that absorptive capacity and supply chain agility fully mediate the influences of IT capabilities on firm performance. In addition to the direct effects, absorptive capacity also has indirect effects on firm performance by shaping supply chain agility. We conclude with implications and suggestions for future research.\n",
            "------------------------------------\n",
            "Title :  A national action plan to support consumer engagement via e-health.\n",
            "Author/s :  L. Ricciardi, F. Mostashari, Judy Murphy, Jodi G. Daniel, Erin P Siminerio\n",
            "Venue :  Health Affairs\n",
            "year :  2013\n",
            "Abstract :  Patient-centered care is considered one pillar of a high-performing, high-quality health care system. It is a key component of many efforts to transform care and achieve better population health. Expansion of health information technology and consumer e-health tools--electronic tools and services such as secure e-mail messaging between patients and providers, or mobile health apps--have created new opportunities for individuals to participate actively in monitoring and directing their health and health care. The Office of the National Coordinator for Health Information Technology in the Department of Health and Human Services leads the strategy to increase electronic access to health information, support the development of tools that enable people to take action with that information, and shift attitudes related to the traditional roles of patients and providers. In this article we review recent evidence in support of consumer e-health and present the federal strategy to promote advances in consumer e-health to increase patient engagement, improve individual health, and achieve broader health care system improvements.\n",
            "------------------------------------\n",
            "Title :  Do Prices Reveal the Presence of Informed Trading?\n",
            "Author/s :  P. Collin-Dufresne, Vyacheslav Fos\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Using a comprehensive sample of trades by Schedule 13D filers, who possess valuable private information when they accumulate stocks of targeted companies, this paper studies whether several liquidity measures reveal the presence of informed trading. The evidence suggests that when Schedule 13D filers trade aggressively, both high-frequency and low-frequency measures of stock liquidity indicate a higher stock liquidity. Importantly, measures that have been used as direct proxies for adverse selection, such the Kyle (1985) lambda, the Easley et al. (1996) pin measure, and the Amihud (2002) illiquidity measure, suggest that the adverse selection is lower when informed trading takes place. The evidence is consistent with informed traders being more aggressive when measured stock liquidity is high.\n",
            "------------------------------------\n",
            "Title :  Information Sharing and Financial Sector Development in Africa\n",
            "Author/s :  Vanessa S. Tchamyou, S. Asongu\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  ABSTRACT This study investigates the effect information sharing has on financial sector development in 53 African countries for the period 2004 to 2011. Information sharing is measured with private credit bureaus and public credit registries. Hitherto unexplored dimensions of financial sector development are employed, namely: financial sector dynamics of formalization, informalization, and non-formalization. The empirical evidence is based on Ordinary Least Squares (OLS) and Generalized Method of Moments (GMM). The following findings are established. Information-sharing bureaus increase (reduce) formal (informal/non-formal) financial sector development. In order to ensure that information-sharing bureaus improve (decrease) formal (informal/non-formal) financial development, public credit registries should have between 45.45 and 50% coverage while private credit bureaus should have at least 26.25% coverage.\n",
            "------------------------------------\n",
            "Title :  Banks as Secret Keepers\n",
            "Author/s :  Tri Vi Dang, Gary B. Gorton, B. Holmström, G. Ordonez\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Banks are optimally opaque institutions. They produce debt for use as a transaction medium (bank money), which requires that information about the backing assets - loans - not be revealed, so that bank money does not fluctuate in value, reducing the efficiency of trade. This need for opacity conflicts with the production of information about investment projects, needed for allocative efficiency. Intermediaries exist to hide such information, so banks select portfolios of information-insensitive assets. For the economy as a whole, firms endogenously separate into bank finance and capital market/stock market finance depending on the cost of producing information about their projects.\n",
            "------------------------------------\n",
            "Title :  Spindle Net: Person Re-identification with Human Body Region Guided Feature Decomposition and Fusion\n",
            "Author/s :  Haiyu Zhao, Maoqing Tian, Shuyang Sun, Jing Shao, Junjie Yan, Shuai Yi, Xiaogang Wang, Xiaoou Tang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2017\n",
            "Abstract :  Person re-identification (ReID) is an important task in video surveillance and has various applications. It is non-trivial due to complex background clutters, varying illumination conditions, and uncontrollable camera settings. Moreover, the person body misalignment caused by detectors or pose variations is sometimes too severe for feature matching across images. In this study, we propose a novel Convolutional Neural Network (CNN), called Spindle Net, based on human body region guided multi-stage feature decomposition and tree-structured competitive feature fusion. It is the first time human body structure information is considered in a CNN framework to facilitate feature learning. The proposed Spindle Net brings unique advantages: 1) it separately captures semantic features from different body regions thus the macro-and micro-body features can be well aligned across images, 2) the learned region features from different semantic regions are merged with a competitive scheme and discriminative features can be well preserved. State of the art performance can be achieved on multiple datasets by large margins. We further demonstrate the robustness and effectiveness of the proposed Spindle Net on our proposed dataset SenseReID without fine-tuning.\n",
            "------------------------------------\n",
            "Title :  Room-Temperature Quantum Bit Memory Exceeding One Second\n",
            "Author/s :  P. Maurer, G. Kucsko, C. Latta, L. Jiang, N. Yao, S. Bennett, F. Pastawski, D. Hunger, N. Chisholm, M. Markham, D. Twitchen, J. Cirac, M. Lukin\n",
            "Venue :  Science\n",
            "year :  2012\n",
            "Abstract :  Extending Quantum Memory Practical applications in quantum communication and quantum computation require the building blocks—quantum bits and quantum memory—to be sufficiently robust and long-lived to allow for manipulation and storage (see the Perspective by Boehme and McCarney). Steger et al. (p. 1280) demonstrate that the nuclear spins of 31P impurities in an almost isotopically pure sample of 28Si can have a coherence time of as long as 192 seconds at a temperature of ∼1.7 K. In diamond at room temperature, Maurer et al. (p. 1283) show that a spin-based qubit system comprised of an isotopic impurity (13C) in the vicinity of a color defect (a nitrogen-vacancy center) could be manipulated to have a coherence time exceeding one second. Such lifetimes promise to make spin-based architectures feasible building blocks for quantum information science. Defects in diamond can be operated as quantum memories at room temperature. Stable quantum bits, capable both of storing quantum information for macroscopic time scales and of integration inside small portable devices, are an essential building block for an array of potential applications. We demonstrate high-fidelity control of a solid-state qubit, which preserves its polarization for several minutes and features coherence lifetimes exceeding 1 second at room temperature. The qubit consists of a single 13C nuclear spin in the vicinity of a nitrogen-vacancy color center within an isotopically purified diamond crystal. The long qubit memory time was achieved via a technique involving dissipative decoupling of the single nuclear spin from its local environment. The versatility, robustness, and potential scalability of this system may allow for new applications in quantum information science.\n",
            "------------------------------------\n",
            "Title :  Characterizing the Propagation of Situational Information in Social Media During COVID-19 Epidemic: A Case Study on Weibo\n",
            "Author/s :  Lifang Li, Qingpeng Zhang, Xiao Wang, J. Zhang, Tao Wang, Tian-Lu Gao, Wei Duan, K. Tsoi, Fei-yue Wang\n",
            "Venue :  IEEE Transactions on Computational Social Systems\n",
            "year :  2020\n",
            "Abstract :  During the ongoing outbreak of coronavirus disease (COVID-19), people use social media to acquire and exchange various types of information at a historic and unprecedented scale. Only the situational information are valuable for the public and authorities to response to the epidemic. Therefore, it is important to identify such situational information and to understand how it is being propagated on social media, so that appropriate information publishing strategies can be informed for the COVID-19 epidemic. This article sought to fill this gap by harnessing Weibo data and natural language processing techniques to classify the COVID-19-related information into seven types of situational information. We found specific features in predicting the reposted amount of each type of information. The results provide data-driven insights into the information need and public attention.\n",
            "------------------------------------\n",
            "Title :  A meta-analysis of executive components of working memory.\n",
            "Author/s :  D. E. Nee, Joshua W. Brown, Mary K. Askren, M. Berman, E. Demiralp, A. Krawitz, J. Jonides\n",
            "Venue :  Cerebral Cortex\n",
            "year :  2013\n",
            "Abstract :  Working memory (WM) enables the online maintenance and manipulation of information and is central to intelligent cognitive functioning. Much research has investigated executive processes of WM in order to understand the operations that make WM \"work.\" However, there is yet little consensus regarding how executive processes of WM are organized. Here, we used quantitative meta-analysis to summarize data from 36 experiments that examined executive processes of WM. Experiments were categorized into 4 component functions central to WM: protecting WM from external distraction (distractor resistance), preventing irrelevant memories from intruding into WM (intrusion resistance), shifting attention within WM (shifting), and updating the contents of WM (updating). Data were also sorted by content (verbal, spatial, object). Meta-analytic results suggested that rather than dissociating into distinct functions, 2 separate frontal regions were recruited across diverse executive demands. One region was located dorsally in the caudal superior frontal sulcus and was especially sensitive to spatial content. The other was located laterally in the midlateral prefrontal cortex and showed sensitivity to nonspatial content. We propose that dorsal-\"where\"/ventral-\"what\" frameworks that have been applied to WM maintenance also apply to executive processes of WM. Hence, WM can largely be simplified to a dual selection model.\n",
            "------------------------------------\n",
            "Title :  What Does BERT Look at? An Analysis of BERT’s Attention\n",
            "Author/s :  Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning\n",
            "Venue :  BlackboxNLP@ACL\n",
            "year :  2019\n",
            "Abstract :  Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\n",
            "------------------------------------\n",
            "Title :  Access to Care and Use of the Internet to Search for Health Information: Results From the US National Health Interview Survey\n",
            "Author/s :  Daniel J. Amante, T. Hogan, S. Pagoto, Thomas M. English, K. Lapane\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2015\n",
            "Abstract :  Background The insurance mandate of the Affordable Care Act has increased the number of people with health coverage in the United States. There is speculation that this increase in the number of insured could make accessing health care services more difficult. Those who are unable to access care in a timely manner may use the Internet to search for information needed to answer their health questions. Objective The aim was to determine whether difficulty accessing health care services for reasons unrelated to insurance coverage is associated with increased use of the Internet to obtain health information. Methods Survey data from 32,139 adults in the 2011 National Health Interview Study (NHIS) were used in this study. The exposure for this analysis was reporting difficulty accessing health care services or delaying getting care for a reason unrelated to insurance status. To define this exposure, we examined 8 questions that asked whether different access problems occurred during the previous 12 months. The outcome for this analysis, health information technology (HIT) use, was captured by examining 2 questions that asked survey respondents if they used an online health chat room or searched the Internet to obtain health information in the previous 12 months. Several multinomial logistic regressions estimating the odds of using HIT for each reported access difficulty were conducted to accomplish the study objective. Results Of a survey population of 32,139 adults, more than 15.90% (n=5109) reported experiencing at least one access to care barrier, whereas 3.63% (1168/32,139) reported using online health chat rooms and 43.55% (13,997/32,139) reported searching the Internet for health information. Adults who reported difficulty accessing health care services for reasons unrelated to their health insurance coverage had greater odds of using the Internet to obtain health information. Those who reported delaying getting care because they could not get an appointment soon enough (OR 2.2, 95% CI 1.9-2.5), were told the doctor would not accept them as a new patient or accept their insurance (OR 2.1, 95% CI 1.7-2.5 and OR 2.1, 95% CI 1.7-2.5, respectively), or because the doctor’s office was not open when they could go (OR 2.2, 95% CI 1.9-2.7) had more than twice the odds of using the Internet to obtain health information compared to those who did not report such access difficulties. Conclusions People experiencing trouble accessing health care services for reasons unrelated to their insurance status are more likely to report using the Internet to obtain health information. Improving the accuracy and reliability of health information resources that are publicly available online could help those who are searching for information due to trouble accessing health care services.\n",
            "------------------------------------\n",
            "Title :  Science vs Conspiracy: Collective Narratives in the Age of Misinformation\n",
            "Author/s :  Alessandro Bessi, Mauro Coletto, G. Davidescu, A. Scala, G. Caldarelli, W. Quattrociocchi\n",
            "Venue :  PLoS ONE\n",
            "year :  2014\n",
            "Abstract :  The large availability of user provided contents on online social media facilitates people aggregation around shared beliefs, interests, worldviews and narratives. In spite of the enthusiastic rhetoric about the so called collective intelligence unsubstantiated rumors and conspiracy theories—e.g., chemtrails, reptilians or the Illuminati—are pervasive in online social networks (OSN). In this work we study, on a sample of 1.2 million of individuals, how information related to very distinct narratives—i.e. main stream scientific and conspiracy news—are consumed and shape communities on Facebook. Our results show that polarized communities emerge around distinct types of contents and usual consumers of conspiracy news result to be more focused and self-contained on their specific contents. To test potential biases induced by the continued exposure to unsubstantiated rumors on users’ content selection, we conclude our analysis measuring how users respond to 4,709 troll information—i.e. parodistic and sarcastic imitation of conspiracy theories. We find that 77.92% of likes and 80.86% of comments are from users usually interacting with conspiracy stories.\n",
            "------------------------------------\n",
            "Title :  SEISMIC: A Self-Exciting Point Process Model for Predicting Tweet Popularity\n",
            "Author/s :  Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, A. Rajaraman, J. Leskovec\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2015\n",
            "Abstract :  Social networking websites allow users to create and share content. Big information cascades of post resharing can form as users of these sites reshare others' posts with their friends and followers. One of the central challenges in understanding such cascading behaviors is in forecasting information outbreaks, where a single post becomes widely popular by being reshared by many users. In this paper, we focus on predicting the final number of reshares of a given post. We build on the theory of self-exciting point processes to develop a statistical model that allows us to make accurate predictions. Our model requires no training or expensive feature engineering. It results in a simple and efficiently computable formula that allows us to answer questions, in real-time, such as: Given a post's resharing history so far, what is our current estimate of its final number of reshares? Is the post resharing cascade past the initial stage of explosive growth? And, which posts will be the most reshared in the future? We validate our model using one month of complete Twitter data and demonstrate a strong improvement in predictive accuracy over existing approaches. Our model gives only 15% relative error in predicting final size of an average information cascade after observing it for just one hour.\n",
            "------------------------------------\n",
            "Title :  The role of collaboration in supply chain resilience\n",
            "Author/s :  K. Scholten, Sanne Schilder\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            "– This paper aims to explore how collaboration influences supply chain resilience. Collaborative activities and their underlying mechanisms in relation to visibility, velocity and flexibility are investigated. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            "– An exploratory case study consisting of eight buyer–supplier relationships in the food processing industry was conducted. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            "– Key findings show how specific collaborative activities (information-sharing, collaborative communication, mutually created knowledge and joint relationship efforts) increase supply chain resilience via increased visibility, velocity and flexibility. Underlying mechanisms and interdependencies of these factors within the supply chain network are identified. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            "– This is one of the first papers to provide in-depth insights into collaboration as a formative element of resilience in a supply chain setting. A series of propositions explain the specific influence of collaborative activities on supply chain resilience beyond a single company perspective.\n",
            "------------------------------------\n",
            "Title :  Data Resource Profile: The Korea National Health and Nutrition Examination Survey (KNHANES)\n",
            "Author/s :  Sanghui Kweon, Yuna Kim, Myoung-jin Jang, Yoonjung Kim, Kirang Kim, Sunhye Choi, Chaemin Chun, Y. Khang, Kyungwon Oh\n",
            "Venue :  International Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  The Korea National Health and Nutrition Examination Survey (KNHANES) is a national surveillance system that has been assessing the health and nutritional status of Koreans since 1998. Based on the National Health Promotion Act, the surveys have been conducted by the Korea Centers for Disease Control and Prevention (KCDC). This nationally representative cross-sectional survey includes approximately 10 000 individuals each year as a survey sample and collects information on socioeconomic status, health-related behaviours, quality of life, healthcare utilization, anthropometric measures, biochemical and clinical profiles for non-communicable diseases and dietary intakes with three component surveys: health interview, health examination and nutrition survey. The health interview and health examination are conducted by trained staff members, including physicians, medical technicians and health interviewers, at a mobile examination centre, and dieticians’ visits to the homes of the study participants are followed up. KNHANES provides statistics for health-related policies in Korea, which also serve as the research infrastructure for studies on risk factors and diseases by supporting over 500 publications. KCDC has also supported researchers in Korea by providing annual workshops for data users. KCDC has published the Korea Health Statistics each year, and microdata are publicly available through the KNHANES website (http://knhanes.cdc.go.kr).\n",
            "------------------------------------\n",
            "Title :  EltonTraits 1.0: Species-level foraging attributes of the world's birds and mammals\n",
            "Author/s :  H. Wilman, J. Belmaker, J. Simpson, C. Rosa, M. Rivadeneira, W. Jetz\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Species are characterized by physiological, behavioral, and ecological attributes that are all subject to varying evolutionary and ecological constraints and jointly determine species' role and function in ecosystems. Attributes such as diet, foraging strata, foraging time, and body size, in particular, characterize a large portion of the “Eltonian” niches of species. Here we present a global species-level compilation of these key attributes for all 9993 and 5400 extant bird and mammal species derived from key literature sources. Global handbooks and monographs allowed the consistent sourcing of attributes for most species. For diet and foraging stratum we followed a defined protocol to translate the verbal descriptions into standardized, semiquantitative information about relative importance of different categories. Together with body size (continuous) and activity time (categorical) this enables a much finer distinction of species' foraging ecology than typical categorical guild assignments allow. Attri...\n",
            "------------------------------------\n",
            "Title :  The Human Phenotype Ontology project: linking molecular biology and disease through phenotype data\n",
            "Author/s :  S. Köhler, S. Doelken, C. Mungall, Sebastian Bauer, H. Firth, I. Bailleul-Forestier, G. Black, Danielle L. Brown, M. Brudno, Jennifer Campbell, D. Fitzpatrick, J. Eppig, A. Jackson, K. Freson, M. Gîrdea, I. Helbig, J. Hurst, J. Jähn, L. Jackson, A. Kelly, D. Ledbetter, S. Mansour, C. Martin, C. Moss, A. Mumford, W. Ouwehand, Soo-Mi Park, E. Riggs, R. Scott, S. Sisodiya, S. V. Vooren, R. Wapner, A. Wilkie, C. Wright, A. V. Silfhout, N. Leeuw, B. Vries, N. Washington, Cynthia L. Smith, M. Westerfield, P. Schofield, B. Ruef, G. Gkoutos, M. Haendel, D. Smedley, S. Lewis, P. Robinson\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2013\n",
            "Abstract :  The Human Phenotype Ontology (HPO) project, available at http://www.human-phenotype-ontology.org, provides a structured, comprehensive and well-defined set of 10,088 classes (terms) describing human phenotypic abnormalities and 13,326 subclass relations between the HPO classes. In addition we have developed logical definitions for 46% of all HPO classes using terms from ontologies for anatomy, cell types, function, embryology, pathology and other domains. This allows interoperability with several resources, especially those containing phenotype information on model organisms such as mouse and zebrafish. Here we describe the updated HPO database, which provides annotations of 7,278 human hereditary syndromes listed in OMIM, Orphanet and DECIPHER to classes of the HPO. Various meta-attributes such as frequency, references and negations are associated with each annotation. Several large-scale projects worldwide utilize the HPO for describing phenotype information in their datasets. We have therefore generated equivalence mappings to other phenotype vocabularies such as LDDB, Orphanet, MedDRA, UMLS and phenoDB, allowing integration of existing datasets and interoperability with multiple biomedical resources. We have created various ways to access the HPO database content using flat files, a MySQL database, and Web-based tools. All data and documentation on the HPO project can be found online.\n",
            "------------------------------------\n",
            "Title :  Political News in the News Feed: Learning Politics from Social Media\n",
            "Author/s :  L. Bode\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Although literature about the relationship between social media and political behaviors has expanded in recent years, little is known about the roles of social media as a source of political information. To fill this gap, this article considers the question of whether and to what extent learning political information occurs via Facebook and Twitter. Theory suggests that social media may play a significant role in the learning of political information within the modern media environment. Making use of a combination of experimental and survey-based studies, the data suggest that the potential for users to learn political information from social media exists but is not always realized within the general population.\n",
            "------------------------------------\n",
            "Title :  Hierarchical recurrent neural network for skeleton based action recognition\n",
            "Author/s :  Yong Du, Wei Wang, Liang Wang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2015\n",
            "Abstract :  Human actions can be represented by the trajectories of skeleton joints. Traditional methods generally model the spatial structure and temporal dynamics of human skeleton with hand-crafted features and recognize human actions by well-designed classifiers. In this paper, considering that recurrent neural network (RNN) can model the long-term contextual information of temporal sequences well, we propose an end-to-end hierarchical RNN for skeleton based action recognition. Instead of taking the whole skeleton as the input, we divide the human skeleton into five parts according to human physical structure, and then separately feed them to five subnets. As the number of layers increases, the representations extracted by the subnets are hierarchically fused to be the inputs of higher layers. The final representations of the skeleton sequences are fed into a single-layer perceptron, and the temporally accumulated output of the perceptron is the final decision. We compare with five other deep RNN architectures derived from our model to verify the effectiveness of the proposed network, and also compare with several other methods on three publicly available datasets. Experimental results demonstrate that our model achieves the state-of-the-art performance with high computational efficiency.\n",
            "------------------------------------\n",
            "Title :  A scoping review of rapid review methods\n",
            "Author/s :  A. Tricco, J. Antony, W. Zarin, L. Strifler, M. Ghassemi, J. Ivory, L. Perrier, B. Hutton, D. Moher, S. Straus\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The End of Framing as we Know it … and the Future of Media Effects\n",
            "Author/s :  M. Cacciatore, D. Scheufele, S. Iyengar\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Framing has become one of the most popular areas of research for scholars in communication and a wide variety of other disciplines, such as psychology, behavioral economics, political science, and sociology. Particularly in the communication discipline, however, ambiguities surrounding how we conceptualize and therefore operationalize framing have begun to overlap with other media effects models to a point that is dysfunctional. This article provides an in-depth examination of framing and positions the theory in the context of recent evolutions in media effects research. We begin by arguing for changes in how communication scholars approach framing as a theoretical construct. We urge scholars to abandon the general term “framing” altogether and instead distinguish between different types of framing. We also propose that, as a field, we refocus attention on the concept's original theoretical foundations and, more important, the potential empirical contributions that the concept can make to our field and our understanding of media effects. Finally, we discuss framing as a bridge between paradigms as we shift from an era of mass communication to one of echo chambers, tailored information and microtargeting in the new media environment.\n",
            "------------------------------------\n",
            "Title :  Tri-Party Deep Network Representation\n",
            "Author/s :  Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang\n",
            "Venue :  International Joint Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  A Rational Theory of Mutual Funds' Attention Allocation\n",
            "Author/s :  Marcin T. Kacperczyk, Stijn Van Nieuwerburgh, Laura L. Veldkamp\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  The question of whether and how mutual fund managers provide valuable services for their clients motivates one of the largest literatures in finance. One candidate explanation is that funds process information about future asset values and use that information to invest in high‐valued assets. But formal theories are scarce because information choice models with many assets are difficult to solve as well as difficult to test. This paper tackles both problems by developing a new attention allocation model that uses the state of the business cycle to predict information choices, which in turn, predict observable patterns of portfolio investments and returns. The predictions about fund portfolios' covariance with payoff shocks, cross‐fund portfolio and return dispersion, and their excess returns are all supported by the data. These findings offer new evidence that some investment managers have skill and that attention is allocated rationally.\n",
            "------------------------------------\n",
            "Title :  What is big data? A consensual definition and a review of key research topics\n",
            "Author/s :  Andrea De Mauro, Marco Greco, M. Grimaldi\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Although Big Data is a trending buzzword in both academia and the industry, its meaning is still shrouded by much conceptual vagueness. The term is used to describe a wide range of concepts: from the technological ability to store, aggregate, and process data, to the cultural shift that is pervasively invading business and society, both drowning in information overload. The lack of a formal definition has led research to evolve into multiple and inconsistent paths. Furthermore, the existing ambiguity among researchers and practitioners undermines an efficient development of the subject. In this paper we have reviewed the existing literature on Big Data and analyzed its previous definitions in order to pursue two results: first, to provide a summary of the key research areas related to the phenomenon, identifying emerging trends and suggesting opportunities for future development; second, to provide a consensual definition for Big Data, by synthesizing common themes of existing works and patterns in previous definitions.\n",
            "------------------------------------\n",
            "Title :  Political Parties, Motivated Reasoning, and Public Opinion Formation\n",
            "Author/s :  Thomas J. Leeper, Rune Slothuus\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  A key characteristic of democratic politics is competition between groups, first of all political parties. Yet, the unavoidably partisan nature of political conflict has had too little influence on scholarship on political psychology. Despite more than 50 years of research on political parties and citizens, we continue to lack a systematic understanding of when and how political parties influence public opinion. We suggest that alternative approaches to political parties and public opinion can be best reconciled and examined through a richer theoretical perspective grounded in motivated reasoning theory. Clearly, parties shape citizens' opinions by mobilizing, influencing, and structuring choices among political alternatives. But the answer to when and how parties influence citizens' reasoning and political opinions depends on an interaction between citizens' motivations, effort, and information generated from the political environment (particularly through competition between parties). The contribution of motivated reasoning, as we describe it, is to provide a coherent theoretical framework for understanding partisan influence on citizens' political opinions. We review recent empirical work consistent with this framework. We also point out puzzles ripe for future research and discuss how partisan-motivated reasoning provides a useful point of departure for such work.\n",
            "------------------------------------\n",
            "Title :  Analysing How People Orient to and Spread Rumours in Social Media by Looking at Conversational Threads\n",
            "Author/s :  A. Zubiaga, Geraldine Wong Sak Hoi, Maria Liakata, R. Procter, P. Tolmie\n",
            "Venue :  PLoS ONE\n",
            "year :  2015\n",
            "Abstract :  As breaking news unfolds people increasingly rely on social media to stay abreast of the latest updates. The use of social media in such situations comes with the caveat that new information being released piecemeal may encourage rumours, many of which remain unverified long after their point of release. Little is known, however, about the dynamics of the life cycle of a social media rumour. In this paper we present a methodology that has enabled us to collect, identify and annotate a dataset of 330 rumour threads (4,842 tweets) associated with 9 newsworthy events. We analyse this dataset to understand how users spread, support, or deny rumours that are later proven true or false, by distinguishing two levels of status in a rumour life cycle i.e., before and after its veracity status is resolved. The identification of rumours associated with each event, as well as the tweet that resolved each rumour as true or false, was performed by journalist members of the research team who tracked the events in real time. Our study shows that rumours that are ultimately proven true tend to be resolved faster than those that turn out to be false. Whilst one can readily see users denying rumours once they have been debunked, users appear to be less capable of distinguishing true from false rumours when their veracity remains in question. In fact, we show that the prevalent tendency for users is to support every unverified rumour. We also analyse the role of different types of users, finding that highly reputable users such as news organisations endeavour to post well-grounded statements, which appear to be certain and accompanied by evidence. Nevertheless, these often prove to be unverified pieces of information that give rise to false rumours. Our study reinforces the need for developing robust machine learning techniques that can provide assistance in real time for assessing the veracity of rumours. The findings of our study provide useful insights for achieving this aim.\n",
            "------------------------------------\n",
            "Title :  Photonic quantum information processing: a review\n",
            "Author/s :  F. Flamini, N. Spagnolo, F. Sciarrino\n",
            "Venue :  Reports on progress in physics. Physical Society\n",
            "year :  2018\n",
            "Abstract :  Photonic quantum technologies represent a promising platform for several applications, ranging from long-distance communications to the simulation of complex phenomena. Indeed, the advantages offered by single photons do make them the candidate of choice for carrying quantum information in a broad variety of areas with a versatile approach. Furthermore, recent technological advances are now enabling first concrete applications of photonic quantum information processing. The goal of this manuscript is to provide the reader with a comprehensive review of the state of the art in this active field, with a due balance between theoretical, experimental and technological results. When more convenient, we will present significant achievements in tables or in schematic figures, in order to convey a global perspective of the several horizons that fall under the name of photonic quantum information.\n",
            "------------------------------------\n",
            "Title :  Patient Portals and Patient Engagement: A State of the Science Review\n",
            "Author/s :  Taya Irizarry, A. D. DeVito Dabbs, C. Curran\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2015\n",
            "Abstract :  Background Patient portals (ie, electronic personal health records tethered to institutional electronic health records) are recognized as a promising mechanism to support greater patient engagement, yet questions remain about how health care leaders, policy makers, and designers can encourage adoption of patient portals and what factors might contribute to sustained utilization. Objective The purposes of this state of the science review are to (1) present the definition, background, and how current literature addresses the encouragement and support of patient engagement through the patient portal, and (2) provide a summary of future directions for patient portal research and development to meaningfully impact patient engagement. Methods We reviewed literature from 2006 through 2014 in PubMed, Ovid Medline, and PsycInfo using the search terms “patient portal” OR “personal health record” OR “electronic personal health record”. Final inclusion criterion dictated that studies report on the patient experience and/or ways that patients may be supported to make competent health care decisions and act on those decisions using patient portal functionality. Results We found 120 studies that met the inclusion criteria. Based on the research questions, explicit and implicit aims of the studies, and related measures addressed, the studies were grouped into five major topics (patient adoption, provider endorsement, health literacy, usability, and utility). We discuss the findings and conclusions of studies that address the five topical areas. Conclusions Current research has demonstrated that patients’ interest and ability to use patient portals is strongly influenced by personal factors such age, ethnicity, education level, health literacy, health status, and role as a caregiver. Health care delivery factors, mainly provider endorsement and patient portal usability also contribute to patient’s ability to engage through and with the patient portal. Future directions of research should focus on identifying specific populations and contextual considerations that would benefit most from a greater degree of patient engagement through a patient portal. Ultimately, adoption by patients and endorsement by providers will come when existing patient portal features align with patients’ and providers’ information needs and functionality.\n",
            "------------------------------------\n",
            "Title :  Topic Aware Neural Response Generation\n",
            "Author/s :  Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, M. Zhou, Wei-Ying Ma\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  \n",
            " \n",
            " We consider incorporating topic information into a sequence-to-sequence framework to generate informative and interesting responses for chatbots. To this end, we propose a topic aware sequence-to-sequence (TA-Seq2Seq) model. The model utilizes topics to simulate prior human knowledge that guides them to form informative and interesting responses in conversation, and leverages topic information in generation by a joint attention mechanism and a biased generation probability. The joint attention mechanism summarizes the hidden vectors of an input message as context vectors by message attention and synthesizes topic vectors by topic attention from the topic words of the message obtained from a pre-trained LDA model, with these vectors jointly affecting the generation of words in decoding. To increase the possibility of topic words appearing in responses, the model modifies the generation probability of topic words by adding an extra probability item to bias the overall distribution. Empirical studies on both automatic evaluation metrics and human annotations show that TA-Seq2Seq can generate more informative and interesting responses, significantly outperforming state-of-the-art response generation models.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  SlowFast Networks for Video Recognition\n",
            "Author/s :  Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, Kaiming He\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2018\n",
            "Abstract :  We present SlowFast networks for video recognition. Our model involves (i) a Slow pathway, operating at low frame rate, to capture spatial semantics, and (ii) a Fast pathway, operating at high frame rate, to capture motion at fine temporal resolution. The Fast pathway can be made very lightweight by reducing its channel capacity, yet can learn useful temporal information for video recognition. Our models achieve strong performance for both action classification and detection in video, and large improvements are pin-pointed as contributions by our SlowFast concept. We report state-of-the-art accuracy on major video recognition benchmarks, Kinetics, Charades and AVA. Code has been made available at: https://github.com/facebookresearch/SlowFast.\n",
            "------------------------------------\n",
            "Title :  EVOLUTION OF THE WORLD WIDE WEB : FROM WEB 1.0 TO WEB 4.0\n",
            "Author/s :  Sareh Aghaei, M. Nematbakhsh, Hadi Khosravi Farsani\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  The World Wide Web as the largest information construct has had much progress since its advent. This paper provides a background of the evolution of the web from web 1.0 to web 4.0. Web 1.0 as a web of information connections, Web 2.0 as a web of people connections, Web 3.0 as a web of knowledge connections and web 4.0 as a web of intelligence connections are described as four generations of the web in the paper.\n",
            "------------------------------------\n",
            "Title :  Flow-Guided Feature Aggregation for Video Object Detection\n",
            "Author/s :  Xizhou Zhu, Yujie Wang, Jifeng Dai, Lu Yuan, Yichen Wei\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong singleframe baselines in ImageNet VID [33], especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The code would be released.\n",
            "------------------------------------\n",
            "Title :  Local E‐Government in the United States: Transformation or Incremental Change?\n",
            "Author/s :  D. Norris, C. Reddick\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  In this article, the authors address the recent trajectory of local e-government in the United States and compare it with the predictions of early e-government writings, using empirical data from two nationwide surveys of e-government among American local governments. The authors find that local e-government has not produced the results that those writings predicted. Instead, its development has largely been incremental, and local e-government is mainly about delivering information and services online, followed by a few transactions and limited interactivity. Local e-government is also mainly one way, from government to citizens, and there is little or no evidence that it is transformative in any way. This disparity between early predictions and actual results is partly attributable to the incremental nature of American public administration. Other reasons include a lack of attention by early writers to the history of information technology in government and the influence of technological determinism on those writings.\n",
            "------------------------------------\n",
            "Title :  Competing spreading processes on multiplex networks: awareness and epidemics\n",
            "Author/s :  C. Granell, S. Gómez, A. Arenas\n",
            "Venue :  Physical review. E, Statistical, nonlinear, and soft matter physics\n",
            "year :  2014\n",
            "Abstract :  Epidemiclike spreading processes on top of multilayered interconnected complex networks reveal a rich phase diagram of intertwined competition effects. A recent study by the authors [C. Granell et al., Phys. Rev. Lett. 111, 128701 (2013).] presented an analysis of the interrelation between two processes accounting for the spreading of an epidemic, and the spreading of information awareness to prevent infection, on top of multiplex networks. The results in the case in which awareness implies total immunization to the disease revealed the existence of a metacritical point at which the critical onset of the epidemics starts, depending on completion of the awareness process. Here we present a full analysis of these critical properties in the more general scenario where the awareness spreading does not imply total immunization, and where infection does not imply immediate awareness of it. We find the critical relation between the two competing processes for a wide spectrum of parameters representing the interaction between them. We also analyze the consequences of a massive broadcast of awareness (mass media) on the final outcome of the epidemic incidence. Importantly enough, the mass media make the metacritical point disappear. The results reveal that the main finding, i.e., existence of a metacritical point, is rooted in the competition principle and holds for a large set of scenarios.\n",
            "------------------------------------\n",
            "Title :  User preference of cyber security awareness delivery methods\n",
            "Author/s :  J. Abawajy\n",
            "Venue :  Behavior and Information Technology\n",
            "year :  2014\n",
            "Abstract :  Operating systems and programmes are more protected these days and attackers have shifted their attention to human elements to break into the organisation's information systems. As the number and frequency of cyber-attacks designed to take advantage of unsuspecting personnel are increasing, the significance of the human factor in information security management cannot be understated. In order to counter cyber-attacks designed to exploit human factors in information security chain, information security awareness with an objective to reduce information security risks that occur due to human related vulnerabilities is paramount. This paper discusses and evaluates the effects of various information security awareness delivery methods used in improving end-users’ information security awareness and behaviour. There are a wide range of information security awareness delivery methods such as web-based training materials, contextual training and embedded training. In spite of efforts to increase information security awareness, research is scant regarding effective information security awareness delivery methods. To this end, this study focuses on determining the security awareness delivery method that is most successful in providing information security awareness and which delivery method is preferred by users. We conducted information security awareness using text-based, game-based and video-based delivery methods with the aim of determining user preferences. Our study suggests that a combined delivery methods are better than individual security awareness delivery method.\n",
            "------------------------------------\n",
            "Title :  Tri-Party Deep Network Representation\n",
            "Author/s :  Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang\n",
            "Venue :  International Joint Conference on Artificial Intelligence\n",
            "year :  2016\n",
            "Abstract :  Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Sustainability reports as simulacra? A counter-account of A and A+ GRI reports\n",
            "Author/s :  O. Boiral\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Purpose - – The purpose of this paper is to examine the extent to which sustainability reporting can be viewed as a simulacrum used to camouflage real sustainable-development problems and project an idealized view of the firms' situations. Design/methodology/approach - – The method was based on the content analysis and counter accounting of 23 sustainability reports from firms in the energy and mining sectors which had received application levels of A or A+ from the Global Reporting Initiative (GRI). The information disclosed in some 2,700 pages of reports was structured around 92 GRI indicators and compared with 116 significant news events that clearly addressed the responsibility of these firms in sustainable development problems. Moreover, the 1,258 pictures included in sustainability reports were categorized into recurring themes from an inductive perspective. Findings - – A total of 90 per cent of the significant negative events were not reported, contrary to the principles of balance, completeness and transparency of GRI reports. Moreover, the pictures included in these reports showcase various simulacra clearly disconnected with the impact of business activities. Originality/value - – The paper shows the relevance of the counter accounting approach in assessing the quality of sustainability reports and question the reliability of the GRI's A or A+ application levels. It contributes to debates concerning the transparency of sustainability reports in light of Debord's and Baudrillard's critical perspective. The paper reveals the underexplored role of images in the emergence of several types of simulacra.\n",
            "------------------------------------\n",
            "Title :  P-CNN: Pose-Based CNN Features for Action Recognition\n",
            "Author/s :  Guilhem Chéron, I. Laptev, C. Schmid\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2015\n",
            "Abstract :  This work targets human action recognition in video. While recent methods typically represent actions by statistics of local video features, here we argue for the importance of a representation derived from human pose. To this end we propose a new Pose-based Convolutional Neural Network descriptor (P-CNN) for action recognition. The descriptor aggregates motion and appearance information along tracks of human body parts. We investigate different schemes of temporal aggregation and experiment with P-CNN features obtained both for automatically estimated and manually annotated human poses. We evaluate our method on the recent and challenging JHMDB and MPII Cooking datasets. For both datasets our method shows consistent improvement over the state of the art.\n",
            "------------------------------------\n",
            "Title :  Graph Convolutional Matrix Completion\n",
            "Author/s :  Rianne van den Berg, Thomas Kipf, M. Welling\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title :  Fundamentals of Wireless Information and Power Transfer: From RF Energy Harvester Models to Signal and System Designs\n",
            "Author/s :  B. Clerckx, Rui Zhang, R. Schober, Derrick Wing Kwan Ng, Dong In Kim, H. Poor\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2018\n",
            "Abstract :  Radio waves carry both energy and information simultaneously. Nevertheless, radio-frequency (RF) transmissions of these quantities have traditionally been treated separately. Currently, the community is experiencing a paradigm shift in wireless network design, namely, unifying wireless transmission of information and power so as to make the best use of the RF spectrum and radiation as well as the network infrastructure for the dual purpose of communicating and energizing. In this paper, we review and discuss recent progress in laying the foundations of the envisioned dual purpose networks by establishing a signal theory and design for wireless information and power transmission (WIPT) and identifying the fundamental tradeoff between conveying information and power wirelessly. We start with an overview of WIPT challenges and technologies, namely, simultaneous WIPT (SWIPT), wirelessly powered communication networks (WPCNs), and wirelessly powered backscatter communication (WPBC). We then characterize energy harvesters and show how WIPT signal and system designs crucially revolve around the underlying energy harvester model. To that end, we highlight three different energy harvester models, namely, one linear model and two nonlinear models, and show how WIPT designs differ for each of them in single-user and multi-user deployments. Topics discussed include rate-energy region characterization, transmitter and receiver architectures, waveform design, modulation, beamforming and input distribution optimizations, resource allocation, and RF spectrum use. We discuss and check the validity of the different energy harvester models and the resulting signal theory and design based on circuit simulations, prototyping, and experimentation. We also point out numerous directions that are promising for future research.\n",
            "------------------------------------\n",
            "Title :  Variable selection – A review and recommendations for the practicing statistician\n",
            "Author/s :  G. Heinze, C. Wallisch, D. Dunkler\n",
            "Venue :  Biometrical journal. Biometrische Zeitschrift\n",
            "year :  2018\n",
            "Abstract :  Statistical models support medical research by facilitating individualized outcome prognostication conditional on independent variables or by estimating effects of risk factors adjusted for covariates. Theory of statistical models is well‐established if the set of independent variables to consider is fixed and small. Hence, we can assume that effect estimates are unbiased and the usual methods for confidence interval estimation are valid. In routine work, however, it is not known a priori which covariates should be included in a model, and often we are confronted with the number of candidate variables in the range 10–30. This number is often too large to be considered in a statistical model. We provide an overview of various available variable selection methods that are based on significance or information criteria, penalized likelihood, the change‐in‐estimate criterion, background knowledge, or combinations thereof. These methods were usually developed in the context of a linear regression model and then transferred to more generalized linear models or models for censored survival data. Variable selection, in particular if used in explanatory modeling where effect estimates are of central interest, can compromise stability of a final model, unbiasedness of regression coefficients, and validity of p‐values or confidence intervals. Therefore, we give pragmatic recommendations for the practicing statistician on application of variable selection methods in general (low‐dimensional) modeling problems and on performing stability investigations and inference. We also propose some quantities based on resampling the entire variable selection process to be routinely reported by software packages offering automated variable selection algorithms.\n",
            "------------------------------------\n",
            "Title :  The New Ambiguity of 'Open Government'\n",
            "Author/s :  Harlan Yu, Harlan Yu, Harlan Yu, D. G. Robinson\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  “Open government” used to carry a hard political edge: it referred to politically sensitive disclosures of government information. The phrase was first used in the 1950s, in the debates leading up to passage of the Freedom of Information Act. But over the last few years, that traditional meaning has blurred, and has shifted toward technology. Open technologies involve sharing data over the Internet, and all kinds of governments can use them, for all kinds of reasons. Recent public policies have stretched the label “open government” to reach any public sector use of these technologies. Thus, “open government data” might refer to data that makes the government as a whole more open (that is, more accountable to the public), but might equally well refer to politically neutral public sector disclosures that are easy to reuse, but that may have nothing to do with public accountability. Today a regime can call itself “open” if it builds the right kind of web site — even if it does not become more accountable. This shift in vocabulary makes it harder for policymakers and activists to articulate clear priorities and make cogent demands.This essay proposes a more useful way for participants on all sides to frame the debate: We separate the politics of open government from the technologies of open data. Technology can make public information more adaptable, empowering third parties to contribute in exciting new ways across many aspects of civic life. But technological enhancements will not resolve debates about the best priorities for civic life, and enhancements to government services are no substitute for public accountability.\n",
            "------------------------------------\n",
            "Title :  An event-driven manufacturing information system architecture for Industry 4.0\n",
            "Author/s :  Alfred Theorin, Kristofer Bengtsson, Julien Provost, Michael Lieder, C. Johnsson, T. Lundholm, B. Lennartson\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2017\n",
            "Abstract :  Future manufacturing systems need to be more flexible, to embrace tougher and constantly changing market demands. They need to make better use of plant data, ideally utilising all data from the entire plant. Low-level data should be refined to real-time information for decision-making, to facilitate competitiveness through informed and timely decisions. The Line Information System Architecture (LISA), is presented in this paper. It is an event-driven architecture featuring loose coupling, a prototype-oriented information model and formalised transformation services. LISA is designed to enable flexible factory integration and data utilisation. The focus of LISA is on integration of devices and services on all levels, simplifying hardware changes and integration of new smart services as well as supporting continuous improvements on information visualisation and control. The architecture has been evaluated on both real industrial data and industrial demonstrators and it is also being installed at a large automotive company. This article is an extended and revised version of the paper presented at the 2015 IFAC Symposium on Information Control in Manufacturing (INCOM 2015). The paper has been restructured in regards to the order and title of the chapters, and additional information about the integration between devices and services aspects have been added. The introduction and the general structure of the paper now better highlight the contributions of the paper and the uniqueness of the framework.\n",
            "------------------------------------\n",
            "Title :  Multimodal learning with deep Boltzmann machines\n",
            "Author/s :  Nitish Srivastava, R. Salakhutdinov\n",
            "Venue :  Journal of machine learning research\n",
            "year :  2012\n",
            "Abstract :  Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.\n",
            "------------------------------------\n",
            "Title :  Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment\n",
            "Author/s :  K. Huckvale, José Tomás Prieto, M. Tilney, Pierre Benghozi, J. Car\n",
            "Venue :  BMC Medicine\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  How Much Information?: Effects of Transparency on Trust in an Algorithmic Interface\n",
            "Author/s :  René F. Kizilcec\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2016\n",
            "Abstract :  The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online field experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justification of perceived inconsistency. Designing for trust requires balanced interface transparency - not too little and not too much.\n",
            "------------------------------------\n",
            "Title :  The Ease of Language Understanding (ELU) model: theoretical, empirical, and clinical advances\n",
            "Author/s :  J. Rönnberg, T. Lunner, A. Zekveld, Patrik Sörqvist, H. Danielsson, B. Lyxell, Ö. Dahlström, Carine Signoret, S. Stenfelt, M. Pichora-Fuller, M. Rudner\n",
            "Venue :  Frontiers in Systems Neuroscience\n",
            "year :  2013\n",
            "Abstract :  Working memory is important for online language processing during conversation. We use it to maintain relevant information, to inhibit or ignore irrelevant information, and to attend to conversation selectively. Working memory helps us to keep track of and actively participate in conversation, including taking turns and following the gist. This paper examines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg, 2003; Rönnberg et al., 2008) in light of new behavioral and neural findings concerning the role of working memory capacity (WMC) in uni-modal and bimodal language processing. The new ELU model is a meaning prediction system that depends on phonological and semantic interactions in rapid implicit and slower explicit processing mechanisms that both depend on WMC albeit in different ways. It is based on findings that address the relationship between WMC and (a) early attention processes in listening to speech, (b) signal processing in hearing aids and its effects on short-term memory, (c) inhibition of speech maskers and its effect on episodic long-term memory, (d) the effects of hearing impairment on episodic and semantic long-term memory, and finally, (e) listening effort. New predictions and clinical implications are outlined. Comparisons with other WMC and speech perception models are made.\n",
            "------------------------------------\n",
            "Title :  InfoVAE: Information Maximizing Variational Autoencoders\n",
            "Author/s :  Shengjia Zhao, Jiaming Song, S. Ermon\n",
            "Venue :  ArXiv\n",
            "year :  2017\n",
            "Abstract :  A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.\n",
            "------------------------------------\n",
            "Title :  Dual-Function Radar-Communications: Information Embedding Using Sidelobe Control and Waveform Diversity\n",
            "Author/s :  A. Hassanien, M. Amin, Yimin D. Zhang, F. Ahmad\n",
            "Venue :  IEEE Transactions on Signal Processing\n",
            "year :  2016\n",
            "Abstract :  We develop a new technique for a dual-function system with joint radar and communication platforms. Sidelobe control of the transmit beamforming in tandem with waveform diversity enables communication links using the same pulse radar spectrum. Multiple simultaneously transmitted orthogonal waveforms are used for embedding a sequence of LB bits during each radar pulse. Two weight vectors are designed to achieve two transmit spatial power distribution patterns, which have the same main radar beam, but differ in sidelobe levels towards the intended communication receivers. The receiver interpretation of the bit is based on its radiated beam. The proposed technique allows information delivery to single or multiple communication directions outside the mainlobe of the radar. It is shown that the communication process is inherently secure against intercept from directions other than the pre-assigned communication directions. The employed waveform diversity scheme supports a multiple-input multiple-output radar operation mode. The performance of the proposed technique is investigated in terms of the bit error rate.\n",
            "------------------------------------\n",
            "Title :  A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\n",
            "Author/s :  A. Casali, O. Gosseries, M. Rosanova, M. Boly, S. Sarasso, K. Casali, S. Casarotto, M. Bruno, Steven Laureys, G. Tononi, M. Massimini\n",
            "Venue :  Science Translational Medicine\n",
            "year :  2013\n",
            "Abstract :  A theory-derived index of consciousness, which quantifies the complexity of the brain’s response to a stimulus, measures the level of consciousness in awake, sleeping, anesthetized, and brain-damaged subjects. Quantifying the Unquantifiable Manipulation of consciousness is an everyday medical trick—think anesthesia—but physicians have only the crudest of tools to detect when a person is not aware. The usual question or physical stimulus does not always provide reliable reactions, and a more precise index is needed to avoid, for example, the conclusion that people who have locked-in syndrome (in which they are aware but cannot respond) are unconscious. Here, Casali et al. have extended their previous work on electrical correlates of consciousness to define an electroencephalographic-derived index of human consciousness [the perturbational complexity index (PCI)] that reflects the information content of the brain’s response to a magnetic stimulus. The PCI could allow tracking of consciousness in individual patients. The authors used data already collected from previous experiments, in which they had stimulated people’s brains with transcranial magnetic stimulation. By calculating the likely brain regional sources of the signals and then comparing the unique information in each, the authors derived PCI values. The values ranged from 0.44 to 0.67 in 32 awake healthy people, but fell to 0.18 to 0.28 during nonrapid eye movement (NREM) sleep. Then, to see whether a completely different way of inducing unconsciousness had the same effect on PCI, the authors assessed data from patients given various amounts of the anesthetics midazolam, xenon, and propofol. These agents too caused low “unconscious” values for the PCI: midazolam deep sedation, 0.23 to 0.31; propofol, 0.13 to 0.30; and xenon, 0.12 to 0.31. However, what about patients who suffer brain damage and who exhibit various levels of consciousness by conventional assessment methods? In these people, consciousness varies widely, as does the underlying damage from stroke or trauma. Here, too, the authors found promising results in those who had emerged from coma but were in a vegetative state or minimally conscious state, or exhibited locked-in syndrome. The PCI values from these patients clearly reflected the state of their consciousness, with the six patients in a vegetative state clearly unconscious (0.19 to 0.31), the two with locked-in syndrome clearly aware (0.51 to 0.62), and those in a minimally conscious state showing intermediate values (0.32 to 0.49). The validity of PCI for clinical application will need to be assessed in prospective trials, but it has the advantage of being derived from a simple noninvasive measurement. The new index reported by Casali et al. appears to be a robust measure that distinguishes conscious from unconscious states well enough to be used on an individual basis, a prerequisite for deployment in the clinic. One challenging aspect of the clinical assessment of brain-injured, unresponsive patients is the lack of an objective measure of consciousness that is independent of the subject’s ability to interact with the external environment. Theoretical considerations suggest that consciousness depends on the brain’s ability to support complex activity patterns that are, at once, distributed among interacting cortical areas (integrated) and differentiated in space and time (information-rich). We introduce and test a theory-driven index of the level of consciousness called the perturbational complexity index (PCI). PCI is calculated by (i) perturbing the cortex with transcranial magnetic stimulation (TMS) to engage distributed interactions in the brain (integration) and (ii) compressing the spatiotemporal pattern of these electrocortical responses to measure their algorithmic complexity (information). We test PCI on a large data set of TMS-evoked potentials recorded in healthy subjects during wakefulness, dreaming, nonrapid eye movement sleep, and different levels of sedation induced by anesthetic agents (midazolam, xenon, and propofol), as well as in patients who had emerged from coma (vegetative state, minimally conscious state, and locked-in syndrome). PCI reliably discriminated the level of consciousness in single individuals during wakefulness, sleep, and anesthesia, as well as in patients who had emerged from coma and recovered a minimal level of consciousness. PCI can potentially be used for objective determination of the level of consciousness at the bedside.\n",
            "------------------------------------\n",
            "Title :  Decentralized Stochastic Control with Partial History Sharing: A Common Information Approach\n",
            "Author/s :  A. Nayyar, Aditya Mahajan, D. Teneketzis\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2012\n",
            "Abstract :  A general model of decentralized stochastic control called partial history sharing information structure is presented. In this model, at each step the controllers share part of their observation and control history with each other. This general model subsumes several existing models of information sharing as special cases. Based on the information commonly known to all the controllers, the decentralized problem is reformulated as an equivalent centralized problem from the perspective of a coordinator. The coordinator knows the common information and selects prescriptions that map each controller's local information to its control actions. The optimal control problem at the coordinator is shown to be a partially observable Markov decision process (POMDP) which is solved using techniques from Markov decision theory. This approach provides 1) structural results for optimal strategies and 2) a dynamic program for obtaining optimal strategies for all controllers in the original decentralized problem. Thus, this approach unifies the various ad-hoc approaches taken in the literature. In addition, the structural results on optimal control strategies obtained by the proposed approach cannot be obtained by the existing generic approach (the person-by-person approach) for obtaining structural results in decentralized problems; and the dynamic program obtained by the proposed approach is simpler than that obtained by the existing generic approach (the designer's approach) for obtaining dynamic programs in decentralized problems.\n",
            "------------------------------------\n",
            "Title :  A Group Incremental Approach to Feature Selection Applying Rough Set Technique\n",
            "Author/s :  Jiye Liang, Feng Wang, C. Dang, Y. Qian\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2014\n",
            "Abstract :  Many real data increase dynamically in size. This phenomenon occurs in several fields including economics, population studies, and medical research. As an effective and efficient mechanism to deal with such data, incremental technique has been proposed in the literature and attracted much attention, which stimulates the result in this paper. When a group of objects are added to a decision table, we first introduce incremental mechanisms for three representative information entropies and then develop a group incremental rough feature selection algorithm based on information entropy. When multiple objects are added to a decision table, the algorithm aims to find the new feature subset in a much shorter time. Experiments have been carried out on eight UCI data sets and the experimental results show that the algorithm is effective and efficient.\n",
            "------------------------------------\n",
            "Title :  Continuous Variable Quantum Information: Gaussian States and Beyond\n",
            "Author/s :  G. Adesso, Sammy Ragy, Antony R. Lee\n",
            "Venue :  Open systems & information dynamics\n",
            "year :  2014\n",
            "Abstract :  The study of Gaussian states has arisen to a privileged position in contin- uous variable quantum information in recent years. This is due to vehemently pursued experimental realisations and a magnificently elegant mathematical framework. In this paper, we provide a brief, and hopefully didactic, exposition of Gaussian state quantum information and its contemporary uses, including sometimes omitted crucial details. After introducing the subject material and outlining the essential toolbox of continuous variable systems, we define the basic notions needed to understand Gaussian states and Gaussian operations. In particular, emphasis is placed on the mathematical structure combining notions of algebra and symplectic geometry fundamental to a complete understanding of Gaussian informatics. Furthermore, we discuss the quantification of different forms of cor- relations (including entanglement and quantum discord) for Gaussian states, paying special attention to recently developed measures. The paper is concluded by succinctly expressing the main Gaussian state limitations and outlining a selection of possible future lines for quantum information processing with continuous variable systems.\n",
            "------------------------------------\n",
            "Title :  Quality of patient health information on the Internet: reviewing a complex and evolving landscape.\n",
            "Author/s :  E. Fahy, R. Hardikar, A. Fox, S. Mackay\n",
            "Venue :  Australasian Medical Journal\n",
            "year :  2014\n",
            "Abstract :  BACKGROUND\n",
            "The popularity of the Internet has enabled unprecedented access to health information. As a largely unregulated source, there is potential for inconsistency in the quality of information that reaches the patient.\n",
            "\n",
            "\n",
            "AIMS\n",
            "To review the literature relating to the quality indicators of health information for patients on the Internet.\n",
            "\n",
            "\n",
            "METHOD\n",
            "A search of English language literature was conducted using PubMed, Google Scholar and EMBASE databases.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Many articles have been published which assess the quality of information relating to specific medical conditions. Indicators of quality have been defined in an attempt to predict higher quality health information on the Internet. Quality evaluation tools are scoring systems based on indicators of quality. Established tools such as the HONcode may help patients navigate to more reliable information. Google and Wikipedia are important emerging sources of patient health information.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "The Internet is crucial for modern dissemination of health information, but it is clear that quality varies significantly between sources. Quality indicators for web-information have been developed but there is no agreed standard yet. We envisage that reliable rating tools, effective search engine ranking and progress in crowd-edited websites will enhance patient access to health information on the Internet.\n",
            "------------------------------------\n",
            "Title :  ExFuse: Enhancing Feature Fusion for Semantic Segmentation\n",
            "Author/s :  Zhenli Zhang, X. Zhang, Chao Peng, Dazhi Cheng, Jian Sun\n",
            "Venue :  European Conference on Computer Vision\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Unpacking the Use of Social Media for Protest Behavior\n",
            "Author/s :  S. Valenzuela\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Recent studies have shown a positive link between frequency of social media use and political participation. However, there has been no clear elaboration of how using social media translates into increased political activity. The current study examines three explanations for this relationship in the context of citizens’ protest behavior: information (social media as a source for news), opinion expression (using social media to express political opinions), and activism (joining causes and finding mobilizing information through social media). To test these relationships, the study uses survey data collected in Chile in 2011, amid massive demonstrations demanding wholesale changes in education and energy policy. Findings suggest that using social media for opinion expression and activism mediates the relationship between overall social media use and protest behavior. These findings deepen our knowledge of the uses and effects of social media and provide new evidence on the role of digital platforms as facilitators of direct political action.\n",
            "------------------------------------\n",
            "Title :  Exploring the Space of Topic Coherence Measures\n",
            "Author/s :  Michael Röder, A. Both, A. Hinneburg\n",
            "Venue :  Web Search and Data Mining\n",
            "year :  2015\n",
            "Abstract :  Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.\n",
            "------------------------------------\n",
            "Title :  Is This Review Believable? A Study of Factors Affecting the Credibility of Online Consumer Reviews from an ELM Perspective\n",
            "Author/s :  Cindy Man-Yee Cheung, C. Sia, Kevin K. Y. Kuan\n",
            "Venue :  Journal of the AIS\n",
            "year :  2012\n",
            "Abstract :  With the ever-increasing popularity of online consumer reviews, understanding what makes an online review believable has attracted increased attention from both academics and practitioners. Drawing on the elaboration likelihood model (ELM), this study examines four information cues used to evaluate the credibility of online reviews: Argument quality, source credibility, review consistency, and review sidedness, under different levels of involvement and expertise. We conducted an online survey that involved users of Epinions.com, a popular online consumer review website, to test the research model empirically. Consistent with previous research, the results reveal that argument quality, a central cue, was the primary factor affecting review credibility. Participants also relied on peripheral cues such as source credibility, review consistency, and review sidedness when evaluating online consumer reviews. Review sidedness had a stronger impact on review credibility when the recipient had a low involvement level and a high expertise level. However, the other interaction effects were not significant. We discuss the theoretical and practical implications of these results.\n",
            "------------------------------------\n",
            "Title :  Externalities of Public Firm Presence: Evidence from Private Firms’ Investment Decisions\n",
            "Author/s :  Brad A. Badertscher, Nemit Shroff, H. White\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Public firms provide a large amount of information through their disclosures. In addition, information intermediaries publicly analyze, discuss and disseminate these disclosures. Thus, greater public firm presence in an industry should reduce uncertainty in that industry. Following the theoretical prediction of investment under uncertainty, we hypothesize and find that private firms are more responsive to their investment opportunities when they operate in industries with greater public firm presence. Further, we find that the effect of public firm presence is greater in industries with better information quality and in industries characterized by a greater degree of investment irreversibility. Our results suggest that public firms generate positive externalities by reducing industry uncertainty and facilitating more efficient private firm investment.\n",
            "------------------------------------\n",
            "Title :  DroidScope: Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android Malware Analysis\n",
            "Author/s :  Lok K. Yan, Heng Yin\n",
            "Venue :  USENIX Security Symposium\n",
            "year :  2012\n",
            "Abstract :  The prevalence of mobile platforms, the large market share of Android, plus the openness of the Android Market makes it a hot target for malware attacks. Once a malware sample has been identified, it is critical to quickly reveal its malicious intent and inner workings. In this paper we present DroidScope, an Android analysis platform that continues the tradition of virtualization-based malware analysis. Unlike current desktop malware analysis platforms, DroidScope reconstructs both the OS-level and Java-level semantics simultaneously and seamlessly. To facilitate custom analysis, DroidScope exports three tiered APIs that mirror the three levels of an Android device: hardware, OS and Dalvik Virtual Machine. On top of DroidScope, we further developed several analysis tools to collect detailed native and Dalvik instruction traces, profile API-level activity, and track information leakage through both the Java and native components using taint analysis. These tools have proven to be effective in analyzing real world malware samples and incur reasonably low performance overheads.\n",
            "------------------------------------\n",
            "Title :  Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA\n",
            "Author/s :  Sahil Loomba, A. de Figueiredo, S. Piatek, K. de Graaf, H. Larson\n",
            "Venue :  Nature Human Behaviour\n",
            "year :  2021\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information Sharing in a Supply Chain with a Common Retailer\n",
            "Author/s :  Weixin Shang, Albert Y. Ha, Shilu Tong\n",
            "Venue :  Management Sciences\n",
            "year :  2013\n",
            "Abstract :  We study the problem of information sharing in a supply chain with two competing manufacturers selling substitutable products through a common retailer. Our analysis shows that the retailer’s incentive to share information strongly depends on nonlinear production cost, competition intensity, and whether the retailer can offer a contract to charge a payment for the information. Without information contracting, the retailer has an incentive to share information for free when production economy is large but has no incentive to do so when there is production diseconomy. With information contracting, the retailer has an incentive to share information when either production diseconomy/economy is large or competition is intense. We characterize the conditions under which the retailer shares information with none, one, or both of the manufacturers. We also show that the retailer prefers to sell information sequentially rather than concurrently to the manufacturers, whereas the manufacturers’ preferences are reversed. This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  Ideology, Motivated Reasoning, and Cognitive Reflection: An Experimental Study\n",
            "Author/s :  D. Kahan\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Social psychologists have identified various plausible sources of ideological polarization over climate change, gun violence, national security, and like societal risks. This paper describes a study of three of them: the predominance of heuristic-driven information processing by members of the public; ideologically motivated cognition; and personality-trait correlates of political conservativism. The results of the study suggest reason to doubt two common surmises about how these dynamics interact. First, the study presents both observational and experimental data inconsistent with the hypothesis that political conservatism is distinctively associated with closed-mindedness: conservatives did no better or worse than liberals on an objective measure of cognitive reflection; and more importantly, both demonstrated the same unconscious tendency to fit assessments of empirical evidence to their ideological predispositions. Second, the study suggests that this form of bias is not a consequence of overreliance on heuristic or intuitive forms of reasoning; on the contrary, subjects who scored highest in cognitive reflection were the most likely to display ideologically motivated cognition. These findings corroborated the hypotheses of a third theory, which identifies motivated cognition as a form of information processing that rationally promotes individuals’ interests in forming and maintaining beliefs that signify their loyalty to important affinity groups. The paper discusses the normative significance of these findings, including the need to develop science communication strategies that shield policy-relevant facts from the influences that turn them into divisive symbols of identity.\n",
            "------------------------------------\n",
            "Title :  Semantic trajectories modeling and analysis\n",
            "Author/s :  C. Parent, S. Spaccapietra, C. Renso, G. Andrienko, N. Andrienko, V. Bogorny, M. Damiani, A. Gkoulalas-Divanis, J. Macêdo, N. Pelekis, Y. Theodoridis, Zhixian Yan\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Focus on movement data has increased as a consequence of the larger availability of such data due to current GPS, GSM, RFID, and sensors techniques. In parallel, interest in movement has shifted from raw movement data analysis to more application-oriented ways of analyzing segments of movement suitable for the specific purposes of the application. This trend has promoted semantically rich trajectories, rather than raw movement, as the core object of interest in mobility studies. This survey provides the definitions of the basic concepts about mobility data, an analysis of the issues in mobility data management, and a survey of the approaches and techniques for: (i) constructing trajectories from movement tracks, (ii) enriching trajectories with semantic information to enable the desired interpretations of movements, and (iii) using data mining to analyze semantic trajectories and extract knowledge about their characteristics, in particular the behavioral patterns of the moving objects. Last but not least, the article surveys the new privacy issues that arise due to the semantic aspects of trajectories.\n",
            "------------------------------------\n",
            "Title :  Digital twin-driven product design, manufacturing and service with big data\n",
            "Author/s :  F. Tao, Jiangfeng Cheng, Qinglin Qi, Meng Zhang, He Zhang, Fangyuan Sui\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  An Optimization of Allocation of Information Granularity in the Interpretation of Data Structures: Toward Granular Fuzzy Clustering\n",
            "Author/s :  W. Pedrycz, A. Bargiela\n",
            "Venue :  IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)\n",
            "year :  2012\n",
            "Abstract :  Clustering forms one of the most visible conceptual and algorithmic framework of developing information granules. In spite of the algorithm being used, the representation of information granules-clusters is predominantly numeric (coming in the form of prototypes, partition matrices, dendrograms, etc.). In this paper, we consider a concept of granular prototypes that generalizes the numeric representation of the clusters and, in this way, helps capture more details about the data structure. By invoking the granulation-degranulation scheme, we design granular prototypes being reflective of the structure of data to a higher extent than the representation that is provided by their numeric counterparts (prototypes). The design is formulated as an optimization problem, which is guided by the coverage criterion, meaning that we maximize the number of data for which their granular realization includes the original data. The granularity of the prototypes themselves is treated as an important design asset; hence, its allocation to the individual prototypes is optimized so that the coverage criterion becomes maximized. With this regard, several schemes of optimal allocation of information granularity are investigated, where interval-valued prototypes are formed around the already produced numeric representatives. Experimental studies are provided in which the design of granular prototypes of interval format is discussed and characterized.\n",
            "------------------------------------\n",
            "Title :  Social Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature\n",
            "Author/s :  Joshua A. Tucker, A. Guess, Pablo Barberá, Cristian Vaccari, A. Siegel, Sergey Sanovich, D. Stukal, B. Nyhan\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  The following report is intended to provide an overview of the current state of the literature on the relationship between social media; political polarization; and political “disinformation,” a term used to encompass a wide range of types of information about politics found online, including “fake news,” rumors, deliberately factually incorrect information, inadvertently factually incorrect information, politically slanted information, and “hyperpartisan” news. The review of the literature is provided in six separate sections, each of which can be read individually but that cumulatively are intended to provide an overview of what is known—and unknown—about the relationship between social media, political polarization, and disinformation. The report concludes by identifying key gaps in our understanding of these phenomena and the data that are needed to address them.\n",
            "------------------------------------\n",
            "Title :  A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula\n",
            "Author/s :  Robin A. A. Ince, Bruno L. Giordano, C. Kayser, G. Rousselet, J. Gross, P. Schyns\n",
            "Venue :  bioRxiv\n",
            "year :  2016\n",
            "Abstract :  We begin by reviewing the statistical framework of information theory as applicable to neuroimaging data analysis. A major factor hindering wider adoption of this framework in neuroimaging is the difficulty of estimating information theoretic quantities in practice. We present a novel estimation technique that combines the statistical theory of copulas with the closed form solution for the entropy of Gaussian variables. This results in a general, computationally efficient, flexible, and robust multivariate statistical framework that provides effect sizes on a common meaningful scale, allows for unified treatment of discrete, continuous, uni-and multi-dimensional variables, and enables direct comparisons of representations from behavioral and brain responses across any recording modality. We validate the use of this estimate as a statistical test within a neuroimaging context, considering both discrete stimulus classes and continuous stimulus features. We also present examples of analyses facilitated by these developments, including application of multivariate analyses to MEG planar magnetic field gradients, and pairwise temporal interactions in evoked EEG responses. We show the benefit of considering the instantaneous temporal derivative together with the raw values of M/EEG signals as a multivariate response, how we can separately quantify modulations of amplitude and direction for vector quantities, and how we can measure the emergence of novel information over time in evoked responses. Open-source Matlab and Python code implementing the new methods accompanies this article. Highlights Novel estimator for mutual information and other information theoretic quantities Provides general, efficient, flexible and robust multivariate statistical framework Validated statistical performance on EEG and MEG data Applications to spectral power and phase, 2D magnetic field gradients, temporal derivatives Interaction information relates information content in different responses\n",
            "------------------------------------\n",
            "Title :  Is the privacy paradox a relic of the past? An in‐depth analysis of privacy attitudes and privacy behaviors\n",
            "Author/s :  T. Dienlin, Sabine Trepte\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  The privacy paradox states that online privacy concerns do not sufficiently explain online privacy behaviors on social network sites (SNSs). In this study, it was first asked whether the privacy paradox would still exist when analyzed as in prior research. Second, it was hypothesized that the privacy paradox would disappear when analyzed in a new approach. The new approach featured a multidimensional operationalization of privacy by differentiating between informational, social, and psychological privacy. Next to privacy concerns, also, privacy attitudes and privacy intentions were analyzed. With the aim to improve methodological aspects, all items were designed on the basis of the theory of planned behavior. In an online questionnaire with N = 595 respondents, it was found that online privacy concerns were not significantly related to specific privacy behaviors, such as the frequency or content of disclosures on SNSs (e.g., name, cell-phone number, or religious views). This demonstrated that the privacy paradox still exists when it is operationalized as in prior research. With regard to the new approach, all hypotheses were confirmed: Results showed both a direct relation and an indirect relation between privacy attitudes and privacy behaviors, the latter mediated by privacy intentions. In addition, also an indirect relation between privacy concerns and privacy behaviors was found, mediated by privacy attitudes and privacy intentions. Therefore, privacy behaviors can be explained sufficiently when using privacy attitudes, privacy concerns, and privacy intentions within the theory of planned behavior. The behaviors of SNS users are not as paradoxical as was once believed. Copyright © 2014 John Wiley & Sons, Ltd.\n",
            "------------------------------------\n",
            "Title :  AIDR: artificial intelligence for disaster response\n",
            "Author/s :  Muhammad Imran, Carlos Castillo, J. Lucas, P. Meier, Sarah Vieweg\n",
            "Venue :  The Web Conference\n",
            "year :  2014\n",
            "Abstract :  We present AIDR (Artificial Intelligence for Disaster Response), a platform designed to perform automatic classification of crisis-related microblog communications. AIDR enables humans and machines to work together to apply human intelligence to large-scale data at high speed. The objective of AIDR is to classify messages that people post during disasters into a set of user-defined categories of information (e.g., \"needs\", \"damage\", etc.) For this purpose, the system continuously ingests data from Twitter, processes it (i.e., using machine learning classification techniques) and leverages human-participation (through crowdsourcing) in real-time. AIDR has been successfully tested to classify informative vs. non-informative tweets posted during the 2013 Pakistan Earthquake. Overall, we achieved a classification quality (measured using AUC) of 80%. AIDR is available at http://aidr.qcri.org/.\n",
            "------------------------------------\n",
            "Title :  Exploring the Security of Information Sharing on Social Networking Sites: The Role of Perceived Control of Information\n",
            "Author/s :  Nick Hajli, Xiaolin Lin\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Unmet adolescent and young adult cancer survivors information and service needs: a population-based cancer registry study\n",
            "Author/s :  T. Keegan, D. Lichtensztajn, I. Kato, E. Kent, Xiao-Cheng Wu, Michelle M. West, A. Hamilton, B. Zebrack, K. Bellizzi, Ashley Wilder Smith, and the Uic Experiences of Care Project Group\n",
            "Venue :  Journal of cancer survivorship\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Helpfulness of Online Consumer Reviews: Readers' Objectives and Review Cues\n",
            "Author/s :  Hyunmi Baek, Joongho Ahn, Youngseok Choi\n",
            "Venue :  International Journal of Electronic Commerce\n",
            "year :  2012\n",
            "Abstract :  With the growth of e-commerce, online consumer reviews have increasingly become important sources of information that help consumers in their purchase decisions. However, the influx of online consumer reviews has caused information overload, making it difficult for consumers to choose reliable reviews. For an online retail market to succeed, it is important to lead product reviewers to write more helpful reviews, and for consumers to get helpful reviews more easily by figuring out the factors determining the helpfulness of online reviews. For this research, 75,226 online consumer reviews were collected from Amazon.com using a Web data crawler. Additional information on review content was also gathered by carrying out a sentiment analysis for mining review text. Our results show that both peripheral cues, including review rating and reviewer's credibility, and central cues, such as the content of reviews, influence the helpfulness of reviews. Based on dual process theories, we find that consumers focus on different information sources of reviews, depending on their purposes for reading reviews: online reviews can be used for information search or for evaluating alternatives. Our findings provide new perspectives to online market owners on how to manage online reviews on their Web sites.\n",
            "------------------------------------\n",
            "Title :  Content Sharing in a Social Broadcasting Environment: Evidence from Twitter\n",
            "Author/s :  Zhan Shi, Huaxia Rui, Andrew Whinston\n",
            "Venue :  MIS Q.\n",
            "year :  2014\n",
            "Abstract :  The rise of social broadcasting technologies has greatly facilitated open access to information worldwide, not only by powering decentralized information production and consumption, but also by expediting information diffusion through social interactions like content sharing. Voluntary information sharing by users in the context of Twitter, the predominant social broadcasting site, is studied by modeling both the technology and user behavior. A detailed data set about the official content-sharing function on Twitter, called retweet, is collected and the statistical relationships between users' social network characteristics and their retweeting acts are documented. A two-stage consumption-sharing model is then estimated using the conditional maximum likelihood estimatio (MLE) method. The empirical results convincingly support our hypothesis that weak ties (in the form of unidirectional links) are more likely to engage in the social exchange process of content sharing. Specifically, we find that after a median quality tweet (as defined in the sample) is consumed, the likelihood that a unidirectional follower will retweet is 3.1 percentage point higher than the likelihood that a bidirectional follower will do so.\n",
            "------------------------------------\n",
            "Title :  Are we making a better world with ICTs? Reflections on a future agenda for the IS field\n",
            "Author/s :  G. Walsham\n",
            "Venue :  Journal of Information and Technology\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Political Incentives to Suppress Negative Information: Evidence from Chinese Listed Firms\n",
            "Author/s :  Joseph D. Piotroski, T. Wong, Tian-Yu Zhang\n",
            "Venue :  Journal of Accounting Research\n",
            "year :  2015\n",
            "Abstract :  ABSTRACT This paper tests the proposition that politicians and their affiliated firms (i.e., firms operating in their province) temporarily suppress negative information in response to political incentives. We examine the stock price behavior of Chinese listed firms around two visible political events—meetings of the National Congress of the Chinese Communist Party and promotions of high‐level provincial politicians—that are expected to asymmetrically increase the costs of releasing bad news. The costs create an incentive for local politicians and their affiliated firms to temporarily restrict the flow of negative information about the companies. The result will be fewer stock price crashes for the affiliated firms during these event windows, followed by an increase in crashes after the event. Consistent with these predictions, we find that the affiliated firms experience a reduction (an increase) in negative stock return skewness before (after) the event. These effects are strongest in the three‐month period directly preceding the event, among firms that are more politically connected, and when the province is dominated by faction politics and cronyism. Additional tests document a significant reduction in published newspaper articles about affected firms in advance of these political events, suggestive of a link between our observed stock price behavior and temporary shifts in the listed firms’ information environment.\n",
            "------------------------------------\n",
            "Title :  Mobile health 2012\n",
            "Author/s :  Maeve Duggan, Susannah Fox\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Half of smartphone owners use their devices to get health information and one-fifth of smartphone owners have health apps. The results reported here come from a nationwide survey of 3,014 adults living in the United States. Telephone interviews were conducted by landline (1,808) and cell phone (1,206, including 624 without a landline phone). The survey was conducted by Princeton Survey Research Associates International. Interviews were done in English and Spanish by Princeton Data Source from August 7 to September 6, 2012. Statistical results are weighted to correct known demographic discrepancies. The margin of sampling error for the complete set of weighted data is ±2.4 percentage points.\n",
            "------------------------------------\n",
            "Title :  Tweeting From Left to Right\n",
            "Author/s :  Pablo Barberá, J. Jost, Jonathan Nagler, Joshua A. Tucker, Richard Bonneau\n",
            "Venue :  Psychology Science\n",
            "year :  2015\n",
            "Abstract :  We estimated ideological preferences of 3.8 million Twitter users and, using a data set of nearly 150 million tweets concerning 12 political and nonpolitical issues, explored whether online communication resembles an “echo chamber” (as a result of selective exposure and ideological segregation) or a “national conversation.” We observed that information was exchanged primarily among individuals with similar ideological preferences in the case of political issues (e.g., 2012 presidential election, 2013 government shutdown) but not many other current events (e.g., 2013 Boston Marathon bombing, 2014 Super Bowl). Discussion of the Newtown shootings in 2012 reflected a dynamic process, beginning as a national conversation before transforming into a polarized exchange. With respect to both political and nonpolitical issues, liberals were more likely than conservatives to engage in cross-ideological dissemination; this is an important asymmetry with respect to the structure of communication that is consistent with psychological theory and research bearing on ideological differences in epistemic, existential, and relational motivation. Overall, we conclude that previous work may have overestimated the degree of ideological segregation in social-media usage.\n",
            "------------------------------------\n",
            "Title :  Uncertainty, scepticism and attitudes towards climate change: biased assimilation and attitude polarisation\n",
            "Author/s :  A. Corner, L. Whitmarsh, D. Xenias\n",
            "Venue :  Climatic Change\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Neural Evidence for a Distinction between Short-term Memory and the Focus of Attention\n",
            "Author/s :  J. Lewis-Peacock, A. Drysdale, K. Oberauer, B. Postle\n",
            "Venue :  Journal of Cognitive Neuroscience\n",
            "year :  2012\n",
            "Abstract :  It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.\n",
            "------------------------------------\n",
            "Title :  A meta-analysis of executive components of working memory.\n",
            "Author/s :  D. E. Nee, Joshua W. Brown, Mary K. Askren, M. Berman, E. Demiralp, A. Krawitz, J. Jonides\n",
            "Venue :  Cerebral Cortex\n",
            "year :  2013\n",
            "Abstract :  Working memory (WM) enables the online maintenance and manipulation of information and is central to intelligent cognitive functioning. Much research has investigated executive processes of WM in order to understand the operations that make WM \"work.\" However, there is yet little consensus regarding how executive processes of WM are organized. Here, we used quantitative meta-analysis to summarize data from 36 experiments that examined executive processes of WM. Experiments were categorized into 4 component functions central to WM: protecting WM from external distraction (distractor resistance), preventing irrelevant memories from intruding into WM (intrusion resistance), shifting attention within WM (shifting), and updating the contents of WM (updating). Data were also sorted by content (verbal, spatial, object). Meta-analytic results suggested that rather than dissociating into distinct functions, 2 separate frontal regions were recruited across diverse executive demands. One region was located dorsally in the caudal superior frontal sulcus and was especially sensitive to spatial content. The other was located laterally in the midlateral prefrontal cortex and showed sensitivity to nonspatial content. We propose that dorsal-\"where\"/ventral-\"what\" frameworks that have been applied to WM maintenance also apply to executive processes of WM. Hence, WM can largely be simplified to a dual selection model.\n",
            "------------------------------------\n",
            "Title :  Direct and Mediated Associations among Earnings Quality, Information Asymmetry, and the Cost of Equity\n",
            "Author/s :  Nilabhra Bhattacharya, Frank Ecker, Per Olsson, K. Schipper\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  ABSTRACT: Using path analysis, we investigate the direct and indirect links between three measures of earnings quality and the cost of equity. Our investigation is motivated by analytical models that specify both a direct link and an indirect link that is mediated by information asymmetry, but do not suggest which link would be more important empirically. We measure information asymmetry as both the adverse selection component of the bid-ask spread and the probability of informed trading (PIN). For a large sample of Value Line firms during 1993–2005, we find statistically reliable evidence of both a direct path from earnings quality to the cost of equity, and an indirect path that is mediated by information asymmetry, with the weight of the evidence favoring the direct path as the more important.\n",
            "------------------------------------\n",
            "Title :  Cyberchondria: towards a better understanding of excessive health-related Internet use\n",
            "Author/s :  V. Starcevic, D. Berle\n",
            "Venue :  Expert Review of Neurotherapeutics\n",
            "year :  2013\n",
            "Abstract :  Looking for information about symptoms and illnesses on the Internet is common and often serves useful purposes. However, a number of people who are overly distressed or anxious about their health perform excessive or repeated health-related searches on the Internet, only to become more distressed or frightened – a pattern defined here as cyberchondria. This behavior, which can also be construed as a form of reassurance seeking and occurs as a manifestation of health anxiety and hypochondriasis, is the focus of this article. The antecedents of cyberchondria, factors that maintain it and its consequences are examined conceptually and in light of the relatively little research that has been performed so far. Managing cyberchondria poses a challenge, and several approaches as part of the treatment of health anxiety and hypochondriasis are described. The article makes suggestions for further research on cyberchondria.\n",
            "------------------------------------\n",
            "Title :  What is consciousness, and could machines have it?\n",
            "Author/s :  S. Dehaene, H. Lau, S. Kouider\n",
            "Venue :  Science\n",
            "year :  2017\n",
            "Abstract :  The controversial question of whether machines may ever be conscious must be based on a careful consideration of how consciousness arises in the only physical system that undoubtedly possesses it: the human brain. We suggest that the word “consciousness” conflates two different types of information-processing computations in the brain: the selection of information for global broadcasting, thus making it flexibly available for computation and report (C1, consciousness in the first sense), and the self-monitoring of those computations, leading to a subjective sense of certainty or error (C2, consciousness in the second sense). We argue that despite their recent successes, current machines are still mostly implementing computations that reflect unconscious processing (C0) in the human brain. We review the psychological and neural science of unconscious (C0) and conscious computations (C1 and C2) and outline how they may inspire novel machine architectures.\n",
            "------------------------------------\n",
            "Title :  Work and information processing in a solvable model of Maxwell’s demon\n",
            "Author/s :  D. Mandal, C. Jarzynski\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2012\n",
            "Abstract :  We describe a minimal model of an autonomous Maxwell demon, a device that delivers work by rectifying thermal fluctuations while simultaneously writing information to a memory register. We solve exactly for the steady-state behavior of our model, and we construct its phase diagram. We find that our device can also act as a “Landauer eraser”, using externally supplied work to remove information from the memory register. By exposing an explicit, transparent mechanism of operation, our model offers a simple paradigm for investigating the thermodynamics of information processing by small systems.\n",
            "------------------------------------\n",
            "Title :  DeepStack: Expert-level artificial intelligence in heads-up no-limit poker\n",
            "Author/s :  Matej Moravcík, Martin Schmid, Neil Burch, V. Lisý, Dustin Morrill, Nolan Bard, Trevor Davis, K. Waugh, Michael Bradley Johanson, Michael H. Bowling\n",
            "Venue :  Science\n",
            "year :  2017\n",
            "Abstract :  Computer code based on continual problem re-solving beats human professional poker players at a two-player variant of poker. Artificial intelligence masters poker Computers can beat humans at games as complex as chess or go. In these and similar games, both players have access to the same information, as displayed on the board. Although computers have the ultimate poker face, it has been tricky to teach them to be good at poker, where players cannot see their opponents' cards. Moravčík et al. built a code dubbed DeepStack that managed to beat professional poker players at a two-player poker variant called heads-up no-limit Texas hold'em. Instead of devising its strategy beforehand, DeepStack recalculated it at each step, taking into account the current state of the game. The principles behind DeepStack may enable advances in solving real-world problems that involve information asymmetry. Science, this issue p. 508 Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold’em. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.\n",
            "------------------------------------\n",
            "Title :  Variational Information Distillation for Knowledge Transfer\n",
            "Author/s :  Sungsoo Ahn, S. Hu, A. Damianou, Neil D. Lawrence, Zhenwen Dai\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  Transferring knowledge from a teacher neural network pretrained on the same or a similar task to a student neural network can significantly improve the performance of the student neural network. Existing knowledge transfer approaches match the activations or the corresponding hand-crafted features of the teacher and the student networks. We propose an information-theoretic framework for knowledge transfer which formulates knowledge transfer as maximizing the mutual information between the teacher and the student networks. We compare our method with existing knowledge transfer methods on both knowledge distillation and transfer learning tasks and show that our method consistently outperforms existing methods. We further demonstrate the strength of our method on knowledge transfer across heterogeneous network architectures by transferring knowledge from a convolutional neural network (CNN) to a multi-layer perceptron (MLP) on CIFAR-10. The resulting MLP significantly outperforms the-state-of-the-art methods and it achieves similar performance to the CNN with a single convolutional layer.\n",
            "------------------------------------\n",
            "Title :  Predictive information in a sensory population\n",
            "Author/s :  S. Palmer, O. Marre, Michael J. Berry, W. Bialek\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2013\n",
            "Abstract :  Significance Prediction is an essential part of life. However, are we really “good” at making predictions? More specifically, are pieces of our brain close to being optimal predictors? To assess the efficiency of prediction, we need to measure the information that neurons carry about the future of our sensory experiences. We show how to do this, at least in simplified contexts, and find that groups of neurons in the retina indeed are close to maximally efficient at separating predictive information from the nonpredictive background. Efficient coding of predictive information is a principle that can be applied at every stage of neural computation. Guiding behavior requires the brain to make predictions about the future values of sensory inputs. Here, we show that efficient predictive computation starts at the earliest stages of the visual system. We compute how much information groups of retinal ganglion cells carry about the future state of their visual inputs and show that nearly every cell in the retina participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons that exhibit feature selectivity that would support predictive computations. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.\n",
            "------------------------------------\n",
            "Title :  Room-Temperature Quantum Bit Memory Exceeding One Second\n",
            "Author/s :  P. Maurer, G. Kucsko, C. Latta, L. Jiang, N. Yao, S. Bennett, F. Pastawski, D. Hunger, N. Chisholm, M. Markham, D. Twitchen, J. Cirac, M. Lukin\n",
            "Venue :  Science\n",
            "year :  2012\n",
            "Abstract :  Extending Quantum Memory Practical applications in quantum communication and quantum computation require the building blocks—quantum bits and quantum memory—to be sufficiently robust and long-lived to allow for manipulation and storage (see the Perspective by Boehme and McCarney). Steger et al. (p. 1280) demonstrate that the nuclear spins of 31P impurities in an almost isotopically pure sample of 28Si can have a coherence time of as long as 192 seconds at a temperature of ∼1.7 K. In diamond at room temperature, Maurer et al. (p. 1283) show that a spin-based qubit system comprised of an isotopic impurity (13C) in the vicinity of a color defect (a nitrogen-vacancy center) could be manipulated to have a coherence time exceeding one second. Such lifetimes promise to make spin-based architectures feasible building blocks for quantum information science. Defects in diamond can be operated as quantum memories at room temperature. Stable quantum bits, capable both of storing quantum information for macroscopic time scales and of integration inside small portable devices, are an essential building block for an array of potential applications. We demonstrate high-fidelity control of a solid-state qubit, which preserves its polarization for several minutes and features coherence lifetimes exceeding 1 second at room temperature. The qubit consists of a single 13C nuclear spin in the vicinity of a nitrogen-vacancy color center within an isotopically purified diamond crystal. The long qubit memory time was achieved via a technique involving dissipative decoupling of the single nuclear spin from its local environment. The versatility, robustness, and potential scalability of this system may allow for new applications in quantum information science.\n",
            "------------------------------------\n",
            "Title :  The thermodynamics of prediction\n",
            "Author/s :  S. Still, David A. Sivak, A. J. Bell, G. Crooks\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  A system responding to a stochastic driving signal can be interpreted as computing, by means of its dynamics, an implicit model of the environmental variables. The system's state retains information about past environmental fluctuations, and a fraction of this information is predictive of future ones. The remaining nonpredictive information reflects model complexity that does not improve predictive power, and thus represents the ineffectiveness of the model. We expose the fundamental equivalence between this model inefficiency and thermodynamic inefficiency, measured by dissipation. Our results hold arbitrarily far from thermodynamic equilibrium and are applicable to a wide range of systems, including biomolecular machines. They highlight a profound connection between the effective use of information and efficient thermodynamic operation: any system constructed to keep memory about its environment and to operate with maximal energetic efficiency has to be predictive.\n",
            "------------------------------------\n",
            "Title :  The Rise of the Network Society - The Information Age: Economy, Society, and Culture\n",
            "Author/s :  Taner Kizilhan, Sevil Bal Kızılhan\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Castell’s book is the first part of his milstone “The Information Age: Economy Society, and Culture” work. The author states that, the triology was prepared to be a single book, but then with the contributions of the editor, it was divided into three books by making each part of the study a separate book. In this particular book, Castells presents an easily understandable and comprehensive analysis by examining the economic, social, and cultural changes that caused by the Network Society. He does this by being as realistic as possible and reaching a clear conclusion by supporting all of his claims with various statistics and examples.\n",
            "------------------------------------\n",
            "Title :  Mobile devices in medicine: a survey of how medical students, residents, and faculty use smartphones and other mobile devices to find information.\n",
            "Author/s :  J. Boruff, D. Storie\n",
            "Venue :  Journal of the Medical Library Association\n",
            "year :  2014\n",
            "Abstract :  OBJECTIVES\n",
            "The research investigated the extent to which students, residents, and faculty members in Canadian medical faculties use mobile devices, such as smartphones (e.g., iPhone, Android, Blackberry) and tablet computers (e.g., iPad), to answer clinical questions and find medical information. The results of this study will inform how health libraries can effectively support mobile technology and collections.\n",
            "\n",
            "\n",
            "METHODS\n",
            "An electronic survey was distributed by medical librarians at four Canadian universities to medical students, residents, and faculty members via departmental email discussion lists, personal contacts, and relevant websites. It investigated the types of information sought, facilitators to mobile device use in medical information seeking, barriers to access, support needs, familiarity with institutionally licensed resources, and most frequently used resources.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The survey of 1,210 respondents indicated widespread use of smartphones and tablets in clinical settings in 4 Canadian universities. Third- and fourth-year undergraduate students (i.e., those in their clinical clerkships) and medical residents, compared to other graduate students and faculty, used their mobile devices more often, used them for a broader range of activities, and purchased more resources for their devices.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Technological and intellectual barriers do not seem to prevent medical trainees and faculty from regularly using mobile devices for their medical information searches; however, barriers to access and lack of awareness might keep them from using reliable, library-licensed resources.\n",
            "\n",
            "\n",
            "IMPLICATIONS\n",
            "Libraries should focus on providing access to a smaller number of highly used mobile resources instead of a huge collection until library-licensed mobile resources have streamlined authentication processes.\n",
            "------------------------------------\n",
            "Title :  Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University From RSSI to CSI: Indoor localization via channel response From RSSI to CSI: Indoor localization via channel response\n",
            "Author/s :  Zhengju Yang, Zimu\n",
            "Venue :  \n",
            "year :  2020\n",
            "Abstract :  The spatial features of emitted wireless signals are the basis of location distinction and determination for wireless indoor localization. Available in mainstream wireless signal measurements, the Received Signal Strength Indicator (RSSI) has been adopted in vast indoor localization systems. However, it suffers from dramatic performance degradation in complex situations due to multipath fading and temporal dynamics. Break-through techniques resort to ﬁner-grained wireless channel measurement than RSSI. Different from RSSI, the PHY layer power feature, channel response, is able to discriminate multipath characteristics, and thus holds the potential for the convergence of accurate and pervasive indoor localization. Channel State Information (CSI, reﬂecting channel response in 802.11 a/g/n) has attracted many research efforts and some pioneer works have demonstrated submeter or even centimeter-level accuracy. In this article, we survey this new trend of channel response in localization. The differences between CSI and RSSI are highlighted with respect to network layering, time resolution, frequency resolution, stability, and accessibility. Furthermore, we investigate a large body of recent works and classify them overall into three categories according to how to use CSI. For each category, we emphasize the basic principles and address future directions of research in this new and largely open area.\n",
            "------------------------------------\n",
            "Title :  Flooding Facebook - the use of social media during the Queensland and Victorian floods\n",
            "Author/s :  Deanne Bird, Megan Ling, K. Haynes\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Community-initiated Facebook groups emerged during the 2010/11 Queensland and Victorian floods, gaining a near instant following from local residents within, and family and friends beyond, the impacted areas. Administrators of the groups sourced their data from agencies such as the Bureau of Meteorology, State Emergency Service, Queensland and Victorian Police Departments, local councils and news media. Even more importantly, administrators published near-real time information from the general public: Facebook members posted information and questions; local residents asked for and received help and advice; and, travellers driving through the area posted and received up-to-date information on road closures and flooding. During the floods in Queensland and Victoria, Risk Frontiers used Facebook to distribute a survey to members of community groups such as CQ Flood Update-version 2 and Victorian Floods. The results indicate that most respondents began using the community groups on the floods to get information about their community and almost all found the medium useful and an effective means of communicating with family or friends. In this paper, we discuss the results of this survey and consider the value of social media to the emergency services, not only as a tool to disseminate information but also as an important resource to tap into and review informal communications, something that was previously inaccessible.\n",
            "------------------------------------\n",
            "Title :  Toward a synthesis of cognitive biases: how noisy information processing can bias human decision making.\n",
            "Author/s :  M. Hilbert\n",
            "Venue :  Psychological bulletin\n",
            "year :  2012\n",
            "Abstract :  A single coherent framework is proposed to synthesize long-standing research on 8 seemingly unrelated cognitive decision-making biases. During the past 6 decades, hundreds of empirical studies have resulted in a variety of rules of thumb that specify how humans systematically deviate from what is normatively expected from their decisions. Several complementary generative mechanisms have been proposed to explain those cognitive biases. Here it is suggested that (at least) 8 of these empirically detected decision-making biases can be produced by simply assuming noisy deviations in the memory-based information processes that convert objective evidence (observations) into subjective estimates (decisions). An integrative framework is presented to show how similar noise-based mechanisms can lead to conservatism, the Bayesian likelihood bias, illusory correlations, biased self-other placement, subadditivity, exaggerated expectation, the confidence bias, and the hard-easy effect. Analytical tools from information theory are used to explore the nature and limitations that characterize such information processes for binary and multiary decision-making exercises. The ensuing synthesis offers formal mathematical definitions of the biases and their underlying generative mechanism, which permits a consolidated analysis of how they are related. This synthesis contributes to the larger goal of creating a coherent picture that explains the relations among the myriad of seemingly unrelated biases and their potential psychological generative mechanisms. Limitations and research questions are discussed.\n",
            "------------------------------------\n",
            "Title :  Political News in the News Feed: Learning Politics from Social Media\n",
            "Author/s :  L. Bode\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Although literature about the relationship between social media and political behaviors has expanded in recent years, little is known about the roles of social media as a source of political information. To fill this gap, this article considers the question of whether and to what extent learning political information occurs via Facebook and Twitter. Theory suggests that social media may play a significant role in the learning of political information within the modern media environment. Making use of a combination of experimental and survey-based studies, the data suggest that the potential for users to learn political information from social media exists but is not always realized within the general population.\n",
            "------------------------------------\n",
            "Title :  Spectre Attacks: Exploiting Speculative Execution\n",
            "Author/s :  P. Kocher, Daniel Genkin, D. Gruss, Werner Haas, Michael Hamburg, Moritz Lipp, S. Mangard, Thomas Prescher, Michael Schwarz, Y. Yarom\n",
            "Venue :  IEEE Symposium on Security and Privacy\n",
            "year :  2018\n",
            "Abstract :  Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.\n",
            "------------------------------------\n",
            "Title :  A survey of context data distribution for mobile ubiquitous systems\n",
            "Author/s :  P. Bellavista, Antonio Corradi, M. Fanelli, L. Foschini\n",
            "Venue :  CSUR\n",
            "year :  2012\n",
            "Abstract :  The capacity to gather and timely deliver to the service level any relevant information that can characterize the service-provisioning environment, such as computing resources/capabilities, physical device location, user preferences, and time constraints, usually defined as context-awareness, is widely recognized as a core function for the development of modern ubiquitous and mobile systems. Much work has been done to enable context-awareness and to ease the diffusion of context-aware services; at the same time, several middleware solutions have been designed to transparently implement context management and provisioning in the mobile system. However, to the best of our knowledge, an in-depth analysis of the context data distribution, namely, the function in charge of distributing context data to interested entities, is still missing. Starting from the core assumption that only effective and efficient context data distribution can pave the way to the deployment of truly context-aware services, this article aims at putting together current research efforts to derive an original and holistic view of the existing literature. We present a unified architectural model and a new taxonomy for context data distribution by considering and comparing a large number of solutions. Finally, based on our analysis, we draw some of the research challenges still unsolved and identify some possible directions for future work.\n",
            "------------------------------------\n",
            "Title :  Everything you wanted to know about smart cities: The Internet of things is the backbone\n",
            "Author/s :  S. Mohanty\n",
            "Venue :  IEEE Consumer Electronics Magazine\n",
            "year :  2016\n",
            "Abstract :  This article is a single-source introduction to the emerging concept of smart cities. It can be used for familiarizing researchers with the vast scope of research possible in this application domain. The smart city is primarily a concept, and there is still not a clear and consistent definition among practitioners and academia. As a simplistic explanation, a smart city is a place where traditional networks and services are made more flexible, efficient, and sustainable with the use of information, digital, and telecommunication technologies to improve the city's operations for the benefit of its inhabitants. Smart cities are greener, safer, faster, and friendlier. The different components of a smart city include smart infrastructure, smart transportation, smart energy, smart health care, and smart technology. These components are what make the cities smart and efficient. Information and communication technology (ICT) are enabling keys for transforming traditional cities into smart cities. Two closely related emerging technology frameworks, the Internet of Things (IoT) and big data (BD), make smart cities efficient and responsive. The technology has matured enough to allow smart cities to emerge. However, there is much needed in terms of physical infrastructure, a smart city, the digital technologies translate into better public services for inhabitants and better use of resources while reducing environmental impacts. One of the formal definitions of the smart city is the following: a city \"connecting the physical infrastructure, the information-technology infrastructure, the social infrastructure, and the business infrastructure to leverage the collective intelligence of the city\". Another formal and comprehensive definition is \"a smart sustainable city is an innovative city that uses information and communication technologies (ICTs) and other means to improve quality of life, efficiency of urban operations and services, and competitiveness, while ensuring that it meets the needs of present and future generations with respect to economic, social and environmental aspects\". Any combination of various smart components can make cities smart. A city need not have all the components to be labeled as smart. The number of smart components depends on the cost and available technology.\n",
            "------------------------------------\n",
            "Title :  The Impact of Relative Standards on the Propensity to Disclose\n",
            "Author/s :  A. Acquisti, L. John, G. Loewenstein\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Two sets of studies illustrate the comparative nature of disclosure behavior. The first set investigates how divulgence is affected by signals about others' readiness to divulge and shows a “herding” effect: Survey respondents are more willing to divulge sensitive information when told that previous respondents have made sensitive disclosures (Study 1a). The authors provide evidence of the process underlying this effect and rule out alternative explanations by showing that information on others' propensity to disclose affects respondents' discomfort associated with divulgence (Study 1b) but not their interpretation of the questions (Study 1c). The second set of studies investigates how divulgence is affected by the order in which inquiries of varying intrusiveness are made and suggests that divulgence is anchored by the initial questions in a survey. People are particularly likely to divulge when questions are presented in decreasing order of intrusiveness and less likely when questions are presented in increasing order (Study 2a). The authors show that the effect arises by affecting people's judgments of the intrusiveness of the inquiries (Study 2b). The effect is altered when, at the outset of the study, privacy concerns are primed (Study 2c) and when respondents are made to consider the relative intrusiveness of a different set of questions (Study 2d). This research helps illuminate how consumers' propensity to disclose is affected by continual streams of requests for personal information and by the equally unavoidable barrage of personal information about others.\n",
            "------------------------------------\n",
            "Title :  Empirical Studies in Information Visualization: Seven Scenarios\n",
            "Author/s :  Heidi Lam, E. Bertini, P. Isenberg, C. Plaisant, M. Carpendale\n",
            "Venue :  IEEE Transactions on Visualization and Computer Graphics\n",
            "year :  2012\n",
            "Abstract :  We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.\n",
            "------------------------------------\n",
            "Title :  CSI-Based Indoor Localization\n",
            "Author/s :  Kaishun Wu, Jiang Xiao, Youwen Yi, Dihu Chen, Xiaonan Luo, L. Ni\n",
            "Venue :  IEEE Transactions on Parallel and Distributed Systems\n",
            "year :  2013\n",
            "Abstract :  Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in orthogonal frequency division multiplexing systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to build a propagation model and a fingerprinting system at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.\n",
            "------------------------------------\n",
            "Title :  Motivations for sharing information and social support in social media: A comparative analysis of Facebook, Twitter, Delicious, YouTube, and Flickr\n",
            "Author/s :  Sanghee Oh, Sue Yeon Syn\n",
            "Venue :  J. Assoc. Inf. Sci. Technol.\n",
            "year :  2015\n",
            "Abstract :  The success or failure of social media is highly dependent on the active participation of its users. In order to examine the influential factors that inspire dynamic and eager participation, this study investigates what motivates social media users to share their personal experiences, information, and social support with anonymous others. A variety of information‐sharing activities in social media, including creating postings, photos, and videos in 5 different types of social media: Facebook, Twitter, Delicious, YouTube, and Flickr, were observed. Ten factors: enjoyment, self‐efficacy, learning, personal gain, altruism, empathy, social engagement, community interest, reciprocity, and reputation, were tested to identify the motivations of social media users based on reviews of major motivation theories and models. Findings from this study indicate that all of the 10 motivations are influential in encouraging users' information sharing to some degree and strongly correlate with one another. At the same time, motivations differ across the 5 types of social media, given that they deliver different information content and serve different purposes. Understanding such differences in motivations could benefit social media developers and those organizations or institutes that would like to use social media to facilitate communication among their community members; appropriate types of social media could be chosen that would fit their own purposes and they could develop strategies that would encourage their members to contribute to their communities through social media.\n",
            "------------------------------------\n",
            "Title :  Mining big data: current status, and forecast to the future\n",
            "Author/s :  Wei Fan, A. Bifet\n",
            "Venue :  SKDD\n",
            "year :  2013\n",
            "Abstract :  Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.\n",
            "------------------------------------\n",
            "Title :  Guide to health informatics\n",
            "Author/s :  E. Coiera\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Basic Concepts in Informatics Models Information Information Systems Informatics Skills Communicating Structuring Questioning Searching Making Decisions Information Systems in Healthcare Information Management Systems The Electronic Health Record Designing and Evaluating Information and Communication Systems Implementation Information System Safety Information Economics Guideline- and Protocol-Based Systems Guidelines, Protocols and Evidence-Based Healthcare Computer-Based Protocol Systems Designing, Disseminating and Applying protocols Communication Systems in Healthcare Communication Systems Basics Interlude-the Internet and the World Wide Web Information and Communication Networks Social Networks and Social Media Interventions Telehealth and Mobile Health Language, Coding and Classification Terms, Codes and Classification Healthcare Terminologies and Classification Systems Natural Language and Formal Terminology Clinical Decision Support and Analytics Clinical Decision Support Systems Interlude-Artificial Intelligence in Medicine Computational Reasoning Methods Model Building for Decision Support, Data Analysis and Scientific Discovery Specialized Applications for Health Informatics Patient Monitoring and Control Population Surveillance and Public Health Informatics Bioinformatics Clinical Bioinformatics and Personalized Medicine Consumer Health Informatics Glossary References\n",
            "------------------------------------\n",
            "Title :  Searching for superspreaders of information in real-world social media\n",
            "Author/s :  S. Pei, Lev Muchnik, J. S. Andrade, Zhiming Zheng, H. Makse\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The role of collaboration in supply chain resilience\n",
            "Author/s :  K. Scholten, Sanne Schilder\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            "– This paper aims to explore how collaboration influences supply chain resilience. Collaborative activities and their underlying mechanisms in relation to visibility, velocity and flexibility are investigated. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            "– An exploratory case study consisting of eight buyer–supplier relationships in the food processing industry was conducted. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            "– Key findings show how specific collaborative activities (information-sharing, collaborative communication, mutually created knowledge and joint relationship efforts) increase supply chain resilience via increased visibility, velocity and flexibility. Underlying mechanisms and interdependencies of these factors within the supply chain network are identified. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            "– This is one of the first papers to provide in-depth insights into collaboration as a formative element of resilience in a supply chain setting. A series of propositions explain the specific influence of collaborative activities on supply chain resilience beyond a single company perspective.\n",
            "------------------------------------\n",
            "Title :  Multi-View Intact Space Learning\n",
            "Author/s :  Chang Xu, D. Tao, Chao Xu\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2015\n",
            "Abstract :  It is practical to assume that an individual view is unlikely to be sufficient for effective multi-view learning. Therefore, integration of multi-view information is both valuable and necessary. In this paper, we propose the Multi-view Intact Space Learning (MISL) algorithm, which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data. Even though each view on its own is insufficient, we show theoretically that by combing multiple views we can obtain abundant information for latent intact space learning. Employing the Cauchy loss (a technique used in statistical learning) as the error measurement strengthens robustness to outliers. We propose a new definition of multi-view stability and then derive the generalization error bound based on multi-view stability and Rademacher complexity, and show that the complementarity between multiple views is beneficial for the stability and generalization. MISL is efficiently optimized using a novel Iteratively Reweight Residuals (IRR) technique, whose convergence is theoretically analyzed. Experiments on synthetic data and real-world datasets demonstrate that MISL is an effective and promising algorithm for practical applications.\n",
            "------------------------------------\n",
            "Title :  Image Quality Assessment Based on Gradient Similarity\n",
            "Author/s :  Anmin Liu, Weisi Lin, Manish Narwaria\n",
            "Venue :  IEEE Transactions on Image Processing\n",
            "year :  2012\n",
            "Abstract :  In this paper, we propose a new image quality assessment (IQA) scheme, with emphasis on gradient similarity. Gradients convey important visual information and are crucial to scene understanding. Using such information, structural and contrast changes can be effectively captured. Therefore, we use the gradient similarity to measure the change in contrast and structure in images. Apart from the structural/contrast changes, image quality is also affected by luminance changes, which must be also accounted for complete and more robust IQA. Hence, the proposed scheme considers both luminance and contrast-structural changes to effectively assess image quality. Furthermore, the proposed scheme is designed to follow the masking effect and visibility threshold more closely, i.e., the case when both masked and masking signals are small is more effectively tackled by the proposed scheme. Finally, the effects of the changes in luminance and contrast-structure are integrated via an adaptive method to obtain the overall image quality score. Extensive experiments conducted with six publicly available subject-rated databases (comprising of diverse images and distortion types) have confirmed the effectiveness, robustness, and efficiency of the proposed scheme in comparison with the relevant state-of-the-art schemes.\n",
            "------------------------------------\n",
            "Title :  Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\n",
            "Author/s :  Zuxuan Wu, Xi Wang, Yu-Gang Jiang, Hao Ye, X. Xue\n",
            "Venue :  ACM Multimedia\n",
            "year :  2015\n",
            "Abstract :  Classifying videos according to content semantics is an important problem with a wide range of applications. In this paper, we propose a hybrid deep learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos. Specifically, the spatial and the short-term motion features are extracted separately by two Convolutional Neural Networks (CNN). These two types of CNN-based features are then combined in a regularized feature fusion network for classification, which is able to learn and utilize feature relationships for improved performance. In addition, Long Short Term Memory (LSTM) networks are applied on top of the two features to further model longer-term temporal clues. The main contribution of this work is the hybrid learning framework that can model several important aspects of the video data. We also show that (1) combining the spatial and the short-term motion features in the regularized fusion network is better than direct classification and fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is highly complementary to the traditional classification strategy without considering the temporal frame orders. Extensive experiments are conducted on two popular and challenging benchmarks, the UCF-101 Human Actions and the Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves very competitive performance: 91.3% on the UCF-101 and 83.5% on the CCV.\n",
            "------------------------------------\n",
            "Title :  PROV-DM: The PROV Data Model\n",
            "Author/s :  Khalid Belhajjame, Reza B'Far, J. Cheney, Sam Coppens, S. Cresswell, Y. Gil, Paul Groth, G. Klyne, Timothy Lebo, Jamie McCusker, S. Miles, J. Myers, S. Sahoo, C. Tilmes\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness. PROV-DM is the conceptual data model that forms a basis for the W3C provenance (PROV) family of specifications. PROV-DM distinguishes core structures, forming the essence of provenance information, from extended structures catering for more specific uses of provenance. PROV-DM is organized in six components, respectively dealing with: (1) entities and activities, and the time at which they were created, used, or ended; (2) derivations of entities from entities; (3) agents bearing responsibility for entities that were generated and activities that happened; (4) a notion of bundle, a mechanism to support provenance of provenance; (5) properties to link entities that refer to the same thing; and, (6) collections forming a logical structure for its members. This document introduces the provenance concepts found in PROV and defines PROV-DM types and relations. The PROV data model is domain-agnostic, but is equipped with extensibility points allowing domain-specific information to be included. Two further documents complete the specification of PROV-DM. First, a companion document specifies the set of constraints that provenance should follow. Second, a separate document describes a provenance notation for expressing instances of provenance for human consumption; this notation is used in examples in this document.\n",
            "------------------------------------\n",
            "Title :  A Longitudinal Study of Herd Behavior in the Adoption and Continued Use of Technology\n",
            "Author/s :  Heshan Sun\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Herd literature suggests that people tend to discount their own beliefs and imitate others when making adoption decisions and that the resulting adoption decisions are fragile and can be easily reversed during the post-adoptive stage. This helps explain why the adoption of a number of new technologies--from Amazon's Kindle, to Apple's iPod, iPhone, and iPad, to various types of Web 2.0 technologies--appears to have adoption patterns similar to those of new fashion trends (i. e., an initial en masse acquisition followed by subsequent abandonment). It is important to understand these phenomena because they are strongly related to the staying power of technology. From a herd behavior perspective, this study proposes two new concepts, namely discounting one's own information and imitating others, to describe herd behavior in technology adoption. A research model is developed to describe the conditions under which herd behavior in technology adoption occurs, how it impacts technology adoption decision making, and how it influences post-adoptive system use. A longitudinal study is conducted to examine the research model. Findings from this research suggest that the discounting of one's own beliefs and the imitating of others when adopting a new technology are provoked primarily by the observation of prior adoptions and perceptions of uncertainty regarding the adoption of new technology. Herd behavior has a significant influence on user technology adoption; however, it does not necessarily lead to the collapse of the user base, as predicted in the herd literature. Instead, imitation can help reduce post-adoption regret and thus serve as a legitimate strategy for choosing a good enough technology, which may or may not be the best option to enhance job performance. People tend to adjust their beliefs when herding and also to revive their discounted initial beliefs to modify their beliefs about the technology at the post-adoptive stage. Findings from this study have significant research and practical implications.\n",
            "------------------------------------\n",
            "Title :  Systematic Review of Factors Influencing the Adoption of Information and Communication Technologies by Healthcare Professionals\n",
            "Author/s :  M. Gagnon, M. Desmartis, M. Labrecque, J. Car, C. Pagliari, P. Pluye, P. Frémont, J. Gagnon, Nadine Tremblay, F. Légaré\n",
            "Venue :  Journal of medical systems\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Data Resource Profile: The Korea National Health and Nutrition Examination Survey (KNHANES)\n",
            "Author/s :  Sanghui Kweon, Yuna Kim, Myoung-jin Jang, Yoonjung Kim, Kirang Kim, Sunhye Choi, Chaemin Chun, Y. Khang, Kyungwon Oh\n",
            "Venue :  International Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  The Korea National Health and Nutrition Examination Survey (KNHANES) is a national surveillance system that has been assessing the health and nutritional status of Koreans since 1998. Based on the National Health Promotion Act, the surveys have been conducted by the Korea Centers for Disease Control and Prevention (KCDC). This nationally representative cross-sectional survey includes approximately 10 000 individuals each year as a survey sample and collects information on socioeconomic status, health-related behaviours, quality of life, healthcare utilization, anthropometric measures, biochemical and clinical profiles for non-communicable diseases and dietary intakes with three component surveys: health interview, health examination and nutrition survey. The health interview and health examination are conducted by trained staff members, including physicians, medical technicians and health interviewers, at a mobile examination centre, and dieticians’ visits to the homes of the study participants are followed up. KNHANES provides statistics for health-related policies in Korea, which also serve as the research infrastructure for studies on risk factors and diseases by supporting over 500 publications. KCDC has also supported researchers in Korea by providing annual workshops for data users. KCDC has published the Korea Health Statistics each year, and microdata are publicly available through the KNHANES website (http://knhanes.cdc.go.kr).\n",
            "------------------------------------\n",
            "Title :  The Impact of IT Capabilities on Firm Performance: The Mediating Roles of Absorptive Capacity and Supply Chain Agility\n",
            "Author/s :  Hefu Liu, Weiling Ke, K. Wei, Zhongsheng Hua\n",
            "Venue :  Decision Support Systems\n",
            "year :  2013\n",
            "Abstract :  Researchers and practitioners regard information technology (IT) as a competitive tool. However, current knowledge on IT capability mechanisms that affect firm performance remains unclear. Based on the dynamic capabilities perspective and the view of a hierarchy of capabilities, this article proposes a model to examine how IT capabilities (i.e., flexible IT infrastructure and IT assimilation) affect firm performance through absorptive capacity and supply chain agility in the supply chain context. Survey data show that absorptive capacity and supply chain agility fully mediate the influences of IT capabilities on firm performance. In addition to the direct effects, absorptive capacity also has indirect effects on firm performance by shaping supply chain agility. We conclude with implications and suggestions for future research.\n",
            "------------------------------------\n",
            "Title :  Context dependent recurrent neural network language model\n",
            "Author/s :  Tomas Mikolov, G. Zweig\n",
            "Venue :  Spoken Language Technology Workshop\n",
            "year :  2012\n",
            "Abstract :  Recurrent neural network language models (RNNLMs) have recently demonstrated state-of-the-art performance across a variety of tasks. In this paper, we improve their performance by providing a contextual real-valued input vector in association with each word. This vector is used to convey contextual information about the sentence being modeled. By performing Latent Dirichlet Allocation using a block of preceding text, we achieve a topic-conditioned RNNLM. This approach has the key advantage of avoiding the data fragmentation associated with building multiple topic models on different data subsets. We report perplexity results on the Penn Treebank data, where we achieve a new state-of-the-art. We further apply the model to the Wall Street Journal speech recognition task, where we observe improvements in word-error-rate.\n",
            "------------------------------------\n",
            "Title :  Hidden factors and hidden topics: understanding rating dimensions with review text\n",
            "Author/s :  Julian McAuley, J. Leskovec\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2013\n",
            "Abstract :  In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.\n",
            "------------------------------------\n",
            "Title :  Multicriteria decision-making method using the correlation coefficient under single-valued neutrosophic environment\n",
            "Author/s :  Jun Ye\n",
            "Venue :  International Journal of General Systems\n",
            "year :  2013\n",
            "Abstract :  The paper presents the correlation and correlation coefficient of single-valued neutrosophic sets (SVNSs) based on the extension of the correlation of intuitionistic fuzzy sets and demonstrates that the cosine similarity measure is a special case of the correlation coefficient in SVNS. Then a decision-making method is proposed by the use of the weighted correlation coefficient or the weighted cosine similarity measure of SVNSs, in which the evaluation information for alternatives with respect to criteria is carried out by truth-membership degree, indeterminacy-membership degree, and falsity-membership degree under single-valued neutrosophic environment. We utilize the weighted correlation coefficient or the weighted cosine similarity measure between each alternative and the ideal alternative to rank the alternatives and to determine the best one(s). Finally, an illustrative example demonstrates the application of the proposed decision-making method.\n",
            "------------------------------------\n",
            "Title :  Institutions and Information Environment of Chinese Listed Firms\n",
            "Author/s :  Joseph D. Piotroski, T. Wong\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This paper describes the financial reporting practices and information environment of Chinese listed firms and documents the influence that local and country-level institutions have on reporting incentives and the resultant information environment. We identify four key institutional arrangements that influence the supply and demand for information about Chinese listed firms: the State’s controlling ownership of listed firms, the government’s control of capital markets, the limited protection of property rights and weak market institutions, a lack of independence of local auditors, and the importance of social networks and political connections. The paper concludes by discussing how actual and potential changes in these institutional arrangements would likely influence China’s information environment.\n",
            "------------------------------------\n",
            "Title :  Smart Refugees: How Syrian Asylum Migrants Use Social Media Information in Migration Decision-Making\n",
            "Author/s :  R. Dekker, G. Engbersen, Jeanine Klaver, Hanna Vonk\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Social media are increasingly popular channels of information on which migrants base their decisions on whether to migrate and the destinations where to settle. While social media offer a relatively cheap, easily accessible, and media-rich means of communication, their use is not without challenges for asylum migrants. Various studies describe issues with access and evaluation of the truthfulness of available information for this specific group of migrants. This article discusses social media use by asylum migrants prior to and during migration. This study is based on in-depth interviews with 54 Syrian asylum migrants who recently obtained refugee status in the Netherlands. Syrians were the largest group of migrants applying for asylum in European Union (EU) member states in 2015 and 2016. The findings show that the majority of Syrian asylum migrants have access to social media information before and during migration, often through the use of smartphones. Besides uneven access to technologies, fear of government surveillance restricts the smartphone use of asylum migrants. The results of this study indicate that Syrian asylum migrants prefer social media information that originates from existing social ties and information that is based on personal experiences. Generally, this information is considered more trustworthy. Asylum migrants use various strategies to validate rumors that are present on social media and come from unknown sources. These strategies include checking the source of information, validating information with trusted social ties, triangulation of online sources, and comparing information with their own experience.\n",
            "------------------------------------\n",
            "Title :  Misleading Health-Related Information Promoted Through Video-Based Social Media: Anorexia on YouTube\n",
            "Author/s :  S. Syed-Abdul, L. Fernández-Luque, W. Jian, Yu-chuan Li, S. Crain, M. Hsu, Yao-Chin Wang, Dorjsuren Khandregzen, E. Chuluunbaatar, P. Nguyen, Der-Ming Liou\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Introduction The amount of information being uploaded onto social video platforms, such as YouTube, Vimeo, and Veoh, continues to spiral, making it increasingly difficult to discern reliable health information from misleading content. There are thousands of YouTube videos promoting misleading information about anorexia (eg, anorexia as a healthy lifestyle). Objective The aim of this study was to investigate anorexia-related misinformation disseminated through YouTube videos. Methods We retrieved YouTube videos related to anorexia using the keywords anorexia, anorexia nervosa, proana, and thinspo on October 10, 2011.Three doctors reviewed 140 videos with approximately 11 hours of video content, classifying them as informative, pro-anorexia, or others. By informative we mean content describing the health consequences of anorexia and advice on how to recover from it; by pro-anorexia we mean videos promoting anorexia as a fashion, a source of beauty, and that share tips and methods for becoming and remaining anorexic. The 40 most-viewed videos (20 informative and 20 pro-anorexia videos) were assessed to gauge viewer behavior. Results The interrater agreement of classification was moderate (Fleiss’ kappa=0.5), with 29.3% (n=41) being rated as pro-anorexia, 55.7% (n=78) as informative, and 15.0% (n=21) as others. Pro-anorexia videos were favored 3 times more than informative videos (odds ratio [OR] 3.3, 95% CI 3.3-3.4, P<.001). Conclusions Pro-anorexia information was identified in 29.3% of anorexia-related videos. Pro-anorexia videos are less common than informative videos; however, in proportional terms, pro-anorexia content is more highly favored and rated by its viewers. Efforts should focus on raising awareness, particularly among teenagers, about the trustworthiness of online information about beauty and healthy lifestyles. Health authorities producing videos to combat anorexia should consider involving celebrities and models to reach a wider audience. More research is needed to study the characteristics of pro-anorexia videos in order to develop algorithms that will automatically detect and filter those videos before they become popular.\n",
            "------------------------------------\n",
            "Title :  Accessibility of Cities in the Digital Economy\n",
            "Author/s :  E. Tranos, A. Reggiani, P. Nijkamp\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This paper introduces a new measure to approach the accessibility of places in the frame of the digital economy. Information and Communication Technologies (ICTs) and the Internet are not equally spread around places and this heterogeneity affects spatial configuration. Despite the wide societal changes due to ICTs and the extensive interest in accessibility studies, these two themes have not yet come together in order to study the digital accessibility (DA) of places. Adopting an infrastructural perspective and a potential accessibility framework, a DA measure – embedding different types of impedance distance functions – is calculated for cities in Europe. Spatial Interaction Model and Complex Network Analysis are employed to calibrate and validate the DA results. The outcome of this approach is a new urban hierarchy which reveals a core-periphery pattern in Europe owing to digital accessibility.\n",
            "------------------------------------\n",
            "Title :  Social Networks and the Diffusion of User-Generated Content: Evidence from YouTube\n",
            "Author/s :  Anjana Susarla, Jeong-ha Oh, Yong Tan\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This paper is motivated by the success of YouTube, which is attractive to content creators as well as corporations for its potential to rapidly disseminate digital content. The networked structure of interactions on YouTube and the tremendous variation in the success of videos posted online lends itself to an inquiry of the role of social influence. Using a unique data set of video information and user information collected from YouTube, we find that social interactions are influential not only in determining which videos become successful but also on the magnitude of that impact. We also find evidence for a number of mechanisms by which social influence is transmitted, such as (i) a preference for conformity and homophily and (ii) the role of social networks in guiding opinion formation and directing product search and discovery. Econometrically, the problem in identifying social influence is that individuals' choices depend in great part upon the choices of other individuals, referred to as the reflection problem. Another problem in identification is to distinguish between social contagion and user heterogeneity in the diffusion process. Our results are in sharp contrast to earlier models of diffusion, such as the Bass model, that do not distinguish between different social processes that are responsible for the process of diffusion. Our results are robust to potential self-selection according to user tastes, temporal heterogeneity and the reflection problem. Implications for researchers and managers are discussed.\n",
            "------------------------------------\n",
            "Title :  OCNet: Object Context Network for Scene Parsing\n",
            "Author/s :  Yuhui Yuan, Jingdong Wang\n",
            "Venue :  ArXiv\n",
            "year :  2018\n",
            "Abstract :  In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. \n",
            "We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. \n",
            "To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff\n",
            "------------------------------------\n",
            "Title :  Socio-Economic Impact of Mobile Phones on Indian Agriculture\n",
            "Author/s :  Surabhi Mittal, S. Gandhi, G. Tripathi\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Deficits in physical infrastructure, problems with availability of agricultural inputs and poor access to agriculture-related information are the major constraints on the growth of agricultural productivity in India. The more rapid growth of mobile telephony as compared to fixed line telephony and the recent introduction of mobileenabled information services provide a means to overcome existing information asymmetry. It also helps, at least partially, to bridge the gap between the availability and delivery of agricultural inputs and agriculture infrastructure. This paper investigates a series of questions that explore this topic : What kind of information do farmers value the most to improve agricultural productivity? Do mobile phones and mobile-enabled agricultural services have an impact on agriculture? What are the factors that impede the realisation of the full productivity enhancing potential of mobile phones? The answers to these questions have important implications for mobile operators, for information service providers, and for policymakers. The quality of information, its timeliness and trustworthiness are the three important features that have to be ensured to enable farmers to use it effectively to improve productivity. The study found evidence that mobiles are being used in ways which contribute to productivity enhancement. However, to leverage the full potential of information dissemination enabled by mobile telephony will require significant improvements in supporting infrastructure and capacity building amongst farmers to enable them to use the information they access effectively. As mobile penetration continues to increase among farming communities and information services continue to adapt and proliferate, the scope exists for a much greater rural productivity impact in the future.\n",
            "------------------------------------\n",
            "Title :  The Capacity of Private Information Retrieval\n",
            "Author/s :  Hua Sun, S. Jafar\n",
            "Venue :  Global Communications Conference\n",
            "year :  2016\n",
            "Abstract :  In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N^2 + &#183; &#183; &#183; + 1/N({K&#8722;1})^{&#8722;1}. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.\n",
            "------------------------------------\n",
            "Title :  Immediate Psychological Responses and Associated Factors during the Initial Stage of the 2019 Coronavirus Disease (COVID-19) Epidemic among the General Population in China\n",
            "Author/s :  Cuiyan Wang, R. Pan, Xiaoyang Wan, Yilin Tan, Linkang Xu, C. Ho, R. Ho\n",
            "Venue :  International Journal of Environmental Research and Public Health\n",
            "year :  2020\n",
            "Abstract :  Background: The 2019 coronavirus disease (COVID-19) epidemic is a public health emergency of international concern and poses a challenge to psychological resilience. Research data are needed to develop evidence-driven strategies to reduce adverse psychological impacts and psychiatric symptoms during the epidemic. The aim of this study was to survey the general public in China to better understand their levels of psychological impact, anxiety, depression, and stress during the initial stage of the COVID-19 outbreak. The data will be used for future reference. Methods: From 31 January to 2 February 2020, we conducted an online survey using snowball sampling techniques. The online survey collected information on demographic data, physical symptoms in the past 14 days, contact history with COVID-19, knowledge and concerns about COVID-19, precautionary measures against COVID-19, and additional information required with respect to COVID-19. Psychological impact was assessed by the Impact of Event Scale-Revised (IES-R), and mental health status was assessed by the Depression, Anxiety and Stress Scale (DASS-21). Results: This study included 1210 respondents from 194 cities in China. In total, 53.8% of respondents rated the psychological impact of the outbreak as moderate or severe; 16.5% reported moderate to severe depressive symptoms; 28.8% reported moderate to severe anxiety symptoms; and 8.1% reported moderate to severe stress levels. Most respondents spent 20–24 h per day at home (84.7%); were worried about their family members contracting COVID-19 (75.2%); and were satisfied with the amount of health information available (75.1%). Female gender, student status, specific physical symptoms (e.g., myalgia, dizziness, coryza), and poor self-rated health status were significantly associated with a greater psychological impact of the outbreak and higher levels of stress, anxiety, and depression (p < 0.05). Specific up-to-date and accurate health information (e.g., treatment, local outbreak situation) and particular precautionary measures (e.g., hand hygiene, wearing a mask) were associated with a lower psychological impact of the outbreak and lower levels of stress, anxiety, and depression (p < 0.05). Conclusions: During the initial phase of the COVID-19 outbreak in China, more than half of the respondents rated the psychological impact as moderate-to-severe, and about one-third reported moderate-to-severe anxiety. Our findings identify factors associated with a lower level of psychological impact and better mental health status that can be used to formulate psychological interventions to improve the mental health of vulnerable groups during the COVID-19 epidemic.\n",
            "------------------------------------\n",
            "Title :  Opportunities and Challenges for Smartphone Applications in Supporting Health Behavior Change: Qualitative Study\n",
            "Author/s :  L. Dennison, L. Morrison, G. Conway, L. Yardley\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background There is increasing interest from academics and clinicians in harnessing smartphone applications (apps) as a means of delivering behavioral interventions for health. Despite the growing availability of a range of health-related apps on the market, academic research on the development and evaluation of such apps is in the relatively early stages. A few existing studies have explored the views of various populations on using mobile phones for health-related issues and some studies are beginning to report user feedback on specific apps. However, there remains little in depth research on users’ (and potential users’) experiences and views on a wide range of features and technologies that apps are, or will soon be, capable of. In particular, research on young adults is lacking, which is an unfortunate omission considering that this group comprises of a good number of mobile technology adoptors. Objective The current study sought to explore young adults’ perspectives on apps related to health behavior change. It sought their experiences and views of features that might support health behavior change and issues that contribute to interest in and willingness to use such apps. Methods Four focus groups were conducted with 19 students and staff at a University in the United Kingdom. Participants included 13 females and 6 males with a mean age of 23.79 (SD 7.89). The focus group discussions centred on participants’ experiences of using smartphone apps to support a healthy lifestyle, and their interest in and feelings about features and capabilities of such apps. The focus groups were recorded, transcribed, and analyzed using inductive thematic analysis. Results Study findings suggested that young, currently healthy adults have some interest in apps that attempt to support health-related behavior change. Accuracy and legitimacy, security, effort required, and immediate effects on mood emerged as important influences on app usage. The ability to record and track behavior and goals and the ability to acquire advice and information “on the go” were valued. Context-sensing capabilities and social media features tended to be considered unnecessary and off-putting. Conclusions This study provided insight into the opportunities and challenges involved in delivering health-related behavioral interventions through smartphone apps. The findings suggested a number of valued features and characteristics that app developers may wish to consider when creating health behavior apps. Findings also highlighted several major challenges that appeared to need further consideration and research to ensure the development of effective and well-accepted behavior change apps.\n",
            "------------------------------------\n",
            "Title :  Geodesic Information Flows: Spatially-Variant Graphs and Their Application to Segmentation and Fusion\n",
            "Author/s :  M. Cardoso, M. Modat, R. Wolz, A. Melbourne, D. Cash, D. Rueckert, S. Ourselin\n",
            "Venue :  IEEE Transactions on Medical Imaging\n",
            "year :  2015\n",
            "Abstract :  Clinical annotations, such as voxel-wise binary or probabilistic tissue segmentations, structural parcellations, pathological regions-of-interest and anatomical landmarks are key to many clinical studies. However, due to the time consuming nature of manually generating these annotations, they tend to be scarce and limited to small subsets of data. This work explores a novel framework to propagate voxel-wise annotations between morphologically dissimilar images by diffusing and mapping the available examples through intermediate steps. A spatially-variant graph structure connecting morphologically similar subjects is introduced over a database of images, enabling the gradual diffusion of information to all the subjects, even in the presence of large-scale morphological variability. We illustrate the utility of the proposed framework on two example applications: brain parcellation using categorical labels and tissue segmentation using probabilistic features. The application of the proposed method to categorical label fusion showed highly statistically significant improvements when compared to state-of-the-art methodologies. Significant improvements were also observed when applying the proposed framework to probabilistic tissue segmentation of both synthetic and real data, mainly in the presence of large morphological variability.\n",
            "------------------------------------\n",
            "Title :  RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments\n",
            "Author/s :  Peter Henry, Michael Krainin, E. Herbst, Xiaofeng Ren, D. Fox\n",
            "Venue :  Int. J. Robotics Res.\n",
            "year :  2012\n",
            "Abstract :  RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.\n",
            "------------------------------------\n",
            "Title :  Susceptibility to misinformation about COVID-19 around the world\n",
            "Author/s :  J. Roozenbeek, C. Schneider, S. Dryhurst, J. Kerr, A. Freeman, G. Recchia, A. M. van der Bles, S. van der Linden\n",
            "Venue :  Royal Society Open Science\n",
            "year :  2020\n",
            "Abstract :  Misinformation about COVID-19 is a major threat to public health. Using five national samples from the UK (n = 1050 and n = 1150), Ireland (n = 700), the USA (n = 700), Spain (n = 700) and Mexico (n = 700), we examine predictors of belief in the most common statements about the virus that contain misinformation. We also investigate the prevalence of belief in COVID-19 misinformation across different countries and the role of belief in such misinformation in predicting relevant health behaviours. We find that while public belief in misinformation about COVID-19 is not particularly common, a substantial proportion views this type of misinformation as highly reliable in each country surveyed. In addition, a small group of participants find common factual information about the virus highly unreliable. We also find that increased susceptibility to misinformation negatively affects people's self-reported compliance with public health guidance about COVID-19, as well as people's willingness to get vaccinated against the virus and to recommend the vaccine to vulnerable friends and family. Across all countries surveyed, we find that higher trust in scientists and having higher numeracy skills were associated with lower susceptibility to coronavirus-related misinformation. Taken together, these results demonstrate a clear link between susceptibility to misinformation and both vaccine hesitancy and a reduced likelihood to comply with health guidance measures, and suggest that interventions which aim to improve critical thinking and trust in science may be a promising avenue for future research.\n",
            "------------------------------------\n",
            "Title :  Minimum information reporting in bio–nano experimental literature\n",
            "Author/s :  Matthew Faria, M. Björnmalm, K. Thurecht, S. Kent, R. Parton, M. Kavallaris, A. Johnston, J. Gooding, S. Corrie, B. Boyd, P. Thordarson, A. Whittaker, M. Stevens, C. Prestidge, C. Porter, W. Parak, T. P. Davis, E. Crampin, F. Caruso\n",
            "Venue :  Nature Nanotechnology\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Mandatory IFRS Adoption and Financial Statement Comparability\n",
            "Author/s :  François Brochet, Alan D. Jagolinzer, Edward J. Riedl\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This study examines whether mandatory adoption of International Financial Reporting Standards (IFRS) leads to capital market benefits through enhanced financial statement comparability. UK domestic standards are considered very similar to IFRS (Bae et al. 2008), suggesting any capital market benefits observed for UK-domiciled firms are more likely attributable to improvements in comparability (i.e., better precision of across-firm information) than to changes in information quality specific to the firm (i.e., core information quality). If IFRS adoption improves financial statement comparability, we predict this should reduce insiders’ ability to benefit from private information. Consistent with these expectations, we find that abnormal returns to insider purchases ― used to proxy for private information ― are reduced following IFRS adoption. Similar results obtain across numerous subsamples and proxies used to isolate IFRS effects attributable to comparability. Together, the findings are consistent with mandatory IFRS adoption improving comparability and thus leading to capital market benefits by reducing insiders’ ability to exploit private information.\n",
            "------------------------------------\n",
            "Title :  Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths\n",
            "Author/s :  Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2015\n",
            "Abstract :  Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an $F_1$-score of 83.7\\%, higher than competing methods in the literature.\n",
            "------------------------------------\n",
            "Title :  Learning Character-level Representations for Part-of-Speech Tagging\n",
            "Author/s :  C. D. Santos, B. Zadrozny\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2014\n",
            "Abstract :  Distributed word representations have recently been proven to be an invaluable resource for NLP. These representations are normally learned using neural networks and capture syntactic and semantic information about words. Information about word morphology and shape is normally ignored when learning word representations. However, for tasks like part-of-speech tagging, intra-word information is extremely useful, specially when dealing with morphologically rich languages. In this paper, we propose a deep neural network that learns character-level representation of words and associate them with usual word representations to perform POS tagging. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for two languages: English, with 97.32% accuracy on the Penn Treebank WSJ corpus; and Portuguese, with 97.47% accuracy on the Mac-Morpho corpus, where the latter represents an error reduction of 12.2% on the best previous known result.\n",
            "------------------------------------\n",
            "Title :  Coronavirus disease 2019: The harms of exaggerated information and non‐evidence‐based measures\n",
            "Author/s :  J. Ioannidis\n",
            "Venue :  European Journal of Clinical Investigation\n",
            "year :  2020\n",
            "Abstract :  The evolving coronavirus disease 2019 (COVID-19) epidemic1 is certainly cause for concern. Proper communication and optimal decision-making is an ongoing challenge, as data evolve. The challenge is compounded, however, by exaggerated information. This can lead to inappropriate actions. It is important to differentiate promptly the true epidemic from an epidemic of false claims and potentially harmful actions.\n",
            "------------------------------------\n",
            "Title :  Roadmap on optical security\n",
            "Author/s :  B. Javidi, A. Carnicer, Masahiro Yamaguchi, T. Nomura, E. Pérez-Cabré, M. S. Millán, N. Nishchal, R. Torroba, J. F. Barrera, W. He, Xiang Peng, A. Stern, Y. Rivenson, A. Alfalou, C. Brosseau, Changliang Guo, J. Sheridan, G. Situ, M. Naruse, Tsutomu Matsumoto, I. Juvells, E. Tajahuerce, J. Lancis, Wen Chen, Xudong Chen, P. Pinkse, A. Mosk, A. Markman\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Information security and authentication are important challenges facing society. Recent attacks by hackers on the databases of large commercial and financial companies have demonstrated that more research and development of advanced approaches are necessary to deny unauthorized access to critical data. Free space optical technology has been investigated by many researchers in information security, encryption, and authentication. The main motivation for using optics and photonics for information security is that optical waveforms possess many complex degrees of freedom such as amplitude, phase, polarization, large bandwidth, nonlinear transformations, quantum properties of photons, and multiplexing that can be combined in many ways to make information encryption more secure and more difficult to attack. This roadmap article presents an overview of the potential, recent advances, and challenges of optical security and encryption using free space optics. The roadmap on optical security is comprised of six categories that together include 16 short sections written by authors who have made relevant contributions in this field. The first category of this roadmap describes novel encryption approaches, including secure optical sensing which summarizes double random phase encryption applications and flaws [Yamaguchi], the digital holographic encryption in free space optical technique which describes encryption using multidimensional digital holography [Nomura], simultaneous encryption of multiple signals [Pérez-Cabré], asymmetric methods based on information truncation [Nishchal], and dynamic encryption of video sequences [Torroba]. Asymmetric and one-way cryptosystems are analyzed by Peng. The second category is on compression for encryption. In their respective contributions, Alfalou and Stern propose similar goals involving compressed data and compressive sensing encryption. The very important area of cryptanalysis is the topic of the third category with two sections: Sheridan reviews phase retrieval algorithms to perform different attacks, whereas Situ discusses nonlinear optical encryption techniques and the development of a rigorous optical information security theory. The fourth category with two contributions reports how encryption could be implemented at the nano- or micro-scale. Naruse discusses the use of nanostructures in security applications and Carnicer proposes encoding information in a tightly focused beam. In the fifth category, encryption based on ghost imaging using single-pixel detectors is also considered. In particular, the authors [Chen, Tajahuerce] emphasize the need for more specialized hardware and image processing algorithms. Finally, in the sixth category, Mosk and Javidi analyze in their corresponding papers how quantum imaging can benefit optical encryption systems. Sources that use few photons make encryption systems much more difficult to attack, providing a secure method for authentication.\n",
            "------------------------------------\n",
            "Title :  Big Data in product lifecycle management\n",
            "Author/s :  Jingran Li, F. Tao, Ying Cheng, Lian Zhao\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  On the joys of missing data.\n",
            "Author/s :  T. Little, T. Jorgensen, Kyle M Lang, E. Moore\n",
            "Venue :  Journal of Pediatric Psychology\n",
            "year :  2014\n",
            "Abstract :  We provide conceptual introductions to missingness mechanisms--missing completely at random, missing at random, and missing not at random--and state-of-the-art methods of handling missing data--full-information maximum likelihood and multiple imputation--followed by a discussion of planned missing designs: Multiform questionnaire protocols, 2-method measurement models, and wave-missing longitudinal designs. We reviewed 80 articles of empirical studies published in the 2012 issues of the Journal of Pediatric Psychology to present a picture of how adequately missing data are currently handled in this field. To illustrate the benefits of using multiple imputation or full-information maximum likelihood and incorporating planned missingness into study designs, we provide example analyses of empirical data gathered using a 3-form planned missing design.\n",
            "------------------------------------\n",
            "Title :  Oscillatory multiplexing of population codes for selective communication in the mammalian brain\n",
            "Author/s :  T. Akam, D. Kullmann\n",
            "Venue :  Nature Reviews Neuroscience\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  ClinVar: public archive of interpretations of clinically relevant variants\n",
            "Author/s :  M. Landrum, Jennifer M. Lee, M. Benson, Garth R. Brown, Chen Chao, S. Chitipiralla, Baoshan Gu, Jennifer Hart, Douglas Hoffman, Jeffrey Hoover, W. Jang, K. Katz, M. Ovetsky, George R. Riley, Amanjeev Sethi, R. E. Tully, Ricardo Villamarín-Salomón, W. Rubinstein, D. Maglott\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2015\n",
            "Abstract :  ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) at the National Center for Biotechnology Information (NCBI) is a freely available archive for interpretations of clinical significance of variants for reported conditions. The database includes germline and somatic variants of any size, type or genomic location. Interpretations are submitted by clinical testing laboratories, research laboratories, locus-specific databases, OMIM®, GeneReviews™, UniProt, expert panels and practice guidelines. In NCBI's Variation submission portal, submitters upload batch submissions or use the Submission Wizard for single submissions. Each submitted interpretation is assigned an accession number prefixed with SCV. ClinVar staff review validation reports with data types such as HGVS (Human Genome Variation Society) expressions; however, clinical significance is reported directly from submitters. Interpretations are aggregated by variant-condition combination and assigned an accession number prefixed with RCV. Clinical significance is calculated for the aggregate record, indicating consensus or conflict in the submitted interpretations. ClinVar uses data standards, such as HGVS nomenclature for variants and MedGen identifiers for conditions. The data are available on the web as variant-specific views; the entire data set can be downloaded via ftp. Programmatic access for ClinVar records is available through NCBI's E-utilities. Future development includes providing a variant-centric XML archive and a web page for details of SCV submissions.\n",
            "------------------------------------\n",
            "Title :  Nucleation, stability and current-induced motion of isolated magnetic skyrmions in nanostructures.\n",
            "Author/s :  J. Sampaio, V. Cros, S. Rohart, A. Thiaville, A. Fert\n",
            "Venue :  Nature Nanotechnology\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Research Note - Effects of Individual Self-Protection, Industry Self-Regulation, and Government Regulation on Privacy Concerns: A Study of Location-Based Services\n",
            "Author/s :  Heng Xu, H. Teo, B. Tan, Ritu Agarwal\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This study seeks to clarify the nature of control in the context of information privacy to generate insights into the effects of different privacy assurance approaches on context-specific concerns for information privacy. We theorize that such effects are exhibited through mediation by perceived control over personal information and develop arguments in support of the interaction effects involving different privacy assurance approaches (individual self-protection, industry self-regulation, and government legislation). We test the research model in the context of location-based services using data obtained from 178 individuals in Singapore. In general, the results support our core assertion that perceived control over personal information is a key factor affecting context-specific concerns for information privacy. In addition to enhancing our theoretical understanding of the link between control and privacy concerns, these findings have important implications for service providers and consumers as well as for regulatory bodies and technology developers.\n",
            "------------------------------------\n",
            "Title :  Revealing the hidden networks of interaction in mobile animal groups allows prediction of complex behavioral contagion\n",
            "Author/s :  S. Rosenthal, Colin R. Twomey, Andrew T. Hartnett, H. Wu, I. Couzin\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance We know little about the nature of the evolved interaction networks that give rise to the rapid coordinated collective response exhibited by many group-living organisms. Here, we study collective evasion in schooling fish using computational techniques to reconstruct the scene from the perspective of the organisms themselves. This method allows us to establish how the complex social scene is translated into behavioral response at the level of individuals and to visualize, and analyze, the resulting complex communication network as behavioral change spreads rapidly through groups. Thus, we can map, for any moment in time, the extent to which each individual is socially influential during collective evasion and predict the magnitude of such behavioral epidemics before they actually occur. Coordination among social animals requires rapid and efficient transfer of information among individuals, which may depend crucially on the underlying structure of the communication network. Establishing the decision-making circuits and networks that give rise to individual behavior has been a central goal of neuroscience. However, the analogous problem of determining the structure of the communication network among organisms that gives rise to coordinated collective behavior, such as is exhibited by schooling fish and flocking birds, has remained almost entirely neglected. Here, we study collective evasion maneuvers, manifested through rapid waves, or cascades, of behavioral change (a ubiquitous behavior among taxa) in schooling fish (Notemigonus crysoleucas). We automatically track the positions and body postures, calculate visual fields of all individuals in schools of ∼150 fish, and determine the functional mapping between socially generated sensory input and motor response during collective evasion. We find that individuals use simple, robust measures to assess behavioral changes in neighbors, and that the resulting networks by which behavior propagates throughout groups are complex, being weighted, directed, and heterogeneous. By studying these interaction networks, we reveal the (complex, fractional) nature of social contagion and establish that individuals with relatively few, but strongly connected, neighbors are both most socially influential and most susceptible to social influence. Furthermore, we demonstrate that we can predict complex cascades of behavioral change at their moment of initiation, before they actually occur. Consequently, despite the intrinsic stochasticity of individual behavior, establishing the hidden communication networks in large self-organized groups facilitates a quantitative understanding of behavioral contagion.\n",
            "------------------------------------\n",
            "Title :  Inference Attacks on Property-Preserving Encrypted Databases\n",
            "Author/s :  Muhammad Naveed, S. Kamara, C. V. Wright\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2015\n",
            "Abstract :  Many encrypted database (EDB) systems have been proposed in the last few years as cloud computing has grown in popularity and data breaches have increased. The state-of-the-art EDB systems for relational databases can handle SQL queries over encrypted data and are competitive with commercial database systems. These systems, most of which are based on the design of CryptDB (SOSP 2011), achieve these properties by making use of property-preserving encryption schemes such as deterministic (DTE) and order- preserving encryption (OPE). In this paper, we study the concrete security provided by such systems. We present a series of attacks that recover the plaintext from DTE- and OPE-encrypted database columns using only the encrypted column and publicly-available auxiliary information. We consider well-known attacks, including frequency analysis and sorting, as well as new attacks based on combinatorial optimization. We evaluate these attacks empirically in an electronic medical records (EMR) scenario using real patient data from 200 U.S. hospitals. When the encrypted database is operating in a steady-state where enough encryption layers have been peeled to permit the application to run its queries, our experimental results show that an alarming amount of sensitive information can be recovered. In particular, our attacks correctly recovered certain OPE-encrypted attributes (e.g., age and disease severity) for more than 80% of the patient records from 95% of the hospitals; and certain DTE- encrypted attributes (e.g., sex, race, and mortality risk) for more than 60% of the patient records from more than 60% of the hospitals.\n",
            "------------------------------------\n",
            "Title :  Social Media and Clinical Care: Ethical, Professional, and Social Implications\n",
            "Author/s :  Katherine C. Chretien, T. Kind\n",
            "Venue :  Circulation\n",
            "year :  2013\n",
            "Abstract :  It is an exciting time to practice medicine during our digital “coming of age.” Social media, the freely available Web-based platforms that facilitate information sharing of user-generated content, such as social networking sites, media-sharing sites, blogs, microblogs, and wikis, have transformed the way we communicate as a society. Through community building, message amplification, rapid dissemination, and engagement, social media has changed our interactions with others and, by direct consequence, our relationships. For health care, this represents a veritable social revolution. 1\n",
            "\n",
            "Indeed, medicine is constantly evolving to adapt to new technologies. These advances have led to new therapies, diagnostic tools, and ways of communicating. As physicians and lifelong learners, it has been imperative to embrace the new when it has meant better and more efficient patient care while holding on to the stable tenets of medicine that root our profession: humanism, integrity, ethics, professionalism, and trust.\n",
            "\n",
            "Patients have been active on social media to find health information, find support through discussion groups and forums, and chronicle their illness journeys.2 Naturally, they are also interested in using social media to facilitate communication between themselves and their providers. In a survey of patients of an outpatient family practice clinic, 56% wanted their providers to use social media for appointment setting and reminders, diagnostic test results reporting, health information sharing, prescription notifications, and answering general questions.3 For those patients who do not use social media, many would start if they knew that they could connect with their providers there.3\n",
            "\n",
            "Physicians are also exploring ways to use social media, both personally and professionally, although personal use is more common.4–6 Some physicians use social media professionally to find and share health information, communicate/network with colleagues and trainees, disseminate their research, market their practice, or engage in health advocacy. In …\n",
            "------------------------------------\n",
            "Title :  When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author/s :  L. Thygesen, A. Ersbøll\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Photonic quantum simulators\n",
            "Author/s :  Alán Aspuru-Guzik, P. Walther\n",
            "Venue :  Nature Physics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks\n",
            "Author/s :  Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, Yoav Goldberg\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2016\n",
            "Abstract :  There is a lot of research interest in encoding variable length sentences into fixed length vectors, in a way that preserves the sentence meanings. Two common methods include representations based on averaging word vectors, and representations based on the hidden states of recurrent neural networks such as LSTMs. The sentence vectors are used as features for subsequent machine learning tasks or for pre-training in the context of deep learning. However, not much is known about the properties that are encoded in these sentence representations and about the language information they capture. We propose a framework that facilitates better understanding of the encoded representations. We define prediction tasks around isolated aspects of sentence structure (namely sentence length, word content, and word order), and score representations by the ability to train a classifier to solve each prediction task when using the representation as input. We demonstrate the potential contribution of the approach by analyzing different sentence representation mechanisms. The analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks, and on the effect of the encoded vector's dimensionality on the resulting representations.\n",
            "------------------------------------\n",
            "Title :  Thermodynamics with Continuous Information Flow\n",
            "Author/s :  J. Horowitz, M. Esposito\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We provide a unified thermodynamic formalism describing information transfers in autonomous as well as nonautonomous systems described by stochastic thermodynamics. We demonstrate how information is continuously generated in an auxiliary system and then transferred to a relevant system that can utilize it to fuel otherwise impossible processes. Indeed, while the joint system satisfies the second law, the entropy balance for the relevant system is modified by an information term related to the mutual information rate between the two systems. We show that many important results previously derived for nonautonomous Maxwell demons can be recovered from our formalism and use a cycle decomposition to analyze the continuous information flow in autonomous systems operating at steady-state. A model system is used to illustrate our findings.\n",
            "------------------------------------\n",
            "Title :  Development of a Health Information Technology Acceptance Model Using Consumers’ Health Behavior Intention\n",
            "Author/s :  Jeongeun Kim, Hyeoun-Ae Park\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2012\n",
            "Abstract :  Background For effective health promotion using health information technology (HIT), it is mandatory that health consumers have the behavioral intention to measure, store, and manage their own health data. Understanding health consumers’ intention and behavior is needed to develop and implement effective and efficient strategies. Objective To develop and verify the extended Technology Acceptance Model (TAM) in health care by describing health consumers’ behavioral intention of using HIT. Methods This study used a cross-sectional descriptive correlational design. We extended TAM by adding more antecedents and mediating variables to enhance the model’s explanatory power and to make it more applicable to health consumers’ behavioral intention. Additional antecedents and mediating variables were added to the hypothetical model, based on their theoretical relevance, from the Health Belief Model and theory of planned behavior, along with the TAM. We undertook structural equation analysis to examine the specific nature of the relationship involved in understanding consumers’ use of HIT. Study participants were 728 members recruited from three Internet health portals in Korea. Data were collected by a Web-based survey using a structured self-administered questionnaire. Results The overall fitness indices for the model developed in this study indicated an acceptable fit of the model. All path coefficients were statistically significant. This study showed that perceived threat, perceived usefulness, and perceived ease of use significantly affected health consumers’ attitude and behavioral intention. Health consumers’ health status, health belief and concerns, subjective norm, HIT characteristics, and HIT self-efficacy had a strong indirect impact on attitude and behavioral intention through the mediators of perceived threat, perceived usefulness, and perceived ease of use. Conclusions An extended TAM in the HIT arena was found to be valid to describe health consumers’ behavioral intention. We categorized the concepts in the extended TAM into 3 domains: health zone, information zone, and technology zone.\n",
            "------------------------------------\n",
            "Title :  Advances in quantum teleportation\n",
            "Author/s :  S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, S. Braunstein\n",
            "Venue :  Nature Photonics\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Science, New Media, and the Public\n",
            "Author/s :  D. Brossard, D. Scheufele\n",
            "Venue :  Science\n",
            "year :  2013\n",
            "Abstract :  A better understanding is needed about how the online environment affects the communication of science information to the public. Nine in 10 internet users in the United States turn to search engines to find information (1), and 60% of the U.S. public seeking information about specific scientific issues lists the Internet as their primary source of information (2). This has created a new urgency for scientists to pay attention to these trends and to the emerging scholarly literature about communicating science in this brave new “online” world.\n",
            "------------------------------------\n",
            "Title :  Accounting information systems\n",
            "Author/s :  S. Altschuller, Shaya Altschuller\n",
            "Venue :  The Routledge Companion to Risk, Crisis and Security in Business\n",
            "year :  2018\n",
            "Abstract :  Accounting Information Systems Introduction The development of information technology impacts significantly on various fields and activities. The biggest impact can be seen in accounting practice. The changes are becoming more and more complex as there are shifts in business activities, such as in organization management, the concept of change management, and integration activities making closer ties among suppliers, customers and even competitors (Computing Curricula 2005, Information System).\n",
            "------------------------------------\n",
            "Title :  The Ethics of Information\n",
            "Author/s :  L. Floridi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  PREFACE 1. ETHICS AFTER THE INFORMATION REVOLUTION 2. WHAT IS INFORMATION ETHICS? 3. THE METHOD OF ABSTRACTION 4. INFORMATION ETHICS AS E-NVIRONMENTAL ETHICS 5. INFORMATION ETHICS AND THE FOUNDATIONALIST DEBATE 6. THE INTRINSIC VALUE OF THE INFOSPHERE 7. THE MORALITY OF ARTIFICIAL AGENTS 8. THE CONSTRUCTIONIST VALUES OF HOMO POIETICUS 9. ARTIFICIAL EVIL 10. THE TRAGEDY OF THE GOOD WILL 11. THE INFORMATIONAL NATURE OF SELVES 12. THE ONTOLOGICAL INTERPRETATION OF INFORMATIONAL PRIVACY 13. DISTRIBUTED MORALITY 14. INFORMATION BUSINESS ETHICS 15. GLOBAL INFORMATION ETHICS 16. A DEFENCE OF INFORMATION ETHICS EPILOGUE REFERENCES INDEX\n",
            "------------------------------------\n",
            "Title :  Developing and Testing a Theoretical Framework for Computer‐Mediated Transparency of Local Governments\n",
            "Author/s :  S. Grimmelikhuijsen, E. Welch\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This article contributes to the emerging literature on transparency by developing and empirically testing a theoretical framework that explains the determinants of local government Web site transparency. It aims to answer the following central question: What institutional factors determine the different dimensions of government transparency? The framework distinguishes three dimensions of transparency—decision making transparency, policy information transparency, and policy outcome transparency—and hypothesizes three explanations for each: organizational capacity, political influence, and group influence on government. Results indicate that each dimension of transparency is associated with different factors. Decision-making transparency is associated with political influence; when left-wing parties are strong in the local council, local government tends to be more transparent. Policy information transparency is associated with media attention and external group pressure, and policy outcome transparency is associated with both external group pressure and the organizational capacity. The authors discuss the implications for policy and administration\n",
            "------------------------------------\n",
            "Title :  Connecting with new information landscapes: information literacy practices of refugees\n",
            "Author/s :  A. Lloyd, M. Kennan, K. Thompson, M. Qayyum\n",
            "Venue :  J. Documentation\n",
            "year :  2013\n",
            "Abstract :  Purpose – The purpose of the research reported in this article is to understand how refugees learn to engage with a complex, multimodal information landscape and how their information literacy practice may be constructed to enable them to connect and be included in their new information landscape. Design/methodology/approach – The study is framed through practice and socio‐cultural theories. A qualitative research design is employed including semi‐structured face‐to‐face interviews and focus groups which are thematically analysed through an information practice lens. Findings – Refugees encounter complex and challenging information landscapes that present barriers to their full participation in their new communities. Social inclusion becomes possible where information is provided via sharing through trusted mediators who assist with navigating the information landscape and information mapping, and through visual and social sources. Research limitations/implications – The study is local and situated and therefore not empirically generalizable. It does however provide rich, deep description and explanation that is instructive beyond the specific research site and contributes to theory building. Practical implications – The study highlights the role, and importance, of social and visual information sources and the key role of service providers as mediators and navigators. Governments, funders and service providers can use these findings to inform their service provision. Originality/value – This is an original research paper in which the results provide practical advice for those working with refugees and which also extends theories of information literacy practice as an information practice.\n",
            "------------------------------------\n",
            "Title :  The eICU Collaborative Research Database, a freely available multi-center database for critical care research\n",
            "Author/s :  T. Pollard, A. Johnson, J. Raffa, L. Celi, R. Mark, O. Badawi\n",
            "Venue :  Scientific Data\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Suspense and Surprise\n",
            "Author/s :  Jeffrey C. Ely, A. Frankel, Emir Kamenica\n",
            "Venue :  Journal of Political Economy\n",
            "year :  2015\n",
            "Abstract :  We model demand for noninstrumental information, drawing on the idea that people derive entertainment utility from suspense and surprise. A period has more suspense if the variance of the next period’s beliefs is greater. A period has more surprise if the current belief is further from the last period’s belief. Under these definitions, we analyze the optimal way to reveal information over time so as to maximize expected suspense or surprise experienced by a Bayesian audience. We apply our results to the design of mystery novels, political primaries, casinos, game shows, auctions, and sports.\n",
            "------------------------------------\n",
            "Title :  EGNet: Edge Guidance Network for Salient Object Detection\n",
            "Author/s :  Jiaxing Zhao, Jiangjiang Liu, Deng-Ping Fan, Yang Cao, Jufeng Yang, Ming-Ming Cheng\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2019\n",
            "Abstract :  Fully convolutional neural networks (FCNs) have shown their advantages in the salient object detection task. However, most existing FCNs-based methods still suffer from coarse object boundaries. In this paper, to solve this problem, we focus on the complementarity between salient edge information and salient object information. Accordingly, we present an edge guidance network (EGNet) for salient object detection with three steps to simultaneously model these two kinds of complementary information in a single network. In the ﬁrst step, we extract the salient object features by a progressive fusion way. In the second step, we integrate the local edge information and global location information to obtain the salient edge features. Finally, to sufﬁciently leverage these complementary features, we couple the same salient edge features with salient object features at various resolutions. Beneﬁting from the rich edge information and location information in salient edge features, the fused features can help locate salient objects, especially their boundaries more accurately. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art methods on six widely used datasets without any pre-processing and post-processing. The source code is available at http: //mmcheng.net/egnet/.\n",
            "------------------------------------\n",
            "Title :  Service innovation in the digital age: key contributions and future directions\n",
            "Author/s :  M. Barrett, E. Davidson, Jaideep Prabhu, Stephen L. Vargo\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Over the last decade, there has been an increasing focus on service across socioeconomic sectors coupled with transformational developments in information and communication technologies (ICTs). Together these developments are engendering dramatic new opportunities for service innovation, the study of which is both timely and important. Fully understanding these opportunities challenges us to question conventional approaches that construe service as a distinctive form of socioeconomic exchange (i.e., as services) and to reconsider what service means and thus how service innovation may develop. The aim of this special issue, therefore, is to bring together some of the latest scholarship from the Marketing and Information Systems disciplines to advance theoretical developments on service innovation in a digital age.\n",
            "------------------------------------\n",
            "Title :  Neural Sentiment Classification with User and Product Attention\n",
            "Author/s :  Huimin Chen, Maosong Sun, Cunchao Tu, Yankai Lin, Zhiyuan Liu\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2016\n",
            "Abstract :  Document-level sentiment classification aims to predict user’s overall sentiment in a document about a product. However, most of existing methods only focus on local text information and ignore the global user preference and product characteristics. Even though some works take such information into account, they usually suffer from high model complexity and only consider wordlevel preference rather than semantic levels. To address this issue, we propose a hierarchical neural network to incorporate global user and product information into sentiment classification. Our model first builds a hierarchical LSTM model to generate sentence and document representations. Afterwards, user and product information is considered via attentions over different semantic levels due to its ability of capturing crucial semantic components. The experimental results show that our model achieves significant and consistent improvements compared to all state-of-theart methods. The source code of this paper can be obtained from https://github. com/thunlp/NSC.\n",
            "------------------------------------\n",
            "Title :  Making existing production systems Industry 4.0-ready\n",
            "Author/s :  Jan Schlechtendahl, Matthias Keinert, F. Kretschmer, A. Lechler, A. Verl\n",
            "Venue :  Production Engineering\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author/s :  Lei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeleton-based action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.\n",
            "------------------------------------\n",
            "Title :  How Virtualization, Decentralization and Network Building Change the Manufacturing Landscape: An Industry 4.0 Perspective\n",
            "Author/s :  Malte Brettel, Niklas Friederichsen, M. Keller, Marius Rosenberg\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  : The German manufacturing industry has to withstand an increasing global competition on product quality and production costs. As labor costs are high, several industries have suffered severely under the relocation of production facilities towards aspiring countries, which have managed to close the productivity and quality gap substantially. Established manufacturing companies have recognized that customers are not willing to pay large price premiums for incremental quality improvements. As a consequence, many companies from the German manufacturing industry adjust their production focusing on customized products and fast time to market. Leveraging the advantages of novel production strategies such as Agile Manufacturing and Mass Customization, manufacturing companies transform into integrated networks, in which companies unite their core competencies. Hereby, virtualization of the process- and supply-chain ensures smooth inter-company operations providing real-time access to relevant product and production information for all participating entities. Boundaries of companies deteriorate, as autonomous systems exchange data, gained by embedded systems throughout the entire value chain. By including Cyber-Physical-Systems, advanced communication between machines is tantamount to their dialogue with humans. The increasing utilization of information and communication technology allows digital engineering of products and production processes alike. Modular simulation and modeling techniques allow decentralized units to flexibly alter products and thereby enable rapid product innovation. The present article describes the developments of Industry 4.0 within the literature and reviews the associated research streams. Hereby, we analyze eight scientific journals with regards to the following research fields: Individualized production, end-to-end engineering in a virtual process chain and production networks. We employ cluster analysis to assign sub-topics into the respective research field. To assess the practical implications, we conducted face-to-face interviews with managers from the industry as well as from the consulting business using a structured interview guideline. The results reveal reasons for the adaption and refusal of Industry 4.0 practices from a managerial point of view. Our findings contribute to the upcoming research stream of Industry 4.0 and support decision-makers to assess their need for transformation towards Industry 4.0 practices.\n",
            "------------------------------------\n",
            "Title :  Jerusalem Lectures on Black Holes and Quantum Information\n",
            "Author/s :  D. Harlow\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  In these lectures I give an introduction to the quantum physics of black holes, including recent developments based on quantum information theory such as the rewall paradox and its various cousins. I also give an introduction to holography and the AdS/CFT correspondence, focusing on those aspects which are relevant for the black hole information problem.\n",
            "------------------------------------\n",
            "Title :  A Review of “Doing Case Study Research: A Practical Guide for Beginning Researchers”\n",
            "Author/s :  L. Vernon-Dotson\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  I n Doing Case Study Research: A Practical Guide for Beginning Researchers, Hancock and Algozzine provide a concrete, step-by-step process for beginning researchers who are conducting case study research. The authors claim that Doing Case Study Research is not a “case study research for dummies” (p. xii) manual, and I absolutely concur. They are successful in stripping away the theories and attacking case study research in a very rudimentary manner, hence providing readers a prescriptive approach. It is a practical look at doing case study research—a solid companion for those teaching, facilitating, or conducting introductory qualitative research. Doing Case Study Research is divided into three sections: “Foundations” (Chapters 1–2), “Stages of Doing Case Study Research” (Chapters 3–11), and “Putting It All Together” (Chapters 12–13). In the first part, Hancock and Algozzine provide insights into the purposes and processes of research, in general, and offer their readers an overview of basic types of qualitative and quantitative research. The authors fittingly provide the reader with guidance in selecting the appropriate research within the two broad traditions. Comprising 59 of the book’s 114 pages, the second section is truly the “nuts and bolts” of conducting case study research. In this section, the authors outline their prescriptive, step-by-step process, which spans from literature review and research design through data collection and interpretation and then ending with reporting and confirming the findings. Each chapter in this section is thorough, with just enough information as to not overwhelm novice researchers. For example, Chapter 4 (“Determining What We Know”) beautifully illustrates and iterates the rationale for the conceptual framework and outlines a seminal and well-documented process for writing a literature review. For instance, the authors suggest following Galvan’s (1999, 2009) key directions for writing literature reviews by first selecting a topic and identifying the literature to review followed by analyzing, criticizing, synthesizing, and documenting the literature. The final section focuses on preparing proposals and disseminating research. These last two chapters bring the book full circle by providing the reader with steps for the typical outlets of their completed work. This book is an easy, quick read and is very user friendly. Hancock and Algozzine offer a variety of cross-disciplinary examples from published works to support their basic process for doing case study research. For example, in Chapter 3 (“Setting the Stage”) the authors provide the readers with examples of published studies from researchers who utilized case study research through 18 brief descriptions of events, situations, programs, and activities across several disciplines including, but not limited to education, social work, counseling, technology, adult education, criminal justice, and psychology. At the conclusion of each chapter, the authors deliver questions (Content Review) and activities to facilitate understanding (Activities and Applications for Prospective Researchers). I greatly appreciated the attention to research design (Chapter 5: “Selecting a Design”); in many qualitative texts, this seems to be overlooked or lacking specificity within the context of case study research. I have reviewed several manuscripts submitted for publication where “case study research” was indicated as the “design.” It seems that beginning researchers (and some veterans) fail to realize that, as Hancock and Algozzine indicated, “[d]oing case study research means selecting a design that matches the disciplinary perspective of the investigation” (p. 37). Not only did the authors distinguish between the classifications, types, and orientations of case study research designs, they also provided 12 different examples that clearly illustrated these different designs. Although this is a practical guide for implementing case study research, a few weaknesses should be noted. First, Hancock and Algozzine make it sound easy. They do mention that qualitative research is a time-consuming task in the first section of the book; however, the time factor is not otherwise stressed. Further, the data analysis section just scratches the surface of what needs to be done to effectively interpret mass amounts of data typically gathered over a long period of time. With that said, the authors appropriately emphasize the need to remain focused on the research questions when sifting through the data—something both beginning and seasoned qualitative researchers tend to forget. Finally, a chapter on the uses, pros, and cons of qualitative data management systems versus just mentioning them in passing (Chapter 9: “Summarizing and Interpreting the Information”) may be helpful to novice researchers who may mistakenly believe that the software (e.g., NVivo, NUDIST, Atlis-ti) actually analyze the data with the click of a button. The lack of context and theory in Doing Case Study Research is both purposeful and effective. Hancock and Algozzine fill a gap in the literature with regard to case study research and their book makes a very useful accompaniment to qualitative research courses. It may not teach some old research dogs new tricks, but Doing Case Study Research is definitely a useful resource to pass along to more novice researchers.\n",
            "------------------------------------\n",
            "Title :  Health Literacy and Use and Trust in Health Information\n",
            "Author/s :  Xuewei Chen, J. Hay, Erika A. Waters, M. Kiviniemi, Caitlin Biddle, E. Schofield, Yuelin Li, K. Kaphingst, H. Orom\n",
            "Venue :  Journal of health communication\n",
            "year :  2018\n",
            "Abstract :  There is a need to investigate which health information sources are used and trusted by people with limited health literacy to help identify strategies for addressing knowledge gaps that can contribute to preventable illness. We examined whether health literacy was associated with people’s use of and trust in a range of potential health information sources. Six hundred participants from a GfK Internet survey panel completed an online survey. We assessed health literacy using the Newest Vital Sign, the sources participants used to get health information, and the extent to which participants trusted health information from these sources. We performed multivariable regressions, controlling for demographic characteristics. Lower health literacy was associated with lower odds of using medical websites for health information and with higher odds of using television, social media, and blogs or celebrity webpages. People with lower health literacy were less likely to trust health information from specialist doctors and dentists, but more likely to trust television, social media, blogs/celebrity webpages, friends, and pharmaceutical companies. People with limited health literacy had higher rates of using and trusting sources such as social media and blogs, which might contain lower quality health information compared to information from healthcare professionals. Thus, it might be necessary to enhance the public’s ability to evaluate the quality of health information sources. The results of this study could be used to improve the reach of high-quality health information among people with limited health literacy and thereby increase the effectiveness of health communication programs and campaigns.\n",
            "------------------------------------\n",
            "Title :  Revisiting Natural Gradient for Deep Networks\n",
            "Author/s :  Razvan Pascanu, Yoshua Bengio\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2013\n",
            "Abstract :  We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for training deep models: Hessian-Free (Martens, 2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et al., 2008). We describe how one can use unlabeled data to improve the generalization error obtained by natural gradient and empirically evaluate the robustness of the algorithm to the ordering of the training set compared to stochastic gradient descent. Finally we extend natural gradient to incorporate second order information alongside the manifold information and provide a benchmark of the new algorithm using a truncated Newton approach for inverting the metric matrix instead of using a diagonal approximation of it.\n",
            "------------------------------------\n",
            "Title :  Identifying Participants in the Personal Genome Project by Name\n",
            "Author/s :  L. Sweeney, A. Abu, Julia Winn\n",
            "Venue :  ArXiv\n",
            "year :  2013\n",
            "Abstract :  We linked names and contact information to publicly available profiles in the Personal Genome Project. These profiles contain medical and genomic information, including details about medications, procedures and diseases, and demographic information, such as date of birth, gender, and postal code. By linking demographics to public records such as voter lists, and mining for names hidden in attached documents, we correctly identified 84 to 97 percent of the profiles for which we provided names. Our ability to learn their names is based on their demographics, not their DNA, thereby revisiting an old vulnerability that could be easily thwarted with minimal loss of research value. So, we propose technical remedies for people to learn about their demographics to make better decisions.\n",
            "------------------------------------\n",
            "Title :  Ubiquitous Data Accessing Method in IoT-Based Information System for Emergency Medical Services\n",
            "Author/s :  Boyi Xu, Lida Xu, Hongming Cai, Cheng Xie, Jingyuan Hu, Fenglin Bu\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2014\n",
            "Abstract :  The rapid development of Internet of things (IoT) technology makes it possible for connecting various smart objects together through the Internet and providing more data interoperability methods for application purpose. Recent research shows more potential applications of IoT in information intensive industrial sectors such as healthcare services. However, the diversity of the objects in IoT causes the heterogeneity problem of the data format in IoT platform. Meanwhile, the use of IoT technology in applications has spurred the increase of real-time data, which makes the information storage and accessing more difficult and challenging. In this research, first a semantic data model is proposed to store and interpret IoT data. Then a resource-based data accessing method (UDA-IoT) is designed to acquire and process IoT data ubiquitously to improve the accessibility to IoT data resources. Finally, we present an IoT-based system for emergency medical services to demonstrate how to collect, integrate, and interoperate IoT data flexibly in order to provide support to emergency medical services. The result shows that the resource-based IoT data accessing method is effective in a distributed heterogeneous data environment for supporting data accessing timely and ubiquitously in a cloud and mobile computing platform.\n",
            "------------------------------------\n",
            "Title :  China's Strategic Censorship\n",
            "Author/s :  Peter Lorentzen\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  While it is often assumed that authoritarian regimes inevitably fear and restrict media independence, permitting watchdog journalism can actually help such regimes maintain power by improving governance. Yet such a strategy risks facilitating a coordinated uprising if discontent is revealed to be widespread. A formal model shows that under some conditions, a regime optimally permits investigative reporting on lower-level officialdom, adjusting how much reporting is allowed depending on the level of underlying social tensions. This strategy yields many of the benefits of free media without risking overthrow. An extension shows why an increase in uncontrollable information, such as from the Internet, may result in a reduction in media freedom. The model sheds light on important aspects of China's media policy and its evolution and on authoritarian media control more broadly.\n",
            "------------------------------------\n",
            "Title :  Expectation and purpose: understanding users' mental models of mobile app privacy through crowdsourcing\n",
            "Author/s :  Jialiu Lin, N. Sadeh, Shahriyar Amini, J. Lindqvist, Jason I. Hong, J. Zhang\n",
            "Venue :  Ubiquitous Computing\n",
            "year :  2012\n",
            "Abstract :  Smartphone security research has produced many useful tools to analyze the privacy-related behaviors of mobile apps. However, these automated tools cannot assess people's perceptions of whether a given action is legitimate, or how that action makes them feel with respect to privacy. For example, automated tools might detect that a blackjack game and a map app both use one's location information, but people would likely view the map's use of that data as more legitimate than the game. Our work introduces a new model for privacy, namely privacy as expectations. We report on the results of using crowdsourcing to capture users' expectations of what sensitive resources mobile apps use. We also report on a new privacy summary interface that prioritizes and highlights places where mobile apps break people's expectations. We conclude with a discussion of implications for employing crowdsourcing as a privacy evaluation technique.\n",
            "------------------------------------\n",
            "Title :  Guide to health informatics\n",
            "Author/s :  E. Coiera\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Basic Concepts in Informatics Models Information Information Systems Informatics Skills Communicating Structuring Questioning Searching Making Decisions Information Systems in Healthcare Information Management Systems The Electronic Health Record Designing and Evaluating Information and Communication Systems Implementation Information System Safety Information Economics Guideline- and Protocol-Based Systems Guidelines, Protocols and Evidence-Based Healthcare Computer-Based Protocol Systems Designing, Disseminating and Applying protocols Communication Systems in Healthcare Communication Systems Basics Interlude-the Internet and the World Wide Web Information and Communication Networks Social Networks and Social Media Interventions Telehealth and Mobile Health Language, Coding and Classification Terms, Codes and Classification Healthcare Terminologies and Classification Systems Natural Language and Formal Terminology Clinical Decision Support and Analytics Clinical Decision Support Systems Interlude-Artificial Intelligence in Medicine Computational Reasoning Methods Model Building for Decision Support, Data Analysis and Scientific Discovery Specialized Applications for Health Informatics Patient Monitoring and Control Population Surveillance and Public Health Informatics Bioinformatics Clinical Bioinformatics and Personalized Medicine Consumer Health Informatics Glossary References\n",
            "------------------------------------\n",
            "Title :  RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems\n",
            "Author/s :  Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, M. Guo\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2018\n",
            "Abstract :  To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple \"ripples\" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.\n",
            "------------------------------------\n",
            "Title :  Data Mining for Internet of Things: A Survey\n",
            "Author/s :  Chun-Wei Tsai, Chin-Feng Lai, Ming-Chao Chiang, L. Yang\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2014\n",
            "Abstract :  It sounds like mission impossible to connect everything on the Earth together via Internet, but Internet of Things (IoT) will dramatically change our life in the foreseeable future, by making many \"impossibles\" possible. To many, the massive data generated or captured by IoT are considered having highly useful and valuable information. Data mining will no doubt play a critical role in making this kind of system smart enough to provide more convenient services and environments. This paper begins with a discussion of the IoT. Then, a brief review of the features of \"data from IoT\" and \"data mining for IoT' is given. Finally, changes, potentials, open issues, and future trends of this field are addressed.\n",
            "------------------------------------\n",
            "Title :  An event-driven manufacturing information system architecture for Industry 4.0\n",
            "Author/s :  Alfred Theorin, Kristofer Bengtsson, Julien Provost, Michael Lieder, C. Johnsson, T. Lundholm, B. Lennartson\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2017\n",
            "Abstract :  Future manufacturing systems need to be more flexible, to embrace tougher and constantly changing market demands. They need to make better use of plant data, ideally utilising all data from the entire plant. Low-level data should be refined to real-time information for decision-making, to facilitate competitiveness through informed and timely decisions. The Line Information System Architecture (LISA), is presented in this paper. It is an event-driven architecture featuring loose coupling, a prototype-oriented information model and formalised transformation services. LISA is designed to enable flexible factory integration and data utilisation. The focus of LISA is on integration of devices and services on all levels, simplifying hardware changes and integration of new smart services as well as supporting continuous improvements on information visualisation and control. The architecture has been evaluated on both real industrial data and industrial demonstrators and it is also being installed at a large automotive company. This article is an extended and revised version of the paper presented at the 2015 IFAC Symposium on Information Control in Manufacturing (INCOM 2015). The paper has been restructured in regards to the order and title of the chapters, and additional information about the integration between devices and services aspects have been added. The introduction and the general structure of the paper now better highlight the contributions of the paper and the uniqueness of the framework.\n",
            "------------------------------------\n",
            "Title :  Partisan Paths to Exposure Diversity: Differences in Pro‐ and Counterattitudinal News Consumption\n",
            "Author/s :  R. Garrett, N. Stroud\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study examines selective exposure to political information, arguing that attraction to proattitudinal information and aversion to counterattitudinal information are distinct phenomena, and that the tendency to engage in these behaviors varies by partisanship. Data collected in a strict online experiment support these predictions. Republicans are significantly more likely to engage in selective avoidance of predominantly counterattitudinal information than those with other partisan affiliations, while non-Republicans are significantly more likely to select a story that includes proattitudinal information, regardless of its counterattitudinal content. Individuals across the political spectrum are receptive to predominantly proattitudinal content and to content that offers a mix of views, but the form these preferences take varies by partisanship. The political significance of these findings is discussed.\n",
            "------------------------------------\n",
            "Title :  Characterizing nonclassical correlations via local quantum uncertainty.\n",
            "Author/s :  D. Girolami, T. Tufarelli, G. Adesso\n",
            "Venue :  Physical Review Letters\n",
            "year :  2012\n",
            "Abstract :  Quantum mechanics predicts that measurements of incompatible observables carry a minimum uncertainty which is independent of technical deficiencies of the measurement apparatus or incomplete knowledge of the state of the system. Nothing yet seems to prevent a single physical quantity, such as one spin component, from being measured with arbitrary precision. Here, we show that an intrinsic quantum uncertainty on a single observable is ineludible in a number of physical situations. When revealed on local observables of a bipartite system, such uncertainty defines an entire class of bona fide measures of nonclassical correlations. For the case of 2 × d systems, we find that a unique measure is defined, which we evaluate in closed form. We then discuss the role that these correlations, which are of the \"discord\" type, can play in the context of quantum metrology. We show in particular that the amount of discord present in a bipartite mixed probe state guarantees a minimum precision, as quantified by the quantum Fisher information, in the optimal phase estimation protocol.\n",
            "------------------------------------\n",
            "Title :  Accounting Conservatism and Stock Price Crash Risk: Firm-Level Evidence\n",
            "Author/s :  Jeong‐Bon Kim, Liandong Zhang\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Using a large sample of U.S. firms over the period 1964–2007, we find that conditional conservatism is associated with the lower likelihood of a firm’s future stock price crashes. This finding holds for multiple measures of conditional conservatism and crash risk and it is robust to controlling for other known determinants of crash risk and firm fixed effects. Moreover, we find that the relation between conservatism and crash risk is more pronounced for firms with higher information asymmetries. Overall, our results are consistent with the notion that conditional conservatism limits managers’ incentive and ability to overstate performance and hide bad news from investors, which, in turn, reduces stock price crash risk.\n",
            "------------------------------------\n",
            "Title :  The Danish Medical Birth Register\n",
            "Author/s :  M. Bliddal, A. Broe, A. Pottegård, J. Olsen, J. Langhoff‐Roos\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Comparison of co-expression measures: mutual information, correlation, and model based indices\n",
            "Author/s :  Lin Song, P. Langfelder, S. Horvath\n",
            "Venue :  BMC Bioinformatics\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The GeneCards Suite: From Gene Data Mining to Disease Genome Sequence Analyses\n",
            "Author/s :  Gil Stelzer, Naomi Rosen, Inbar Plaschkes, Shahar Zimmerman, Michal Twik, Simon Fishilevich, Tsippi Iny Stein, R. Nudel, I. Lieder, Yaron Mazor, S. Kaplan, Dvir Dahary, D. Warshawsky, Yaron Guan-Golan, Asher Kohn, N. Rappaport, M. Safran, D. Lancet\n",
            "Venue :  Current Protocols in Bioinformatics\n",
            "year :  2016\n",
            "Abstract :  GeneCards, the human gene compendium, enables researchers to effectively navigate and inter‐relate the wide universe of human genes, diseases, variants, proteins, cells, and biological pathways. Our recently launched Version 4 has a revamped infrastructure facilitating faster data updates, better‐targeted data queries, and friendlier user experience. It also provides a stronger foundation for the GeneCards suite of companion databases and analysis tools. Improved data unification includes gene‐disease links via MalaCards and merged biological pathways via PathCards, as well as drug information and proteome expression. VarElect, another suite member, is a phenotype prioritizer for next‐generation sequencing, leveraging the GeneCards and MalaCards knowledgebase. It automatically infers direct and indirect scored associations between hundreds or even thousands of variant‐containing genes and disease phenotype terms. VarElect's capabilities, either independently or within TGex, our comprehensive variant analysis pipeline, help prepare for the challenge of clinical projects that involve thousands of exome/genome NGS analyses. © 2016 by John Wiley & Sons, Inc.\n",
            "------------------------------------\n",
            "Title :  Granular Computing Approach to Two-Way Learning Based on Formal Concept Analysis in Fuzzy Datasets\n",
            "Author/s :  Weihua Xu, Wentao Li\n",
            "Venue :  IEEE Transactions on Cybernetics\n",
            "year :  2016\n",
            "Abstract :  The main task of granular computing (GrC) is about representing, constructing, and processing information granules. Information granules are formalized in many different approaches. Different formal approaches emphasize the same fundamental facet in different ways. In this paper, we propose a novel GrC method of machine learning by using formal concept description of information granules. Based on information granules, the model and mechanism of two-way learning system is constructed in fuzzy datasets. It is addressed about how to train arbitrary fuzzy information granules to become necessary, sufficient, and necessary and sufficient fuzzy information granules. Moreover, an algorithm of the presented approach is established, and the complexity of the algorithm is analyzed carefully. Finally, to interpret and help understand the theories and algorithm, a real-life case study is considered and experimental evaluation is performed by five datasets from the University of California-Irvine, which is valuable for applying these theories to deal with practical issues.\n",
            "------------------------------------\n",
            "Title :  Nonprice incentives and energy conservation\n",
            "Author/s :  O. Asensio, M. Delmas\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance We investigate the effectiveness of nonprice incentives to motivate conservation behavior. We test whether tailored information about environmental and health damages produces behavior change in the residential electricity sector. In a randomized controlled trial with real-time appliance-level energy metering over 8 mo, we find that environment and health-based information strategies outperform monetary savings information to drive energy conservation. Environment and health-based messages, which communicate the environmental and public health externalities of electricity production—such as pounds of pollutants, childhood asthma, and cancer—motivated 8% energy savings versus control. This strategy was particularly effective on families with children, who achieved 19% energy savings. However, we do not study the persistence of these behavioral changes after the conclusion of the study. In the electricity sector, energy conservation through technological and behavioral change is estimated to have a savings potential of 123 million metric tons of carbon per year, which represents 20% of US household direct emissions in the United States. In this article, we investigate the effectiveness of nonprice information strategies to motivate conservation behavior. We introduce environment and health-based messaging as a behavioral strategy to reduce energy use in the home and promote energy conservation. In a randomized controlled trial with real-time appliance-level energy metering, we find that environment and health-based information strategies, which communicate the environmental and public health externalities of electricity production, such as pounds of pollutants, childhood asthma, and cancer, outperform monetary savings information to drive behavioral change in the home. Environment and health-based information treatments motivated 8% energy savings versus control and were particularly effective on families with children, who achieved up to 19% energy savings. Our results are based on a panel of 3.4 million hourly appliance-level kilowatt–hour observations for 118 residences over 8 mo. We discuss the relative impacts of both cost-savings information and environmental health messaging strategies with residential consumers.\n",
            "------------------------------------\n",
            "Title :  ‘It's on my iPhone’: attitudes to the use of mobile computing devices in medical education, a mixed-methods study\n",
            "Author/s :  Sean Wallace, Marcia L Clark, J. White\n",
            "Venue :  BMJ Open\n",
            "year :  2012\n",
            "Abstract :  Objective The last decade has seen the introduction of new technology which has transformed many aspects of our culture, commerce, communication and education. This study examined how medical teachers and learners are using mobile computing devices such as the iPhone in medical education and practice, and how they envision them being used in the future. Design Semistructured interviews were conducted with medical students, residents and faculty to examine participants’ attitudes about the current and future use of mobile computing devices in medical education and practice. A thematic approach was used to summarise ideas and concepts expressed, and to develop an online survey. A mixed methods approach was used to integrate qualitative and quantitative findings. Setting and participants Medical students, residents and faculty at a large Canadian medical school in 2011. Results Interviews were conducted with 18 participants (10 students, 7 residents and 1 faculty member). Only 213 participants responded to the online survey (76 students, 65 residents and 41 faculty members). Over 85% of participants reported using a mobile-computing device. The main uses described for mobile devices related to information management, communication and time management. Advantages identified were portability, flexibility, access to multimedia and the ability to look up information quickly. Challenges identified included: superficial learning, not understanding how to find good learning resources, distraction, inappropriate use and concerns about access and privacy. Both medical students and physicians expressed the view that the use of these devices in medical education and practice will increase in the future. Conclusions This new technology offers the potential to enhance learning and patient care, but also has potential problems associated with its use. It is important for leadership in medical schools and healthcare organisations to set the agenda in this rapidly developing area to maximise the benefits of this powerful new technology while avoiding unintended consequences.\n",
            "------------------------------------\n",
            "Title :  HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning\n",
            "Author/s :  Tao-yang Fu, Wang-Chien Lee, Zhen Lei\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2017\n",
            "Abstract :  In this paper, we propose a novel representation learning framework, namely HIN2Vec, for heterogeneous information networks (HINs). The core of the proposed framework is a neural network model, also called HIN2Vec, designed to capture the rich semantics embedded in HINs by exploiting different types of relationships among nodes. Given a set of relationships specified in forms of meta-paths in an HIN, HIN2Vec carries out multiple prediction training tasks jointly based on a target set of relationships to learn latent vectors of nodes and meta-paths in the HIN. In addition to model design, several issues unique to HIN2Vec, including regularization of meta-path vectors, node type selection in negative sampling, and cycles in random walks, are examined. To validate our ideas, we learn latent vectors of nodes using four large-scale real HIN datasets, including Blogcatalog, Yelp, DBLP and U.S. Patents, and use them as features for multi-label node classification and link prediction applications on those networks. Empirical results show that HIN2Vec soundly outperforms the state-of-the-art representation learning models for network data, including DeepWalk, LINE, node2vec, PTE, HINE and ESim, by 6.6% to 23.8% of $micro$-$f_1$ in multi-label node classification and 5% to 70.8% of $MAP$ in link prediction.\n",
            "------------------------------------\n",
            "Title :  Predictive Entropy Search for Efficient Global Optimization of Black-box Functions\n",
            "Author/s :  José Miguel Hernández-Lobato, Matthew W. Hoffman, Zoubin Ghahramani\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance.\n",
            "------------------------------------\n",
            "Title :  Information and Communication Technologies\n",
            "Author/s :  R. Szabó, A. Vidács\n",
            "Venue :  Lecture Notes in Computer Science\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The CERT Guide to Insider Threats: How to Prevent, Detect, and Respond to Information Technology Crimes\n",
            "Author/s :  Dawn M. Cappelli, A. Moore, Randall F. Trzeciak\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Since 2001, the CERT Insider Threat Center at Carnegie Mellon Universitys Software Engineering Institute (SEI) has collected and analyzed information about more than seven hundred insider cyber crimes, ranging from national security espionage to theft of trade secrets. The CERT Guide to Insider Threats describes CERTs findings in practical terms, offering specific guidance and countermeasures that can be immediately applied by executives, managers, security officers, and operational staff within any private, government, or military organization. The authors systematically address attacks by all types of malicious insiders, including current and former employees, contractors, business partners, outsourcers, and even cloud-computing vendors. They cover all major types of insider cyber crime: IT sabotage, intellectual property theft, and fraud. For each, they present a crime profile describing how the crime tends to evolve over time, as well as motivations, attack methods, organizational issues, and precursor warnings that could have helped the organization prevent the incident or detect it earlier. Beyond identifying crucial patterns of suspicious behavior, the authors present concrete defensive measures for protecting both systems and data. This book also conveys the big picture of the insider threat problem over time: the complex interactions and unintended consequences of existing policies, practices, technology, insider mindsets, and organizational culture. Most important, it offers actionable recommendations for the entire organization, from executive management and board members to IT, data owners, HR, and legal departments. With this book, you will find out how to Identify hidden signs of insider IT sabotage, theft of sensitive information, and fraud Recognize insider threats throughout the software development life cycle Use advanced threat controls to resist attacks by both technical and nontechnical insiders Increase the effectiveness of existing technical security tools by enhancing rules, configurations, and associated business processes Prepare for unusual insider attacks, including attacks linked to organized crime or the Internet underground By implementing this books security practices, you will be incorporating protection mechanisms designed to resist the vast majority of malicious insider attacks.\n",
            "------------------------------------\n",
            "Title :  Research on information systems failures and successes: Status update and future directions\n",
            "Author/s :  Yogesh Kumar Dwivedi, D. Wastell, Sven Laumer, H. Henriksen, M. Myers, D. Bunker, Amany R. Elbanna, M. Ravishankar, S. Srivastava\n",
            "Venue :  Inf. Syst. Frontiers\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Deep High-Resolution Representation Learning for Human Pose Estimation\n",
            "Author/s :  Ke Sun, Bin Xiao, Dong Liu, Jingdong Wang\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2019\n",
            "Abstract :  In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.\n",
            "------------------------------------\n",
            "Title :  Energy-Efficient Information and Communication Infrastructures in the Smart Grid: A Survey on Interactions and Open Issues\n",
            "Author/s :  M. Erol-Kantarci, H. Mouftah\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2015\n",
            "Abstract :  Smart grid has modernized the way electricity is generated, transported, distributed, and consumed by integrating advanced sensing, communications, and control in the day-to-day operation of the grid. Electricity is a core utility for the functioning of society and for the services provided by information and communication technologies (ICTs). Several concepts of the smart grid, such as dynamic pricing, distributed generation, and demand management, have significantly impacted the operation of ICT services, in particular, communication networks and data centers. Ongoing energy-efficiency and operational expenditures reduction efforts in communication networks and data centers have gained another dimension with those smart grid concepts. In this paper, we provide a comprehensive survey on the smart grid-driven approaches in energy-efficient communications and data centers, and the interaction between smart grid and information and communication infrastructures. Although the studies on smart grid, energy-efficient communications, and green data centers have been separately surveyed in previous studies, to this end, research that falls in the intersection of those fields has not been properly classified and surveyed yet. We start our survey by providing background information on the smart grid and continue with surveying smart grid-driven approaches in energy-efficient communication systems, followed by energy, cost and emission minimizing approaches in data centers, and the corresponding cloud network infrastructure. We discuss the open issues in smart grid-driven approaches in ICTs and point some important research directions such as the distributed renewable energy generation capability-coupled communication infrastructures, optimum energy-efficient network design for the smart grid environment, the impact of green communication techniques on the reliability and latency requirements of smart grid data, workload consolidation with smart grid-awareness, and many more.\n",
            "------------------------------------\n",
            "Title :  Echo Chambers: Emotional Contagion and Group Polarization on Facebook\n",
            "Author/s :  Michela Del Vicario, G. Vivaldo, Alessandro Bessi, Fabiana Zollo, A. Scala, G. Caldarelli, W. Quattrociocchi\n",
            "Venue :  Scientific Reports\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Cognitive Mechanisms of Treatment in Depression\n",
            "Author/s :  J. Roiser, R. Elliott, B. Sahakian\n",
            "Venue :  Neuropsychopharmacology\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Advances in cognitive theory and therapy: the generic cognitive model.\n",
            "Author/s :  A. Beck, Emily A P Haigh\n",
            "Venue :  Annual Review of Clinical Psychology\n",
            "year :  2014\n",
            "Abstract :  For over 50 years, Beck's cognitive model has provided an evidence-based way to conceptualize and treat psychological disorders. The generic cognitive model represents a set of common principles that can be applied across the spectrum of psychological disorders. The updated theoretical model provides a framework for addressing significant questions regarding the phenomenology of disorders not explained in previous iterations of the original model. New additions to the theory include continuity of adaptive and maladaptive function, dual information processing, energizing of schemas, and attentional focus. The model includes a theory of modes, an organization of schemas relevant to expectancies, self-evaluations, rules, and memories. A description of the new theoretical model is followed by a presentation of the corresponding applied model, which provides a template for conceptualizing a specific disorder and formulating a case. The focus on beliefs differentiates disorders and provides a target for treatment. A variety of interventions are described.\n",
            "------------------------------------\n",
            "Title :  Evidence from internet search data shows information-seeking responses to news of local COVID-19 cases\n",
            "Author/s :  A. Bento, Thuy Nguyen, Coady Wing, Felipe Lozano-Rojas, Yong-Yeol Ahn, K. Simon\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2020\n",
            "Abstract :  The COVID-19 outbreak is a global pandemic with community circulation in many countries, including the United States, with confirmed cases in all states. The course of this pandemic will be shaped by how governments enact timely policies and disseminate information and by how the public reacts to policies and information. Here, we examine information-seeking responses to the first COVID-19 case public announcement in a state. Using an event study framework for all US states, we show that such news increases collective attention to the crisis right away. However, the elevated level of attention is short-lived, even though the initial announcements are followed by increasingly strong policy measures. Specifically, searches for “coronavirus” increased by about 36% (95% CI: 27 to 44%) on the day immediately after the first case announcement but decreased back to the baseline level in less than a week or two. We find that people respond to the first report of COVID-19 in their state by immediately seeking information about COVID-19, as measured by searches for coronavirus, coronavirus symptoms, and hand sanitizer. On the other hand, searches for information regarding community-level policies (e.g., quarantine, school closures, testing) or personal health strategies (e.g., masks, grocery delivery, over-the-counter medications) do not appear to be immediately triggered by first reports. These results are representative of the study period being relatively early in the epidemic, and more-elaborate policy responses were not yet part of the public discourse. Further analysis should track evolving patterns of responses to subsequent flows of public information.\n",
            "------------------------------------\n",
            "Title :  Recognizing actions using depth motion maps-based histograms of oriented gradients\n",
            "Author/s :  Xiaodong Yang, Chenyang Zhang, Yingli Tian\n",
            "Venue :  ACM Multimedia\n",
            "year :  2012\n",
            "Abstract :  In this paper, we propose an effective method to recognize human actions from sequences of depth maps, which provide additional body shape and motion information for action recognition. In our approach, we project depth maps onto three orthogonal planes and accumulate global activities through entire video sequences to generate the Depth Motion Maps (DMM). Histograms of Oriented Gradients (HOG) are then computed from DMM as the representation of an action video. The recognition results on Microsoft Research (MSR) Action3D dataset show that our approach significantly outperforms the state-of-the-art methods, although our representation is much more compact. In addition, we investigate how many frames are required in our framework to recognize actions on the MSR Action3D dataset. We observe that a short sub-sequence of 30-35 frames is sufficient to achieve comparable results to that operating on entire video sequences.\n",
            "------------------------------------\n",
            "Title :  Millimeter-Wave Vehicular Communication to Support Massive Automotive Sensing\n",
            "Author/s :  Junil Choi, Vutha Va, N. G. Prelcic, R. Daniels, C. Bhat, R. Heath\n",
            "Venue :  IEEE Communications Magazine\n",
            "year :  2016\n",
            "Abstract :  As driving becomes more automated, vehicles are being equipped with more sensors generating even higher data rates. Radars are used for object detection, visual cameras as virtual mirrors, and LIDARs for generating high resolution depth associated range maps, all to enhance the safety and efficiency of driving. Connected vehicles can use wireless communication to exchange sensor data, allowing them to enlarge their sensing range and improve automated driving functions. Unfortunately, conventional technologies, such as DSRC and 4G cellular communication, do not support the gigabit-per-second data rates that would be required for raw sensor data exchange between vehicles. This article makes the case that mmWave communication is the only viable approach for high bandwidth connected vehicles. The motivations and challenges associated with using mmWave for vehicle-to-vehicle and vehicle-to-infrastructure applications are highlighted. A high-level solution to one key challenge - the overhead of mmWave beam training - is proposed. The critical feature of this solution is to leverage information derived from the sensors or DSRC as side information for the mmWave communication link configuration. Examples and simulation results show that the beam alignment overhead can be reduced by using position information obtained from DSRC.\n",
            "------------------------------------\n",
            "Title :  The Role of the Board in the Dissemination of Integrated Corporate Social Reporting\n",
            "Author/s :  José-Valeriano Frías-Aceituno, Lázaro Rodríguez‐Ariza, I. García‐Sánchez\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The stakeholder theory recognizes that, besides shareholders and creditors, there exists a broad range of agents who are interested in companies' attitudes towards sustainability. Through corporate social reporting, the social and environmental effects of companies' economic actions are communicated to interest groups. However, the information contained in financial and social reports tends to be presented quite separately from that in the others, and this may lead to confusion among users. Therefore, several major companies have introduced an integrated reporting system, which coherently summarizes the information available, thus making stakeholders participants in business management. \n",
            " \n",
            "Corporate governance mechanisms such as the Board of Directors play an important role in good practices of corporate social responsibility, implementing policies of stakeholder engagement, including processes to achieve holistic transparency. \n",
            " \n",
            "The aim of this paper is to demonstrate the influence played by certain features of the Board of Directors in the degree of information integration presented by leading non-financial multinational firms. Specifically, we examined 568 companies from 15 countries, for the period 2008–2010. The results obtained show that growth opportunities, the size of a company and its management bodies, together with gender diversity, are the most important factors in the integrated dissemination of information. This effect has been confirmed for the Anglo-Saxon, Germanic and Latin models of corporate governance. Copyright © 2012 John Wiley & Sons, Ltd and ERP Environment\n",
            "------------------------------------\n",
            "Title :  A General Self-Organized Tree-Based Energy-Balance Routing Protocol for Wireless Sensor Network\n",
            "Author/s :  Zhao Han, Jie Wu, Jie Zhang, Liefeng Liu, Kaiyun Tian\n",
            "Venue :  IEEE Transactions on Nuclear Science\n",
            "year :  2012\n",
            "Abstract :  Wireless sensor network (WSN) is a system composed of a large number of low-cost micro-sensors. This network is used to collect and send various kinds of messages to a base station (BS). WSN consists of low-cost nodes with limited battery power, and the battery replacement is not easy for WSN with thousands of physically embedded nodes, which means energy efficient routing protocol should be employed to offer a long-life work time. To achieve the aim, we need not only to minimize total energy consumption but also to balance WSN load. Researchers have proposed many protocols such as LEACH, HEED, PEGASIS, TBC and PEDAP. In this paper, we propose a General Self-Organized Tree-Based Energy-Balance routing protocol (GSTEB) which builds a routing tree using a process where, for each round, BS assigns a root node and broadcasts this selection to all sensor nodes. Subsequently, each node selects its parent by considering only itself and its neighbors' information, thus making GSTEB a dynamic protocol. Simulation results show that GSTEB has a better performance than other protocols in balancing energy consumption, thus prolonging the lifetime of WSN.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Classification of Hyperspectral Data Based on Deep Belief Network\n",
            "Author/s :  Yushi Chen, Xing Zhao, X. Jia\n",
            "Venue :  IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "year :  2015\n",
            "Abstract :  Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title :  Context dependent recurrent neural network language model\n",
            "Author/s :  Tomas Mikolov, G. Zweig\n",
            "Venue :  Spoken Language Technology Workshop\n",
            "year :  2012\n",
            "Abstract :  Recurrent neural network language models (RNNLMs) have recently demonstrated state-of-the-art performance across a variety of tasks. In this paper, we improve their performance by providing a contextual real-valued input vector in association with each word. This vector is used to convey contextual information about the sentence being modeled. By performing Latent Dirichlet Allocation using a block of preceding text, we achieve a topic-conditioned RNNLM. This approach has the key advantage of avoiding the data fragmentation associated with building multiple topic models on different data subsets. We report perplexity results on the Penn Treebank data, where we achieve a new state-of-the-art. We further apply the model to the Wall Street Journal speech recognition task, where we observe improvements in word-error-rate.\n",
            "------------------------------------\n",
            "Title :  Therapeutic target database 2020: enriched resource for facilitating research and early development of targeted therapeutics\n",
            "Author/s :  Yunxia Wang, Song-zhao Zhang, Fengcheng Li, Ying Zhou, Ying Zhang, Zhengwen Wang, Runyuan Zhang, Jiang Zhu, Yuxiang Ren, Ying Tan, C. Qin, Yinghong Li, Xiaoxu Li, Yuzong Chen, Feng Zhu\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2019\n",
            "Abstract :  Abstract Knowledge of therapeutic targets and early drug candidates is useful for improved drug discovery. In particular, information about target regulators and the patented therapeutic agents facilitates research regarding druggability, systems pharmacology, new trends, molecular landscapes, and the development of drug discovery tools. To complement other databases, we constructed the Therapeutic Target Database (TTD) with expanded information about (i) target-regulating microRNAs and transcription factors, (ii) target-interacting proteins, and (iii) patented agents and their targets (structures and experimental activity values if available), which can be conveniently retrieved and is further enriched with regulatory mechanisms or biochemical classes. We also updated the TTD with the recently released International Classification of Diseases ICD-11 codes and additional sets of successful, clinical trial, and literature-reported targets that emerged since the last update. TTD is accessible at http://bidd.nus.edu.sg/group/ttd/ttd.asp. In case of possible web connectivity issues, two mirror sites of TTD are also constructed (http://db.idrblab.org/ttd/ and http://db.idrblab.net/ttd/).\n",
            "------------------------------------\n",
            "Title :  DKN: Deep Knowledge-Aware Network for News Recommendation\n",
            "Author/s :  Hongwei Wang, Fuzheng Zhang, Xing Xie, M. Guo\n",
            "Venue :  The Web Conference\n",
            "year :  2018\n",
            "Abstract :  Online news recommender systems aim to address the information explosion of news and make personalized recommendation for users. In general, news language is highly condensed, full of knowledge entities and common sense. However, existing methods are unaware of such external knowledge and cannot fully discover latent knowledge-level connections among news. The recommended results for a user are consequently limited to simple patterns and cannot be extended reasonably. To solve the above problem, in this paper, we propose a deep knowledge-aware network (DKN) that incorporates knowledge graph representation into news recommendation. DKN is a content-based deep recommendation framework for click-through rate prediction. The key component of DKN is a multi-channel and word-entity-aligned knowledge-aware convolutional neural network (KCNN) that fuses semantic-level and knowledge-level representations of news. KCNN treats words and entities as multiple channels, and explicitly keeps their alignment relationship during convolution. In addition, to address users» diverse interests, we also design an attention module in DKN to dynamically aggregate a user»s history with respect to current candidate news. Through extensive experiments on a real online news platform, we demonstrate that DKN achieves substantial gains over state-of-the-art deep recommendation models. We also validate the efficacy of the usage of knowledge in DKN.\n",
            "------------------------------------\n",
            "Title :  Blockchain Disruption and Smart Contracts\n",
            "Author/s :  L. Cong, Zhiguo He\n",
            "Venue :  The Review of financial studies\n",
            "year :  2018\n",
            "Abstract :  Blockchain technology provides decentralized consensus and potentially enlarges the contracting space using smart contracts with tamper-proofness and algorithmic executions. Meanwhile, generating decentralized consensus entails distributing information which necessarily alters the informational environment. We analyze how decentralization affects consensus effectiveness, and how the quintessential features of blockchain reshape industrial organization and the landscape of competition. Smart contracts can mitigate informational asymmetry and improve welfare and consumer surplus through enhanced entry and competition, yet the irreducible distribution of information during consensus generation may encourage greater collusion. In general, blockchains can sustain market equilibria with a wider range of economic outcomes. We further discuss anti-trust policy implications targeted to blockchain applications, such as separating consensus record-keepers from users.\n",
            "------------------------------------\n",
            "Title :  Correlates of Health-Related Social Media Use Among Adults\n",
            "Author/s :  R. Thackeray, B. Crookston, J. West\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2013\n",
            "Abstract :  Background Sixty percent of Internet users report using the Internet to look for health information. Social media sites are emerging as a potential source for online health information. However, little is known about how people use social media for such purposes. Objectives The purpose of this study was two-fold: (1) to establish the frequency of various types of online health-seeking behaviors, and (2) to identify correlates of 2 health-related online activities, social networking sites (SNS) for health-related activities and consulting online user-generated content for answers about health care providers, health facilities, or medical treatment. Methods The study consisted of a telephone survey of 1745 adults who reported going online to look for health-related information. Four subscales were created to measure use of online resources for (1) using SNS for health-related activities; (2) consulting online rankings and reviews of doctors, hospitals or medical facilities, and drugs or medical treatments; (3) posting a review online of doctors, hospitals or medical facilities, and drugs or medical treatments, and (4) posting a comment or question about health or medical issues on various social media. Univariate and multivariate logistic regression analyses were performed. Results Respondents consulted online rankings or reviews (41.15%), used SNS for health (31.58%), posted reviews (9.91%), and posted a comment, question, or information (15.19%). Respondents with a chronic disease were nearly twice as likely to consult online rankings (odds ratio [OR] 2.09, 95% CI 1.66-2.63, P<.001). Lower odds of consulting online reviews were associated with less formal education (OR 0.49, 95% CI 0.37-0.65, P<.001) and being male (OR 0.71, 95% CI 0.57-0.87, P<.001). Respondents with higher incomes were 1.5 times as likely to consult online rankings or reviews (OR 1.49, 95% CI 0.10-2.24, P=.05), than respondents with a regular provider (OR 2.05, 95% CI 1.52-2.78, P<.001), or living in an urban/suburban location (OR 1.61, 95% CI 1.17-2.22, P<.001). Older respondents were less likely to use SNS for health-related activities (OR 0.96, 95% CI 0.95-0.97, P<.001), as were males (OR 0.70, 95% CI 0.56-0.87, P<.001), whereas respondents with a regular provider had nearly twice the likelihood of using SNS for health-related activities (OR 1.89, 95% CI 1.43-2.52, P<.001). Conclusions People are using social media for seeking health information. However, individuals are more likely to consume information than they are to contribute to the dialog. The inherent value of “social” in social media is not being captured with online health information seeking. People with a regular health care provider, chronic disease, and those in younger age groups are more likely to consult online rankings and reviews and use SNS for health-related activities.\n",
            "------------------------------------\n",
            "Title :  Deep Collaborative Filtering via Marginalized Denoising Auto-encoder\n",
            "Author/s :  Sheng Li, Jaya Kawale, Y. Fu\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2015\n",
            "Abstract :  Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.\n",
            "------------------------------------\n",
            "Title :  Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-Temporal Path Proposals\n",
            "Author/s :  Yantao Shen, Tong Xiao, Hongsheng Li, Shuai Yi, Xiaogang Wang\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2017\n",
            "Abstract :  Vehicle re-identification is an important problem and has many applications in video surveillance and intelligent transportation. It gains increasing attention because of the recent advances of person re-identification techniques. However, unlike person re-identification, the visual differences between pairs of vehicle images are usually subtle and even challenging for humans to distinguish. Incorporating additional spatio-temporal information is vital for solving the challenging re-identification task. Existing vehicle re-identification methods ignored or used oversimplified models for the spatio-temporal relations between vehicle images. In this paper, we propose a two-stage framework that incorporates complex spatio-temporal information for effectively regularizing the re-identification results. Given a pair of vehicle images with their spatiotemporal information, a candidate visual-spatio-temporal path is first generated by a chain MRF model with a deeply learned potential function, where each visual-spatiotemporal state corresponds to an actual vehicle image with its spatio-temporal information. A Siamese-CNN+Path- LSTM model takes the candidate path as well as the pairwise queries to generate their similarity score. Extensive experiments and analysis show the effectiveness of our proposed method and individual components.\n",
            "------------------------------------\n",
            "Title :  Predictive information in a sensory population\n",
            "Author/s :  S. Palmer, O. Marre, Michael J. Berry, W. Bialek\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2013\n",
            "Abstract :  Significance Prediction is an essential part of life. However, are we really “good” at making predictions? More specifically, are pieces of our brain close to being optimal predictors? To assess the efficiency of prediction, we need to measure the information that neurons carry about the future of our sensory experiences. We show how to do this, at least in simplified contexts, and find that groups of neurons in the retina indeed are close to maximally efficient at separating predictive information from the nonpredictive background. Efficient coding of predictive information is a principle that can be applied at every stage of neural computation. Guiding behavior requires the brain to make predictions about the future values of sensory inputs. Here, we show that efficient predictive computation starts at the earliest stages of the visual system. We compute how much information groups of retinal ganglion cells carry about the future state of their visual inputs and show that nearly every cell in the retina participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons that exhibit feature selectivity that would support predictive computations. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.\n",
            "------------------------------------\n",
            "Title :  Learning Semantic Representations of Users and Products for Document Level Sentiment Classification\n",
            "Author/s :  Duyu Tang, Bing Qin, Ting Liu\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2015\n",
            "Abstract :  Neural network methods have achieved promising results for sentiment classification of text. However, these models only use semantics of texts, while ignoring users who express the sentiment and products which are evaluated, both of which have great influences on interpreting the sentiment of text. In this paper, we address this issue by incorporating userand productlevel information into a neural network approach for document level sentiment classification. Users and products are modeled using vector space models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, productand documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1.\n",
            "------------------------------------\n",
            "Title :  An Empirical Examination of the Antecedents and Consequences of Contribution Patterns in Crowd-Funded Markets\n",
            "Author/s :  Gordon Burtch, A. Ghose, S. Wattal\n",
            "Venue :  Information systems research\n",
            "year :  2013\n",
            "Abstract :  Crowd-funded markets have recently emerged as a novel source of capital for entrepreneurs. As the economic potential of these markets is now being realized, they are beginning to go mainstream, a trend reflected by the explicit attention crowdfunding has received in the American Jobs Act as a potential avenue for economic growth, as well as the recent focus that regulators such as the U.S. Securities and Exchange Commission have placed upon it. Although the formulation of regulation and policy surrounding crowd-funded markets is becoming increasingly important, the behavior of crowdfunders, an important aspect that must be considered in this formulation effort, is not yet well understood. A key factor that can influence the behavior of crowd funders is information on prior contribution behavior, including the amount and timing of others’ contributions, which is published for general consumption. With that in mind, in this study, we empirically examine social influence in a crowd-funded marketplace for online journalism projects, employing a unique data set that incorporates contribution events and Web traffic statistics for approximately 100 story pitches. This data set allows us to examine both the antecedents and consequences of the contribution process. First, noting that digital journalism is a form of public good, we evaluate the applicability of two competing classes of economic models that explain private contribution toward public goods in the presence of social information: substitution models and reinforcement models. We also propose a new measure that captures both the amount and the timing of others’ contribution behavior: contribution frequency (dollars per unit time). We find evidence in support of a substitution model, which suggests a partial crowding-out effect, where contributors may experience a decrease in their marginal utility from making a contribution as it becomes less important to the recipient. Further, we find that the duration of funding and, more importantly, the degree of exposure that a pitch receives over the course of the funding process, are positively associated with readership upon the story’s publication. This appears to validate the widely held belief that a key benefit of the crowdfunding model is the potential it offers for awareness and attention-building around causes and ventures. This last aspect is a major contribution of the study, as it demonstrates a clear linkage between marketing effort and the success of crowd-funded projects.\n",
            "------------------------------------\n",
            "Title :  Fairness for Non-Orthogonal Multiple Access in 5G Systems\n",
            "Author/s :  S. Timotheou, I. Krikidis\n",
            "Venue :  IEEE Signal Processing Letters\n",
            "year :  2015\n",
            "Abstract :  In non-orthogonal multiple access (NOMA) downlink, multiple data flows are superimposed in the power domain and user decoding is based on successive interference cancellation. NOMA's performance highly depends on the power split among the data flows and the associated power allocation (PA) problem. In this letter, we study NOMA from a fairness standpoint and we investigate PA techniques that ensure fairness for the downlink users under i) instantaneous channel state information (CSI) at the transmitter, and ii) average CSI. Although the formulated problems are non-convex, we have developed low-complexity polynomial algorithms that yield the optimal solution in both cases considered.\n",
            "------------------------------------\n",
            "Title :  The Effect of Economic Policy Uncertainty on Investor Information Asymmetry and Management Disclosures\n",
            "Author/s :  Venky Nagar, Jordan Schoenfeld, Laura A. Wellman\n",
            "Venue :  Journal of Accounting & Economics\n",
            "year :  2018\n",
            "Abstract :  Abstract Investor uncertainty about firm value drives investors’ information collection and trading activities, as well as managers’ disclosure choices. This study examines an important source of uncertainty that likely cannot be influenced by most managers and investors: uncertainty about government economic policy. We find that this uncertainty is associated with increased bid-ask spreads and decreased stock price reactions to earnings surprises. Managers respond to this uncertainty by increasing their voluntary disclosures, but these disclosures only partly mitigate the bid-ask spread increase. We conclude that government economic policy uncertainty is an important component of firms’ information environments and managers’ voluntary disclosure decisions.\n",
            "------------------------------------\n",
            "Title :  How Much Information?: Effects of Transparency on Trust in an Algorithmic Interface\n",
            "Author/s :  René F. Kizilcec\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2016\n",
            "Abstract :  The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online field experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justification of perceived inconsistency. Designing for trust requires balanced interface transparency - not too little and not too much.\n",
            "------------------------------------\n",
            "Title :  Attributed Social Network Embedding\n",
            "Author/s :  Lizi Liao, Xiangnan He, Hanwang Zhang, Tat-Seng Chua\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2017\n",
            "Abstract :  Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Attributed Social Network Embedding framework (ASNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, ASNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, ASNE significantly outperforms  node2vec with an 8.2 percent relative improvement on the link prediction task, and a 12.7 percent gain on the node classification task.\n",
            "------------------------------------\n",
            "Title :  Variable selection with stepwise and best subset approaches.\n",
            "Author/s :  Wentao Bao\n",
            "Venue :  Annals of Translational Medicine\n",
            "year :  2016\n",
            "Abstract :  While purposeful selection is performed partly by software and partly by hand, the stepwise and best subset approaches are automatically performed by software. Two R functions stepAIC() and bestglm() are well designed for stepwise and best subset regression, respectively. The stepAIC() function begins with a full or null model, and methods for stepwise regression can be specified in the direction argument with character values \"forward\", \"backward\" and \"both\". The bestglm() function begins with a data frame containing explanatory variables and response variables. The response variable should be in the last column. Varieties of goodness-of-fit criteria can be specified in the IC argument. The Bayesian information criterion (BIC) usually results in more parsimonious model than the Akaike information criterion.\n",
            "------------------------------------\n",
            "Title :  Prefrontal–hippocampal interactions in episodic memory\n",
            "Author/s :  H. Eichenbaum\n",
            "Venue :  Nature Reviews Neuroscience\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Editorial - Big Data, Data Science, and Analytics: The Opportunity and Challenge for IS Research\n",
            "Author/s :  Ritu Agarwal, V. Dhar\n",
            "Venue :  Information systems research\n",
            "year :  2014\n",
            "Abstract :  We address key questions related to the explosion of interest in the emerging fields of big data, analytics, and data science. We discuss the novelty of the fields and whether the underlying questions are fundamentally different, the strengths that the information systems IS community brings to this discourse, interesting research questions for IS scholars, the role of predictive and explanatory modeling, and how research in this emerging area should be evaluated for contribution and significance.\n",
            "------------------------------------\n",
            "Title :  Comparing Online and Offline Self-Disclosure: A Systematic Review\n",
            "Author/s :  M. Nguyen, Y. Bin, A. Campbell\n",
            "Venue :  Cyberpsychology, Behavior, and Social Networking\n",
            "year :  2012\n",
            "Abstract :  Disclosure of personal information is believed to be more frequent in online compared to offline communication. However, this assumption is both theoretically and empirically contested. This systematic review examined existing research comparing online and offline self-disclosure to ascertain the evidence for current theories of online communication. Studies that compared online and offline disclosures in dyadic interactions were included for review. Contrary to expectations, disclosure was not consistently found to be greater in online contexts. Factors such as the relationship between the communicators, the specific mode of communication, and the context of the interaction appear to moderate the degree of disclosure. In relation to the theories of online communication, there is support for each theory. It is argued that the overlapping predictions of each theory and the current state of empirical research highlights a need for an overarching theory of communication that can account for disclosure in both online and offline interactions.\n",
            "------------------------------------\n",
            "Title :  High-dimensional quantum cryptography with twisted light\n",
            "Author/s :  M. Mirhosseini, O. Magaña-Loaiza, M. O’Sullivan, B. Rodenburg, M. Malik, M. Lavery, M. Padgett, D. Gauthier, R. Boyd\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Quantum key distribution (QKD) systems often rely on polarization of light for encoding, thus limiting the amount of information that can be sent per photon and placing tight bounds on the error rates that such a system can tolerate. Here we describe a proof-of-principle experiment that indicates the feasibility of high-dimensional QKD based on the transverse structure of the light field allowing for the transfer of more than 1 bit per photon. Our implementation uses the orbital angular momentum (OAM) of photons and the corresponding mutually unbiased basis of angular position (ANG). Our experiment uses a digital micro-mirror device for the rapid generation of OAM and ANG modes at 4 kHz, and a mode sorter capable of sorting single photons based on their OAM and ANG content with a separation efficiency of 93%. Through the use of a seven-dimensional alphabet encoded in the OAM and ANG bases, we achieve a channel capacity of 2.05 bits per sifted photon. Our experiment demonstrates that, in addition to having an increased information capacity, multilevel QKD systems based on spatial-mode encoding can be more resilient against intercept-resend eavesdropping attacks.\n",
            "------------------------------------\n",
            "Title :  Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks\n",
            "Author/s :  Massimo Quadrana, Alexandros Karatzoglou, Balázs Hidasi, P. Cremonesi\n",
            "Venue :  ACM Conference on Recommender Systems\n",
            "year :  2017\n",
            "Abstract :  Session-based recommendations are highly relevant in many modern on-line services (e.g. e-commerce, video streaming) and recommendation settings. Recently, Recurrent Neural Networks have been shown to perform very well in session-based settings. While in many session-based recommendation domains user identifiers are hard to come by, there are also domains in which user profiles are readily available. We propose a seamless way to personalize RNN models with cross-session information transfer and devise a Hierarchical RNN model that relays end evolves latent hidden states of the RNNs across user sessions. Results on two industry datasets show large improvements over the session-only RNNs.\n",
            "------------------------------------\n",
            "Title :  Does Mandatory IFRS Adoption Improve Information Comparability?\n",
            "Author/s :  Rita W. Y. Yip, Danqing Young\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  ABSTRACT: This study examines whether the mandatory adoption of International Financial Reporting Standards (IFRS) in the European Union significantly improves information comparability in 17 European countries. We employ three proxies—the similarity of accounting functions that translate economic events into accounting data, the degree of information transfer, and the similarity of the information content of earnings and of the book value of equity—to measure information comparability. Our results suggest that mandatory IFRS adoption improves cross-country information comparability by making similar things look more alike without making different things look less different. Our results also suggest that both accounting convergence and higher quality information under IFRS are the likely drivers of the comparability improvement. In addition, we find some evidence that cross-country comparability improvement is affected by firms' institutional environment. Data Availability: Data are available from commerc...\n",
            "------------------------------------\n",
            "Title :  The Simple Rules of Social Contagion\n",
            "Author/s :  Nathan Oken Hodas, Kristina Lerman\n",
            "Venue :  Scientific Reports\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  New approach for understanding genome variations in KEGG\n",
            "Author/s :  M. Kanehisa, Yoko Sato, Miho Furumichi, Kanae Morishima, M. Tanabe\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2018\n",
            "Abstract :  Abstract KEGG (Kyoto Encyclopedia of Genes and Genomes; https://www.kegg.jp/ or https://www.genome.jp/kegg/) is a reference knowledge base for biological interpretation of genome sequences and other high-throughput data. It is an integrated database consisting of three generic categories of systems information, genomic information and chemical information, and an additional human-specific category of health information. KEGG pathway maps, BRITE hierarchies and KEGG modules have been developed as generic molecular networks with KEGG Orthology nodes of functional orthologs so that KEGG pathway mapping and other procedures can be applied to any cellular organism. Unfortunately, however, this generic approach was inadequate for knowledge representation in the health information category, where variations of human genomes, especially disease-related variations, had to be considered. Thus, we have introduced a new approach where human gene variants are explicitly incorporated into what we call ‘network variants’ in the recently released KEGG NETWORK database. This allows accumulation of knowledge about disease-related perturbed molecular networks caused not only by gene variants, but also by viruses and other pathogens, environmental factors and drugs. We expect that KEGG NETWORK will become another reference knowledge base for the basic understanding of disease mechanisms and practical use in clinical sequencing and drug development.\n",
            "------------------------------------\n",
            "Title :  A Turn Toward Avoidance? Selective Exposure to Online Political Information, 2004–2008\n",
            "Author/s :  R. Garrett, Dustin Carnahan, Emily K. Lynch\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A predictive model for the temporal dynamics of information diffusion in online social networks\n",
            "Author/s :  Adrien Guille, Hakim Hacid\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  Today, online social networks have become powerful tools for the spread of information. They facilitate the rapid and large-scale propagation of content and the consequences of an information -- whether it is favorable or not to someone, false or true -- can then take considerable proportions. Therefore it is essential to provide means to analyze the phenomenon of information dissemination in such networks. Many recent studies have addressed the modeling of the process of information diffusion, from a topological point of view and in a theoretical perspective, but we still know little about the factors involved in it. With the assumption that the dynamics of the spreading process at the macroscopic level is explained by interactions at microscopic level between pairs of users and the topology of their interconnections, we propose a practical solution which aims to predict the temporal dynamics of diffusion in social networks. Our approach is based on machine learning techniques and the inference of time-dependent diffusion probabilities from a multidimensional analysis of individual behaviors. Experimental results on a real dataset extracted from Twitter show the interest and effectiveness of the proposed approach as well as interesting recommendations for future investigation.\n",
            "------------------------------------\n",
            "Title :  Uncertainty, scepticism and attitudes towards climate change: biased assimilation and attitude polarisation\n",
            "Author/s :  A. Corner, L. Whitmarsh, D. Xenias\n",
            "Venue :  Climatic Change\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Wireless powered communication networks: an overview\n",
            "Author/s :  S. Bi, Yong Zeng, Rui Zhang\n",
            "Venue :  IEEE wireless communications\n",
            "year :  2015\n",
            "Abstract :  Wireless powered communication networking (WPCN) is a new networking paradigm where the battery of wireless communication devices can be remotely replenished by means of microwave wireless power transfer (WPT) technology. WPCN eliminates the need for frequent manual battery replacement/recharging, and thus significantly improves the performance over conventional battery-powered communication networks in many aspects, such as higher throughput, longer device lifetime, and lower network operating cost. However, the design and future application of WPCN is essentially challenged by the low WPT efficiency over long distance, and the complex nature of joint wireless information and power transfer within the same network. In this article, we provide an overview of the key networking structures and performance enhancing techniques to build an efficient WPCN. In addition, we point out new and challenging future research directions for WPCN.\n",
            "------------------------------------\n",
            "Title :  SpotFi: Decimeter Level Localization Using WiFi\n",
            "Author/s :  Manikanta Kotaru, K. Joshi, Dinesh Bharadia, S. Katti\n",
            "Venue :  Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication\n",
            "year :  2015\n",
            "Abstract :  This paper presents the design and implementation of SpotFi, an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes, yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First, SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second, it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath.\n",
            "------------------------------------\n",
            "Title :  Are we making a better world with ICTs? Reflections on a future agenda for the IS field\n",
            "Author/s :  G. Walsham\n",
            "Venue :  Journal of Information and Technology\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Pengaruh Investasi Dan Ekspor Terhadap Pertumbuhan Ekonomi Serta Penyerapan Tenaga Kerja Provinsi Kalimantan Timur\n",
            "Author/s :  M. Taufik, Eny Rochaida, Fitriadi Fitriadi\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This research was aims to know the influence of investment and exports on economic growth and Labor recruitment of East Kalimantan Province. The research was analyzed by using model of analysis two lanes performed with SPSS software version 11.5 with data retrival based on primary data of investment, exports, economic growth and labor from BPS of East Kalimantan from 2003 until 2011. Based on analysis way substructure 1 model through F test, showed that the independent variables (investment and exports) have a significant influence on economic growth because the value of the probability of the F-statistic less than standard real (0,008 < 0,08). So it can be said that both free variables used in the model has a real influence on economic growth at 5% level of trust (a=0,05). On the sub structure 2 model, indicates that the three of independent variables (investment, exports, economic growth) has significant effects on the labor recruitment  because probability F statistic’s value is less than real standard used by (0,000 < 0,05). So it can be said which this third free variable has a significant influence to labor reqruitment at 5% level of trust (a=0,05).\n",
            "------------------------------------\n",
            "Title :  BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\n",
            "Author/s :  Andreas Kirsch, Joost R. van Amersfoort, Y. Gal\n",
            "Venue :  Neural Information Processing Systems\n",
            "year :  2019\n",
            "Abstract :  We develop BatchBALD, a tractable approximation to the mutual information between a batch of points and model parameters, which we use as an acquisition function to select multiple informative points jointly for the task of deep Bayesian active learning. BatchBALD is a greedy linear-time $1 - \\frac{1}{e}$-approximate algorithm amenable to dynamic programming and efficient caching. We compare BatchBALD to the commonly used approach for batch data acquisition and find that the current approach acquires similar and redundant points, sometimes performing worse than randomly acquiring data. We finish by showing that, using BatchBALD to consider dependencies within an acquisition batch, we achieve new state of the art performance on standard benchmarks, providing substantial data efficiency improvements in batch acquisition.\n",
            "------------------------------------\n",
            "Title :  Thermodynamics as a theory of decision-making with information-processing costs\n",
            "Author/s :  Pedro A. Ortega, D. Braun\n",
            "Venue :  Proceedings of the Royal Society A\n",
            "year :  2012\n",
            "Abstract :  Perfectly rational decision-makers maximize expected utility, but crucially ignore the resource costs incurred when determining optimal actions. Here, we propose a thermodynamically inspired formalization of bounded rational decision-making where information processing is modelled as state changes in thermodynamic systems that can be quantified by differences in free energy. By optimizing a free energy, bounded rational decision-makers trade off expected utility gains and information-processing costs measured by the relative entropy. As a result, the bounded rational decision-making problem can be rephrased in terms of well-known variational principles from statistical physics. In the limit when computational costs are ignored, the maximum expected utility principle is recovered. We discuss links to existing decision-making frameworks and applications to human decision-making experiments that are at odds with expected utility theory. Since most of the mathematical machinery can be borrowed from statistical physics, the main contribution is to re-interpret the formalism of thermodynamic free-energy differences in terms of bounded rational decision-making and to discuss its relationship to human decision-making experiments.\n",
            "------------------------------------\n",
            "Title :  Building Ontologies with Basic Formal Ontology\n",
            "Author/s :  R. Arp, Barry Smith, Andrew D. Spear\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In the era of \"big data,\" science is increasingly information driven, and the potential for computers to store, manage, and integrate massive amounts of data has given rise to such new disciplinary fields as biomedical informatics. Applied ontology offers a strategy for the organization of scientific information in computer-tractable form, drawing on concepts not only from computer and information science but also from linguistics, logic, and philosophy. This book provides an introduction to the field of applied ontology that is of particular relevance to biomedicine, covering theoretical components of ontologies, best practices for ontology design, and examples of biomedical ontologies in use.After defining an ontology as a representation of the types of entities in a given domain, the book distinguishes between different kinds of ontologies and taxonomies, and shows how applied ontology draws on more traditional ideas from metaphysics. It presents the core features of the Basic Formal Ontology (BFO), now used by over one hundred ontology projects around the world, and offers examples of domain ontologies that utilize BFO. The book also describes Web Ontology Language (OWL), a common framework for Semantic Web technologies. Throughout, the book provides concrete recommendations for the design and construction of domain ontologies.\n",
            "------------------------------------\n",
            "Title :  Experimental realization of a Szilard engine with a single electron\n",
            "Author/s :  J. Koski, V. Maisi, J. Pekola, D. Averin\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2014\n",
            "Abstract :  Significance A Maxwell demon makes use of information to convert thermal energy of a reservoir into work. A quantitative example is a thought experiment known as a Szilard engine, which uses one bit of information about the position of a thermalized molecule in a box to extract kBT ln 2 of work. The second law of thermodynamics remains valid because, according to Landauer principle, erasure of the information dissipates at least the same amount of heat. Here, we present an experimental realization of a Maxwell demon similar to a Szilard engine, in the form of a single electron box. We provide, to our knowledge, the first demonstration of extracting nearly kBT ln 2 of work for one bit of information. The most succinct manifestation of the second law of thermodynamics is the limitation imposed by the Landauer principle on the amount of heat a Maxwell demon (MD) can convert into free energy per single bit of information obtained in a measurement. We propose and realize an electronic MD based on a single-electron box operated as a Szilard engine, where kBT ln 2 of heat is extracted from the reservoir at temperature T per one bit of created information. The information is encoded in the position of an extra electron in the box.\n",
            "------------------------------------\n",
            "Title :  Local E‐Government in the United States: Transformation or Incremental Change?\n",
            "Author/s :  D. Norris, C. Reddick\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  In this article, the authors address the recent trajectory of local e-government in the United States and compare it with the predictions of early e-government writings, using empirical data from two nationwide surveys of e-government among American local governments. The authors find that local e-government has not produced the results that those writings predicted. Instead, its development has largely been incremental, and local e-government is mainly about delivering information and services online, followed by a few transactions and limited interactivity. Local e-government is also mainly one way, from government to citizens, and there is little or no evidence that it is transformative in any way. This disparity between early predictions and actual results is partly attributable to the incremental nature of American public administration. Other reasons include a lack of attention by early writers to the history of information technology in government and the influence of technological determinism on those writings.\n",
            "------------------------------------\n",
            "Title :  Rumor Cascades\n",
            "Author/s :  A. Friggeri, Lada A. Adamic, Dean Eckles, Justin Cheng\n",
            "Venue :  International Conference on Web and Social Media\n",
            "year :  2014\n",
            "Abstract :  \n",
            " \n",
            " Online social networks provide a rich substrate for rumor propagation. Information received via friends tends to be trusted, and online social networks allow individuals to transmit information to many friends at once. By referencing known rumors from Snopes.com, a popular website documenting memes and urban legends, we track the propagation of thousands of rumors appearing on Facebook. From this sample we infer the rates at which rumors from different categories and of varying truth value are uploaded and reshared. We find that rumor cascades run deeper in the social network than reshare cascades in general. We then examine the effect of individual reshares receiving a comment containing a link to a Snopes article on the evolution of the cascade. We find that receiving such a comment increases the likelihood that a reshare of a rumor will be deleted. Furthermore, large cascades are able to accumulate hundreds of Snopes comments while continuing to propagate. Finally, using a dataset of rumors copied and pasted from one status update to another, we show that rumors change over time and that different variants tend to dominate different bursts in popularity.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  A national action plan to support consumer engagement via e-health.\n",
            "Author/s :  L. Ricciardi, F. Mostashari, Judy Murphy, Jodi G. Daniel, Erin P Siminerio\n",
            "Venue :  Health Affairs\n",
            "year :  2013\n",
            "Abstract :  Patient-centered care is considered one pillar of a high-performing, high-quality health care system. It is a key component of many efforts to transform care and achieve better population health. Expansion of health information technology and consumer e-health tools--electronic tools and services such as secure e-mail messaging between patients and providers, or mobile health apps--have created new opportunities for individuals to participate actively in monitoring and directing their health and health care. The Office of the National Coordinator for Health Information Technology in the Department of Health and Human Services leads the strategy to increase electronic access to health information, support the development of tools that enable people to take action with that information, and shift attitudes related to the traditional roles of patients and providers. In this article we review recent evidence in support of consumer e-health and present the federal strategy to promote advances in consumer e-health to increase patient engagement, improve individual health, and achieve broader health care system improvements.\n",
            "------------------------------------\n",
            "Title :  Situation Awareness Misconceptions and Misunderstandings\n",
            "Author/s :  M. Endsley\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Situation awareness (SA) has become a widely used construct within the human factors community, the focus of considerable research over the past 25 years. This research has been used to drive the development of advanced information displays, the design of automated systems, information fusion algorithms, and new training approaches for improving SA in individuals and teams. In recent years, a number of papers criticized the Endsley model of SA on various grounds. I review those criticisms here and show them to be based on misunderstandings of the model. I also review several new models of SA, including situated SA, distributed SA, and sensemaking, in light of this discussion and show how they compare to existing models of SA in individuals and teams.\n",
            "------------------------------------\n",
            "Title :  Everything you wanted to know about smart cities: The Internet of things is the backbone\n",
            "Author/s :  S. Mohanty\n",
            "Venue :  IEEE Consumer Electronics Magazine\n",
            "year :  2016\n",
            "Abstract :  This article is a single-source introduction to the emerging concept of smart cities. It can be used for familiarizing researchers with the vast scope of research possible in this application domain. The smart city is primarily a concept, and there is still not a clear and consistent definition among practitioners and academia. As a simplistic explanation, a smart city is a place where traditional networks and services are made more flexible, efficient, and sustainable with the use of information, digital, and telecommunication technologies to improve the city's operations for the benefit of its inhabitants. Smart cities are greener, safer, faster, and friendlier. The different components of a smart city include smart infrastructure, smart transportation, smart energy, smart health care, and smart technology. These components are what make the cities smart and efficient. Information and communication technology (ICT) are enabling keys for transforming traditional cities into smart cities. Two closely related emerging technology frameworks, the Internet of Things (IoT) and big data (BD), make smart cities efficient and responsive. The technology has matured enough to allow smart cities to emerge. However, there is much needed in terms of physical infrastructure, a smart city, the digital technologies translate into better public services for inhabitants and better use of resources while reducing environmental impacts. One of the formal definitions of the smart city is the following: a city \"connecting the physical infrastructure, the information-technology infrastructure, the social infrastructure, and the business infrastructure to leverage the collective intelligence of the city\". Another formal and comprehensive definition is \"a smart sustainable city is an innovative city that uses information and communication technologies (ICTs) and other means to improve quality of life, efficiency of urban operations and services, and competitiveness, while ensuring that it meets the needs of present and future generations with respect to economic, social and environmental aspects\". Any combination of various smart components can make cities smart. A city need not have all the components to be labeled as smart. The number of smart components depends on the cost and available technology.\n",
            "------------------------------------\n",
            "Title :  When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author/s :  L. Thygesen, A. Ersbøll\n",
            "Venue :  European Journal of Epidemiology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Directional Message Passing for Molecular Graphs\n",
            "Author/s :  Johannes Klicpera, Janek Groß, Stephan Günnemann\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2020\n",
            "Abstract :  Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes) and not the spatial direction from one atom to another. However, directional information plays a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions to construct a theoretically well-founded, orthogonal radial basis that achieves better performance than the currently prevalent Gaussian radial basis functions while using more than 4x fewer parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 77% on MD17 and by 41% on QM9.\n",
            "------------------------------------\n",
            "Title :  T-CNN: Tubelets With Convolutional Neural Networks for Object Detection From Videos\n",
            "Author/s :  Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Binh Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang\n",
            "Venue :  IEEE transactions on circuits and systems for video technology (Print)\n",
            "year :  2016\n",
            "Abstract :  The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks, such as GoogleNet and VGG, novel object detection frameworks, such as R-CNN and its successors, Fast R-CNN, and Faster R-CNN, play an essential role in improving the state of the art. Despite their effectiveness on still images, those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this paper, we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN, i.e., tubelets with convolutional neueral networks. The proposed framework won newly introduced an object-detection-from-video task with provided data in the ImageNet Large-Scale Visual Recognition Challenge 2015. Code is publicly available at https://github.com/myfavouritekk/T-CNN.\n",
            "------------------------------------\n",
            "Title :  The Filter Bubble\n",
            "Author/s :  Eli Pariser\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  : Introduced by tech entrepreneur and activist Eli Pariser in 2011, the ‘filter bubble’ is a persistent concept which suggests that search engines and social media, together with their recommendation and personalisation algorithms, are centrally culpable for the societal and ideological polarisation experienced in many countries: we no longer encounter a balanced and healthy information diet, but only see information that targets our established interests and reinforces our existing worldviews. Filter bubbles are seen as critical enablers of Brexit, Trump, Bolsonaro, and other populist political phenomena, and search and social media companies have been criticised for failing to prevent their development. Yet, there is scant empirical evidence for their existence, or for the related concept of ‘echo chambers’: indeed, search and social media users generally appear to encounter a highly centrist media diet that is, if anything, more diverse than that of non-users. However, the persistent use of these concepts in mainstream media and political debates has now created its own discursive reality that continues to impact materially on societal institutions, media and communication platforms, and ordinary users themselves. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to redirect scholarly attention from far more critical areas of enquiry.\n",
            "------------------------------------\n",
            "Title :  Measuring Information-Transfer Delays\n",
            "Author/s :  M. Wibral, Nicolae Pampu, V. Priesemann, F. Siebenhühner, Hannes Seiwert, Michael Lindner, J. Lizier, Raul Vicente\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  In complex networks such as gene networks, traffic systems or brain circuits it is important to understand how long it takes for the different parts of the network to effectively influence one another. In the brain, for example, axonal delays between brain areas can amount to several tens of milliseconds, adding an intrinsic component to any timing-based processing of information. Inferring neural interaction delays is thus needed to interpret the information transfer revealed by any analysis of directed interactions across brain structures. However, a robust estimation of interaction delays from neural activity faces several challenges if modeling assumptions on interaction mechanisms are wrong or cannot be made. Here, we propose a robust estimator for neuronal interaction delays rooted in an information-theoretic framework, which allows a model-free exploration of interactions. In particular, we extend transfer entropy to account for delayed source-target interactions, while crucially retaining the conditioning on the embedded target state at the immediately previous time step. We prove that this particular extension is indeed guaranteed to identify interaction delays between two coupled systems and is the only relevant option in keeping with Wiener’s principle of causality. We demonstrate the performance of our approach in detecting interaction delays on finite data by numerical simulations of stochastic and deterministic processes, as well as on local field potential recordings. We also show the ability of the extended transfer entropy to detect the presence of multiple delays, as well as feedback loops. While evaluated on neuroscience data, we expect the estimator to be useful in other fields dealing with network dynamics.\n",
            "------------------------------------\n",
            "Title :  Helpfulness of Online Consumer Reviews: Readers' Objectives and Review Cues\n",
            "Author/s :  Hyunmi Baek, Joongho Ahn, Youngseok Choi\n",
            "Venue :  International Journal of Electronic Commerce\n",
            "year :  2012\n",
            "Abstract :  With the growth of e-commerce, online consumer reviews have increasingly become important sources of information that help consumers in their purchase decisions. However, the influx of online consumer reviews has caused information overload, making it difficult for consumers to choose reliable reviews. For an online retail market to succeed, it is important to lead product reviewers to write more helpful reviews, and for consumers to get helpful reviews more easily by figuring out the factors determining the helpfulness of online reviews. For this research, 75,226 online consumer reviews were collected from Amazon.com using a Web data crawler. Additional information on review content was also gathered by carrying out a sentiment analysis for mining review text. Our results show that both peripheral cues, including review rating and reviewer's credibility, and central cues, such as the content of reviews, influence the helpfulness of reviews. Based on dual process theories, we find that consumers focus on different information sources of reviews, depending on their purposes for reading reviews: online reviews can be used for information search or for evaluating alternatives. Our findings provide new perspectives to online market owners on how to manage online reviews on their Web sites.\n",
            "------------------------------------\n",
            "Title :  Background and Data Configuration Process of a Nationwide Population-Based Study Using the Korean National Health Insurance System\n",
            "Author/s :  Sun-Ok Song, C. Jung, Y. Song, Cheol-Young Park, H. Kwon, B. Cha, J. Park, Ki-Up Lee, K. Ko, Byung-wan Lee\n",
            "Venue :  Diabetes & Metabolism Journal\n",
            "year :  2014\n",
            "Abstract :  Background The National Health Insurance Service (NHIS) recently signed an agreement to provide limited open access to the databases within the Korean Diabetes Association for the benefit of Korean subjects with diabetes. Here, we present the history, structure, contents, and way to use data procurement in the Korean National Health Insurance (NHI) system for the benefit of Korean researchers. Methods The NHIS in Korea is a single-payer program and is mandatory for all residents in Korea. The three main healthcare programs of the NHI, Medical Aid, and long-term care insurance (LTCI) provide 100% coverage for the Korean population. The NHIS in Korea has adopted a fee-for-service system to pay health providers. Researchers can obtain health information from the four databases of the insured that contain data on health insurance claims, health check-ups and LTCI. Results Metabolic disease as chronic disease is increasing with aging society. NHIS data is based on mandatory, serial population data, so, this might show the time course of disease and predict some disease progress, and also be used in primary and secondary prevention of disease after data mining. Conclusion The NHIS database represents the entire Korean population and can be used as a population-based database. The integrated information technology of the NHIS database makes it a world-leading population-based epidemiology and disease research platform.\n",
            "------------------------------------\n",
            "Title :  The Real Effects of Financial Shocks: Evidence from Exogenous Changes in Analyst Coverage\n",
            "Author/s :  F. Derrien, Ambrus Kecskés\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  We study the causal effects of analyst coverage on corporate investment and financing policies. We hypothesize that a decrease in analyst coverage increases information asymmetry and thus increases the cost of capital; as a result, firms decrease their investment and financing. We use broker closures and broker mergers to identify changes in analyst coverage that are exogenous to corporate policies. Using a difference-in-differences approach, we find that firms that lose an analyst decrease their investment and financing by 2.4% and 2.6% of total assets, respectively. These results are significantly stronger for firms that are smaller, have less analyst coverage, have a bigger increase in information asymmetry, and are more financially constrained.\n",
            "------------------------------------\n",
            "Title :  The orbitofrontal cortex.\n",
            "Author/s :  E. Rolls\n",
            "Venue :  Philosophical transactions of the Royal Society of London. Series B, Biological sciences\n",
            "year :  2019\n",
            "Abstract :  The orbitofrontal cortex contains the secondary taste cortex, in which the reward value of taste is represented. It also contains the secondary and tertiary olfactory cortical areas, in which information about the identity and also about the reward value of odours is represented. The orbitofrontal cortex also receives information about the sight of objects from the temporal lobe cortical visual areas, and is involved in learning and in reversing stimulus-reinforcement associations. The stimulus might be a visual or olfactory stimulus, and the primary (unlearned) reinforcer a taste or touch. Damage to the orbitofrontal cortex impairs the learning and reversal of stimulus-reinforcement associations, and thus the correction of behavioural responses when these are no longer appropriate because previous reinforcement contingencies change. The information which reaches the orbitofrontal cortex for these functions includes information about faces, and damage to the orbitofrontal cortex can impair face expression identification. This evidence thus shows that the orbitofrontal cortex is involved in decoding some primary reinforcers such as taste; in learning and reversing associations of visual and other stimuli to these primary reinforcers; and plays an executive function in controlling and correcting reward-related and punishment-related behaviour, and thus in emotion.\n",
            "------------------------------------\n",
            "Title :  Selecting optimal partitioning schemes for phylogenomic datasets\n",
            "Author/s :  R. Lanfear, B. Calcott, D. Kainer, C. Mayer, A. Stamatakis\n",
            "Venue :  BMC Evolutionary Biology\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Decentralized Stochastic Control with Partial History Sharing: A Common Information Approach\n",
            "Author/s :  A. Nayyar, Aditya Mahajan, D. Teneketzis\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2012\n",
            "Abstract :  A general model of decentralized stochastic control called partial history sharing information structure is presented. In this model, at each step the controllers share part of their observation and control history with each other. This general model subsumes several existing models of information sharing as special cases. Based on the information commonly known to all the controllers, the decentralized problem is reformulated as an equivalent centralized problem from the perspective of a coordinator. The coordinator knows the common information and selects prescriptions that map each controller's local information to its control actions. The optimal control problem at the coordinator is shown to be a partially observable Markov decision process (POMDP) which is solved using techniques from Markov decision theory. This approach provides 1) structural results for optimal strategies and 2) a dynamic program for obtaining optimal strategies for all controllers in the original decentralized problem. Thus, this approach unifies the various ad-hoc approaches taken in the literature. In addition, the structural results on optimal control strategies obtained by the proposed approach cannot be obtained by the existing generic approach (the person-by-person approach) for obtaining structural results in decentralized problems; and the dynamic program obtained by the proposed approach is simpler than that obtained by the existing generic approach (the designer's approach) for obtaining dynamic programs in decentralized problems.\n",
            "------------------------------------\n",
            "Title :  Research Note - Privacy Concerns and Privacy-Protective Behavior in Synchronous Online Social Interactions\n",
            "Author/s :  Z. Jiang, C. Heng, Ben C. F. Choi\n",
            "Venue :  Information systems research\n",
            "year :  2013\n",
            "Abstract :  Privacy is of prime importance to many individuals when they attempt to develop online social relationships. Nonetheless, it has been observed that individuals' behavior is at times inconsistent with their privacy concerns, e.g., they disclose substantial private information in synchronous online social interactions, even though they are aware of the risks involved. Drawing on the hyperpersonal framework and the privacy calculus perspective, this paper elucidates the interesting roles of privacy concerns and social rewards in synchronous online social interactions by examining the causes and the behavioral strategies that individuals utilize to protect their privacy. An empirical study involving 251 respondents was conducted in online chat rooms. Our results indicate that individuals utilize both self-disclosure and misrepresentation to protect their privacy and that social rewards help explain why individuals may not behave in accordance with their privacy concerns. In addition, we find that perceived anonymity of others and perceived intrusiveness affect both privacy concerns and social rewards. Our findings also suggest that higher perceived anonymity of self decreases individuals' privacy concerns, and higher perceived media richness increases social rewards. Generally, this study contributes to the information systems literature by integrating the hyperpersonal framework and the privacy calculus perspective to identify antecedents of privacy trade-off and predict individuals' behavior in synchronous online social interactions.\n",
            "------------------------------------\n",
            "Title :  From Use to Effective Use: A Representation Theory Perspective\n",
            "Author/s :  A. Burton-Jones, Camille Grange\n",
            "Venue :  Information systems research\n",
            "year :  2013\n",
            "Abstract :  Information systems must be used effectively to obtain maximum benefits from them. However, despite a great deal of research on when and why systems are used, very little research has examined what effective system use involves and what drives it. To move from use to effective use requires understanding an information system's nature and purpose, which in turn requires a theory of information systems. We draw on representation theory, which states that an information system is made up of several structures that serve to represent some part of the world that a user and other stakeholders must understand. From this theory, we derive a high-level framework of how effective use and performance evolve, as well as specific models of the nature and drivers of effective use. The models are designed to explain the effective use of any information system and offer unique insights that would not be offered by traditional views, which tend to consider information systems to be just another tool. We explain how our theory extends existing research, provides a rich platform for research on effective use, and how it contributes back to the theory of information systems from which it was derived.\n",
            "------------------------------------\n",
            "Title :  IEA International Computer and Information Literacy Study 2018 Assessment Framework\n",
            "Author/s :  J. Fraillon, Wolfram Schulz, J. Ainley\n",
            "Venue :  \n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Pyramid Stereo Matching Network\n",
            "Author/s :  Jia-Ren Chang, Yonghao Chen\n",
            "Venue :  2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  Recent work has shown that depth estimation from a stereo pair of images can be formulated as a supervised learning task to be resolved with convolutional neural networks (CNNs). However, current architectures rely on patch-based Siamese networks, lacking the means to exploit context information for finding correspondence in ill-posed regions. To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision. The proposed approach was evaluated on several benchmark datasets. Our method ranked first in the KITTI 2012 and 2015 leaderboards before March 18, 2018. The codes of PSMNet are available at: https://github.com/JiaRenChang/PSMNet.\n",
            "------------------------------------\n",
            "Title :  Advances in communications using optical vortices\n",
            "Author/s :  Jian Wang\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  An optical vortex having an isolated point singularity is associated with the spatial structure of light waves. A polarization vortex (vector beam) with a polarization singularity has spatially variant polarizations. A phase vortex with phase singularity or screw dislocation has a spiral phase front. The optical vortex has recently gained increasing interest in optical trapping, optical tweezers, laser machining, microscopy, quantum information processing, and optical communications. In this paper, we review recent advances in optical communications using optical vortices. First, basic concepts of polarization/phase vortex modulation and multiplexing in communications and key techniques of polarization/phase vortex generation and (de)multiplexing are introduced. Second, free-space and fiber optical communications using optical vortex modulation and optical vortex multiplexing are presented. Finally, key challenges and perspectives of optical communications using optical vortices are discussed. It is expected that optical vortices exploiting the space physical dimension of light waves might find more interesting applications in optical communications and interconnects.\n",
            "------------------------------------\n",
            "Title :  Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author/s :  Sijie Yan, Yuanjun Xiong, Dahua Lin\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2018\n",
            "Abstract :  \n",
            " \n",
            " Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Bridges, brokers and boundary spanners in collaborative networks: a systematic review\n",
            "Author/s :  J. Long, F. Cunningham, J. Braithwaite\n",
            "Venue :  BMC Health Services Research\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Integrated information theory of consciousness: an updated account.\n",
            "Author/s :  G. Tononi\n",
            "Venue :  Archives Italiennes de Biologie\n",
            "year :  2012\n",
            "Abstract :  This article presents an updated account of integrated information theory of consciousness (liT) and some of its implications. /IT stems from thought experiments that lead to phenomenological axioms (existence, compositionality, information, integration, exclusion) and corresponding ontological postulates. The information axiom asserts that every experience is spec~fic - it is what it is by differing in its particular way from a large repertoire of alternatives. The integration axiom asserts that each experience is unified- it cannot be reduced to independent components. The exclusion axiom asserts that every experience is definite - it is limited to particular things and not others and flows at a particular speed and resolution. /IT formalizes these intuitions with postulates. The information postulate states that only \"differences that make a difference\" from the intrinsic perpective of a system matter: a mechanism generates cause-effect information if its present state has selective past causes and selective future effects within a system. The integration postulate states that only information that is irreducible matters: mechanisms generate integrated information only to the extent that the information they generate cannot be partitioned into that generated within independent components. The exclusion postulate states that only maxima of integrated information matter: a mechanism specifies only one maximally irreducible set of past causes and future effects - a concept. A complex is a set of elements specifying a maximally irreducible constellation of concepts, where the maximum is evaluated over elements and at the optimal spatiatemporal scale. Its concepts specify a maximally integrated conceptual information structure or quale, which is identical with an experience. Finally, changes in information integration upon exposure to the environment reflect a system's ability to match the causal structure of the world. After introducing an updated definition of information integration and related quantities, the article presents some theoretical considerations about the relationship between information and causation and about the relational structure of concepts within a qua/e. It also explores the relationship between the temporal grain size of information integration and the dynamic of metastable states in the corticothalamic complex. Finally, it summarizes how liT accounts for empirical findings about the neural substrate of consciousness, and how various aspects of phenomenology may in principle be addressed in terms of the geometry of information integration.\n",
            "------------------------------------\n",
            "Title :  A review on supply chain contracting with information considerations: information updating and information asymmetry\n",
            "Author/s :  Bin Shen, T. Choi, S. Minner\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2019\n",
            "Abstract :  Supply chain contracting and the use of information are undoubtedly two critical and influential areas in modern supply chain management. However, relatively little is known about supply chain contracting mechanisms with different information settings. To fill this gap, we review and classify the related supply chain contracting literature into three categories with respect to different kinds of information considerations, namely (i) demand information updating, (ii) supply information updating and (iii) information asymmetry. We report the publication trend and classify the commonly studied supply chain contracts with the use of information such as pricing contracts, commitment contracts and menu of contracts. We discuss how contracting and the use of information influence each other in the supply chain. Moreover, we review the major application areas of information usage and report the historical development of major related topics. Finally, we propose several important future research directions.\n",
            "------------------------------------\n",
            "Title :  HL7 FHIR: An Agile and RESTful approach to healthcare information exchange\n",
            "Author/s :  D. Bender, K. Sartipi\n",
            "Venue :  Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems\n",
            "year :  2013\n",
            "Abstract :  This research examines the potential for new Health Level 7 (HL7) standard Fast Healthcare Interoperability Resources (FHIR, pronounced “fire”) standard to help achieve healthcare systems interoperability. HL7 messaging standards are widely implemented by the healthcare industry and have been deployed internationally for decades. HL7 Version 2 (“v2”) health information exchange standards are a popular choice of local hospital communities for the exchange of healthcare information, including electronic medical record information. In development for 15 years, HL7 Version 3 (“v3”) was designed to be the successor to Version 2, addressing Version 2's shortcomings. HL7 v3 has been heavily criticized by the industry for being internally inconsistent even in it's own documentation, too complex and expensive to implement in real world systems and has been accused of contributing towards many failed and stalled systems implementations. HL7 is now experimenting with a new approach to the development of standards with FHIR. This research provides a chronicle of the evolution of the HL7 messaging standards, an introduction to HL7 FHIR and a comparative analysis between HL7 FHIR and previous HL7 messaging standards.\n",
            "------------------------------------\n",
            "Title :  The Goldilocks Effect: Human Infants Allocate Attention to Visual Sequences That Are Neither Too Simple Nor Too Complex\n",
            "Author/s :  Celeste Kidd, S. Piantadosi, R. Aslin\n",
            "Venue :  PLoS ONE\n",
            "year :  2012\n",
            "Abstract :  Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants’ visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants’ probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.\n",
            "------------------------------------\n",
            "Title :  Leveraging media and health communication strategies to overcome the COVID-19 infodemic\n",
            "Author/s :  Nour Mheidly, Jawad Fares\n",
            "Venue :  Journal of Public Health Policy\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Towards a definition of the Internet of Things ( IoT )\n",
            "Author/s :  \n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  ion Yes No Partly Availability / Mobility No No No Fault tolerance Partly No Partly Flexibility/Event based Yes Partly Partly Uncertainty of Information No No No\n",
            "------------------------------------\n",
            "Title :  The evolutionary basis of human social learning\n",
            "Author/s :  T. Morgan, L. Rendell, M. Ehn, W. Hoppitt, K. Laland\n",
            "Venue :  Proceedings of the Royal Society B: Biological Sciences\n",
            "year :  2012\n",
            "Abstract :  Humans are characterized by an extreme dependence on culturally transmitted information. Such dependence requires the complex integration of social and asocial information to generate effective learning and decision making. Recent formal theory predicts that natural selection should favour adaptive learning strategies, but relevant empirical work is scarce and rarely examines multiple strategies or tasks. We tested nine hypotheses derived from theoretical models, running a series of experiments investigating factors affecting when and how humans use social information, and whether such behaviour is adaptive, across several computer-based tasks. The number of demonstrators, consensus among demonstrators, confidence of subjects, task difficulty, number of sessions, cost of asocial learning, subject performance and demonstrator performance all influenced subjects' use of social information, and did so adaptively. Our analysis provides strong support for the hypothesis that human social learning is regulated by adaptive learning rules.\n",
            "------------------------------------\n",
            "Title :  How Long to Wait? Predicting Bus Arrival Time With Mobile Phone Based Participatory Sensing\n",
            "Author/s :  Pengfei Zhou, Yuanqing Zheng, Mo Li\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  The bus arrival time is primary information to most city transport travelers. Excessively long waiting time at bus stops often discourages the travelers and makes them reluctant to take buses. In this paper, we present a bus arrival time prediction system based on bus passengers' participatory sensing. With commodity mobile phones, the bus passengers' surrounding environmental context is effectively collected and utilized to estimate the bus traveling routes and predict bus arrival time at various bus stops. The proposed system solely relies on the collaborative effort of the participating users and is independent from the bus operating companies, so it can be easily adopted to support universal bus service systems without requesting support from particular bus operating companies. Instead of referring to GPS-enabled location information, we resort to more generally available and energy efficient sensing resources, including cell tower signals, movement statuses, audio recordings, etc., which bring less burden to the participatory party and encourage their participation. We develop a prototype system with different types of Android-based mobile phones and comprehensively experiment with the NTU campus shuttle buses as well as Singapore public buses over a 7-week period. The evaluation results suggest that the proposed system achieves outstanding prediction accuracy compared with those bus operator initiated and GPS supported solutions. We further adopt our system and conduct quick trial experiments with London bus system for 4 days, which suggests the easy deployment of our system and promising system performance across cities. At the same time, the proposed solution is more generally available and energy friendly.\n",
            "------------------------------------\n",
            "Title :  Building Information Modeling\n",
            "Author/s :  K. Kensek\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Preface Acknowledgements Introduction Fundamentals 1. BIM Overview Parametric Modeling and the Virtual Building Model BIM \"Dimensions\" Level of Development Summary 2. Stakeholders and BIM's Many Roles Architects, Engineers, Consultants Construction Managers, Contractors, Sub-contractors Fabricators Facilities Managers and Owners Summary 3. Data Exchange and Interoperability Interoperability Data Exchange Workflows Single Model and Federated Model Systems Data and Communication Formats Summary 4. BIM Implementation Transforming the Office to BIM Delivery Methods Legal Issues Office Standards BIM Execution Plan (BEP) Metrics for BIM Maturity Summary 5. Beyond Basic BIM BIM Analytics Cloud Computing Computational Design Increased Sophistication of Owners Summary Application: Project Case Studies designLAB: Small BIM Tames Big Brutalism ZGF: BIM in Transition: Making the Leap at a Large Firm CASE: Building Information Coordinators Mortenson Construction: Outstanding Project Success Through Collaboration Conclusion References and Software Mentioned Index\n",
            "------------------------------------\n",
            "Title :  Technology Acceptance Model: A Survey of Literature\n",
            "Author/s :  Priyanka Surendran\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  The technology acceptance model has been a theory that is most widely used to explain an individualâ€™s acceptance of an information system. This study has reviewed numerous literatures available in this area. The different studies in this area were evaluated to understand the modifications that were done on this model. The paper then tries to provide an insight on future trends in the technology acceptance model.\n",
            "------------------------------------\n",
            "Title :  A predictive model for the temporal dynamics of information diffusion in online social networks\n",
            "Author/s :  Adrien Guille, Hakim Hacid\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  Today, online social networks have become powerful tools for the spread of information. They facilitate the rapid and large-scale propagation of content and the consequences of an information -- whether it is favorable or not to someone, false or true -- can then take considerable proportions. Therefore it is essential to provide means to analyze the phenomenon of information dissemination in such networks. Many recent studies have addressed the modeling of the process of information diffusion, from a topological point of view and in a theoretical perspective, but we still know little about the factors involved in it. With the assumption that the dynamics of the spreading process at the macroscopic level is explained by interactions at microscopic level between pairs of users and the topology of their interconnections, we propose a practical solution which aims to predict the temporal dynamics of diffusion in social networks. Our approach is based on machine learning techniques and the inference of time-dependent diffusion probabilities from a multidimensional analysis of individual behaviors. Experimental results on a real dataset extracted from Twitter show the interest and effectiveness of the proposed approach as well as interesting recommendations for future investigation.\n",
            "------------------------------------\n",
            "Title :  Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols\n",
            "Author/s :  P. Campos, F. Díez, Iván Cantador\n",
            "Venue :  User modeling and user-adapted interaction\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Improving Diagnosis in Health Care\n",
            "Author/s :  E. Balogh, B. Miller, J. Ball\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Getting the right diagnosis is a key aspect of health care - it provides an explanation of a patient's health problem and informs subsequent health care decisions. The diagnostic process is a complex, collaborative activity that involves clinical reasoning and information gathering to determine a patient's health problem. According to Improving Diagnosis in Health Care, diagnostic errors-inaccurate or delayed diagnoses-persist throughout all settings of care and continue to harm an unacceptable number of patients. It is likely that most people will experience at least one diagnostic error in their lifetime, sometimes with devastating consequences. Diagnostic errors may cause harm to patients by preventing or delaying appropriate treatment, providing unnecessary or harmful treatment, or resulting in psychological or financial repercussions. The committee concluded that improving the diagnostic process is not only possible, but also represents a moral, professional, and public health imperative. Improving Diagnosis in Health Care a continuation of the landmark Institute of Medicine reports To Err Is Human (2000) and Crossing the Quality Chasm (2001) finds that diagnosis–and, in particular, the occurrence of diagnostic errors–has been largely unappreciated in efforts to improve the quality and safety of health care. Without a dedicated focus on improving diagnosis, diagnostic errors will likely worsen as the delivery of health care and the diagnostic process continue to increase in complexity. Just as the diagnostic process is a collaborative activity, improving diagnosis will require collaboration and a widespread commitment to change among health care professionals, health care organizations, patients and their families, researchers, and policy makers. The recommendations of Improving Diagnosis in Health Care contribute to the growing momentum for change in this crucial area of health care quality and safety.\n",
            "------------------------------------\n",
            "Title :  Feeling Blue? Go Online: An Empirical Study of Social Support among Patients\n",
            "Author/s :  L. Yan, Yong Tan\n",
            "Venue :  Information systems research\n",
            "year :  2014\n",
            "Abstract :  In this paper, we investigate whether social support exchanged in an online healthcare community benefits patients' mental health. We propose a nonhomogeneous Partially Observed Markov Decision Process POMDP model to examine the latent health outcomes for online health community members. The transition between different health states is modeled as a probability function that incorporates different forms of social support that patients exchange via discussion board posts. We find that patients benefit from learning from others and that their participation in the online community helps them to improve their health and to better engage in their disease self-management process. Our results also reveal differences in the influence of various forms of social support exchanged on the evolution of patients' health conditions. We find evidence that informational support is the most prevalent type in the online healthcare community. Nevertheless, emotional support plays the most significant role in helping patients move to a healthier state. Overall, the influence of social support is found to vary depending on patients' health conditions. Finally, we demonstrate that our proposed POMDP model can provide accurate predictions for patients' health states and can be used to recover missing or unavailable information on patients' health conditions.\n",
            "------------------------------------\n",
            "Title :  Temporal Contiguity and Negativity Bias in the Impact of Online Word of Mouth\n",
            "Author/s :  Zoey Chen, Nicholas H. Lurie\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Prior research shows that positive online reviews are less valued than negative reviews. The authors argue that this is due to differences in causal attributions for positive versus negative information such that positive reviews tend to be relatively more attributed to the reviewer (vs. product experience) than negative reviews. The presence of temporal contiguity cues, which indicate that review writing closely follows consumption, reduces the relative extent to which positive reviews are attributed to the reviewer and mitigates the negativity bias. An examination of 65,531 Yelp.com restaurant reviews shows that review value is negatively related to review valence but that this negative relationship is absent for reviews that contain temporal contiguity cues. A series of lab studies replicates these findings and suggests that temporal contiguity cues enhance the value of a positive review and increase the likelihood of choosing a product with a positive review by changing reader beliefs about the cause of the review.\n",
            "------------------------------------\n",
            "Title :  Resolving human object recognition in space and time\n",
            "Author/s :  Radoslaw Martin Cichy, D. Pantazis, A. Oliva\n",
            "Venue :  Nature Neuroscience\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  An Evolutionary Upgrade of Cognitive Load Theory: Using the Human Motor System and Collaboration to Support the Learning of Complex Cognitive Tasks\n",
            "Author/s :  F. Paas, J. Sweller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  What Do Systems Users Have to Fear? Using Fear Appeals to Engender Threats and Fear that Motivate Protective Security Behaviors\n",
            "Author/s :  Scott R. Boss, D. Galletta, P. Lowry, Gregory Moody, P. Polak\n",
            "Venue :  MIS Q.\n",
            "year :  2015\n",
            "Abstract :  Because violations of information security (ISec) and privacy have become ubiquitous in both personal and work environments, academic attention to ISec and privacy has taken on paramount importance. Consequently, a key focus of ISec research has been discovering ways to motivate individuals to engage in more secure behaviors. Over time, the protection motivation theory (PMT) has become a leading theoretical foundation used in ISec research to help motivate individuals to change their security-related behaviors to protect themselves and their organizations. Our careful review of the foundation for PMT identified four opportunities for improving ISec PMT research. First, extant ISec studies do not use the full nomology of PMT constructs. Second, only one study uses fear-appeal manipulations, even though these are a core element of PMT. Third, virtually no ISec study models or measures fear. Fourth, whereas these studies have made excellent progress in predicting security intentions, none of them have addressed actual security behaviors. \n",
            " \n",
            "This article describes the theoretical foundation of these four opportunities for improvement. We tested the nomology of PMT, including manipulated fear appeals, in two different ISec contexts that model the modern theoretical treatment of PMT more closely than do extant ISec studies. The first data collection was a longitudinal study in the context of data backups. The second study was a short-term cross-sectional study in the context of anti-malware software. Our new model demonstrated better results and stronger fit than the existing models and confirms the efficacy of the four potential improvements we identified.\n",
            "------------------------------------\n",
            "Title :  What's skill got to do with it?: Information literacy skills and self-views of ability among first-year college students\n",
            "Author/s :  M. Gross, D. Latham\n",
            "Venue :  J. Assoc. Inf. Sci. Technol.\n",
            "year :  2012\n",
            "Abstract :  This study replicates a previous study based on work in psychology, which demonstrates that students who score as below proficient in information literacy (IL) skills have a miscalibrated self-view of their ability. Simply stated, these students tend to believe that they have above-average IL skills, when, in fact, an objective test of their ability indicates that they are below-proficient in terms of their actual skills. This investigation was part of an Institute of Museum and Library Services-funded project and includes demographic data about participants, their scores on an objective test of their information literacy skills, and self-estimates of their ability. Findings support previous research that indicates many students come to college without proficient IL skills, that students with below-proficient IL skills have inflated views of their ability, and that this miscalibration can also be expressed by students who test as proficient. Implications for research and practice are discussed. © 2012 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title :  Technology acceptance model (TAM) and social media usage: an empirical study on Facebook\n",
            "Author/s :  Rupak Rauniar, Greg Rawski, Jei Yang, Ben Johnson\n",
            "Venue :  Journal of Enterprise Information Management\n",
            "year :  2014\n",
            "Abstract :  Purpose – Given the widespread popularity of social media, such as Twitter, Facebook, Google+, and LinkedIn, theorizing and understanding the user attitude and usage behavior of social media site is fundamental in developing future understandings and deployment of these new technologies. One approach to such studies on drivers of social media usage behavior would be to revisit the technology acceptance model (TAM). The purpose of this paper is to discuss these issues. Design/methodology/approach – Decades of extensive research have focussed on validating the TAM, proposed by Davis (1986), for various types of information systems and communication technologies. TAM forecasts individual adoption and voluntary use of technology. This study examines individual adoption behavior of the most popular social networking site Facebook. The influences on the intention of using social networking based on individual's perceived ease of use (EU), the user's critical mass (CM), social networking site capability (CP), pe...\n",
            "------------------------------------\n",
            "Title :  Internet of Things-IOT : Definition , Characteristics , Architecture , Enabling Technologies , Application & Future Challenges\n",
            "Author/s :  Keyur K. Patel, Sunil M Patel\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  The Internet of things refers to a type of network to connect anything with the Internet based on stipulated protocols through information sensing equipments to conduct information exchange and communications in order to achieve smart recognitions, positioning, tracing, monitoring, and administration. In this paper we briefly discussed about what IOT is, how IOT enables different technologies, about its architecture, characteristics & applications, IOT functional view & what are the future challenges for IOT. Key Terms: IOT (Internet of Things), IOT definitions, IOT functional view, architecture, characteristics, future challenges.\n",
            "------------------------------------\n",
            "Title :  BIM for facility managers\n",
            "Author/s :  P. Teicholz\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Building owners and facility managers are discovering that Building Information Modeling (BIM) models of buildings are deep reservoirs of information that can provide valuable spatial and mechanical details on every aspect of a property. When used appropriately, this data can improve performance and save time, effort, and money in running and maintaining the building during its life cycle. It can also provide information for future modifications. For instance, a BIM could reveal everything from the manufacturer of a light fixture to its energy usage to maintenance instructions.\n",
            "------------------------------------\n",
            "Title :  Big Data-Survey\n",
            "Author/s :  P. Sri, M. Anusha\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Big data is the term for any gathering of information sets, so expensive and complex, that it gets to be hard to process for utilizing customary information handling applications. The difficulties incorporate investigation, catch, duration, inquiry, sharing, stockpiling, Exchange, perception, and protection infringement. To reduce spot business patterns, anticipate diseases, conflict etc., we require bigger data sets when compared with the smaller data sets. Enormous information is hard to work with utilizing most social database administration frameworks and desktop measurements and perception bundles, needing rather enormously parallel programming running on tens, hundreds, or even a large number of servers. In this paper there was an observation on Hadoop architecture, different tools used for big data and its security issues.\n",
            "------------------------------------\n",
            "Title :  Graph Convolution over Pruned Dependency Trees Improves Relation Extraction\n",
            "Author/s :  Yuhao Zhang, Peng Qi, Christopher D. Manning\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2018\n",
            "Abstract :  Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.\n",
            "------------------------------------\n",
            "Title :  SHARE, LIKE, RECOMMEND\n",
            "Author/s :  A. Hermida, F. Fletcher, Darryl Korell, Donna Logan\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This study examines the impact of social media spaces on news consumption, based on an online survey of 1600 Canadians. News organizations are rushing into social media, viewing services like Facebook and Twitter as opportunities to market and distribute content. There has been limited research outside the United States into the effects of social media on news consumption. Our study found that social networks are becoming a significant source of news for Canadians. Two-fifths of social networking users said they receive news from people they follow on services like Facebook, while a fifth get news from news organizations and individual journalists they follow. Users said they valued social media because it helped them keep up with events and exposed them to a wider range of news and information. While social interaction has always affected the dissemination of news, our study contributes to research that suggests social media are becoming central to the way people experience news. Networked media technologies are extending the ability of users to create and receive personalized news streams. Investigating how networked publics are reframing the news and shaping news flows would contribute to our understanding of the evolving relationship between the journalist and the audience.\n",
            "------------------------------------\n",
            "Title :  Information Transmission in Irrigation Technology Adoption and Diffusion: Social Learning, Extension Services, and Spatial Effects\n",
            "Author/s :  Margarita Genius, P. Koundouri, V. Tzouvelekas, Céline Nauges\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  In this article, we investigate the role of information transmission in promoting agricultural technology adoption and diffusion through extension services and social learning. We develop a theoretical model of technology adoption and diffusion, which we then empirically apply, using duration analysis, on a micro-dataset consisting of recall data covering the period 1994-2004 for olive-producing farms from Crete, Greece. Our findings suggest that both extension services and social learning are strong determinants of technology adoption and diffusion, while the effectiveness of each of the two informational channels is enhanced by the presence of the other.\n",
            "------------------------------------\n",
            "Title :  Differential Recurrent Neural Networks for Action Recognition\n",
            "Author/s :  Vivek Veeriah, Naifan Zhuang, Guo-Jun Qi\n",
            "Venue :  IEEE International Conference on Computer Vision\n",
            "year :  2015\n",
            "Abstract :  The long short-term memory (LSTM) neural network is capable of processing complex sequential information since it utilizes special gating schemes for learning representations from long input sequences. It has the potential to model any time-series or sequential data, where the current hidden state has to be considered in the context of the past hidden states. This property makes LSTM an ideal choice to learn the complex dynamics of various actions. Unfortunately, the conventional LSTMs do not consider the impact of spatio-temporal dynamics corresponding to the given salient motion patterns, when they gate the information that ought to be memorized through time. To address this problem, we propose a differential gating scheme for the LSTM neural network, which emphasizes on the change in information gain caused by the salient motions between the successive frames. This change in information gain is quantified by Derivative of States (DoS), and thus the proposed LSTM model is termed as differential Recurrent Neural Network (dRNN). We demonstrate the effectiveness of the proposed model by automatically recognizing actions from the real-world 2D and 3D human action datasets. Our study is one of the first works towards demonstrating the potential of learning complex time-series representations via high-order derivatives of states.\n",
            "------------------------------------\n",
            "Title :  Externalities of Public Firm Presence: Evidence from Private Firms’ Investment Decisions\n",
            "Author/s :  Brad A. Badertscher, Nemit Shroff, H. White\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Public firms provide a large amount of information through their disclosures. In addition, information intermediaries publicly analyze, discuss and disseminate these disclosures. Thus, greater public firm presence in an industry should reduce uncertainty in that industry. Following the theoretical prediction of investment under uncertainty, we hypothesize and find that private firms are more responsive to their investment opportunities when they operate in industries with greater public firm presence. Further, we find that the effect of public firm presence is greater in industries with better information quality and in industries characterized by a greater degree of investment irreversibility. Our results suggest that public firms generate positive externalities by reducing industry uncertainty and facilitating more efficient private firm investment.\n",
            "------------------------------------\n",
            "Title :  Minimum information reporting in bio–nano experimental literature\n",
            "Author/s :  Matthew Faria, M. Björnmalm, K. Thurecht, S. Kent, R. Parton, M. Kavallaris, A. Johnston, J. Gooding, S. Corrie, B. Boyd, P. Thordarson, A. Whittaker, M. Stevens, C. Prestidge, C. Porter, W. Parak, T. P. Davis, E. Crampin, F. Caruso\n",
            "Venue :  Nature Nanotechnology\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Nudging Energy Efficiency Behavior: The Role of Information Labels\n",
            "Author/s :  R. Newell, J. Siikamäki\n",
            "Venue :  Journal of the Association of Environmental and Resource Economists\n",
            "year :  2013\n",
            "Abstract :  We use choice experiments and randomized information treatments to study the effectiveness of alternative energy efficiency labels in guiding households’ energy efficiency decisions. We disentangle the relative importance of different types of information and distinguish it from intertemporal behavior. We find that insufficient information can lead to considerable undervaluation of energy efficiency. Simple information on the monetary value of energy savings was the most important element guiding cost-efficient energy efficiency investments, with information on physical energy use and carbon dioxide emissions having additional but lesser importance. The degree to which the current US EnergyGuide label guided cost-efficient decisions depends on the discount rate. Using elicited individual discount rates, the current EnergyGuide label came very close to guiding cost-efficient decisions. Using a uniform 5% discount rate, the current label led to one-third undervaluation of energy efficiency. Our results reinforce the centrality of discounting in understanding individual behavior and guiding policy.\n",
            "------------------------------------\n",
            "Title :  Crowdsourcing Geographic Knowledge: Volunteered Geographic Information (VGI) in Theory and Practice\n",
            "Author/s :  D. Sui, S. Elwood, M. Goodchild\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Consensus-Based Linear and Nonlinear Filtering\n",
            "Author/s :  G. Battistelli, L. Chisci, G. Mugnai, A. Farina, A. Graziano\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2015\n",
            "Abstract :  This note addresses Distributed State Estimation (DSE) over sensor networks. Two existing consensus approaches for DSE, i.e., consensus on information (CI) and consensus on measurements (CM), are combined to provide a novel class of hybrid consensus filters (named Hybrid CMCI) which enjoy the complementary benefits of CM and CI. Novel theoretical results, limitedly to linear systems, on the guaranteed stability of the Hybrid CMCI filters under collective observability and network connectivity are proved. Finally, the effectiveness of the proposed class of consensus filters is evaluated on a target tracking case study with both linear and nonlinear sensors.\n",
            "------------------------------------\n",
            "Title :  ClinVar: improving access to variant interpretations and supporting evidence\n",
            "Author/s :  M. Landrum, Jennifer M. Lee, M. Benson, Garth R. Brown, Chen Chao, S. Chitipiralla, Baoshan Gu, Jennifer Hart, Douglas Hoffman, W. Jang, Karen Karapetyan, K. Katz, Chunlei Liu, Zenith Maddipatla, A. Malheiro, Kurt McDaniel, M. Ovetsky, George R. Riley, George Zhou, J. B. Holmes, B. Kattman, D. Maglott\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2017\n",
            "Abstract :  Abstract ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) is a freely available, public archive of human genetic variants and interpretations of their significance to disease, maintained at the National Institutes of Health. Interpretations of the clinical significance of variants are submitted by clinical testing laboratories, research laboratories, expert panels and other groups. ClinVar aggregates data by variant-disease pairs, and by variant (or set of variants). Data aggregated by variant are accessible on the website, in an improved set of variant call format files and as a new comprehensive XML report. ClinVar recently started accepting submissions that are focused primarily on providing phenotypic information for individuals who have had genetic testing. Submissions may come from clinical providers providing their own interpretation of the variant (‘provider interpretation’) or from groups such as patient registries that primarily provide phenotypic information from patients (‘phenotyping only’). ClinVar continues to make improvements to its search and retrieval functions. Several new fields are now indexed for more precise searching, and filters allow the user to narrow down a large set of search results.\n",
            "------------------------------------\n",
            "Title :  LayoutLM: Pre-training of Text and Layout for Document Image Understanding\n",
            "Author/s :  Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2019\n",
            "Abstract :  Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm.\n",
            "------------------------------------\n",
            "Title :  The Simple Rules of Social Contagion\n",
            "Author/s :  Nathan Oken Hodas, Kristina Lerman\n",
            "Venue :  Scientific Reports\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Overview of the CLEF eHealth Evaluation Lab 2016\n",
            "Author/s :  L. Kelly, L. Goeuriot, H. Suominen, Aurélie Névéol, João Palotti, G. Zuccon\n",
            "Venue :  Conference and Labs of the Evaluation Forum\n",
            "year :  2015\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Crowdfunding: Geography, Social Networks, and the Timing of Investment Decisions\n",
            "Author/s :  A. Agrawal, Christian Catalini, Avi Goldfarb\n",
            "Venue :  Journal of Economics &amp; Management Strategy\n",
            "year :  2015\n",
            "Abstract :  type=\"main\"> We examine a crowdfunding platform that connects artists with funders. Although the Internet reduces many distance-related frictions, local and distant funders exhibit different funding patterns. Local funders appear less responsive to information about the cumulative funds raised by an artist. However, this distance effect appears to proxy for a social effect: it is largely explained by funders who likely have an offline social relationship with the artist (“friends and family”). Yet, this social effect does not persist past the first investment, suggesting that it may be driven by an activity like search but not monitoring. Thus, although the platform seems to diminish many distance-sensitive costs, it does not eliminate all of them. These findings provide a deeper understanding of the abilities and limitations of online markets to facilitate transactions and convey information between buyers and sellers with varying degrees of social connectedness.\n",
            "------------------------------------\n",
            "Title :  End-to-End Flow Correlation Tracking with Spatial-Temporal Attention\n",
            "Author/s :  Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan\n",
            "Venue :  2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year :  2017\n",
            "Abstract :  Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable performance in recent tracking benchmarks. However, most of existing DCF trackers only consider appearance features of current frame, and hardly benefit from motion and inter-frame information. The lack of temporal information degrades the tracking performance during challenges such as partial occlusion and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. The FlowTrack formulates individual components, including optical flow estimation, feature extraction, aggregation and correlation filters tracking as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in deep learning framework. Then the historical feature maps at predefined intervals are warped and aggregated with current ones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VOT2015 and VOT2016.\n",
            "------------------------------------\n",
            "Title :  Rumors and Health Care Reform: Experiments in Political Misinformation\n",
            "Author/s :  A. Berinsky\n",
            "Venue :  British Journal of Political Science\n",
            "year :  2015\n",
            "Abstract :  This article explores belief in political rumors surrounding the health care reforms enacted by Congress in 2010. Refuting rumors with statements from unlikely sources can, under certain circumstances, increase the willingness of citizens to reject rumors regardless of their own political predilections. Such source credibility effects, while well known in the political persuasion literature, have not been applied to the study of rumor. Though source credibility appears to be an effective tool for debunking political rumors, risks remain. Drawing upon research from psychology on ‘fluency’ – the ease of information recall – this article argues that rumors acquire power through familiarity. Attempting to quash rumors through direct refutation may facilitate their diffusion by increasing fluency. The empirical results find that merely repeating a rumor increases its power.\n",
            "------------------------------------\n",
            "Title :  Norm Perception as a Vehicle for Social Change\n",
            "Author/s :  Margaret E. Tankard, E. Paluck\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  How can we change social norms, the standards describing typical or desirable behavior? Because individuals’ perceptions of norms guide their personal behavior, influencing these perceptions is one way to create social change. And yet individuals do not form perceptions of typical or desirable behavior in an unbiased manner. Individuals attend to select sources of normative information, and their resulting perceptions rarely match actual rates of behavior in their environment. Thus, changing social norms requires an understanding of how individuals perceive norms in the first place. We describe three sources of information that people use to understand norms—individual behavior, summary information about a group, and institutional signals. Social change interventions have used each source to influence perceived norms and behaviors, including recycling, intimate-partner violence, and peer harassment. We discuss conditions under which influence over perceived norms is likely to be stronger, based on the source of the normative information and individuals’ relationship to the source. Finally, we point to future research and suggest when it is most appropriate to use a norm change strategy in the interest of behavior and social change.\n",
            "------------------------------------\n",
            "Title :  Determinants of Sharing Travel Experiences in Social Media\n",
            "Author/s :  Myunghwa Kang, M. Schuett\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT The advent of Internet-based social media technologies has enabled travelers to quickly and conveniently share their travel experiences. Shared information on social media sites is recognized as an important information source which may influence travel decision making for potential travelers. This study tests a conceptual framework which examines why travelers share their travel experiences on social media based on the social influence theory and its three conceptual foundations—identification, internalization, and compliance. Data were collected using an online survey and the research model was tested with 543 respondents who were social media users. Results showed that identification and internalization are critical determinants that positively increase actual travel-experience sharing on social media as mediated by perceived enjoyment. Our research extends prior literature on social media by identifying specific determinants that can impact travel-experience sharing. Suggestions are provided for academics, the travel industry, and those working with social media.\n",
            "------------------------------------\n",
            "Title :  How the public uses social media wechat to obtain health information in china: a survey study\n",
            "Author/s :  Xingting Zhang, Dong Wen, Jun Liang, Jianbo Lei\n",
            "Venue :  BMC Medical Informatics and Decision Making\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The lure of rationality: Why does the deficit model persist in science communication?\n",
            "Author/s :  Molly Simis, Haley C. Madden, M. Cacciatore, Sara K. Yeo\n",
            "Venue :  Public Understanding of Science\n",
            "year :  2016\n",
            "Abstract :  Science communication has been historically predicated on the knowledge deficit model. Yet, empirical research has shown that public communication of science is more complex than what the knowledge deficit model suggests. In this essay, we pose four lines of reasoning and present empirical data for why we believe the deficit model still persists in public communication of science. First, we posit that scientists’ training results in the belief that public audiences can and do process information in a rational manner. Second, the persistence of this model may be a product of current institutional structures. Many graduate education programs in science, technology, engineering, and math (STEM) fields generally lack formal training in public communication. We offer empirical evidence that demonstrates that scientists who have less positive attitudes toward the social sciences are more likely to adhere to the knowledge deficit model of science communication. Third, we present empirical evidence of how scientists conceptualize “the public” and link this to attitudes toward the deficit model. We find that perceiving a knowledge deficit in the public is closely tied to scientists’ perceptions of the individuals who comprise the public. Finally, we argue that the knowledge deficit model is perpetuated because it can easily influence public policy for science issues. We propose some ways to uproot the deficit model and move toward more effective science communication efforts, which include training scientists in communication methods grounded in social science research and using approaches that engage community members around scientific issues.\n",
            "------------------------------------\n",
            "Title :  Enabling Flexibility in Process-Aware Information Systems: Challenges, Methods, Technologies\n",
            "Author/s :  M. Reichert, B. Weber\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  In todays dynamic business world, the success of a company increasingly depends on its ability to react to changes in its environment in a quick and flexible way. Companies have therefore identified process agility as a competitive advantage to address business trends like increasing product and service variability or faster time to market, and to ensure business IT alignment. Along this trend, a new generation of information systems has emergedso-called process-aware information systems (PAIS), like workflow management systems, case handling tools, and service orchestration engines. With this book, Reichert and Weber address these flexibility needs and provide an overview of PAIS with a strong focus on methods and technologies fostering flexibility for all phases of the process lifecycle (i.e., modeling, configuration, execution and evolution). Their presentation is divided into six parts. Part I starts with an introduction of fundamental PAIS concepts and establishes the context of process flexibility in the light of practical scenarios. Part II focuses on flexibility support for pre-specified processes, the currently predominant paradigm in the field of business process management (BPM). Part III details flexibility support for loosely specified processes, which only partially specify the process model at build-time, while decisions regarding the exact specification of certain model parts are deferred to the run-time. Part IV deals with user- and data-driven processes, which aim at a tight integration of processes and data, and hence enable an increased flexibility compared to traditional PAIS. Part V introduces existing technologies and systems for the realization of a flexible PAIS. Finally, Part VI summarizes the main ideas of this book and gives an outlook on advanced flexibility issues. The bookstarget groups include researchers, PhD students and Master students in the field of information systems. After reading the book, they will better understand PAIS flexibility aspects. To support the easy use as a textbook, a series of exercises is provided at the end of each chapter and slides and further teaching material are available on the books web site www.flexible-processes.com. Professionals specializing in business process management (BPM) who want to obtain a good understanding of flexibility challenges in BPM and state-of-the-art solutions will also benefit from the presentations of open source as well as commercial process management systems and related practical scenarios.\n",
            "------------------------------------\n",
            "Title :  User cooperation in wireless powered communication networks\n",
            "Author/s :  Hyungsik Ju, Rui Zhang\n",
            "Venue :  2014 IEEE Global Communications Conference\n",
            "year :  2014\n",
            "Abstract :  This paper studies user cooperation in the emerging wireless powered communication network (WPCN) for throughput optimization. For the purpose of exposition, we consider a two-user WPCN, in which one hybrid access point (H-AP) broadcasts wireless energy to two distributed users in the downlink (DL) and the users transmit their independent information using their individually harvested energy to the H-AP in the uplink (UL) through time-division-multiple-access (TDMA). We propose user cooperation in the WPCN where the user that is nearer to the H-AP and in general has a better channel for DL energy harvesting as well as UL information transmission uses part of its allocated UL time and DL harvested energy to help relay the far user's information to the H-AP, in order to achieve more balanced throughput. We maximize the weighted sum-rate (WSR) of the two users by jointly optimizing the time and power allocations in the network for both wireless energy transfer in the DL and wireless information transmission and relaying in the UL. Simulation results show that the proposed user cooperation scheme can effectively improve the achievable throughput in the WPCN with desired user fairness.\n",
            "------------------------------------\n",
            "Title :  A Longitudinal Study of Herd Behavior in the Adoption and Continued Use of Technology\n",
            "Author/s :  Heshan Sun\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  Herd literature suggests that people tend to discount their own beliefs and imitate others when making adoption decisions and that the resulting adoption decisions are fragile and can be easily reversed during the post-adoptive stage. This helps explain why the adoption of a number of new technologies--from Amazon's Kindle, to Apple's iPod, iPhone, and iPad, to various types of Web 2.0 technologies--appears to have adoption patterns similar to those of new fashion trends (i. e., an initial en masse acquisition followed by subsequent abandonment). It is important to understand these phenomena because they are strongly related to the staying power of technology. From a herd behavior perspective, this study proposes two new concepts, namely discounting one's own information and imitating others, to describe herd behavior in technology adoption. A research model is developed to describe the conditions under which herd behavior in technology adoption occurs, how it impacts technology adoption decision making, and how it influences post-adoptive system use. A longitudinal study is conducted to examine the research model. Findings from this research suggest that the discounting of one's own beliefs and the imitating of others when adopting a new technology are provoked primarily by the observation of prior adoptions and perceptions of uncertainty regarding the adoption of new technology. Herd behavior has a significant influence on user technology adoption; however, it does not necessarily lead to the collapse of the user base, as predicted in the herd literature. Instead, imitation can help reduce post-adoption regret and thus serve as a legitimate strategy for choosing a good enough technology, which may or may not be the best option to enhance job performance. People tend to adjust their beliefs when herding and also to revive their discounted initial beliefs to modify their beliefs about the technology at the post-adoptive stage. Findings from this study have significant research and practical implications.\n",
            "------------------------------------\n",
            "Title :  Exploring the Security of Information Sharing on Social Networking Sites: The Role of Perceived Control of Information\n",
            "Author/s :  Nick Hajli, Xiaolin Lin\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Compressed Sensing Signal and Data Acquisition in Wireless Sensor Networks and Internet of Things\n",
            "Author/s :  Shancang Li, Lida Xu, Xinheng Wang\n",
            "Venue :  IEEE Transactions on Industrial Informatics\n",
            "year :  2013\n",
            "Abstract :  The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.\n",
            "------------------------------------\n",
            "Title :  Challenges and opportunities of digital information at the intersection of Big Data Analytics and supply chain management\n",
            "Author/s :  Florian Kache, S. Seuring\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Purpose \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Despite the variety of supply chain management (SCM) research, little attention has been given to the use of Big Data Analytics for increased information exploitation in a supply chain. The purpose of this paper is to contribute to theory development in SCM by investigating the potential impacts of Big Data Analytics on information usage in a corporate and supply chain context. As it is imperative for companies in the supply chain to have access to up-to-date, accurate, and meaningful information, the exploratory research will provide insights into the opportunities and challenges emerging from the adoption of Big Data Analytics in SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Although Big Data Analytics is gaining increasing attention in management, empirical research on the topic is still scarce. Due to the limited availability of comparable material at the intersection of Big Data Analytics and SCM, the authors apply the Delphi research technique. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Portraying the emerging transition trend from a digital business environment, the presented Delphi study findings contribute to extant knowledge by identifying 43 opportunities and challenges linked to the emergence of Big Data Analytics from a corporate and supply chain perspective. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Research limitations/implications \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "These constructs equip the research community with a first collection of aspects, which could provide the basis to tailor further research at the nexus of Big Data Analytics and SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The research adds to the existing knowledge base as no empirical research has been presented so far specifically assessing opportunities and challenges on corporate and supply chain level with a special focus on the implications imposed through Big Data Analytics.\n",
            "------------------------------------\n",
            "Title :  Predictive Entropy Search for Efficient Global Optimization of Black-box Functions\n",
            "Author/s :  José Miguel Hernández-Lobato, Matthew W. Hoffman, Zoubin Ghahramani\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance.\n",
            "------------------------------------\n",
            "Title :  What is an Information System?\n",
            "Author/s :  S. Boell, D. Cecez-Kecmanovic\n",
            "Venue :  Hawaii International Conference on System Sciences\n",
            "year :  2015\n",
            "Abstract :  This paper aims to advance understanding of information systems (IS) through a critical reflection on how IS are currently defined in the IS literature. Using the hermeneutic approach for conducting literature reviews the paper identifies 34 definitions of IS in the literature. Based on the analysis of these 34 definitions four different views of IS are distinguished: a technology view emphasizing the technological aspects of IS, a social view emphasizing the socio cultural aspects, a socio-technical view emphasizing the interconnection of technology and social elements, and a process view emphasizing the activity orientation of IS. The paper critically examines the contributions and limitations of these different approaches for understanding and theorizing IS. Based on this examination the paper argues to for the need to develop an additional, alternative sociomaterial conceptualization of IS based on a non-dualist, relational ontology.\n",
            "------------------------------------\n",
            "Title :  Database resources of the National Center for Biotechnology Information.\n",
            "Author/s :  E. Sayers, J. Beck, J. R. Brister, Evan E. Bolton, Kathi Canese, Donald C. Comeau, Kathryn Funk, A. Ketter, Sunghwan Kim, Avi Kimchi, P. Kitts, A. Kuznetsov, S. Lathrop, Zhiyong Lu, Kelly M. McGarvey, T. Madden, Terence D. Murphy, N. O'Leary, Lon Phan, Valerie A. Schneider, F. Thibaud-Nissen, B. Trawick, K. Pruitt, J. Ostell\n",
            "Venue :  Nucleic Acids Research\n",
            "year :  2019\n",
            "Abstract :  The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface, a sequence database search and a gene orthologs page. Additional resources that were updated in the past year include PMC, Bookshelf, My Bibliography, Assembly, RefSeq, viral genomes, the prokaryotic genome annotation pipeline, Genome Workbench, dbSNP, BLAST, Primer-BLAST, IgBLAST and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title :  Information network or social network?: the structure of the twitter follow graph\n",
            "Author/s :  Seth A. Myers, Aneesh Sharma, Pankaj Gupta, Jimmy J. Lin\n",
            "Venue :  The Web Conference\n",
            "year :  2014\n",
            "Abstract :  In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.\n",
            "------------------------------------\n",
            "Title :  Supervised Contrastive Learning\n",
            "Author/s :  Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan\n",
            "Venue :  Neural Information Processing Systems\n",
            "year :  2020\n",
            "Abstract :  Cross entropy is the most widely used loss function for supervised training of image classification models. In this paper, we propose a novel training methodology that consistently outperforms cross entropy on supervised learning tasks across different architectures and data augmentations. We modify the batch contrastive loss, which has recently been shown to be very effective at learning powerful representations in the self-supervised setting. We are thus able to leverage label information more effectively than cross entropy. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. In addition to this, we leverage key ingredients such as large batch sizes and normalized embeddings, which have been shown to benefit self-supervised learning. On both ResNet-50 and ResNet-200, we outperform cross entropy by over 1%, setting a new state of the art number of 78.8% among methods that use AutoAugment data augmentation. The loss also shows clear benefits for robustness to natural corruptions on standard benchmarks on both calibration and accuracy. Compared to cross entropy, our supervised contrastive loss is more stable to hyperparameter settings such as optimizers or data augmentations.\n",
            "------------------------------------\n",
            "Title :  Information geometry\n",
            "Author/s :  S. Amari\n",
            "Venue :  Japanese journal of mathematics\n",
            "year :  2021\n",
            "Abstract :  Information geometry has emerged from the study of the invariant structure in families of probability distributions. This invariance uniquely determines a second-order symmetric tensor g and third-order symmetric tensor T in a manifold of probability distributions. A pair of these tensors ( g, T ) defines a Riemannian metric and a pair of affine connections which together preserve the metric. Information geometry involves studying a Riemannian manifold having a pair of dual affine connections. Such a structure also arises from an asymmetric divergence function and affine differential geometry. A dually flat Riemannian manifold is particularly useful for various applications, because a generalized Pythagorean theorem and projection theorem hold. The Wasserstein distance gives another important geometry on probability distributions, which is non-invariant but responsible for the metric properties of a sample space. I attempt to construct information geometry of the entropy-regularized Wasserstein distance.\n",
            "------------------------------------\n",
            "Title :  Information Cascades among Investors in Equity Crowdfunding\n",
            "Author/s :  Silvio Vismara\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Finance studies on information cascades, usually in an initial public offering setting, typically differentiate between institutional and retail investors, as this is the only information available to potential backers. Information available through equity crowdfunding platforms includes details on individual investors as they may disclose information about themselves by linking their profile to social networks or websites. Using a sample of 132 equity offerings on Crowdcube in 2014, we show that information cascades among individual investors play a crucial role in crowdfunding campaigns. Investors with a public profile increase the appeal of the offer among early investors, who in turn attract late investors.\n",
            "------------------------------------\n",
            "Title :  Integration of Online and Offline Channels in Retail: The Impact of Sharing Reliable Inventory Availability Information\n",
            "Author/s :  Santiago Gallino, Antonio Moreno\n",
            "Venue :  Management Sciences\n",
            "year :  2014\n",
            "Abstract :  Using a proprietary data set, we analyze the impact of the implementation of a “buy-online, pick-up-in-store” BOPS project. The implementation of this project is associated with a reduction in online sales and an increase in store sales and traffic. These results can be explained by two simultaneous phenomena: 1 additional store sales from customers who use the BOPS functionality and buy additional products in the stores cross-selling effect and 2 the shift of some customers from the online to the brick-and-mortar channel and the conversion of noncustomers into store customers channel-shift effect. We explain these channel-shift patterns as an increase in “research online, purchase offline” behavior enabled by BOPS implementation, and we validate this explanation with evidence from the change of cart abandonment and conversion rates of the brick-and-mortar and online channels. We interpret these results in light of recent operations management literature that analyzes the impact of sharing inventory availability information. Our analysis illustrates the limitations of drawing conclusions about complex interventions using single-channel data. \n",
            " \n",
            "This paper was accepted by Alok Gupta, special issue on business analytics.\n",
            "------------------------------------\n",
            "Title :  Unmet care needs of advanced cancer patients and their informal caregivers: a systematic review\n",
            "Author/s :  Tao Wang, A. Molassiotis, B. Chung, J. Tan\n",
            "Venue :  BMC Palliative Care\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Why People Use Chatbots\n",
            "Author/s :  P. Brandtzæg, A. Følstad\n",
            "Venue :  International Conference on Internet Science\n",
            "year :  2017\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A strategy for the design of skyrmion racetrack memories\n",
            "Author/s :  R. Tomasello, E. Martínez, R. Zivieri, L. Torres, M. Carpentieri, G. Finocchio\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Effective Pattern Discovery for Text Mining\n",
            "Author/s :  N. Zhong, Yuefeng Li, Sheng-Tang Wu\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2012\n",
            "Abstract :  Many data mining techniques have been proposed for mining useful patterns in text documents. However, how to effectively use and update discovered patterns is still an open research issue, especially in the domain of text mining. Since most existing text mining methods adopted term-based approaches, they all suffer from the problems of polysemy and synonymy. Over the years, people have often held the hypothesis that pattern (or phrase)-based approaches should perform better than the term-based ones, but many experiments do not support this hypothesis. This paper presents an innovative and effective pattern discovery technique which includes the processes of pattern deploying and pattern evolving, to improve the effectiveness of using and updating discovered patterns for finding relevant and interesting information. Substantial experiments on RCV1 data collection and TREC topics demonstrate that the proposed solution achieves encouraging performance.\n",
            "------------------------------------\n",
            "Title :  Life With and Without Coding: Two Methods for Early-Stage Data Analysis in Qualitative Research Aiming at Causal Explanations\n",
            "Author/s :  J. Gläser, G. Laudel\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Qualitative research aimed at \"mechanismic\" explanations poses specific challenges to qualitative data analysis because it must integrate existing theory with patterns identified in the data. We explore the utilization of two methods—coding and qualitative content analysis—for the first steps in the data analysis process, namely \"cleaning\" and organizing qualitative data. Both methods produce an information base that is structured by categories and can be used in the subsequent search for patterns in the data and integration of these patterns into a systematic, theoretically embedded explanation. Used as a stand-alone method outside the grounded theory approach, coding leads to an indexed text, i.e. both the original text and the index (the system of codes describing the content of text segments) are subjected to further analysis. Qualitative content analysis extracts the relevant information, i.e. separates it from the original text, and processes only this information. We suggest that qualitative content analysis has advantages compared to coding whenever the research question is embedded in prior theory and can be answered without processing knowledge about the form of statements and their position in the text, which usually is the case in the search for \"mechanismic\" explanations. Coding outperforms qualitative content analysis in research that needs this information in later stages of the analysis, e.g. the exploration of meaning or the study of the construction of narratives.\n",
            "------------------------------------\n",
            "Title :  Health-protective behaviour, social media usage and conspiracy belief during the COVID-19 public health emergency\n",
            "Author/s :  D. Allington, B. Duffy, S. Wessely, N. Dhavan, J. Rubin\n",
            "Venue :  Psychological Medicine\n",
            "year :  2020\n",
            "Abstract :  Abstract Background Social media platforms have long been recognised as major disseminators of health misinformation. Many previous studies have found a negative association between health-protective behaviours and belief in the specific form of misinformation popularly known as ‘conspiracy theory’. Concerns have arisen regarding the spread of COVID-19 conspiracy theories on social media. Methods Three questionnaire surveys of social media use, conspiracy beliefs and health-protective behaviours with regard to COVID-19 among UK residents were carried out online, one using a self-selecting sample (N = 949) and two using stratified random samples from a recruited panel (N = 2250, N = 2254). Results All three studies found a negative relationship between COVID-19 conspiracy beliefs and COVID-19 health-protective behaviours, and a positive relationship between COVID-19 conspiracy beliefs and use of social media as a source of information about COVID-19. Studies 2 and 3 also found a negative relationship between COVID-19 health-protective behaviours and use of social media as a source of information, and Study 3 found a positive relationship between health-protective behaviours and use of broadcast media as a source of information. Conclusions When used as an information source, unregulated social media may present a health risk that is partly but not wholly reducible to their role as disseminators of health-related conspiracy beliefs.\n",
            "------------------------------------\n",
            "Title :  Privacy as part of the app decision-making process\n",
            "Author/s :  Patrick Gage Kelley, L. Cranor, N. Sadeh\n",
            "Venue :  International Conference on Human Factors in Computing Systems\n",
            "year :  2013\n",
            "Abstract :  Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.\n",
            "------------------------------------\n",
            "Title :  What, Me Worry? The Role of Affect in Information Seeking and Avoidance\n",
            "Author/s :  Z. J. Yang, L. Kahlor\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Guided by the risk information-seeking and processing model, this study examines positive and negative affect separately in their influence on information-seeking intentions and avoidance through structural equation analyses. The highlight is that information avoidance seems to be driven by positive affect, while information seeking seems to be more heavily influenced by negative affect. Another interesting finding is that informational subjective norms are positively related to both seeking and avoidance, which suggests that one’s social environment has the potential to strongly influence the way he or she handles climate change information. Implications for theory and practice are discussed.\n",
            "------------------------------------\n",
            "Title :  Mixed Method Research: Instruments, Validity, Reliability and Reporting Findings\n",
            "Author/s :  Mohammad Zohrabi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The mixed method approaches have recently risen to prominence. The reason that more researchers are opting for these types of research is that both qualitative and quantitative data are simultaneously collected, analyzed and interpreted. In this article the main research instruments (questionnaire, interview and classroom observation) usually used in the mixed method designs are presented and elaborated on. It is believed that using different types of procedures for collecting data and obtaining that information through different sources (learners, teachers, program staff, etc.) can augment the validity and reliability of the data and their interpretation. Therefore, the various ways of boosting the validity and reliability of the data and instruments are delineated at length. Finally, an outline of reporting the findings in the mixed method approaches is sketched out. It is believed that this article can be useful and beneficial to the researchers in general and postgraduate students in particular who want to start or are involved in the process of conducting research.\n",
            "------------------------------------\n",
            "Title :  The Media and Mispricing: The Role of the Business Press in the Pricing of Accounting Information\n",
            "Author/s :  Michael S. Drake, Nicholas Guest, Brady J. Twedt\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  ABSTRACT: This study investigates the role of the business press in the pricing of accounting information. Using a comprehensive dataset of more than 111,000 earnings-related business press articles published from 2000 to 2010, we find that press coverage of the annual earnings announcement mitigates cash flow mispricing, but has a negligible effect on accrual mispricing. We provide evidence that this impact is driven primarily by the press disseminating the information more broadly, rather than by the creation of new content that helps investors understand the implications of accounting information. Our results suggest that the business press plays an important role in facilitating the market's ability to efficiently impound accounting information into stock prices and provide new insights into the role of the business press as an information intermediary in capital markets.\n",
            "------------------------------------\n",
            "Title :  CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations\n",
            "Author/s :  Stefan Seemayer, M. Gruber, J. Söding\n",
            "Venue :  Bioinform.\n",
            "year :  2014\n",
            "Abstract :  Motivation: Recent breakthroughs in protein residue–residue contact prediction have made reliable de novo prediction of protein structures possible. The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e. to separate direct from indirect effects. Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM). Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads. This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein–protein interactions. Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35–113 times faster and with the same precision as the most accurate published methods. For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4–14 times faster. Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15–60 s on a consumer-grade GPU and 1–6 min on a six-core CPU. Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title :  Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n",
            "Author/s :  I. Korstjens, A. Moser\n",
            "Venue :  European Journal of General Practice\n",
            "year :  2017\n",
            "Abstract :  Abstract In the course of our supervisory work over the years we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The first article provides an introduction to this series. The second article focused on context, research questions and designs. The third article focused on sampling, data collection and analysis. This fourth article addresses FAQs about trustworthiness and publishing. Quality criteria for all qualitative research are credibility, transferability, dependability, and confirmability. Reflexivity is an integral part of ensuring the transparency and quality of qualitative research. Writing a qualitative research article reflects the iterative nature of the qualitative research process: data analysis continues while writing. A qualitative research article is mostly narrative and tends to be longer than a quantitative paper, and sometimes requires a different structure. Editors essentially use the criteria: is it new, is it true, is it relevant? An effective cover letter enhances confidence in the newness, trueness and relevance, and explains why your study required a qualitative design. It provides information about the way you applied quality criteria or a checklist, and you can attach the checklist to the manuscript.\n",
            "------------------------------------\n",
            "Title :  Consumer Evaluation of the Quality of Online Health Information: Systematic Literature Review of Relevant Criteria and Indicators\n",
            "Author/s :  Yalin Sun, Yan Zhang, J. Gwizdka, Ciaran B. Trace\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2019\n",
            "Abstract :  Background As the quality of online health information remains questionable, there is a pressing need to understand how consumers evaluate this information. Past reviews identified content-, source-, and individual-related factors that influence consumer judgment in this area. However, systematic knowledge concerning the evaluation process, that is, why and how these factors influence the evaluation behavior, is lacking. Objective This review aims (1) to identify criteria (rules that reflect notions of value and worth) that consumers use to evaluate the quality of online health information and the indicators (properties of information objects to which criteria are applied to form judgments) they use to support the evaluation in order to achieve a better understanding of the process of information quality evaluation and (2) to explicate the relationship between indicators and criteria to provide clear guidelines for designers of consumer health information systems. Methods A systematic literature search was performed in seven digital reference databases including Medicine, Psychology, Communication, and Library and Information Science to identify empirical studies that report how consumers directly and explicitly describe their evaluation of online health information quality. Thirty-seven articles met the inclusion criteria. A qualitative content analysis was performed to identify quality evaluation criteria, indicators, and their relationships. Results We identified 25 criteria and 165 indicators. The most widely reported criteria used by consumers were trustworthiness, expertise, and objectivity. The indicators were related to source, content, and design. Among them, 114 were positive indicators (entailing positive quality judgments), 35 were negative indicators (entailing negative judgments), and 16 indicators had both positive and negative quality influence, depending on contextual factors (eg, source and individual differences) and criteria applied. The most widely reported indicators were site owners/sponsors; consensus among multiple sources; characteristics of writing and language; advertisements; content authorship; and interface design. Conclusions Consumer evaluation of online health information is a complex cost-benefit analysis process that involves the use of a wide range of criteria and a much wider range of quality indicators. There are commonalities in the use of criteria across user groups and source types, but the differences are hard to ignore. Evidently, consumers’ health information evaluation can be characterized as highly subjective and contextualized, and sometimes, misinformed. These findings invite more research into how different user groups evaluate different types of online sources and a personalized approach to educate users about evaluating online health information quality.\n",
            "------------------------------------\n",
            "Title :  Attributed Social Network Embedding\n",
            "Author/s :  Lizi Liao, Xiangnan He, Hanwang Zhang, Tat-Seng Chua\n",
            "Venue :  IEEE Transactions on Knowledge and Data Engineering\n",
            "year :  2017\n",
            "Abstract :  Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Attributed Social Network Embedding framework (ASNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, ASNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, ASNE significantly outperforms  node2vec with an 8.2 percent relative improvement on the link prediction task, and a 12.7 percent gain on the node classification task.\n",
            "------------------------------------\n",
            "Title :  At Least Bias Is Bipartisan: A Meta-Analytic Comparison of Partisan Bias in Liberals and Conservatives\n",
            "Author/s :  P. Ditto, Brittany S. Liu, Cory J. Clark, S. Wojcik, Eric Chen, R. Grady, Jared B. Celniker, Joanne F. Zinger\n",
            "Venue :  Perspectives on Psychological Science\n",
            "year :  2017\n",
            "Abstract :  Both liberals and conservatives accuse their political opponents of partisan bias, but is there empirical evidence that one side of the political aisle is indeed more biased than the other? To address this question, we meta-analyzed the results of 51 experimental studies, involving over 18,000 participants, that examined one form of partisan bias—the tendency to evaluate otherwise identical information more favorably when it supports one’s political beliefs or allegiances than when it challenges those beliefs or allegiances. Two hypotheses based on previous literature were tested: an asymmetry hypothesis (predicting greater partisan bias in conservatives than in liberals) and a symmetry hypothesis (predicting equal levels of partisan bias in liberals and conservatives). Mean overall partisan bias was robust (r = .245), and there was strong support for the symmetry hypothesis: Liberals (r = .235) and conservatives (r = .255) showed no difference in mean levels of bias across studies. Moderator analyses reveal this pattern to be consistent across a number of different methodological variations and political topics. Implications of the current findings for the ongoing ideological symmetry debate and the role of partisan bias in scientific discourse and political conflict are discussed.\n",
            "------------------------------------\n",
            "Title :  Roadmap on optical security\n",
            "Author/s :  B. Javidi, A. Carnicer, Masahiro Yamaguchi, T. Nomura, E. Pérez-Cabré, M. S. Millán, N. Nishchal, R. Torroba, J. F. Barrera, W. He, Xiang Peng, A. Stern, Y. Rivenson, A. Alfalou, C. Brosseau, Changliang Guo, J. Sheridan, G. Situ, M. Naruse, Tsutomu Matsumoto, I. Juvells, E. Tajahuerce, J. Lancis, Wen Chen, Xudong Chen, P. Pinkse, A. Mosk, A. Markman\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Information security and authentication are important challenges facing society. Recent attacks by hackers on the databases of large commercial and financial companies have demonstrated that more research and development of advanced approaches are necessary to deny unauthorized access to critical data. Free space optical technology has been investigated by many researchers in information security, encryption, and authentication. The main motivation for using optics and photonics for information security is that optical waveforms possess many complex degrees of freedom such as amplitude, phase, polarization, large bandwidth, nonlinear transformations, quantum properties of photons, and multiplexing that can be combined in many ways to make information encryption more secure and more difficult to attack. This roadmap article presents an overview of the potential, recent advances, and challenges of optical security and encryption using free space optics. The roadmap on optical security is comprised of six categories that together include 16 short sections written by authors who have made relevant contributions in this field. The first category of this roadmap describes novel encryption approaches, including secure optical sensing which summarizes double random phase encryption applications and flaws [Yamaguchi], the digital holographic encryption in free space optical technique which describes encryption using multidimensional digital holography [Nomura], simultaneous encryption of multiple signals [Pérez-Cabré], asymmetric methods based on information truncation [Nishchal], and dynamic encryption of video sequences [Torroba]. Asymmetric and one-way cryptosystems are analyzed by Peng. The second category is on compression for encryption. In their respective contributions, Alfalou and Stern propose similar goals involving compressed data and compressive sensing encryption. The very important area of cryptanalysis is the topic of the third category with two sections: Sheridan reviews phase retrieval algorithms to perform different attacks, whereas Situ discusses nonlinear optical encryption techniques and the development of a rigorous optical information security theory. The fourth category with two contributions reports how encryption could be implemented at the nano- or micro-scale. Naruse discusses the use of nanostructures in security applications and Carnicer proposes encoding information in a tightly focused beam. In the fifth category, encryption based on ghost imaging using single-pixel detectors is also considered. In particular, the authors [Chen, Tajahuerce] emphasize the need for more specialized hardware and image processing algorithms. Finally, in the sixth category, Mosk and Javidi analyze in their corresponding papers how quantum imaging can benefit optical encryption systems. Sources that use few photons make encryption systems much more difficult to attack, providing a secure method for authentication.\n",
            "------------------------------------\n",
            "Title :  Direction of information flow in large-scale resting-state networks is frequency-dependent\n",
            "Author/s :  A. Hillebrand, P. Tewarie, E. van Dellen, Meichen Yu, Ellen W. S. Carbo, L. Douw, A. Gouw, E. V. van Straaten, C. Stam\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2016\n",
            "Abstract :  Significance A description of the structural and functional connections in the human brain is necessary for the understanding of both normal and abnormal brain functioning. Although it has become clear in recent years that stable patterns of functional connectivity can be observed during the resting state, to date, it remains unclear what the dominant patterns of information flow are in this functional connectome and how these relate to the integration of brain function. Our results are the first to describe the large-scale frequency-specific patterns of information flow in the human brain, showing that different subsystems form a loop through which information “reverberates” or “circulates.” These results could be extended to give insights into how such flow optimizes integrative cognitive processing. Normal brain function requires interactions between spatially separated, and functionally specialized, macroscopic regions, yet the directionality of these interactions in large-scale functional networks is unknown. Magnetoencephalography was used to determine the directionality of these interactions, where directionality was inferred from time series of beamformer-reconstructed estimates of neuronal activation, using a recently proposed measure of phase transfer entropy. We observed well-organized posterior-to-anterior patterns of information flow in the higher-frequency bands (alpha1, alpha2, and beta band), dominated by regions in the visual cortex and posterior default mode network. Opposite patterns of anterior-to-posterior flow were found in the theta band, involving mainly regions in the frontal lobe that were sending information to a more distributed network. Many strong information senders in the theta band were also frequent receivers in the alpha2 band, and vice versa. Our results provide evidence that large-scale resting-state patterns of information flow in the human brain form frequency-dependent reentry loops that are dominated by flow from parieto-occipital cortex to integrative frontal areas in the higher-frequency bands, which is mirrored by a theta band anterior-to-posterior flow.\n",
            "------------------------------------\n",
            "Title :  From the Office of the National Coordinator: the strategy for advancing the exchange of health information.\n",
            "Author/s :  Claudia H. Williams, F. Mostashari, Kory Mertz, E. Hogin, P. Atwal\n",
            "Venue :  Health Affairs\n",
            "year :  2012\n",
            "Abstract :  Electronic health information exchange addresses a critical need in the US health care system to have information follow patients to support patient care. Today little information is shared electronically, leaving doctors without the information they need to provide the best care. With payment reforms providing a strong business driver, the demand for health information exchange is poised to grow. The Office of the National Coordinator for Health Information Technology, Department of Health and Human Services, has led the process of establishing the essential building blocks that will support health information exchange. Over the coming year, this office will develop additional policies and standards that will make information exchange easier and cheaper and facilitate its use on a broader scale.\n",
            "------------------------------------\n",
            "Title :  Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\n",
            "Author/s :  Jiasen Lu, Caiming Xiong, Devi Parikh, R. Socher\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2016\n",
            "Abstract :  Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.\n",
            "------------------------------------\n",
            "Title :  Online Product Reviews: Implications for Retailers and Competing Manufacturers\n",
            "Author/s :  Young Kwark, Jianqing Chen, Srinivasan Raghunathan\n",
            "Venue :  Information systems research\n",
            "year :  2012\n",
            "Abstract :  This paper studies the effect of online product reviews on different players in a channel structure. We consider a retailer selling two substitutable products produced by different manufacturers, and the products differ in both their qualities and fits to consumers' needs. Online product reviews provide additional information for consumers to mitigate the uncertainty about the quality of a product and about its fit to consumers' needs. We show that the effect of reviews on the upstream competition between the manufacturers is critical in understanding which firms gain and which firms lose. The upstream competition is affected in fundamentally different ways by quality information and fit information, and each information type has different implications for the retailer and manufacturers. Quality information homogenizes consumers' perceived utility differences between the two products and increases the upstream competition, which benefits the retailer but hurts the manufacturers. Fit information heterogenizes consumers' estimated fits to the products and softens the upstream competition, which hurts the retailer but benefits the manufacturers. Furthermore, reviews may also alter the nature of upstream competition from one in which consumers' own assessment on the quality dimension plays a dominant role in consumers' comparative evaluation of products to one in which fit dimension plays a dominant role. If manufacturers do not respond strategically to reviews and keep the same wholesale prices regardless of reviews i.e., the upstream competition is assumed to be unaffected by reviews, then, we show that reviews never hurt the retailer and the manufacturer with favorable reviews, and never benefit the manufacturer with unfavorable reviews, a finding that demonstrates why reviews' effect on upstream competition is critical for firms in online marketplaces.\n",
            "------------------------------------\n",
            "Title :  CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations\n",
            "Author/s :  Stefan Seemayer, M. Gruber, J. Söding\n",
            "Venue :  Bioinform.\n",
            "year :  2014\n",
            "Abstract :  Motivation: Recent breakthroughs in protein residue–residue contact prediction have made reliable de novo prediction of protein structures possible. The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e. to separate direct from indirect effects. Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM). Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads. This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein–protein interactions. Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35–113 times faster and with the same precision as the most accurate published methods. For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4–14 times faster. Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15–60 s on a consumer-grade GPU and 1–6 min on a six-core CPU. Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title :  Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n",
            "Author/s :  I. Korstjens, A. Moser\n",
            "Venue :  European Journal of General Practice\n",
            "year :  2017\n",
            "Abstract :  Abstract In the course of our supervisory work over the years we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The first article provides an introduction to this series. The second article focused on context, research questions and designs. The third article focused on sampling, data collection and analysis. This fourth article addresses FAQs about trustworthiness and publishing. Quality criteria for all qualitative research are credibility, transferability, dependability, and confirmability. Reflexivity is an integral part of ensuring the transparency and quality of qualitative research. Writing a qualitative research article reflects the iterative nature of the qualitative research process: data analysis continues while writing. A qualitative research article is mostly narrative and tends to be longer than a quantitative paper, and sometimes requires a different structure. Editors essentially use the criteria: is it new, is it true, is it relevant? An effective cover letter enhances confidence in the newness, trueness and relevance, and explains why your study required a qualitative design. It provides information about the way you applied quality criteria or a checklist, and you can attach the checklist to the manuscript.\n",
            "------------------------------------\n",
            "Title :  Consumer Evaluation of the Quality of Online Health Information: Systematic Literature Review of Relevant Criteria and Indicators\n",
            "Author/s :  Yalin Sun, Yan Zhang, J. Gwizdka, Ciaran B. Trace\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2019\n",
            "Abstract :  Background As the quality of online health information remains questionable, there is a pressing need to understand how consumers evaluate this information. Past reviews identified content-, source-, and individual-related factors that influence consumer judgment in this area. However, systematic knowledge concerning the evaluation process, that is, why and how these factors influence the evaluation behavior, is lacking. Objective This review aims (1) to identify criteria (rules that reflect notions of value and worth) that consumers use to evaluate the quality of online health information and the indicators (properties of information objects to which criteria are applied to form judgments) they use to support the evaluation in order to achieve a better understanding of the process of information quality evaluation and (2) to explicate the relationship between indicators and criteria to provide clear guidelines for designers of consumer health information systems. Methods A systematic literature search was performed in seven digital reference databases including Medicine, Psychology, Communication, and Library and Information Science to identify empirical studies that report how consumers directly and explicitly describe their evaluation of online health information quality. Thirty-seven articles met the inclusion criteria. A qualitative content analysis was performed to identify quality evaluation criteria, indicators, and their relationships. Results We identified 25 criteria and 165 indicators. The most widely reported criteria used by consumers were trustworthiness, expertise, and objectivity. The indicators were related to source, content, and design. Among them, 114 were positive indicators (entailing positive quality judgments), 35 were negative indicators (entailing negative judgments), and 16 indicators had both positive and negative quality influence, depending on contextual factors (eg, source and individual differences) and criteria applied. The most widely reported indicators were site owners/sponsors; consensus among multiple sources; characteristics of writing and language; advertisements; content authorship; and interface design. Conclusions Consumer evaluation of online health information is a complex cost-benefit analysis process that involves the use of a wide range of criteria and a much wider range of quality indicators. There are commonalities in the use of criteria across user groups and source types, but the differences are hard to ignore. Evidently, consumers’ health information evaluation can be characterized as highly subjective and contextualized, and sometimes, misinformed. These findings invite more research into how different user groups evaluate different types of online sources and a personalized approach to educate users about evaluating online health information quality.\n",
            "------------------------------------\n",
            "Title :  At Least Bias Is Bipartisan: A Meta-Analytic Comparison of Partisan Bias in Liberals and Conservatives\n",
            "Author/s :  P. Ditto, Brittany S. Liu, Cory J. Clark, S. Wojcik, Eric Chen, R. Grady, Jared B. Celniker, Joanne F. Zinger\n",
            "Venue :  Perspectives on Psychological Science\n",
            "year :  2017\n",
            "Abstract :  Both liberals and conservatives accuse their political opponents of partisan bias, but is there empirical evidence that one side of the political aisle is indeed more biased than the other? To address this question, we meta-analyzed the results of 51 experimental studies, involving over 18,000 participants, that examined one form of partisan bias—the tendency to evaluate otherwise identical information more favorably when it supports one’s political beliefs or allegiances than when it challenges those beliefs or allegiances. Two hypotheses based on previous literature were tested: an asymmetry hypothesis (predicting greater partisan bias in conservatives than in liberals) and a symmetry hypothesis (predicting equal levels of partisan bias in liberals and conservatives). Mean overall partisan bias was robust (r = .245), and there was strong support for the symmetry hypothesis: Liberals (r = .235) and conservatives (r = .255) showed no difference in mean levels of bias across studies. Moderator analyses reveal this pattern to be consistent across a number of different methodological variations and political topics. Implications of the current findings for the ongoing ideological symmetry debate and the role of partisan bias in scientific discourse and political conflict are discussed.\n",
            "------------------------------------\n",
            "Title :  Mixed Method Research: Instruments, Validity, Reliability and Reporting Findings\n",
            "Author/s :  Mohammad Zohrabi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The mixed method approaches have recently risen to prominence. The reason that more researchers are opting for these types of research is that both qualitative and quantitative data are simultaneously collected, analyzed and interpreted. In this article the main research instruments (questionnaire, interview and classroom observation) usually used in the mixed method designs are presented and elaborated on. It is believed that using different types of procedures for collecting data and obtaining that information through different sources (learners, teachers, program staff, etc.) can augment the validity and reliability of the data and their interpretation. Therefore, the various ways of boosting the validity and reliability of the data and instruments are delineated at length. Finally, an outline of reporting the findings in the mixed method approaches is sketched out. It is believed that this article can be useful and beneficial to the researchers in general and postgraduate students in particular who want to start or are involved in the process of conducting research.\n",
            "------------------------------------\n",
            "Title :  Direction of information flow in large-scale resting-state networks is frequency-dependent\n",
            "Author/s :  A. Hillebrand, P. Tewarie, E. van Dellen, Meichen Yu, Ellen W. S. Carbo, L. Douw, A. Gouw, E. V. van Straaten, C. Stam\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2016\n",
            "Abstract :  Significance A description of the structural and functional connections in the human brain is necessary for the understanding of both normal and abnormal brain functioning. Although it has become clear in recent years that stable patterns of functional connectivity can be observed during the resting state, to date, it remains unclear what the dominant patterns of information flow are in this functional connectome and how these relate to the integration of brain function. Our results are the first to describe the large-scale frequency-specific patterns of information flow in the human brain, showing that different subsystems form a loop through which information “reverberates” or “circulates.” These results could be extended to give insights into how such flow optimizes integrative cognitive processing. Normal brain function requires interactions between spatially separated, and functionally specialized, macroscopic regions, yet the directionality of these interactions in large-scale functional networks is unknown. Magnetoencephalography was used to determine the directionality of these interactions, where directionality was inferred from time series of beamformer-reconstructed estimates of neuronal activation, using a recently proposed measure of phase transfer entropy. We observed well-organized posterior-to-anterior patterns of information flow in the higher-frequency bands (alpha1, alpha2, and beta band), dominated by regions in the visual cortex and posterior default mode network. Opposite patterns of anterior-to-posterior flow were found in the theta band, involving mainly regions in the frontal lobe that were sending information to a more distributed network. Many strong information senders in the theta band were also frequent receivers in the alpha2 band, and vice versa. Our results provide evidence that large-scale resting-state patterns of information flow in the human brain form frequency-dependent reentry loops that are dominated by flow from parieto-occipital cortex to integrative frontal areas in the higher-frequency bands, which is mirrored by a theta band anterior-to-posterior flow.\n",
            "------------------------------------\n",
            "Title :  From the Office of the National Coordinator: the strategy for advancing the exchange of health information.\n",
            "Author/s :  Claudia H. Williams, F. Mostashari, Kory Mertz, E. Hogin, P. Atwal\n",
            "Venue :  Health Affairs\n",
            "year :  2012\n",
            "Abstract :  Electronic health information exchange addresses a critical need in the US health care system to have information follow patients to support patient care. Today little information is shared electronically, leaving doctors without the information they need to provide the best care. With payment reforms providing a strong business driver, the demand for health information exchange is poised to grow. The Office of the National Coordinator for Health Information Technology, Department of Health and Human Services, has led the process of establishing the essential building blocks that will support health information exchange. Over the coming year, this office will develop additional policies and standards that will make information exchange easier and cheaper and facilitate its use on a broader scale.\n",
            "------------------------------------\n",
            "Title :  Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\n",
            "Author/s :  Jiasen Lu, Caiming Xiong, Devi Parikh, R. Socher\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2016\n",
            "Abstract :  Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.\n",
            "------------------------------------\n",
            "Title :  Rise and fall patterns of information diffusion: model and implications\n",
            "Author/s :  Yasuko Matsubara, Yasushi Sakurai, B. Prakash, Lei Li, C. Faloutsos\n",
            "Venue :  Knowledge Discovery and Data Mining\n",
            "year :  2012\n",
            "Abstract :  The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated faster propagation of news and rumors. How quickly does a piece of news spread over these media? How does its popularity diminish over time? Does the rising and falling pattern follow a simple universal law?\n",
            " In this paper, we propose SpikeM, a concise yet flexible analytical model for the rise and fall patterns of influence propagation. Our model has the following advantages: (a) unification power: it generalizes and explains earlier theoretical models and empirical observations; (b) practicality: it matches the observed behavior of diverse sets of real data; (c) parsimony: it requires only a handful of parameters; and (d) usefulness: it enables further analytics tasks such as fore- casting, spotting anomalies, and interpretation by reverse- engineering the system parameters of interest (e.g. quality of news, count of interested bloggers, etc.).\n",
            " Using SpikeM, we analyzed 7.2GB of real data, most of which were collected from the public domain. We have shown that our SpikeM model accurately and succinctly describes all the patterns of the rise-and-fall spikes in these real datasets.\n",
            "------------------------------------\n",
            "Title :  A Hybrid Collaborative Filtering Model with Deep Structure for Recommender Systems\n",
            "Author/s :  Xin Dong, Lei Yu, Zhonghuo Wu, Yuxia Sun, Lingfeng Yuan, Fangxi Zhang\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2017\n",
            "Abstract :  \n",
            " \n",
            " Collaborative filtering (CF) is a widely used approach in recommender systems to solve many real-world problems. Traditional CF-based methods employ the user-item matrix which encodes the individual preferences of users for items for learning to make recommendation. In real applications, the rating matrix is usually very sparse, causing CF-based methods to degrade significantly in recommendation performance. In this case, some improved CF methods utilize the increasing amount of side information to address the data sparsity problem as well as the cold start problem. However, the learned latent factors may not be effective due to the sparse nature of the user-item matrix and the side information. To address this problem, we utilize advances of learning effective representations in deep learning, and propose a hybrid model which jointly performs deep users and items’ latent factors learning from side information and collaborative filtering from the rating matrix. Extensive experimental results on three real-world datasets show that our hybrid model outperforms other methods in effectively utilizing side information and achieves performance improvement.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  The Pen Is Mightier Than the Keyboard\n",
            "Author/s :  Pam Mueller, Daniel M. Oppenheimer\n",
            "Venue :  Psychology Science\n",
            "year :  2014\n",
            "Abstract :  Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students’ capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers’ tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning.\n",
            "------------------------------------\n",
            "Title :  BIM in facilities management applications: a case study of a large university complex\n",
            "Author/s :  M. Kassem, G. Kelly, N. Dawood, M. Serginson, S. Lockley\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose – Building information modelling (BIM) in facilities management (FM) applications is an emerging area of research based on the theoretical proposition that BIM information, generated and captured during the lifecycle of a facility, can improve its management. Using this proposition as a starting point, the purpose of this paper is to investigate the value of BIM and the challenges affecting its adoption in FM applications. Design/methodology/approach – Two inter-related research methods are utilised. The literature is utilised to identify the application areas, value and challenges of BIM in FM. Due to the lack of case studies identified in the literature review, and to provide empirical evidence of the value and challenges of BIM in FM, a case study of Northumbria University’s city campus, is used to empirically explore the value and challenges of BIM in FM. Findings – The results demonstrated that BIM value in FM stems from improvement to current manual processes of information handover; improve...\n",
            "------------------------------------\n",
            "Title :  Information Exchange in Policy Networks\n",
            "Author/s :  P. Leifeld, V. Schneider\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Information exchange in policy networks is usually attributed to preference similarity, influence reputation, social trust, and institutional actor roles. We suggest that political opportunity structures and transaction costs play another crucial role and estimate a rich statistical network model on tie formation in the German toxic chemicals policy domain. The results indicate that the effect of preference similarity is absorbed by institutional, relational, and social opportunity structures. Political actors choose contacts who minimize transaction costs while maximizing outreach and information. We also find that different types of information exchange operate in complementary, but not necessarily congruent, ways.\n",
            "------------------------------------\n",
            "Title :  Integrated photonic quantum technologies\n",
            "Author/s :  Jianwei Wang, F. Sciarrino, A. Laing, M. Thompson\n",
            "Venue :  Nature Photonics\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Oruta: privacy-preserving public auditing for shared data in the cloud\n",
            "Author/s :  Boyang Wang, Baochun Li, Hui Li\n",
            "Venue :  IEEE Transactions on Cloud Computing\n",
            "year :  2012\n",
            "Abstract :  With cloud data services, it is commonplace for data to be not only stored in the cloud, but also shared across multiple users. Unfortunately, the integrity of cloud data is subject to skepticism due to the existence of hardware/software failures and human errors. Several mechanisms have been designed to allow both data owners and public verifiers to efficiently audit cloud data integrity without retrieving the entire data from the cloud server. However, public auditing on the integrity of shared data with these existing mechanisms will inevitably reveal confidential information-identity privacy-to public verifiers. In this paper, we propose a novel privacy-preserving mechanism that supports public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute verification metadata needed to audit the correctness of shared data. With our mechanism, the identity of the signer on each block in shared data is kept private from public verifiers, who are able to efficiently verify shared data integrity without retrieving the entire file. In addition, our mechanism is able to perform multiple auditing tasks simultaneously instead of verifying them one by one. Our experimental results demonstrate the effectiveness and efficiency of our mechanism when auditing shared data integrity.\n",
            "------------------------------------\n",
            "Title :  Twitcident: fighting fire with information from social web streams\n",
            "Author/s :  F. Abel, C. Hauff, G. Houben, R.J.P. Stronkman, Ke Tao\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  In this paper, we present Twitcident, a framework and Web-based system for filtering, searching and analyzing information about real-world incidents or crises. Twitcident connects to emergency broadcasting services and automatically starts tracking and filtering information from Social Web streams (Twitter) when a new incident occurs. It enriches the semantics of streamed Twitter messages to profile incidents and to continuously improve and adapt the information filtering to the current temporal context. Faceted search and analytical tools allow users to retrieve particular information fragments and overview and analyze the current situation as reported on the Social Web. Demo: http://wis.ewi.tudelft.nl/twitcident/\n",
            "------------------------------------\n",
            "Title :  Empowering patients through social media: The benefits and challenges\n",
            "Author/s :  M. Househ, E. Borycki, A. Kushniruk\n",
            "Venue :  Health Informatics Journal\n",
            "year :  2014\n",
            "Abstract :  This article explores the range of social media platforms used by patients and examines the benefits and challenges of using these tools from a patient perspective. A literature review was performed to investigate the use of social media technology by patients. The MEDLINE database was searched using the terms “social media” and “patient.” The search was conducted in September 2012 and yielded 765 abstracts. Initially, 63 abstracts were selected. All articles dating from 2004 through 2012 were included. Only 12 articles were found to be relevant for the purposes of the review. The results of this research found that there appears to be an increase in the use of social media by patients across the healthcare spectrum. The research indicates a promising future for the use of social media by patients; however, evidence related to the efficacy and effectiveness of social media is currently limited. Various challenges have also been identified relating to privacy and security concerns, usability, the manipulation of identity, and misinformation. The use of social media technology is an emerging trend for patients who are seeking health information. Conclusions are that such technology holds promise for improving patient engagement and empowerment and community building. Social media has a future in healthcare, especially with regard to patient engagement and empowerment; however, there are several challenges to overcome before the technology can achieve its potential.\n",
            "------------------------------------\n",
            "Title :  The Updated DeLone and McLean Model of Information Systems Success\n",
            "Author/s :  Nils Urbach, B. Müller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Patients want granular privacy control over health information in electronic medical records\n",
            "Author/s :  Kelly E. Caine, Rima Hanania\n",
            "Venue :  J. Am. Medical Informatics Assoc.\n",
            "year :  2013\n",
            "Abstract :  OBJECTIVE\n",
            "To assess patients' desire for granular level privacy control over which personal health information should be shared, with whom, and for what purpose; and whether these preferences vary based on sensitivity of health information.\n",
            "\n",
            "\n",
            "MATERIALS AND METHODS\n",
            "A card task for matching health information with providers, questionnaire, and interview with 30 patients whose health information is stored in an electronic medical record system. Most patients' records contained sensitive health information.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "No patients reported that they would prefer to share all information stored in an electronic medical record (EMR) with all potential recipients. Sharing preferences varied by type of information (EMR data element) and recipient (eg, primary care provider), and overall sharing preferences varied by participant. Patients with and without sensitive records preferred less sharing of sensitive versus less-sensitive information.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Patients expressed sharing preferences consistent with a desire for granular privacy control over which health information should be shared with whom and expressed differences in sharing preferences for sensitive versus less-sensitive EMR data. The pattern of results may be used by designers to generate privacy-preserving EMR systems including interfaces for patients to express privacy and sharing preferences.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "To maintain the level of privacy afforded by medical records and to achieve alignment with patients' preferences, patients should have granular privacy control over information contained in their EMR.\n",
            "------------------------------------\n",
            "Title :  Remote Sensing Technologies for Enhancing Forest Inventories: A Review\n",
            "Author/s :  J. White, N. Coops, M. Wulder, M. Vastaranta, T. Hilker, P. Tompalski\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Abstract Forest inventory and management requirements are changing rapidly in the context of an increasingly complex set of economic, environmental, and social policy objectives. Advanced remote sensing technologies provide data to assist in addressing these escalating information needs and to support the subsequent development and parameterization of models for an even broader range of information needs. This special issue contains papers that use a variety of remote sensing technologies to derive forest inventory or inventory-related information. Herein, we review the potential of 4 advanced remote sensing technologies, which we posit as having the greatest potential to influence forest inventories designed to characterize forest resource information for strategic, tactical, and operational planning: airborne laser scanning (ALS), terrestrial laser scanning (TLS), digital aerial photogrammetry (DAP), and high spatial resolution (HSR)/very high spatial resolution (VHSR) satellite optical imagery. ALS, in particular, has proven to be a transformative technology, offering forest inventories the required spatial detail and accuracy across large areas and a diverse range of forest types. The coupling of DAP with ALS technologies will likely have the greatest impact on forest inventory practices in the next decade, providing capacity for a broader suite of attributes, as well as for monitoring growth over time.\n",
            "------------------------------------\n",
            "Title :  Community Detection in Networks with Node Attributes\n",
            "Author/s :  Jaewon Yang, Julian McAuley, J. Leskovec\n",
            "Venue :  2013 IEEE 13th International Conference on Data Mining\n",
            "year :  2013\n",
            "Abstract :  Community detection algorithms are fundamental tools that allow us to uncover organizational principles in networks. When detecting communities, there are two possible sources of information one can use: the network structure, and the features and attributes of nodes. Even though communities form around nodes that have common edges and common attributes, typically, algorithms have only focused on one of these two data modalities: community detection algorithms traditionally focus only on the network structure, while clustering algorithms mostly consider only node attributes. In this paper, we develop Communities from Edge Structure and Node Attributes (CESNA), an accurate and scalable algorithm for detecting overlapping communities in networks with node attributes. CESNA statistically models the interaction between the network structure and the node attributes, which leads to more accurate community detection as well as improved robustness in the presence of noise in the network structure. CESNA has a linear runtime in the network size and is able to process networks an order of magnitude larger than comparable approaches. Last, CESNA also helps with the interpretation of detected communities by finding relevant node attributes for each community.\n",
            "------------------------------------\n",
            "Title :  The Real Effects of Financial Shocks: Evidence from Exogenous Changes in Analyst Coverage\n",
            "Author/s :  F. Derrien, Ambrus Kecskés\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  We study the causal effects of analyst coverage on corporate investment and financing policies. We hypothesize that a decrease in analyst coverage increases information asymmetry and thus increases the cost of capital; as a result, firms decrease their investment and financing. We use broker closures and broker mergers to identify changes in analyst coverage that are exogenous to corporate policies. Using a difference-in-differences approach, we find that firms that lose an analyst decrease their investment and financing by 2.4% and 2.6% of total assets, respectively. These results are significantly stronger for firms that are smaller, have less analyst coverage, have a bigger increase in information asymmetry, and are more financially constrained.\n",
            "------------------------------------\n",
            "Title :  Stability and Scalability of Homogeneous Vehicular Platoon: Study on the Influence of Information Flow Topologies\n",
            "Author/s :  Yang Zheng, S. Li, Jianqiang Wang, D. Cao, Keqiang Li\n",
            "Venue :  IEEE transactions on intelligent transportation systems (Print)\n",
            "year :  2016\n",
            "Abstract :  In addition to decentralized controllers, the information flow among vehicles can significantly affect the dynamics of a platoon. This paper studies the influence of information flow topology on the internal stability and scalability of homogeneous vehicular platoons moving in a rigid formation. A linearized vehicle longitudinal dynamic model is derived using the exact feedback linearization technique, which accommodates the inertial delay of powertrain dynamics. Directed graphs are adopted to describe different types of allowable information flow interconnecting vehicles, including both radar-based sensors and vehicle-to-vehicle (V2V) communications. Under linear feedback controllers, a unified internal stability theorem is proved by using the algebraic graph theory and Routh-Hurwitz stability criterion. The theorem explicitly establishes the stabilizing thresholds of linear controller gains for platoons, under a large class of different information flow topologies. Using matrix eigenvalue analysis, the scalability is investigated for platoons under two typical information flow topologies, i.e., 1) the stability margin of platoon decays to zero as 0(1/N2) for bidirectional topology; and 2) the stability margin is always bounded and independent of the platoon size for bidirectional-leader topology. Numerical simulations are used to illustrate the results.\n",
            "------------------------------------\n",
            "Title :  Multi-Antenna Wireless Powered Communication With Energy Beamforming\n",
            "Author/s :  Liang Liu, Rui Zhang, K. Chua\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2013\n",
            "Abstract :  The newly emerging wireless powered communication networks (WPCNs) have recently drawn significant attention, where radio signals are used to power wireless terminals for information transmission. In this paper, we study a WPCN where one multi-antenna access point (AP) coordinates energy transfer and information transfer to/from a set of single-antenna users. A harvest-then-transmit protocol is assumed where the AP first broadcasts wireless power to all users via energy beamforming in the downlink (DL), and then, the users send their independent information to the AP simultaneously in the uplink (UL) using their harvested energy. To optimize the users' throughput and yet guarantee their rate fairness, we maximize the minimum throughput among all users by a joint design of the DL-UL time allocation, the DL energy beamforming, and the UL transmit power allocation, as well as receive beamforming. We solve this nonconvex problem optimally by two steps. First, we fix the DL-UL time allocation and obtain the optimal DL energy beamforming, UL power allocation, and receive beamforming to maximize the minimum signal-to-interference-plus-noise ratio of all users. This problem is shown to be still nonconvex; however, we convert it equivalently to a spectral radius minimization problem, which can be solved efficiently by applying the alternating optimization based on the nonnegative matrix theory. Then, the optimal time allocation is found by a one-dimensional search to maximize the minimum rate of all users. Furthermore, two suboptimal designs of lower complexity are also proposed, and their throughput performance is compared against that of the optimal solution.\n",
            "------------------------------------\n",
            "Title :  Wireless Energy and Information Transfer Tradeoff for Limited-Feedback Multiantenna Systems With Energy Beamforming\n",
            "Author/s :  Xiaoming Chen, C. Yuen, Zhaoyang Zhang\n",
            "Venue :  IEEE Transactions on Vehicular Technology\n",
            "year :  2013\n",
            "Abstract :  In this paper, we consider a multiantenna system where the receiver should harvest energy from the transmitter by wireless energy transfer to support its wireless information transmission. To maximize the harvesting energy, we propose the performance of adaptive energy beamforming according to the instantaneous channel state information (CSI). To help the transmitter obtain the CSI for energy beamforming, we further propose a win-win CSI quantization feedback strategy to improve the efficiencies of both power and information transmission. The focus of this paper is on the tradeoff of wireless energy and information transfer by adjusting the transfer duration with a total duration constraint. By revealing the relationship between transmit power, transfer duration, and feedback amount, we derive two wireless energy and information transfer tradeoff schemes by maximizing an upper bound and an approximate lower bound of the average information transmission rate, respectively. Moreover, the impact of imperfect CSI at the receiver is investigated, and the corresponding wireless energy and information transfer tradeoff scheme is also given. Finally, numerical results validate the effectiveness of the proposed schemes.\n",
            "------------------------------------\n",
            "Title :  Relevance Theory\n",
            "Author/s :  Deirdre Wilson\n",
            "Venue :  Oxford Research Encyclopedia of Linguistics\n",
            "year :  2019\n",
            "Abstract :  Relevance theory is a cognitive approach to pragmatics which starts from two broadly Gricean assumptions: (a) that much human communication, both verbal and non-verbal, involves the overt expression and inferential recognition of intentions, and (b) that in inferring these intentions, the addressee presumes that the communicator’s behavior will meet certain standards, which for Grice are based on a Cooperative Principle and maxims, and for relevance theory are derived from the assumption that, as a result of constant selection pressures in the course of human evolution, both cognition and communication are relevance-oriented. Relevance is defined in terms of cognitive (or contextual) effects and processing effort: other things being equal, the greater the cognitive effects and the smaller the processing effort, the greater the relevance.\n",
            " A long-standing aim of relevance theory has been to show that building an adequate theory of communication involves going beyond Grice’s notion of speaker’s meaning. Another is to provide a conceptually unified account of how a much broader variety of communicative acts than Grice was concerned with—including cases of both showing that and telling that—are understood. The resulting pragmatic theory differs from Grice’s in several respects. It sees explicit communication as much richer and more inferential than Grice thought, with encoded sentence meanings providing no more than clues to the speaker’s intentions. It rejects the close link that Grice saw between implicit communication and (real or apparent) maxim violation, showing in particular how figurative utterances might arise naturally and spontaneously in the course of communication. It offers an account of vagueness or indeterminacy in communication, which is often abstracted away from in more formally oriented frameworks. It investigates the role of context in comprehension, and shows how tentative hypotheses about the intended combination of explicit content, contextual assumptions, and implicatures might be refined and mutually adjusted in the course of the comprehension process in order to satisfy expectations of relevance.\n",
            " Relevance theory treats the borderline between semantics and pragmatics as co-extensive with the borderline between (linguistic) decoding and (pragmatic) inference. It sees encoded sentence meanings as typically fragmentary and incomplete, and as having to undergo inferential enrichment or elaboration in order to yield fully propositional forms. It reanalyzes Grice’s conventional implicatures—which he saw as semantic but non-truth-conditional aspects of the meaning of words like but and so—as encoding procedural information with dedicated pragmatic or more broadly cognitive functions, and extends the notion of procedural meaning to a range of further items such as pronouns, discourse particles, mood indicators, and affective intonation.\n",
            "------------------------------------\n",
            "Title :  A State-of-the-Art Review on the Integration of Building Information Modeling (BIM) and Geographic Information System (GIS)\n",
            "Author/s :  Xin Liu, Xiangyu Wang, G. Wright, Jack C. P. Cheng, Xiao Li, R. Liu\n",
            "Venue :  ISPRS Int. J. Geo Inf.\n",
            "year :  2017\n",
            "Abstract :  The integration of Building Information Modeling (BIM) and Geographic Information System (GIS) has been identified as a promising but challenging topic to transform information towards the generation of knowledge and intelligence. Achievement of integrating these two concepts and enabling technologies will have a significant impact on solving problems in the civil, building and infrastructure sectors. However, since GIS and BIM were originally developed for different purposes, numerous challenges are being encountered for the integration. To better understand these two different domains, this paper reviews the development and dissimilarities of GIS and BIM, the existing integration methods, and investigates their potential in various applications. This study shows that the integration methods are developed for various reasons and aim to solve different problems. The parameters influencing the choice can be summarized and named as “EEEF” criteria: effectiveness, extensibility, effort, and flexibility. Compared with other methods, semantic web technologies provide a promising and generalized integration solution. However, the biggest challenges of this method are the large efforts required at early stage and the isolated development of ontologies within one particular domain. The isolation problem also applies to other methods. Therefore, openness is the key of the success of BIM and GIS integration.\n",
            "------------------------------------\n",
            "Title :  Smart Refugees: How Syrian Asylum Migrants Use Social Media Information in Migration Decision-Making\n",
            "Author/s :  R. Dekker, G. Engbersen, Jeanine Klaver, Hanna Vonk\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Social media are increasingly popular channels of information on which migrants base their decisions on whether to migrate and the destinations where to settle. While social media offer a relatively cheap, easily accessible, and media-rich means of communication, their use is not without challenges for asylum migrants. Various studies describe issues with access and evaluation of the truthfulness of available information for this specific group of migrants. This article discusses social media use by asylum migrants prior to and during migration. This study is based on in-depth interviews with 54 Syrian asylum migrants who recently obtained refugee status in the Netherlands. Syrians were the largest group of migrants applying for asylum in European Union (EU) member states in 2015 and 2016. The findings show that the majority of Syrian asylum migrants have access to social media information before and during migration, often through the use of smartphones. Besides uneven access to technologies, fear of government surveillance restricts the smartphone use of asylum migrants. The results of this study indicate that Syrian asylum migrants prefer social media information that originates from existing social ties and information that is based on personal experiences. Generally, this information is considered more trustworthy. Asylum migrants use various strategies to validate rumors that are present on social media and come from unknown sources. These strategies include checking the source of information, validating information with trusted social ties, triangulation of online sources, and comparing information with their own experience.\n",
            "------------------------------------\n",
            "Title :  Semi-Supervised Hashing for Large-Scale Search\n",
            "Author/s :  Jun Wang, Sanjiv Kumar, Shih-Fu Chang\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2012\n",
            "Abstract :  Hashing-based approximate nearest neighbor (ANN) search in huge databases has become popular due to its computational and memory efficiency. The popular hashing methods, e.g., Locality Sensitive Hashing and Spectral Hashing, construct hash functions based on random or principal projections. The resulting hashes are either not very accurate or are inefficient. Moreover, these methods are designed for a given metric similarity. On the contrary, semantic similarity is usually given in terms of pairwise labels of samples. There exist supervised hashing methods that can handle such semantic similarity, but they are prone to overfitting when labeled data are small or noisy. In this work, we propose a semi-supervised hashing (SSH) framework that minimizes empirical error over the labeled set and an information theoretic regularizer over both labeled and unlabeled sets. Based on this framework, we present three different semi-supervised hashing methods, including orthogonal hashing, nonorthogonal hashing, and sequential hashing. Particularly, the sequential hashing method generates robust codes in which each hash function is designed to correct the errors made by the previous ones. We further show that the sequential learning paradigm can be extended to unsupervised domains where no labeled pairs are available. Extensive experiments on four large datasets (up to 80 million samples) demonstrate the superior performance of the proposed SSH methods over state-of-the-art supervised and unsupervised hashing techniques.\n",
            "------------------------------------\n",
            "Title :  A Diversity-Promoting Objective Function for Neural Conversation Models\n",
            "Author/s :  Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, W. Dolan\n",
            "Venue :  North American Chapter of the Association for Computational Linguistics\n",
            "year :  2015\n",
            "Abstract :  Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., \"I don't know\") regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations.\n",
            "------------------------------------\n",
            "Title :  Dimensionality Reduction Technique on SIFT Feature Vector for Content Based Image Retrival\n",
            "Author/s :  Mukul Kirti Verma, Rajesh Dwivedi, Ajay Kumar Mallick, Ebenezer Jangam\n",
            "Venue :  International Conference on Recent Trends in Image Processing and Pattern Recognition\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Psychological and Health Outcomes of Perceived Information Overload\n",
            "Author/s :  Shalini Misra, D. Stokols\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  The rapid growth and transmission of information in the digital age poses new challenges for individuals coping with the onslaught of communications from multiple sources. This research (a) conceptualizes and measures perceived information overload from cyber-based and place-based sources, (b) tests the reliability and validity of a newly developed Perceived Information Overload Scale, and (c) tests hypotheses concerning the psychological and health outcomes of information overload. A repeated-measures panel study design was used to test the proposed hypotheses. Confirmatory factor analyses provided support for the hypothesized two-factor model of perceived information overload, encompassing cyber-based and place-based sources of stimulation. Hierarchical regression analyses indicated that higher levels of perceived cyber-based overload significantly predicted self-reports of greater stress, poorer health, and less time devoted to contemplative activities, controlling for age, gender, ethnicity, and baseline measures of stress and health status. Participants’ sensation-seeking levels were found to significantly moderate the relationships between cyber-based, place-based, and composite perceived information overload and stress. Directions for further study are discussed.\n",
            "------------------------------------\n",
            "Title :  \"Best practice\" for patient-centered communication: a narrative review.\n",
            "Author/s :  A. King, R. Hoppe\n",
            "Venue :  Journal of Graduate Medical Education\n",
            "year :  2013\n",
            "Abstract :  BACKGROUND\n",
            "Communicating with patients has long been identified as an important physician competency. More recently, there is a growing consensus regarding the components that define physician-patient communication. There continues to be emphasis on both the need to teach and to assess the communication skills of physicians.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This narrative review aims to summarize the work that has been conducted in physician-patient communication that supports the efficacy of good communications skills. This work may also help to define the physician-patient communication skills that need to be taught and assessed.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "A review of the literature shows it contains impressive evidence supporting positive associations between physician communication behaviors and positive patient outcomes, such as patient recall, patient understanding, and patient adherence to therapy. There is a consensus about what constitutes \"best practice\" for physician communication in medical encounters: (1) fostering the relationship, (2) gathering information, (3) providing information, (4) making decisions, (5) responding to emotions, and (6) enabling disease- and treatment-related behavior.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Evidence supports the importance of communication skills as a dimension of physician competence. Effort to enhance teaching of communication skills to medical trainees likely will require significant changes in instruction at undergraduate and graduate levels, as well as changes in assessing the developing communication skills of physicians. An added critical dimension is faculty understanding of the importance of communication skills, and their commitment to helping trainees develop those skills.\n",
            "------------------------------------\n",
            "Title :  Improving bug localization using structured information retrieval\n",
            "Author/s :  Ripon K. Saha, Matthew Lease, S. Khurshid, D. Perry\n",
            "Venue :  International Conference on Automated Software Engineering\n",
            "year :  2013\n",
            "Abstract :  Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool.\n",
            "------------------------------------\n",
            "Title :  Qualitative Data Analysis\n",
            "Author/s :  B. MilesMatthew, Huberman A. Michael\n",
            "Venue :  Research Methods for Social Work: A Problem-Based Approach\n",
            "year :  2015\n",
            "Abstract :  Qualitative data is extremely varied in nature. It includes virtually any information that can be captured that is not numerical in nature. Here are some of the major categories or types: \n",
            " \n",
            "In-Depth Interviews \n",
            "In-Depth Interviews include both individual interviews (e.g., one-on-one) as well as \"group\" interviews (including focus groups). The data can be recorded in a wide variety of ways including stenography, audio recording, video recording or written notes. In depth interviews differ from direct observation primarily in the nature of the interaction. In interviews it is assumed that there is a questioner and one or more interviewees. The purpose of the interview is to probe the ideas of the interviewees about the phenomenon of interest. \n",
            " \n",
            "Direct Observation \n",
            "Direct observation is meant very broadly here. It differs from interviewing in that the observer does not actively query the respondent. It can include everything from field research where one lives in another context or culture for a period of time to photographs that illustrate some aspect of the phenomenon. The data can be recorded in many of the same ways as interviews (stenography, audio, video) and through pictures, photos or drawings (e.g., those courtroom drawings of witnesses are a form of direct observation). \n",
            " \n",
            "Written Documents \n",
            "Usually this refers to existing documents (as opposed transcripts of interviews conducted for the research). It can include newspapers, magazines, books, websites, memos, transcripts of conversations, annual reports, and so on. Usually written documents are analyzed with some form of content analysis. \n",
            " \n",
            "sumber : http://www.socialresearchmethods.net/kb/qualdata.php\n",
            "------------------------------------\n",
            "Title :  Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images\n",
            "Author/s :  Saurabh Gupta, Pablo Arbeláez, Jitendra Malik\n",
            "Venue :  2013 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2013\n",
            "Abstract :  We address the problems of contour detection, bottom-up grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information. We show that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.\n",
            "------------------------------------\n",
            "Title :  Three Phased Component Retrival Technique (TPCRT) for Best Qualified Component\n",
            "Author/s :  Vishnu Sharma, V. Shekhawat\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The focus of this paper is to suggest a efficient component retrieval technique. Here a combined architecture of three search techniques from traditional (Keywords based) to latest approach (deductive search) is used to get best qualified component. This approach is useful for the software developers to get the appropriate components to develop efficient software within a short span of time. It also provides an efficient way to retrieve appropriate component from repository. The suggested design effectively supports query specification and component search. It further guides users to exploit component resources for reuse.\n",
            "------------------------------------\n",
            "Title :  The Impact of Study Size on Meta-analyses: Examination of Underpowered Studies in Cochrane Reviews\n",
            "Author/s :  R. Turner, S. Bird, J. Higgins\n",
            "Venue :  PLoS ONE\n",
            "year :  2013\n",
            "Abstract :  Background Most meta-analyses include data from one or more small studies that, individually, do not have power to detect an intervention effect. The relative influence of adequately powered and underpowered studies in published meta-analyses has not previously been explored. We examine the distribution of power available in studies within meta-analyses published in Cochrane reviews, and investigate the impact of underpowered studies on meta-analysis results. Methods and Findings For 14,886 meta-analyses of binary outcomes from 1,991 Cochrane reviews, we calculated power per study within each meta-analysis. We defined adequate power as ≥50% power to detect a 30% relative risk reduction. In a subset of 1,107 meta-analyses including 5 or more studies with at least two adequately powered and at least one underpowered, results were compared with and without underpowered studies. In 10,492 (70%) of 14,886 meta-analyses, all included studies were underpowered; only 2,588 (17%) included at least two adequately powered studies. 34% of the meta-analyses themselves were adequately powered. The median of summary relative risks was 0.75 across all meta-analyses (inter-quartile range 0.55 to 0.89). In the subset examined, odds ratios in underpowered studies were 15% lower (95% CI 11% to 18%, P<0.0001) than in adequately powered studies, in meta-analyses of controlled pharmacological trials; and 12% lower (95% CI 7% to 17%, P<0.0001) in meta-analyses of controlled non-pharmacological trials. The standard error of the intervention effect increased by a median of 11% (inter-quartile range −1% to 35%) when underpowered studies were omitted; and between-study heterogeneity tended to decrease. Conclusions When at least two adequately powered studies are available in meta-analyses reported by Cochrane reviews, underpowered studies often contribute little information, and could be left out if a rapid review of the evidence is required. However, underpowered studies made up the entirety of the evidence in most Cochrane reviews.\n",
            "------------------------------------\n",
            "Title :  Depth Map Prediction from a Single Image using a Multi-Scale Deep Network\n",
            "Author/s :  D. Eigen, Christian Puhrsch, R. Fergus\n",
            "Venue :  NIPS\n",
            "year :  2014\n",
            "Abstract :  Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence suffices for estimation, finding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that refines this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.\n",
            "------------------------------------\n",
            "Title :  Debunking in a world of tribes\n",
            "Author/s :  Fabiana Zollo, Alessandro Bessi, Michela Del Vicario, A. Scala, G. Caldarelli, L. Shekhtman, S. Havlin, W. Quattrociocchi\n",
            "Venue :  PLoS ONE\n",
            "year :  2015\n",
            "Abstract :  Social media aggregate people around common interests eliciting collective framing of narratives and worldviews. However, in such a disintermediated environment misinformation is pervasive and attempts to debunk are often undertaken to contrast this trend. In this work, we examine the effectiveness of debunking on Facebook through a quantitative analysis of 54 million users over a time span of five years (Jan 2010, Dec 2014). In particular, we compare how users usually consuming proven (scientific) and unsubstantiated (conspiracy-like) information on Facebook US interact with specific debunking posts. Our findings confirm the existence of echo chambers where users interact primarily with either conspiracy-like or scientific pages. However, both groups interact similarly with the information within their echo chamber. Then, we measure how users from both echo chambers interacted with 50,220 debunking posts accounting for both users consumption patterns and the sentiment expressed in their comments. Sentiment analysis reveals a dominant negativity in the comments to debunking posts. Furthermore, such posts remain mainly confined to the scientific echo chamber. Only few conspiracy users engage with corrections and their liking and commenting rates on conspiracy posts increases after the interaction.\n",
            "------------------------------------\n",
            "Title :  Diamond NV centers for quantum computing and quantum networks\n",
            "Author/s :  L. Childress, R. Hanson\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The exotic features of quantum mechanics have the potential to revolutionize information technologies. Using superposition and entanglement, a quantum processor could efficiently tackle problems inaccessible to current-day computers. Nonlocal correlations may be exploited for intrinsically secure communication across the globe. Finding and controlling a physical system suitable for fulfi lling these promises is one of the greatest challenges of our time. The nitrogen-vacancy (NV) center in diamond has recently emerged as one of the leading candidates for such quantum information technologies thanks to its combination of atom-like properties and solid-state host environment. We review the remarkable progress made in the past years in controlling electrons, atomic nuclei, and light at the single-quantum level in diamond. We also discuss prospects and challenges for the use of NV centers in future quantum technologies.\n",
            "------------------------------------\n",
            "Title :  Assessing the risks of ‘infodemics’ in response to COVID-19 epidemics\n",
            "Author/s :  R. Gallotti, F. Valle, N. Castaldo, P. Sacco, M. De Domenico\n",
            "Venue :  Nature Human Behaviour\n",
            "year :  2020\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Practical extraction of disaster-relevant information from social media\n",
            "Author/s :  Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, P. Meier\n",
            "Venue :  The Web Conference\n",
            "year :  2013\n",
            "Abstract :  During times of disasters online users generate a significant amount of data, some of which are extremely valuable for relief efforts. In this paper, we study the nature of social-media content generated during two different natural disasters. We also train a model based on conditional random fields to extract valuable information from such content. We evaluate our techniques over our two datasets through a set of carefully designed experiments. We also test our methods over a non-disaster dataset to show that our extraction model is useful for extracting information from socially-generated content in general.\n",
            "------------------------------------\n",
            "Title :  Wireless Information and Power Transfer With Full Duplex Relaying\n",
            "Author/s :  C. Zhong, H. Suraweera, G. Zheng, I. Krikidis, Zhaoyang Zhang\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2014\n",
            "Abstract :  We consider a dual-hop full-duplex relaying system, where the energy constrained relay node is powered by radio frequency signals from the source using the time-switching architecture, both the amplify-and-forward and decode-and-forward relaying protocols are studied. Specifically, we provide an analytical characterization of the achievable throughput of three different communication modes, namely, instantaneous transmission, delay-constrained transmission, and delay tolerant transmission. In addition, the optimal time split is studied for different transmission modes. Our results reveal that, when the time split is optimized, the full-duplex relaying could substantially boost the system throughput compared to the conventional half-duplex relaying architecture for all three transmission modes. In addition, it is shown that the instantaneous transmission mode attains the highest throughput. However, compared to the delay-constrained transmission mode, the throughput gap is rather small. Unlike the instantaneous time split optimization which requires instantaneous channel state information, the optimal time split in the delay-constrained transmission mode depends only on the statistics of the channel, hence, is suitable for practical implementations.\n",
            "------------------------------------\n",
            "Title :  A survey of trust in social networks\n",
            "Author/s :  W. Sherchan, S. Nepal, Cécile Paris\n",
            "Venue :  CSUR\n",
            "year :  2013\n",
            "Abstract :  Web-based social networks have become popular as a medium for disseminating information and connecting like-minded people. The public accessibility of such networks with the ability to share opinions, thoughts, information, and experience offers great promise to enterprises and governments. In addition to individuals using such networks to connect to their friends and families, governments and enterprises have started exploiting these platforms for delivering their services to citizens and customers. However, the success of such attempts relies on the level of trust that members have with each other as well as with the service provider. Therefore, trust becomes an essential and important element of a successful social network. In this article, we present the first comprehensive review of social and computer science literature on trust in social networks. We first review the existing definitions of trust and define social trust in the context of social networks. We then discuss recent works addressing three aspects of social trust: trust information collection, trust evaluation, and trust dissemination. Finally, we compare and contrast the literature and identify areas for further research in social trust.\n",
            "------------------------------------\n",
            "Title :  Object lens: a “spreadsheet” for cooperative work\n",
            "Author/s :  Kum-Yew Lai, T. Malone, Keh-Chiang Yu\n",
            "Venue :  TOIS\n",
            "year :  2018\n",
            "Abstract :  Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times.\n",
            "The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.\n",
            "------------------------------------\n",
            "Title :  ISO/IEC 27000, 27001 and 27002 for Information Security Management\n",
            "Author/s :  Georg Disterer\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  With the increasing significance of information technology, there is \n",
            "an urgent need for adequate measures of information security. \n",
            "Systematic information security management is one of most important initiatives \n",
            "for IT management. At least since reports about privacy and security breaches, \n",
            "fraudulent accounting practices, and attacks on IT systems appeared \n",
            "in public, organizations have recognized their responsibilities to safeguard \n",
            "physical and information assets. Security standards can be used as guideline or \n",
            "framework to develop and maintain an adequate information security management \n",
            "system (ISMS). The standards ISO/IEC 27000, 27001 and 27002 are international \n",
            "standards that are receiving growing recognition and adoption. They are \n",
            "referred to as “common language of organizations around the world” for \n",
            "information security [1]. With ISO/IEC 27001 companies can have their ISMS \n",
            "certified by a third-party organization and thus show their customers evidence \n",
            "of their security measures.\n",
            "------------------------------------\n",
            "Title :  Supplier Encroachment under Asymmetric Information\n",
            "Author/s :  Z. Li, S. Gilbert, Guoming Lai\n",
            "Venue :  Management Sciences\n",
            "year :  2012\n",
            "Abstract :  Prior literature has shown that, for a symmetric information setting, supplier encroachment into a reseller's market can mitigate double marginalization and benefit both the supplier and the reseller. This paper extends the investigation of supplier encroachment to the environment where the reseller might be better informed than the supplier. We find that the launch of the supplier's direct channel can result in costly signaling behavior on the part of the reseller, in which he reduces his order quantity when the market size is small. Such a downward order distortion can amplify double marginalization. As a result, in addition to the “win--win” and “win--lose” outcomes for the supplier and the reseller, supplier encroachment can also lead to “lose--lose” and “lose--win” outcomes, particularly when the reseller has a significant efficiency advantage in the selling process and the prior probability of a large market is low. We further explore the implications of those findings for information management in supply chains. Complementing the conventional understanding, we show that with the ability to encroach, the supplier may prefer to sell to either a better informed or an uninformed reseller in different scenarios. On the other hand, as a result of a supplier developing encroachment capability, a reseller either may choose not to develop an advanced informational capability or may become more willing to find a means of credibly sharing his information. \n",
            " \n",
            "This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  A survey of transfer learning\n",
            "Author/s :  Karl R. Weiss, T. Khoshgoftaar, Dingding Wang\n",
            "Venue :  Journal of Big Data\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Advances in photonic quantum sensing\n",
            "Author/s :  S. Pirandola, B. R. Bardhan, T. Gehring, C. Weedbrook, S. Lloyd\n",
            "Venue :  Nature Photonics\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Molecular Communication: Index\n",
            "Author/s :  T. Nakano, A. Eckford, T. Haraguchi\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This paper describes research challenges in Molecular Communication, a new and interdisciplinary research area that spans the nanotechnology, biotechnology, and communication technology. Molecular communication allows nanomachines to communicate using molecules as a communication carrier. Key research challenges include controlled propagation of carrier molecules, encoding/ decoding of information onto information molecules, and transmission/reception systems for carrier/information molecules. The authors of this paper are currently investigating the feasibility of molecular communication.\n",
            "------------------------------------\n",
            "Title :  Information Acquisition and Welfare\n",
            "Author/s :  L. Colombo, Gianluca Femminis, A. Pavan\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We study information acquisition in a exible framework with strategic complementarity or substitutability in actions and a rich set of externalities that are responsible for possible wedges between the equilibrium and the efficient acquisition of information. First, we relate the (in)efficiency in the acquisition of information to the (in)efficiency in the use of information and explain why efficiency in the use does not guarantee efficiency in the acquisition. Next, we show how the acquisition of private information affects the social value of public information (i.e., the comparative statics of equilibrium welfare with respect to the quality of public information). Finally, we illustrate the implications of our results in a few applications that include beauty contests, monetary economies with price-setting complementarities, and economies with negative production externalities.\n",
            "------------------------------------\n",
            "Title :  Determinants of patient choice of healthcare providers: a scoping review\n",
            "Author/s :  A. Victoor, D. Delnoij, R. Friele, J. Rademakers\n",
            "Venue :  BMC Health Services Research\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Tuning parameter selection in high dimensional penalized likelihood\n",
            "Author/s :  Yingying Fan, C. Tang\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Determining how to select the tuning parameter appropriately is essential in penalized likelihood methods for high dimensional data analysis. We examine this problem in the setting of penalized likelihood methods for generalized linear models, where the dimensionality of covariates p is allowed to increase exponentially with the sample size n. We propose to select the tuning parameter by optimizing the generalized information criterion with an appropriate model complexity penalty. To ensure that we consistently identify the true model, a range for the model complexity penalty is identified in the generlized information criterion. We find that this model complexity penalty should diverge at the rate of some power of log (p) depending on the tail probability behaviour of the response variables. This reveals that using the Akaike information criterion or Bayes information criterion to select the tuning parameter may not be adequate for consistently identifying the true model. On the basis of our theoretical study, we propose a uniform choice of the model complexity penalty and show that the approach proposed consistently identifies the true model among candidate models with asymptotic probability 1. We justify the performance of the procedure proposed by numerical simulations and a gene expression data analysis.\n",
            "------------------------------------\n",
            "Title :  Determinants of Sharing Travel Experiences in Social Media\n",
            "Author/s :  Myunghwa Kang, M. Schuett\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  ABSTRACT The advent of Internet-based social media technologies has enabled travelers to quickly and conveniently share their travel experiences. Shared information on social media sites is recognized as an important information source which may influence travel decision making for potential travelers. This study tests a conceptual framework which examines why travelers share their travel experiences on social media based on the social influence theory and its three conceptual foundations—identification, internalization, and compliance. Data were collected using an online survey and the research model was tested with 543 respondents who were social media users. Results showed that identification and internalization are critical determinants that positively increase actual travel-experience sharing on social media as mediated by perceived enjoyment. Our research extends prior literature on social media by identifying specific determinants that can impact travel-experience sharing. Suggestions are provided for academics, the travel industry, and those working with social media.\n",
            "------------------------------------\n",
            "Title :  Analytic projection from plane‐wave and PAW wavefunctions and application to chemical‐bonding analysis in solids\n",
            "Author/s :  Stefan Maintz, Volker L. Deringer, A. Tchougréeff, R. Dronskowski\n",
            "Venue :  Journal of Computational Chemistry\n",
            "year :  2013\n",
            "Abstract :  Quantum‐chemical computations of solids benefit enormously from numerically efficient plane‐wave (PW) basis sets, and together with the projector augmented‐wave (PAW) method, the latter have risen to one of the predominant standards in computational solid‐state sciences. Despite their advantages, plane waves lack local information, which makes the interpretation of local densities‐of‐states (DOS) difficult and precludes the direct use of atom‐resolved chemical bonding indicators such as the crystal orbital overlap population (COOP) and the crystal orbital Hamilton population (COHP) techniques. Recently, a number of methods have been proposed to overcome this fundamental issue, built around the concept of basis‐set projection onto a local auxiliary basis. In this work, we propose a novel computational technique toward this goal by transferring the PW/PAW wavefunctions to a properly chosen local basis using analytically derived expressions. In particular, we describe a general approach to project both PW and PAW eigenstates onto given custom orbitals, which we then exemplify at the hand of contracted multiple‐ζ Slater‐type orbitals. The validity of the method presented here is illustrated by applications to chemical textbook examples—diamond, gallium arsenide, the transition‐metal titanium—as well as nanoscale allotropes of carbon: a nanotube and the C60 fullerene. Remarkably, the analytical approach not only recovers the total and projected electronic DOS with a high degree of confidence, but it also yields a realistic chemical‐bonding picture in the framework of the projected COHP method. © 2013 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title :  A guide for the utilization of Health Insurance Review and Assessment Service National Patient Samples\n",
            "Author/s :  L. Kim, Jee-Ae Kim, Sanghyun Kim\n",
            "Venue :  Epidemiology and Health\n",
            "year :  2014\n",
            "Abstract :  The claims data of the Health Insurance Review and Assessment Service (HIRA) is an important source of information for healthcare service research. The claims data of HIRA is collected when healthcare service providers submit a claim to HIRA to be reimbursed for a service that they provided to patients. To improve the accessibility of healthcare service researchers to claims data of HIRA, HIRA has developed the Patient Samples which are extracted using a stratified randomized sampling method. The Patient Samples of HIRA consist of five tables: a table for general information (Table 20) containing socio-demographic information such as gender, age and medical aid, indicators for inpatient and outpatient services; a table for specific information on healthcare services provided (Table 30); a table for diagnostic information (Table 40); a table for outpatient prescriptions (Table 53) and a table for information on healthcare service providers (Table of providers). Researchers who are interested in using the Patient Sample data for research can apply via HIRA’s website (https://www.hira.or.kr).\n",
            "------------------------------------\n",
            "Title :  FPGA based Real time 'secure' body temperature monitoring suitable for WBSN 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing\n",
            "Author/s :  M. Rao, T. Newe, I. Grout, E. Lewis, Avijit Mathur\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  In wireless body sensor networks (WBSNs), sensors continuously monitor human physiological activities using medical sensors, for example; blood pressure, body temperature and electrocardiography (ECG). A WBSN can be used to develop a patient monitoring system. The traditional body sensor networks (BSNs) have limited hardware resources in terms of computational capabilities, data processing speed, memory and battery life. Also these BSNs are generally not suitable for the implementation of security mechanisms, reason is that, implementation of security mechanisms require relatively more hardware resources because of the complexity of their algorithms. To get rid of these limitations a Field Programmable Gate Array (FPGA) device is suitable because of its flexible architecture and high performance features. In this paper an FPGA based experimental framework is investigated to implement real time body temperature monitoring with reliable data transmission, using data integrity verification. This data integrity check is very important for patient monitoring systems as unreliable data could lead the healthcare professionals to make an incorrect diagnosis concerning patients health. The data integrity verification is achieved using newly selected cryptographic hash function called, SHA-3 (Secure Hash Algorithm-3). To the best of authors knowledge, all previously published FPGA based WBSNs implementations did not implemented any security mechanisms to secure physiological data, so this work is the first contribution regarding it.\n",
            "------------------------------------\n",
            "Title :  Pathology imaging informatics for quantitative analysis of whole-slide images\n",
            "Author/s :  S. Kothari, J. Phan, T. Stokes, May D. Wang\n",
            "Venue :  JAMIA Journal of the American Medical Informatics Association\n",
            "year :  2013\n",
            "Abstract :  Objectives With the objective of bringing clinical decision support systems to reality, this article reviews histopathological whole-slide imaging informatics methods, associated challenges, and future research opportunities. Target audience This review targets pathologists and informaticians who have a limited understanding of the key aspects of whole-slide image (WSI) analysis and/or a limited knowledge of state-of-the-art technologies and analysis methods. Scope First, we discuss the importance of imaging informatics in pathology and highlight the challenges posed by histopathological WSI. Next, we provide a thorough review of current methods for: quality control of histopathological images; feature extraction that captures image properties at the pixel, object, and semantic levels; predictive modeling that utilizes image features for diagnostic or prognostic applications; and data and information visualization that explores WSI for de novo discovery. In addition, we highlight future research directions and discuss the impact of large public repositories of histopathological data, such as the Cancer Genome Atlas, on the field of pathology informatics. Following the review, we present a case study to illustrate a clinical decision support system that begins with quality control and ends with predictive modeling for several cancer endpoints. Currently, state-of-the-art software tools only provide limited image processing capabilities instead of complete data analysis for clinical decision-making. We aim to inspire researchers to conduct more research in pathology imaging informatics so that clinical decision support can become a reality.\n",
            "------------------------------------\n",
            "Title :  Information Asymmetry in Management Research: Past Accomplishments and Future Opportunities\n",
            "Author/s :  D. Bergh, D. Ketchen, Ilaria Orlandi, P. Heugens, B. Boyd\n",
            "Venue :  Journal of Management\n",
            "year :  2018\n",
            "Abstract :  Information asymmetry is a condition wherein one party in a relationship has more or better information than another. The information asymmetry concept is widely diffused throughout management research, and its existence is a core assumption within leading theories on organizations. Despite information asymmetry’s central role, however, there have been no systematic reviews of the management literature using the concept. As a result, there is no established level of knowledge of information asymmetry as a management concept, nor is there a unified basis for directing future research leveraging the concept. In response, we review 223 relevant articles from leading management journals and develop a framework for organizing and assessing information asymmetry research. We consolidate understanding of information asymmetry’s meaning, conceptual applications, roles in different theoretical models, antecedents, and how focal actors’ self-interests influence the selection of mechanisms for managing it. Further, we highlight opportunities for extensions to core management theories and specify research prospects within several management subfields. Overall, the framework can help guide researchers as they work to advance understanding of one of the management field’s most ubiquitous concepts.\n",
            "------------------------------------\n",
            "Title :  Pragmatism vs interpretivism in qualitative information systems research\n",
            "Author/s :  G. Goldkuhl\n",
            "Venue :  European Journal of Information Systems\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Revenue Sharing and Information Leakage in a Supply Chain\n",
            "Author/s :  Guangwen Kong, S. Rajagopalan, H. Zhang\n",
            "Venue :  Management Sciences\n",
            "year :  2012\n",
            "Abstract :  This work explores the potential of revenue-sharing contracts to facilitate information sharing in a supply chain and mitigate the negative effects of information leakage. We consider a supplier who offers a revenue-sharing contract to two competing retailers, one of whom has private information about uncertain market potential and orders first. This order information may be leaked to the uninformed retailer by the supplier to realize higher profits. We show that the incentives of the supplier and retailers are better aligned under a revenue-sharing contract, as opposed to under a wholesale-price contract, reducing the supplier's incentive to leak. This is true for a wide range of wholesale prices and revenue-share percentages and is more likely when the revenue-share percentage is higher and when variation in demand is greater. Preventing information leakage may result in higher profits not only for the informed retailer and supplier but surprisingly even for the uninformed retailer. Our results are robust when the model is generalized along various dimensions. \n",
            " \n",
            "This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title :  On the Rise of FinTechs – Credit Scoring Using Digital Footprints\n",
            "Author/s :  M. Puri, Tobias Berg, Valentin Burg, Ana Gombović\n",
            "Venue :  The Review of financial studies\n",
            "year :  2018\n",
            "Abstract :  \n",
            " We analyze the information content of a digital footprint—that is, information that users leave online simply by accessing or registering on a Web site—for predicting consumer default. We show that even simple, easily accessible variables from a digital footprint match the information content of credit bureau scores. A digital footprint complements rather than substitutes for credit bureau information and affects access to credit and reduces default rates. We discuss the implications for financial intermediaries’ business models, access to credit for the unbanked, and the behavior of consumers, firms, and regulators in the digital sphere. (JEL G20, G21, G29)\n",
            "------------------------------------\n",
            "Title :  The Economics of Crowdfunding Platforms\n",
            "Author/s :  Paul Belleflamme, N. Omrani, M. Peitz\n",
            "Venue :  Information Economics and Policy\n",
            "year :  2015\n",
            "Abstract :  This paper provides a description of the crowdfunding sector, considering investment- based crowdfunding platforms as well as platforms in which funders do not obtain monetary payments. It lays out key features of this quickly developing sector and explores the economic forces at play that can explain the design of these platforms. In particular, it elaborates on cross-group and within-group external effects and asymmetric information on crowdfunding platforms.\n",
            "------------------------------------\n",
            "Title :  Deep Recurrent Q-Learning for Partially Observable MDPs\n",
            "Author/s :  Matthew J. Hausknecht, P. Stone\n",
            "Venue :  AAAI Fall Symposia\n",
            "year :  2015\n",
            "Abstract :  Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network} (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.\n",
            "------------------------------------\n",
            "Title :  Feature Selection\n",
            "Author/s :  Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P. Trevino, Jiliang Tang, Huan Liu\n",
            "Venue :  Encyclopedia of Machine Learning and Data Mining\n",
            "year :  2016\n",
            "Abstract :  Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.\n",
            "------------------------------------\n",
            "Title :  Analyst Information Discovery and Interpretation Roles: A Topic Modeling Approach\n",
            "Author/s :  Allen H. Huang, Reuven Lehavy, Amy Y. Zang, Rong Zheng\n",
            "Venue :  Management Sciences\n",
            "year :  2016\n",
            "Abstract :  This study examines analyst information intermediary roles using a textual analysis of analyst reports and corporate disclosures. We employ a topic modeling methodology from computational linguistic research to compare the thematic content of a large sample of analyst reports issued promptly after earnings conference calls with the content of the calls themselves. We show that analysts discuss exclusive topics beyond those from conference calls and interpret topics from conference calls. In addition, we find that investors place a greater value on new information in analyst reports when managers face greater incentives to withhold value-relevant information. Analyst interpretation is particularly valuable when the processing costs of conference call information increase. Finally, we document that investors react to analyst report content that simply confirms managers’ conference call discussions. Overall, our study shows that analysts play the information intermediary roles by discovering information beyond corporate disclosures and by clarifying and confirming corporate disclosures.\n",
            "------------------------------------\n",
            "Title :  User cooperation in wireless powered communication networks\n",
            "Author/s :  Hyungsik Ju, Rui Zhang\n",
            "Venue :  2014 IEEE Global Communications Conference\n",
            "year :  2014\n",
            "Abstract :  This paper studies user cooperation in the emerging wireless powered communication network (WPCN) for throughput optimization. For the purpose of exposition, we consider a two-user WPCN, in which one hybrid access point (H-AP) broadcasts wireless energy to two distributed users in the downlink (DL) and the users transmit their independent information using their individually harvested energy to the H-AP in the uplink (UL) through time-division-multiple-access (TDMA). We propose user cooperation in the WPCN where the user that is nearer to the H-AP and in general has a better channel for DL energy harvesting as well as UL information transmission uses part of its allocated UL time and DL harvested energy to help relay the far user's information to the H-AP, in order to achieve more balanced throughput. We maximize the weighted sum-rate (WSR) of the two users by jointly optimizing the time and power allocations in the network for both wireless energy transfer in the DL and wireless information transmission and relaying in the UL. Simulation results show that the proposed user cooperation scheme can effectively improve the achievable throughput in the WPCN with desired user fairness.\n",
            "------------------------------------\n",
            "Title :  The entropy of bulk quantum fields and the entanglement wedge of an evaporating black hole\n",
            "Author/s :  Ahmed Almheiri, Netta Engelhardt, D. Marolf, Henry Maxfield\n",
            "Venue :  Journal of High Energy Physics\n",
            "year :  2019\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Digital Imaging and Communications in Medicine (DICOM)\n",
            "Author/s :  O. Pianykh\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Value of Information\n",
            "Author/s :  N. Welton, H. Thom\n",
            "Venue :  Medical decision making\n",
            "year :  2015\n",
            "Abstract :  Expected value of sample information (EVSI) 1 measures the average net-benefit gain from conducting new research and can be used to inform decisions on which new studies to fund and how best to design those studies. This helps avoid wasting resources researching treatments that were never likely to be cost-effective or conversely by adopting treatments that, if more evidence were collected, may be shown not to be cost-effective. However, the calculations in the general case rely on nested simulations, which can be very computationally demanding and even infeasible to compute in some cases. Since EVSI needs to be repeatedly computed over the potential study design space, this represents a clear barrier to the uptake of EVSI methods in practice. In some special situations, algebraic solutions are available that avoid the inner simulation step. 2–4 More generally, meta-modeling, which attempts to build a model to approximate the relationship between the model inputs (on which a new study can provide information) and model outputs (net benefit), is a promising approach that can lead to substantial computational savings. 5,6 In this issue, 2 novel meta-modeling methods are proposed for the calculation of EVSI, 7,8 both of which require only\n",
            "------------------------------------\n",
            "Title :  Position-aware Graph Neural Networks\n",
            "Author/s :  Jiaxuan You, Rex Ying, J. Leskovec\n",
            "Venue :  International Conference on Machine Learning\n",
            "year :  2019\n",
            "Abstract :  Learning node embeddings that capture a node's position within the broader graph structure is crucial for many prediction tasks on graphs. However, existing Graph Neural Network (GNN) architectures have limited power in capturing the position/location of a given node with respect to all other nodes of the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a new class of GNNs for computing position-aware node embeddings. P-GNN first samples sets of anchor nodes, computes the distance of a given target node to each anchor-set,and then learns a non-linear distance-weighted aggregation scheme over the anchor-sets. This way P-GNNs can capture positions/locations of nodes with respect to the anchor nodes. P-GNNs have several advantages: they are inductive, scalable,and can incorporate node feature information. We apply P-GNNs to multiple prediction tasks including link prediction and community detection. We show that P-GNNs consistently outperform state of the art GNNs, with up to 66% improvement in terms of the ROC AUC score.\n",
            "------------------------------------\n",
            "Title :  Drivers of Performance Information Use: Systematic Literature Review and Directions for Future Research\n",
            "Author/s :  Alexander Kroll\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  ABSTRACT The use of performance information in decision-making is a management behavior that has received much attention in public administration research and practice. This article seeks to contribute to a better understanding of this behavior. It conducts a systematic review of 25 recently published empirical studies that have examined drivers of performance information use. Analyzing these studies, which were selected on the basis of their definition of purposeful data use, the article identifies factors that have repeatedly shown a positive impact: measurement system maturity, stakeholder involvement, leadership support, support capacity, innovative culture, and goal clarity. This systematic analysis also uncovers less conclusive variables; findings which are highly relevant for future studies. Based on the review, the article suggests directions for further research endeavors, including theoretical and methodological propositions.\n",
            "------------------------------------\n",
            "Title :  Searching for explanations: How the Internet inflates estimates of internal knowledge.\n",
            "Author/s :  Matthew Fisher, M. Goddu, F. Keil\n",
            "Venue :  Journal of experimental psychology. General\n",
            "year :  2015\n",
            "Abstract :  As the Internet has become a nearly ubiquitous resource for acquiring knowledge about the world, questions have arisen about its potential effects on cognition. Here we show that searching the Internet for explanatory knowledge creates an illusion whereby people mistake access to information for their own personal understanding of the information. Evidence from 9 experiments shows that searching for information online leads to an increase in self-assessed knowledge as people mistakenly think they have more knowledge \"in the head,\" even seeing their own brains as more active as depicted by functional MRI (fMRI) images.\n",
            "------------------------------------\n",
            "Title :  A brief introduction to weakly supervised learning\n",
            "Author/s :  Zhi-Hua Zhou\n",
            "Venue :  \n",
            "year :  2018\n",
            "Abstract :  Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.\n",
            "------------------------------------\n",
            "Title :  The Evolving Disclosure Landscape: How Changes in Technology, the Media, and Capital Markets Are Affecting Disclosure\n",
            "Author/s :  Gregory S. Miller, Douglas J. Skinner\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Recent changes in technology and the media are causing significant changes in how capital markets assimilate and respond to information. We identify important themes in the disclosure literature and use this as a framework to discuss the conference papers that appear in this volume. These papers examine how managers’ disclosure practices are being affected by changes in technology, the media, and capital markets. While this work makes important progress, we discuss how continuing technological change and the emergence of new forms of media offer further opportunities for research on the role of disclosure in capital markets.\n",
            "------------------------------------\n",
            "Title :  Core concepts of spatial information for transdisciplinary research\n",
            "Author/s :  W. Kuhn\n",
            "Venue :  International Journal of Geographical Information Science\n",
            "year :  2012\n",
            "Abstract :  Geographic information science is emerging from its niche ‘behind the systems’, getting ready to contribute to transdisciplinary research. To succeed, a conceptual consensus across multiple disciplines on what spatial information is and how it can be used is needed. This article proposes a set of 10 core concepts of spatial information, intended to be meaningful to scientists who are not specialists of spatial information: location, neighbourhood, field, object, network, event, granularity, accuracy, meaning, and value. Each proposed concept is briefly characterized, demonstrating the need to map between their different disciplinary uses.\n",
            "------------------------------------\n",
            "Title :  Supervised hashing with kernels\n",
            "Author/s :  W. Liu, Jun Wang, R. Ji, Yu-Gang Jiang, Shih-Fu Chang\n",
            "Venue :  2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2012\n",
            "Abstract :  Recent years have witnessed the growing popularity of hashing in large-scale vision problems. It has been shown that the hashing quality could be boosted by leveraging supervised information into hash function learning. However, the existing supervised methods either lack adequate performance or often incur cumbersome model training. In this paper, we propose a novel kernel-based supervised hashing model which requires a limited amount of supervised information, i.e., similar and dissimilar data pairs, and a feasible training cost in achieving high quality hashing. The idea is to map the data to compact binary codes whose Hamming distances are minimized on similar pairs and simultaneously maximized on dissimilar pairs. Our approach is distinct from prior works by utilizing the equivalence between optimizing the code inner products and the Hamming distances. This enables us to sequentially and efficiently train the hash functions one bit at a time, yielding very short yet discriminative codes. We carry out extensive experiments on two image benchmarks with up to one million samples, demonstrating that our approach significantly outperforms the state-of-the-arts in searching both metric distance neighbors and semantically similar neighbors, with accuracy gains ranging from 13% to 46%.\n",
            "------------------------------------\n",
            "Title :  Containment of misinformation spread in online social networks\n",
            "Author/s :  Nam P. Nguyen, Guanhua Yan, M. Thai, S. Eidenbenz\n",
            "Venue :  Web Science Conference\n",
            "year :  2012\n",
            "Abstract :  With their blistering expansions in recent years, popular on-line social sites such as Twitter, Facebook and Bebo, have become some of the major news sources as well as the most effective channels for viral marketing nowadays. However, alongside these promising features comes the threat of misinformation propagation which can lead to undesirable effects, such as the widespread panic in the general public due to faulty swine flu tweets on Twitter in 2009. Due to the huge magnitude of online social network (OSN) users and the highly clustered structures commonly observed in these kinds of networks, it poses a substantial challenge to efficiently contain viral spread of misinformation in large-scale social networks.\n",
            " In this paper, we focus on how to limit viral propagation of misinformation in OSNs. Particularly, we study a set of problems, namely the β1T -- Node Protectors, which aims to find the smallest set of highly influential nodes whose decontamination with good information helps to contain the viral spread of misinformation, initiated from the set I, to a desired ratio (1 − β) in T time steps. In this family set, we analyze and present solutions including inapproximability result, greedy algorithms that provide better lower bounds on the number of selected nodes, and a community-based heuristic method for the Node Protector problems. To verify our suggested solutions, we conduct experiments on real world traces including NetHEPT, NetHEPT_WC and Facebook networks. Empirical results indicate that our methods are among the best ones for hinting out those important nodes in comparison with other available methods.\n",
            "------------------------------------\n",
            "Title :  An Evolutionary Upgrade of Cognitive Load Theory: Using the Human Motor System and Collaboration to Support the Learning of Complex Cognitive Tasks\n",
            "Author/s :  F. Paas, J. Sweller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The lure of rationality: Why does the deficit model persist in science communication?\n",
            "Author/s :  Molly Simis, Haley C. Madden, M. Cacciatore, Sara K. Yeo\n",
            "Venue :  Public Understanding of Science\n",
            "year :  2016\n",
            "Abstract :  Science communication has been historically predicated on the knowledge deficit model. Yet, empirical research has shown that public communication of science is more complex than what the knowledge deficit model suggests. In this essay, we pose four lines of reasoning and present empirical data for why we believe the deficit model still persists in public communication of science. First, we posit that scientists’ training results in the belief that public audiences can and do process information in a rational manner. Second, the persistence of this model may be a product of current institutional structures. Many graduate education programs in science, technology, engineering, and math (STEM) fields generally lack formal training in public communication. We offer empirical evidence that demonstrates that scientists who have less positive attitudes toward the social sciences are more likely to adhere to the knowledge deficit model of science communication. Third, we present empirical evidence of how scientists conceptualize “the public” and link this to attitudes toward the deficit model. We find that perceiving a knowledge deficit in the public is closely tied to scientists’ perceptions of the individuals who comprise the public. Finally, we argue that the knowledge deficit model is perpetuated because it can easily influence public policy for science issues. We propose some ways to uproot the deficit model and move toward more effective science communication efforts, which include training scientists in communication methods grounded in social science research and using approaches that engage community members around scientific issues.\n",
            "------------------------------------\n",
            "Title :  Adaptive Active Learning for Image Classification\n",
            "Author/s :  X. Li, Yuhong Guo\n",
            "Venue :  2013 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year :  2013\n",
            "Abstract :  Recently active learning has attracted a lot of attention in computer vision field, as it is time and cost consuming to prepare a good set of labeled images for vision data analysis. Most existing active learning approaches employed in computer vision adopt most uncertainty measures as instance selection criteria. Although most uncertainty query selection strategies are very effective in many circumstances, they fail to take information in the large amount of unlabeled instances into account and are prone to querying outliers. In this paper, we present a novel adaptive active learning approach that combines an information density measure and a most uncertainty measure together to select critical instances to label for image classifications. Our experiments on two essential tasks of computer vision, object recognition and scene recognition, demonstrate the efficacy of the proposed approach.\n",
            "------------------------------------\n",
            "Title :  Can Twitter Help Predict Firm-Level Earnings and Stock Returns?\n",
            "Author/s :  Eli Bartov, Lucile Faurel, Partha Mohanram\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  ABSTRACT: Prior research has examined how companies exploit Twitter in communicating with investors, and whether Twitter activity predicts the stock market as a whole. We test whether opinions of individuals tweeted just prior to a firm's earnings announcement predict its earnings and announcement returns. Using a broad sample from 2009 to 2012, we find that the aggregate opinion from individual tweets successfully predicts a firm's forthcoming quarterly earnings and announcement returns. These results hold for tweets that convey original information, as well as tweets that disseminate existing information, and are stronger for tweets providing information directly related to firm fundamentals and stock trading. Importantly, our results hold even after controlling for concurrent information or opinion from traditional media sources, and are stronger for firms in weaker information environments. Our findings highlight the importance of considering the aggregate opinion from individual tweets when assessing...\n",
            "------------------------------------\n",
            "Title :  Faces in Context: A Review and Systematization of Contextual Influences on Affective Face Processing\n",
            "Author/s :  M. Wieser, T. Brosch\n",
            "Venue :  Front. Psychology\n",
            "year :  2012\n",
            "Abstract :  Facial expressions are of eminent importance for social interaction as they convey information about other individuals’ emotions and social intentions. According to the predominant “basic emotion” approach, the perception of emotion in faces is based on the rapid, automatic categorization of prototypical, universal expressions. Consequently, the perception of facial expressions has typically been investigated using isolated, de-contextualized, static pictures of facial expressions that maximize the distinction between categories. However, in everyday life, an individual’s face is not perceived in isolation, but almost always appears within a situational context, which may arise from other people, the physical environment surrounding the face, as well as multichannel information from the sender. Furthermore, situational context may be provided by the perceiver, including already present social information gained from affective learning and implicit processing biases such as race bias. Thus, the perception of facial expressions is presumably always influenced by contextual variables. In this comprehensive review, we aim at (1) systematizing the contextual variables that may influence the perception of facial expressions and (2) summarizing experimental paradigms and findings that have been used to investigate these influences. The studies reviewed here demonstrate that perception and neural processing of facial expressions are substantially modified by contextual information, including verbal, visual, and auditory information presented together with the face as well as knowledge or processing biases already present in the observer. These findings further challenge the assumption of automatic, hardwired categorical emotion extraction mechanisms predicted by basic emotion theories. Taking into account a recent model on face processing, we discuss where and when these different contextual influences may take place, thus outlining potential avenues in future research.\n",
            "------------------------------------\n",
            "Title :  The Hidden Cost of Accommodating Crowdfunder Privacy Preferences: A Randomized Field Experiment\n",
            "Author/s :  Gordon Burtch, A. Ghose, S. Wattal\n",
            "Venue :  Management Sciences\n",
            "year :  2014\n",
            "Abstract :  Online crowdfunding has received a great deal of attention as a promising avenue to fostering entrepreneurship and innovation. Because online settings bring increased visibility and traceability of transactions, many crowdfunding platforms provide mechanisms that enable a campaign contributor to conceal his or her identity or contribution amount from peers. We study the impact of these information (privacy) control mechanisms on crowdfunder behavior. Employing a randomized experiment at one of the world’s largest online crowdfunding platforms, we find evidence of both positive (e.g., comfort) and negative (e.g., privacy priming) causal effects. We find that reducing access to information controls induces a net increase in fundraising, yet this outcome results from two competing influences — treatment increases willingness to engage with the platform (a 4.9% increase in the probability of contribution) and simultaneously decreases the average contribution (a U.S.$5.81 decline). This decline derives from a publicity effect, wherein contributors respond to a lack of privacy by tempering extreme contributions. We unravel the causal mechanisms that drive the results and discuss the implications of our findings for the design of online platforms.\n",
            "------------------------------------\n",
            "Title :  Top Concerns of Tweeters During the COVID-19 Pandemic: Infoveillance Study\n",
            "Author/s :  Alaa A. Abd-alrazaq, Dari Alhuwail, M. Househ, Mounir Hamdi, Zubair Shah\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background The recent coronavirus disease (COVID-19) pandemic is taking a toll on the world’s health care infrastructure as well as the social, economic, and psychological well-being of humanity. Individuals, organizations, and governments are using social media to communicate with each other on a number of issues relating to the COVID-19 pandemic. Not much is known about the topics being shared on social media platforms relating to COVID-19. Analyzing such information can help policy makers and health care organizations assess the needs of their stakeholders and address them appropriately. Objective This study aims to identify the main topics posted by Twitter users related to the COVID-19 pandemic. Methods Leveraging a set of tools (Twitter’s search application programming interface (API), Tweepy Python library, and PostgreSQL database) and using a set of predefined search terms (“corona,” “2019-nCov,” and “COVID-19”), we extracted the text and metadata (number of likes and retweets, and user profile information including the number of followers) of public English language tweets from February 2, 2020, to March 15, 2020. We analyzed the collected tweets using word frequencies of single (unigrams) and double words (bigrams). We leveraged latent Dirichlet allocation for topic modeling to identify topics discussed in the tweets. We also performed sentiment analysis and extracted the mean number of retweets, likes, and followers for each topic and calculated the interaction rate per topic. Results Out of approximately 2.8 million tweets included, 167,073 unique tweets from 160,829 unique users met the inclusion criteria. Our analysis identified 12 topics, which were grouped into four main themes: origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating the risk of infection. The mean sentiment was positive for 10 topics and negative for 2 topics (deaths caused by COVID-19 and increased racism). The mean for tweet topics of account followers ranged from 2722 (increased racism) to 13,413 (economic losses). The highest mean of likes for the tweets was 15.4 (economic loss), while the lowest was 3.94 (travel bans and warnings). Conclusions Public health crisis response activities on the ground and online are becoming increasingly simultaneous and intertwined. Social media provides an opportunity to directly communicate health information to the public. Health systems should work on building national and international disease detection and surveillance systems through monitoring social media. There is also a need for a more proactive and agile public health presence on social media to combat the spread of fake news.\n",
            "------------------------------------\n",
            "Title :  Comparison of SEER Treatment Data With Medicare Claims\n",
            "Author/s :  A. Noone, J. Lund, A. Mariotto, K. Cronin, T. McNeel, D. Deapen, J. Warren\n",
            "Venue :  Medical Care\n",
            "year :  2016\n",
            "Abstract :  Background:The population-based Surveillance, Epidemiology, and End Results (SEER) registries collect information on first-course treatment, including surgery, chemotherapy, radiation therapy, and hormone therapy. However, the SEER program does not release data on chemotherapy or hormone therapy due to uncertainties regarding data completeness. Activities are ongoing to investigate the opportunity to supplement SEER treatment data with other data sources. Methods:Using the linked SEER-Medicare data, we examined the validity of the SEER data to identify receipt of chemotherapy and radiation therapy among those aged 65 and older diagnosed from 2000 to 2006 with bladder, female breast, colorectal, lung, ovarian, pancreas, or prostate cancer and hormone therapy among men diagnosed with prostate cancer at age 65 or older. Treatment collected by SEER was compared with treatment as determined by Medicare claims, using Medicare claims as the gold standard. The &kgr;, sensitivity, specificity, positive predictive values, and negative predictive values were calculated for the receipt of each treatment modality. Results:The overall sensitivity of SEER data to identify chemotherapy, radiation, and hormone therapy receipt was moderate (68%, 80%, and 69%, respectively) and varied by cancer site, stage, and patient characteristics. The overall positive predictive value was high (>85%) for all treatment types and cancer sites except chemotherapy for prostate cancer. Conclusions:SEER data should not generally be used for comparisons of treated and untreated individuals or to estimate the proportion of treated individuals in the population. Augmenting SEER data with other data sources will provide the most accurate treatment information.\n",
            "------------------------------------\n",
            "Title :  Implementing genomic medicine in the clinic: the future is here\n",
            "Author/s :  T. Manolio, R. Chisholm, B. Ozenberger, D. Roden, Marc S. Williams, R. Wilson, D. Bick, E. Bottinger, M. Brilliant, C. Eng, K. Frazer, B. Korf, D. Ledbetter, J. Lupski, C. Marsh, D. Mrazek, M. Murray, P. O’Donnell, D. Rader, M. Relling, A. Shuldiner, D. Valle, R. Weinshilboum, E. Green, G. Ginsburg\n",
            "Venue :  Genetics in Medicine\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  A geographic approach for combining social media and authoritative data towards identifying useful information for disaster management\n",
            "Author/s :  J. Albuquerque, B. Herfort, A. Brenning, A. Zipf\n",
            "Venue :  International Journal of Geographical Information Science\n",
            "year :  2015\n",
            "Abstract :  In recent years, social media emerged as a potential resource to improve the management of crisis situations such as disasters triggered by natural hazards. Although there is a growing research body concerned with the analysis of the usage of social media during disasters, most previous work has concentrated on using social media as a stand-alone information source, whereas its combination with other information sources holds a still underexplored potential. This article presents an approach to enhance the identification of relevant messages from social media that relies upon the relations between georeferenced social media messages as Volunteered Geographic Information and geographic features of flood phenomena as derived from authoritative data (sensor data, hydrological data and digital elevation models). We apply this approach to examine the micro-blogging text messages of the Twitter platform (tweets) produced during the River Elbe Flood of June 2013 in Germany. This is performed by means of a statistical analysis aimed at identifying general spatial patterns in the occurrence of flood-related tweets that may be associated with proximity to and severity of flood events. The results show that messages near (up to 10 km) to severely flooded areas have a much higher probability of being related to floods. In this manner, we conclude that the geographic approach proposed here provides a reliable quantitative indicator of the usefulness of messages from social media by leveraging the existing knowledge about natural hazards such as floods, thus being valuable for disaster management in both crisis response and preventive monitoring.\n",
            "------------------------------------\n",
            "Title :  The Epistemic Engine: Sequence Organization and Territories of Knowledge\n",
            "Author/s :  J. Heritage\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This article reviews a range of conversation analytic findings concerning the role of information imbalances in the organization of conversational sequences. Considering sequences launched from knowing and unknowing epistemic stances, it considers the role of relative epistemic stance and status as warrants for the production of talk and as forces in the process of sequence production and decay.\n",
            "------------------------------------\n",
            "Title :  On the Use of Neuropyhsiological Tools in IS Research: Developing a Research Agenda for NeuroIS\n",
            "Author/s :  A. Dimoka, R. Banker, I. Benbasat, Fred D. Davis, A. Dennis, D. Gefen, Alok Gupta, A. Ischebeck, P. Kenning, P. Pavlou, G. Müller-Putz, R. Riedl, J. Brocke, B. Weber\n",
            "Venue :  MIS Q.\n",
            "year :  2012\n",
            "Abstract :  This article discusses the role of commonly used neurophysiological tools such as psychophysiological tools (e.g., EKG, eye tracking) and neuroimaging tools (e.g., fMRI, EEG) in Information Systems research. There is heated interest now in the social sciences in capturing presumably objective data directly from the human body, and this interest in neurophysiological tools has also been gaining momentum in IS research (termed NeuroIS). This article first reviews commonly used neurophysiological tools with regard to their major strengths and weaknesses. It then discusses several promising application areas and research questions where IS researchers can benefit from the use of neurophysiological data. The proposed research topics are presented within three thematic areas: (1) development and use of systems, (2) IS strategy and business outcomes, and (3) group work and decision support. The article concludes with recommendations on how to use neurophysiological tools in IS research along with a set of practical suggestions for developing a research agenda for NeuroIS and establishing NeuroIS as a viable subfield in the IS literature.\n",
            "------------------------------------\n",
            "Title :  Social Collaborative Filtering by Trust\n",
            "Author/s :  Bo Yang, Yu Lei, Da-you Liu, Jiming Liu\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2013\n",
            "Abstract :  Recommender systems are used to accurately and actively provide users with potentially interesting information or services. Collaborative filtering is a widely adopted approach to recommendation, but sparse data and cold-start users are often barriers to providing high quality recommendations. To address such issues, we propose a novel method that works to improve the performance of collaborative filtering recommendations by integrating sparse rating data given by users and sparse social trust network among these same users. This is a model-based method that adopts matrix factorization technique that maps users into low-dimensional latent feature spaces in terms of their trust relationship, and aims to more accurately reflect the users reciprocal influence on the formation of their own opinions and to learn better preferential patterns of users for high-quality recommendations. We use four large-scale datasets to show that the proposed method performs much better, especially for cold start users, than state-of-the-art recommendation algorithms for social collaborative filtering based on trust.\n",
            "------------------------------------\n",
            "Title :  Psychological characteristics associated with COVID-19 vaccine hesitancy and resistance in Ireland and the United Kingdom\n",
            "Author/s :  Jamie Murphy, F. Vallières, R. Bentall, M. Shevlin, O. McBride, T. Hartman, R. McKay, K. Bennett, L. Mason, J. Gibson-Miller, L. Levita, Antón P. Martínez, T. Stocks, T. Karatzias, P. Hyland\n",
            "Venue :  Nature Communications\n",
            "year :  2021\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  COMPARTMENTS: unification and visualization of protein subcellular localization evidence\n",
            "Author/s :  Janos X. Binder, Sune Pletscher-Frankild, K. Tsafou, C. Stolte, S. O’Donoghue, Reinhard Schneider, L. Jensen\n",
            "Venue :  Database J. Biol. Databases Curation\n",
            "year :  2014\n",
            "Abstract :  Information on protein subcellular localization is important to understand the cellular functions of proteins. Currently, such information is manually curated from the literature, obtained from high-throughput microscopy-based screens and predicted from primary sequence. To get a comprehensive view of the localization of a protein, it is thus necessary to consult multiple databases and prediction tools. To address this, we present the COMPARTMENTS resource, which integrates all sources listed above as well as the results of automatic text mining. The resource is automatically kept up to date with source databases, and all localization evidence is mapped onto common protein identifiers and Gene Ontology terms. We further assign confidence scores to the localization evidence to facilitate comparison of different types and sources of evidence. To further improve the comparability, we assign confidence scores based on the type and source of the localization evidence. Finally, we visualize the unified localization evidence for a protein on a schematic cell to provide a simple overview. Database URL: http://compartments.jensenlab.org\n",
            "------------------------------------\n",
            "Title :  Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks\n",
            "Author/s :  P. Bashivan, I. Rish, M. Yeasin, N. Codella\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2015\n",
            "Abstract :  One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.\n",
            "------------------------------------\n",
            "Title :  Anatomy of news consumption on Facebook\n",
            "Author/s :  A. L. Schmidt, Fabiana Zollo, Michela Del Vicario, Alessandro Bessi, A. Scala, G. Caldarelli, H. Stanley, W. Quattrociocchi\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2017\n",
            "Abstract :  Significance Social media heavily changed the way we get informed and shape our opinions. Users’ polarization seems to dominate news consumption on Facebook. Through a massive analysis on 920 news outlets and 376 million users, we explore the anatomy of news consumption on Facebook on a global scale. We show that users tend to confine their attention on a limited set of pages, thus determining a sharp community structure among news outlets. Furthermore, our findings suggest that users have a more cosmopolitan perspective of the information space than news providers. We conclude with a simple model of selective exposure that well reproduces the observed connectivity patterns. The advent of social media and microblogging platforms has radically changed the way we consume information and form opinions. In this paper, we explore the anatomy of the information space on Facebook by characterizing on a global scale the news consumption patterns of 376 million users over a time span of 6 y (January 2010 to December 2015). We find that users tend to focus on a limited set of pages, producing a sharp community structure among news outlets. We also find that the preferences of users and news providers differ. By tracking how Facebook pages “like” each other and examining their geolocation, we find that news providers are more geographically confined than users. We devise a simple model of selective exposure that reproduces the observed connectivity patterns.\n",
            "------------------------------------\n",
            "Title :  Guiding Through the Fog: Financial Statement Complexity and Voluntary Disclosure\n",
            "Author/s :  W. Guay, Delphine Samuels, Daniel J. Taylor\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  A growing literature documents that complex financial statements negatively affect the information environment. In this paper, we examine whether managers use voluntary disclosure to mitigate these negative effects. Employing cross-sectional and within-firm designs, we find a robust positive relation between financial statement complexity and voluntary disclosure. This relation is stronger when liquidity decreases around the filing of the financial statements, is stronger when firms have more outside monitors, and is weaker when firms have poor performance and greater earnings management. We also examine the relation between financial statement complexity and voluntary disclosure using two quasi-natural experiments. Employing a generalized difference-in-differences design, we find firms affected by the adoption of complex accounting standards (e.g., SFAS 133 and SFAS 157) increase their voluntary disclosure to a greater extent than unaffected firms. Collectively, these findings suggest managers use voluntary disclosure to mitigate the negative effects of complex financial statements on the information environment.\n",
            "------------------------------------\n",
            "Title :  Non-Markovianity and reservoir memory of quantum channels: a quantum information theory perspective\n",
            "Author/s :  B. Bylicka, D. Chruściński, S. Maniscalco\n",
            "Venue :  Scientific Reports\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Regularizing Rioting: Permitting Public Protest in an Authoritarian Regime\n",
            "Author/s :  Peter Lorentzen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Lacking the informative feedback provided by competitive elections, an unfettered press and an active civil society, authoritarian regimes can find it difficult to identify which social groups have become dangerously discontented and to monitor lower levels of government. While a rise in public protest is often seen as a harbinger of regime collapse in such states, this paper uses a formal model and a close examination of the Chinese case to show that the informal toleration and even encouragement of small-scale, narrowly economic protests can be an effective information gathering tool, mitigating these informational problems. The analysis demonstrates that protests should be observed most frequently where discontent is neither too high nor too low. This calls into question the common assumption in comparative politics that an increase in protests necessarily reflects an increase in discontent or the weakness of a regime.\n",
            "------------------------------------\n",
            "Title :  Increasing Accountability Through User-Interface Design Artifacts: A New Approach to Addressing the Problem of Access-Policy Violations\n",
            "Author/s :  Anthony Vance, P. Lowry, D. Eggett\n",
            "Venue :  MIS Q.\n",
            "year :  2015\n",
            "Abstract :  Access-policy violations are a growing problem with substantial costs for organizations. Although training programs and sanctions have been suggested as a means of reducing these violations, evidence shows the problem persists. It is thus imperative to identify additional ways to reduce access-policy violations, especially for systems providing broad access to data. We use accountability theory to develop four user-interface (UI) design artifacts that raise users' accountability perceptions within systems and in turn decrease access-policy violations. To test our model, we uniquely applied the scenario-based factorial survey method to various graphical manipulations of a records system containing sensitive information at a large organization with over 300 end users who use the system daily. We show that the UI design artifacts corresponding to four submanipulations of accountability can raise accountability and reduce access policy violation intentions. Our findings have several theoretical and practical implications for increasing accountability using UI design. Moreover, we are the first to extend the scenario-based factorial survey method to test design artifacts. This method provides the ability to use more design manipulations and to test with fewer users than is required in traditional experimentation and research on human--computer interaction. We also provide bootstrapping tests of mediation and moderation and demonstrate how to analyze fixed and random effects within the factorial survey method optimally.\n",
            "------------------------------------\n",
            "Title :  Twitcident: fighting fire with information from social web streams\n",
            "Author/s :  F. Abel, C. Hauff, G. Houben, R.J.P. Stronkman, Ke Tao\n",
            "Venue :  The Web Conference\n",
            "year :  2012\n",
            "Abstract :  In this paper, we present Twitcident, a framework and Web-based system for filtering, searching and analyzing information about real-world incidents or crises. Twitcident connects to emergency broadcasting services and automatically starts tracking and filtering information from Social Web streams (Twitter) when a new incident occurs. It enriches the semantics of streamed Twitter messages to profile incidents and to continuously improve and adapt the information filtering to the current temporal context. Faceted search and analytical tools allow users to retrieve particular information fragments and overview and analyze the current situation as reported on the Social Web. Demo: http://wis.ewi.tudelft.nl/twitcident/\n",
            "------------------------------------\n",
            "Title :  Can We Make Postoperative Patient Handovers Safer? A Systematic Review of the Literature\n",
            "Author/s :  N. Segall, A. Bonifacio, R. Schroeder, A. Barbeito, Dawn Rogers, D. Thornlow, James D. Emery, S. Kellum, M. Wright, J. Mark\n",
            "Venue :  Anesthesia and Analgesia\n",
            "year :  2012\n",
            "Abstract :  Postoperative patient handovers are fraught with technical and communication errors and may negatively impact patient safety. We systematically reviewed the literature on handover of care from the operating room to postanesthesia or intensive care units and summarized process and communication recommendations based on these findings. From >500 papers, we identified 31 dealing with postoperative handovers. Twenty-four included recommendations for structuring the handover process or information transfer. Several recommendations were broadly supported, including (1) standardize processes (e.g., through the use of checklists and protocols); (2) complete urgent clinical tasks before the information transfer; (3) allow only patient-specific discussions during verbal handovers; (4) require that all relevant team members be present; and (5) provide training in team skills and communication. Only 4 of the studies developed an intervention and formally assessed its impact on different process measures. All 4 interventions improved metrics of effectiveness, efficiency, and perceived teamwork. Most of the papers were cross-sectional studies that identified barriers to safe, effective postoperative handovers including the incomplete transfer of information and other communication issues, inconsistent or incomplete teams, absent or inefficient execution of clinical tasks, and poor standardization. An association between poor-quality handovers and adverse events was also demonstrated. More innovative research is needed to define optimal patient handovers and to determine the effect of handover quality on patient outcomes.\n",
            "------------------------------------\n",
            "Title :  Toward Massive, Ultrareliable, and Low-Latency Wireless Communication With Short Packets\n",
            "Author/s :  G. Durisi, T. Koch, P. Popovski\n",
            "Venue :  Proceedings of the IEEE\n",
            "year :  2015\n",
            "Abstract :  Most of the recent advances in the design of high-speed wireless systems are based on information-theoretic principles that demonstrate how to efficiently transmit long data packets. However, the upcoming wireless systems, notably the fifth-generation (5G) system, will need to support novel traffic types that use short packets. For example, short packets represent the most common form of traffic generated by sensors and other devices involved in machine-to-machine (M2M) communications. Furthermore, there are emerging applications in which small packets are expected to carry critical information that should be received with low latency and ultrahigh reliability. Current wireless systems are not designed to support short-packet transmissions. For example, the design of current systems relies on the assumption that the metadata (control information) is of negligible size compared to the actual information payload. Hence, transmitting metadata using heuristic methods does not affect the overall system performance. However, when the packets are short, metadata may be of the same size as the payload, and the conventional methods to transmit it may be highly suboptimal. In this paper, we review recent advances in information theory, which provide the theoretical principles that govern the transmission of short packets. We then apply these principles to three exemplary scenarios (the two-way channel, the downlink broadcast channel, and the uplink random access channel), thereby illustrating how the transmission of control information can be optimized when the packets are short. The insights brought by these examples suggest that new principles are needed for the design of wireless protocols supporting short packets. These principles will have a direct impact on the system design.\n",
            "------------------------------------\n",
            "Title :  A Survey on Truth Discovery\n",
            "Author/s :  Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, Jiawei Han\n",
            "Venue :  SKDD\n",
            "year :  2015\n",
            "Abstract :  Thanks to information explosion, data for the objects of interest can be collected from increasingly more sources. However, for the same object, there usually exist conflicts among the collected multi-source information. To tackle this challenge, truth discovery, which integrates multi-source noisy information by estimating the reliability of each source, has emerged as a hot topic. Several truth discovery methods have been proposed for various scenarios, and they have been successfully applied in diverse application domains. In this survey, we focus on providing a comprehensive overview of truth discovery methods, and summarizing them from different aspects. We also discuss some future directions of truth discovery research. We hope that this survey will promote a better understanding of the current progress on truth discovery, and offer some guidelines on how to apply these approaches in application domains.\n",
            "------------------------------------\n",
            "Title :  FakeNewsNet: A Data Repository with News Content, Social Context, and Spatiotemporal Information for Studying Fake News on Social Media\n",
            "Author/s :  Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, Huan Liu\n",
            "Venue :  Big Data\n",
            "year :  2018\n",
            "Abstract :  Social media has become a popular means for people to consume and share the news. At the same time, however, it has also enabled the wide dissemination of fake news, that is, news with intentionally false information, causing significant negative effects on society. To mitigate this problem, the research of fake news detection has recently received a lot of attention. Despite several existing computational solutions on the detection of fake news, the lack of comprehensive and community-driven fake news data sets has become one of major roadblocks. Not only existing data sets are scarce, they do not contain a myriad of features often required in the study such as news content, social context, and spatiotemporal information. Therefore, in this article, to facilitate fake news-related research, we present a fake news data repository FakeNewsNet, which contains two comprehensive data sets with diverse features in news content, social context, and spatiotemporal information. We present a comprehensive description of the FakeNewsNet, demonstrate an exploratory analysis of two data sets from different perspectives, and discuss the benefits of the FakeNewsNet for potential applications on fake news study on social media.\n",
            "------------------------------------\n",
            "Title :  Mobile Data Offloading through Opportunistic Communications and Social Participation\n",
            "Author/s :  B. Han, Pan Hui, V. S. A. Kumar, M. Marathe, Jianhua Shao, A. Srinivasan\n",
            "Venue :  IEEE Transactions on Mobile Computing\n",
            "year :  2012\n",
            "Abstract :  3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these algorithms for both synthetic and real-world mobility traces. For example, the Heuristic algorithm can offload mobile data traffic by up to 73.66 percent for a real-world mobility trace. Moreover, to investigate the feasibility of opportunistic communications for mobile phones, we implement a proof-of-concept prototype, called Opp-off, on Nokia N900 smartphones, which utilizes their Bluetooth interface for device/service discovery and content transfer.\n",
            "------------------------------------\n",
            "Title :  The Updated DeLone and McLean Model of Information Systems Success\n",
            "Author/s :  Nils Urbach, B. Müller\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Security Challenges for the Public Cloud\n",
            "Author/s :  K. Ren, Cong Wang, Qian Wang\n",
            "Venue :  IEEE Internet Computing\n",
            "year :  2012\n",
            "Abstract :  Cloud computing represents today's most exciting computing paradigm shift in information technology. However, security and privacy are perceived as primary obstacles to its wide adoption. Here, the authors outline several critical security challenges and motivate further investigation of security solutions for a trustworthy public cloud environment.\n",
            "------------------------------------\n",
            "Title :  Information provision for stroke patients and their caregivers.\n",
            "Author/s :  A. Forster, L. Brown, Jane Smith, A. House, P. Knapp, John Wright, John B. Young\n",
            "Venue :  Cochrane Database of Systematic Reviews\n",
            "year :  2012\n",
            "Abstract :  BACKGROUND\n",
            "Research shows that stroke patients and their families are dissatisfied with the information provided and have a poor understanding of stroke and associated issues.\n",
            "\n",
            "\n",
            "OBJECTIVES\n",
            "To assess the effectiveness of information provision strategies in improving the outcome for stroke patients or their identified caregivers, or both.\n",
            "\n",
            "\n",
            "SEARCH METHODS\n",
            "For this update we searched the Cochrane Stroke Group Trials Register (June 2012), the Cochrane Central Register of Controlled trials (CENTRAL), the Cochrane Database of Systematic Reviews (CDSR), the Database of Abstracts of Reviews of Effects (DARE), the NHS Economic Evaluation Database (EED), and the Health Technology Assessment (HTA) Database (The Cochrane Library June, 2012), MEDLINE (1966 to June 2012), EMBASE (1980 to June 2012), CINAHL (1982 to June 2012) and PsycINFO (1974 to June 2012). We also searched ongoing trials registers, scanned bibliographies of relevant articles and books and contacted researchers.\n",
            "\n",
            "\n",
            "SELECTION CRITERIA\n",
            "Randomised trials involving patients or carers of patients with a clinical diagnosis of stroke or transient ischaemic attack (TIA) where an information intervention was compared with standard care, or where information and another therapy were compared with the other therapy alone.\n",
            "\n",
            "\n",
            "DATA COLLECTION AND ANALYSIS\n",
            "Two review authors independently assessed trial eligibility and methodological quality and extracted data. Primary outcomes were knowledge about stroke and stroke services, and impact on mood.\n",
            "\n",
            "\n",
            "MAIN RESULTS\n",
            "We have added four new trials to this update. This review now includes 21 trials involving 2289 patient and 1290 carer participants. Nine trials evaluated a passive and 12 trials an active information intervention. Meta-analyses showed a significant effect in favour of the intervention on patient knowledge (standardised mean difference (SMD) 0.29, 95% confidence interval (CI) 0.12 to 0.46, P < 0.001), carer knowledge (SMD 0.74, 95% CI 0.06 to 1.43, P = 0.03), one aspect of patient satisfaction (odds ratio (OR) 2.07, 95% CI 1.33 to 3.23, P = 0.001), and patient depression scores (mean difference (MD) -0.52, 95% CI -0.93 to -0.10, P = 0.01). There was no significant effect (P > 0.05) on number of cases of anxiety or depression in patients, carer mood or satisfaction, or death. Qualitative analyses found no strong evidence of an effect on other outcomes. Post-hoc subgroup analyses showed that active information had a significantly greater effect than passive information on patient mood but not on other outcomes.\n",
            "\n",
            "\n",
            "AUTHORS' CONCLUSIONS\n",
            "There is evidence that information improves patient and carer knowledge of stroke, aspects of patient satisfaction, and reduces patient depression scores. However, the reduction in depression scores was small and may not be clinically significant. Although the best way to provide information is still unclear there is some evidence that strategies that actively involve patients and carers and include planned follow-up for clarification and reinforcement have a greater effect on patient mood.\n",
            "------------------------------------\n",
            "Title :  Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks\n",
            "Author/s :  P. Bashivan, I. Rish, M. Yeasin, N. Codella\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2015\n",
            "Abstract :  One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.\n",
            "------------------------------------\n",
            "Title :  On the Bottleneck of Graph Neural Networks and its Practical Implications\n",
            "Author/s :  Uri Alon, Eran Yahav\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2020\n",
            "Abstract :  Graph neural networks (GNNs) were shown to effectively learn from highly structured data containing elements (nodes) with relationships (edges) between them. GNN variants differ in how each node in the graph absorbs the information flowing from its neighbor nodes. In this paper, we highlight an inherent problem in GNNs: the mechanism of propagating information between neighbors creates a bottleneck when every node aggregates messages from its neighbors. This bottleneck causes the over-squashing of exponentially-growing information into fixed-size vectors. As a result, the graph fails to propagate messages flowing from distant nodes and performs poorly when the prediction task depends on long-range information. We demonstrate that the bottleneck hinders popular GNNs from fitting the training data. We show that GNNs that absorb incoming edges equally, like GCN and GIN, are more susceptible to over-squashing than other GNN types. We further show that existing, extensively-tuned, GNN-based models suffer from over-squashing and that breaking the bottleneck improves state-of-the-art results without any hyperparameter tuning or additional weights.\n",
            "------------------------------------\n",
            "Title :  A review on supply chain contracting with information considerations: information updating and information asymmetry\n",
            "Author/s :  Bin Shen, T. Choi, S. Minner\n",
            "Venue :  International Journal of Production Research\n",
            "year :  2019\n",
            "Abstract :  Supply chain contracting and the use of information are undoubtedly two critical and influential areas in modern supply chain management. However, relatively little is known about supply chain contracting mechanisms with different information settings. To fill this gap, we review and classify the related supply chain contracting literature into three categories with respect to different kinds of information considerations, namely (i) demand information updating, (ii) supply information updating and (iii) information asymmetry. We report the publication trend and classify the commonly studied supply chain contracts with the use of information such as pricing contracts, commitment contracts and menu of contracts. We discuss how contracting and the use of information influence each other in the supply chain. Moreover, we review the major application areas of information usage and report the historical development of major related topics. Finally, we propose several important future research directions.\n",
            "------------------------------------\n",
            "Title :  Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation\n",
            "Author/s :  Guosheng Lin, Chunhua Shen, Anton van dan Hengel, I. Reid\n",
            "Venue :  Computer Vision and Pattern Recognition\n",
            "year :  2015\n",
            "Abstract :  Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information, specifically, we explore 'patch-patch' context between image regions, and 'patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-overunion score of 78:0 on the challenging PASCAL VOC 2012 dataset.\n",
            "------------------------------------\n",
            "Title :  A State-of-the-Art Review on the Integration of Building Information Modeling (BIM) and Geographic Information System (GIS)\n",
            "Author/s :  Xin Liu, Xiangyu Wang, G. Wright, Jack C. P. Cheng, Xiao Li, R. Liu\n",
            "Venue :  ISPRS Int. J. Geo Inf.\n",
            "year :  2017\n",
            "Abstract :  The integration of Building Information Modeling (BIM) and Geographic Information System (GIS) has been identified as a promising but challenging topic to transform information towards the generation of knowledge and intelligence. Achievement of integrating these two concepts and enabling technologies will have a significant impact on solving problems in the civil, building and infrastructure sectors. However, since GIS and BIM were originally developed for different purposes, numerous challenges are being encountered for the integration. To better understand these two different domains, this paper reviews the development and dissimilarities of GIS and BIM, the existing integration methods, and investigates their potential in various applications. This study shows that the integration methods are developed for various reasons and aim to solve different problems. The parameters influencing the choice can be summarized and named as “EEEF” criteria: effectiveness, extensibility, effort, and flexibility. Compared with other methods, semantic web technologies provide a promising and generalized integration solution. However, the biggest challenges of this method are the large efforts required at early stage and the isolated development of ontologies within one particular domain. The isolation problem also applies to other methods. Therefore, openness is the key of the success of BIM and GIS integration.\n",
            "------------------------------------\n",
            "Title :  Thermodynamics with Continuous Information Flow\n",
            "Author/s :  J. Horowitz, M. Esposito\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We provide a unified thermodynamic formalism describing information transfers in autonomous as well as nonautonomous systems described by stochastic thermodynamics. We demonstrate how information is continuously generated in an auxiliary system and then transferred to a relevant system that can utilize it to fuel otherwise impossible processes. Indeed, while the joint system satisfies the second law, the entropy balance for the relevant system is modified by an information term related to the mutual information rate between the two systems. We show that many important results previously derived for nonautonomous Maxwell demons can be recovered from our formalism and use a cycle decomposition to analyze the continuous information flow in autonomous systems operating at steady-state. A model system is used to illustrate our findings.\n",
            "------------------------------------\n",
            "Title :  Beyond Comprehension\n",
            "Author/s :  E. Peters\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  When making decisions, people must frequently take into account numerical information, but not all individuals have the ability to understand and use numbers. Less numerate individuals comprehend less numerical information; but numeracy goes beyond comprehension, relating systematically to psychological mechanisms. In particular, greater numeracy has been associated with reduced susceptibility to framing effects, less influence of nonnumerical information such as mood states, and greater sensitivity to different levels of numerical risk. This greater number sensitivity has been linked with number-related affective reactions reported by the highly numerate. I briefly discuss methods to increase number use in decisions and policy implications of numeracy research.\n",
            "------------------------------------\n",
            "Title :  Industry Concentration and Corporate Disclosure Policy\n",
            "Author/s :  Ashiq Ali, Sandy J Klasa, P. Yeung\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  This study examines the association between U.S. Census industry concentration measures and the informativeness of corporate disclosure policy. We find that in more concentrated industries firms׳ management earnings forecasts are less frequent and have shorter horizons, their disclosure ratings by analysts are lower, and they have more opaque information environments, as measured by the properties of analysts׳ earnings forecasts. Also, when these firms raise funds they prefer private placements, which have minimal SEC-mandated disclosure requirements, over seasoned equity offerings. Overall, our findings suggest that firms in more concentrated industries disclose less and avoid certain financing decisions that have non-trivial disclosure implications, presumably due to proprietary costs of disclosure.\n",
            "------------------------------------\n",
            "Title :  Uses and Grats 2.0: New Gratifications for New Media\n",
            "Author/s :  S. Sundar, Anthony M. Limperos\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  This article responds to recent calls for conceptual and methodological refinement, issued by uses-and-gratifications scholars (Rubin, 2009; Ruggiero, 2000), for studying emergent media. Noting that studies on the uses of the Internet have generated a list of gratifications that are remarkably similar to those obtained from older media, it identifies two measurement artifacts—(1) measures designed for older media are used to capture gratifications from newer media; and (2) gratifications are conceptualized and operationalized too broadly (e.g., information-seeking), thus missing the nuanced gratifications obtained from newer media. It challenges the notion that all gratifications are borne out of innate needs, and proposes that affordances of media technology can shape user needs, giving rise to new and distinctive gratifications. A sample of new gratifications and potential measures for those are provided.\n",
            "------------------------------------\n",
            "Title :  A first look at COVID-19 information and misinformation sharing on Twitter\n",
            "Author/s :  L. Singh, S. Bansal, L. Bode, Ceren Budak, G. Chi, Kornraphop Kawintiranon, Colton Padden, R. Vanarsdall, E. Vraga, Yanchen Wang\n",
            "Venue :  ArXiv\n",
            "year :  2020\n",
            "Abstract :  Since December 2019, COVID-19 has been spreading rapidly across the world. Not surprisingly, conversation about COVID-19 is also increasing. This article is a first look at the amount of conversation taking place on social media, specifically Twitter, with respect to COVID-19, the themes of discussion, where the discussion is emerging from, myths shared about the virus, and how much of it is connected to other high and low quality information on the Internet through shared URL links. Our preliminary findings suggest that a meaningful spatio-temporal relationship exists between information flow and new cases of COVID-19, and while discussions about myths and links to poor quality information exist, their presence is less dominant than other crisis specific themes. This research is a first step toward understanding social media conversation about COVID-19.\n",
            "------------------------------------\n",
            "Title :  Unified Theory of Acceptance and Use of Technology: A Synthesis and the Road Ahead\n",
            "Author/s :  V. Venkatesh, J. Thong, Xin Xu\n",
            "Venue :  Journal of the AIS\n",
            "year :  2016\n",
            "Abstract :  The unified theory of acceptance and use of technology (UTAUT) is a little over a decade old and has been used extensively in information systems (IS) and other fields, as the large number of citations to the original paper that introduced the theory evidences. In this paper, we review and synthesize the IS literature on UTAUT from September 2003 until December 2014, perform a theoretical analysis of UTAUT and its extensions, and chart an agenda for research going forward. Based on Weber’s (2012) framework of theory evaluation, we examined UTAUT and its extensions along two sets of quality dimensions; namely, the parts of a theory and the theory as a whole. While our review identifies many merits to UTAUT, we also found that the progress related to this theory has hampered further theoretical development in research into technology acceptance and use. To chart an agenda for research that will enable significant future work, we analyze the theoretical contributions of UTAUT using Whetten’s (2009) notion of cross-context theorizing. Our analysis reveals several limitations that lead us to propose a multi-level framework that can serve as the theoretical foundation for future research. Specifically, this framework integrates the notion of research context and cross-context theorizing with the theory evaluation framework to: (1) synthesize the existing UTAUT extensions across both the dimensions and the levels of the research context and (2) highlight promising research directions. We conclude with recommendations for future UTAUT-related research using the proposed framework.\n",
            "------------------------------------\n",
            "Title :  Building Member Attachment in Online Communities: Applying Theories of Group Identity and Interpersonal Bonds\n",
            "Author/s :  Yuqing Ren, F. M. Harper, Sara Drenner, L. Terveen, S. Kiesler, J. Riedl, R. Kraut\n",
            "Venue :  MIS Q.\n",
            "year :  2012\n",
            "Abstract :  Online communities are increasingly important to organizations and the general public, but there is little theoretically based research on what makes some online communities more successful than others. In this article, we apply theory from the field of social psychology to understand how online communities develop member attachment, an important dimension of community success. We implemented and empirically tested two sets of community features for building member attachment by strengthening either group identity or interpersonal bonds. To increase identity-based attachment, we gave members information about group activities and intergroup competition, and tools for group-level communication. To increase bond-based attachment, we gave members information about the activities of individual members and interpersonal similarity, and tools for interpersonal communication. Results from a six-month field experiment show that participants' visit frequency and self-reported attachment increased in both conditions. Community features intended to foster identity-based attachment had stronger effects than features intended to foster bond-based attachment. Participants in the identity condition with access to group profiles and repeated exposure to their group's activities visited their community twice as frequently as participants in other conditions. The new features also had stronger effects on newcomers than on old-timers. This research illustrates how theory from the social science literature can be applied to gain a more systematic understanding of online communities and how theory-inspired features can improve their success.\n",
            "------------------------------------\n",
            "Title :  Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks\n",
            "Author/s :  Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-rong Wen, Edward Y. Chang\n",
            "Venue :  Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year :  2018\n",
            "Abstract :  With the revival of neural networks, many studies try to adapt powerful sequential neural models, ıe Recurrent Neural Networks (RNN), to sequential recommendation. RNN-based networks encode historical interaction records into a hidden state vector. Although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. It is difficult to capture fine-grained user preference from the interaction sequence. Furthermore, the latent vector representation is usually hard to understand and explain. To address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. Our model integrates the RNN-based networks with Key-Value Memory Network (KV-MN). We further incorporate knowledge base (KB) information to enhance the semantic representation of KV-MN. RNN-based models are good at capturing sequential user preference, while knowledge-enhanced KV-MNs are good at capturing attribute-level user preference. By using a hybrid of RNNs and KV-MNs, it is expected to be endowed with both benefits from these two components. The sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. With the incorporation of KB information, our model is also highly interpretable. To our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale KB information.\n",
            "------------------------------------\n",
            "Title :  Advances in Cryptology: Proceedings Of Crypto 83\n",
            "Author/s :  D. Chaum\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Public Key Cryptosystems and Signatures.- A Prototype Encryption System Using Public Key.- A Public Key Cryptosystem and a Signature Scheme Based on Discrete Logarithms.- A Public-Key Cryptosystem Based on the Word Problem.- Efficient Signature Schemes Based on Polynomial Equations (preliminary version).- Identity-Based Cryptosystems and Signature Schemes.- A Knapsack Type Public Key Cryptosystem Based On Arithmetic in Finite Fields (preliminary draft).- Some Public-Key Crypto-Functions as Intractable as Factorization.- Cryptosystems and Other Hard Problems.- Computing Logarithms in GF (2n).- Wyner's Analog Encryption Scheme: Results of a Simulation.- On Rotation Group and Encryption of Analog Signals.- The History of Book Ciphers.- An Update on Factorization at Sandia National Laboratories.- An LSI Digital Encryption Processor (DEP).- Efficient hardware and software implementations for the DES.- Efficient hardware implementation of the DES.- A Self-Synchronizing Cascaded Cipher System with Dynamic Control of Error Propagation.- Randomness and Its Concomitants.- Efficient and Secure Pseudo-Random Number Generation (Extended Abstract).- An LSI Random Number Generator (RNG).- Generalized Linear Threshold Scheme.- Security of Ramp Schemes.- A Fast Pseudo Random Permutation Generator With Applications to Cryptology.- On the Cryptographic Applications of Random Functions (Extended Abstract).- An Efficient Probabilistic Public-Key Encryption Scheme Which Hides All Partial Information.- Analysis and Cryptanalysis.- RSA/Rabin least significant bits are secure (Extended Abstract).- Information Theory without the Finiteness Assumption, I: Cryptosystems as Group-Theoretic Objects.- Cryptanalysis of Adfgvx Encipherment Systems.- Breaking Iterated Knapsacks.- Dependence of output on input in DES: Small avalanche characteristics.- Des has no Per Round Linear Factors.- Protocols and Authentication.- A Message Authenticator Algorithm Suitable for a Mainframe Computer.- Key Management for Secure Electronic Funds Transfer in a Retail Environment.- Authentication Theory/Coding Theory.- New Secret Codes Can Prevent a Computerized Big Brother.- Fair Exchange of Secrets (extended abstract).- Cryptoprotocols: Subscription to a Public Key, The Secret Blocking and The Multi-Player Mental Poker Game (extended abstract).- Poker Protocols.- Impromptu Talks.- A \"Paradoxical\" Solution to The Signature Problem.- Sequence Complexity as a Test for Cryptographic Systems.- An Update on Quantum Cryptography.- How to Keep a Secret Alive.\n",
            "------------------------------------\n",
            "Title :  Information and Energy Cooperation in Cognitive Radio Networks\n",
            "Author/s :  G. Zheng, Z. Ho, Eduard Axel Jorswieck, B. Ottersten\n",
            "Venue :  IEEE Transactions on Signal Processing\n",
            "year :  2014\n",
            "Abstract :  Cooperation between the primary and secondary systems can improve the spectrum efficiency in cognitive radio networks. The key idea is that the secondary system helps to boost the primary system's performance by relaying, and, in return, the primary system provides more opportunities for the secondary system to access the spectrum. In contrast to most of existing works that only consider information cooperation, this paper studies joint information and energy cooperation between the two systems, i.e., the primary transmitter sends information for relaying and feeds the secondary system with energy as well. This is particularly useful when the secondary transmitter has good channel quality to the primary receiver but is energy constrained. We propose and study three schemes that enable this cooperation. First, we assume there exists an ideal backhaul between the two systems for information and energy transfer. We then consider two wireless information and energy transfer schemes from the primary transmitter to the secondary transmitter using power splitting and time splitting energy harvesting techniques, respectively. For each scheme, the optimal and zero-forcing solutions are derived. Simulation results demonstrate promising performance gain for both systems due to the additional energy cooperation. It is also revealed that the power splitting scheme can achieve larger rate region than the time splitting scheme when the efficiency of the energy transfer is sufficiently large.\n",
            "------------------------------------\n",
            "Title :  Enabling Flexibility in Process-Aware Information Systems: Challenges, Methods, Technologies\n",
            "Author/s :  M. Reichert, B. Weber\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  In todays dynamic business world, the success of a company increasingly depends on its ability to react to changes in its environment in a quick and flexible way. Companies have therefore identified process agility as a competitive advantage to address business trends like increasing product and service variability or faster time to market, and to ensure business IT alignment. Along this trend, a new generation of information systems has emergedso-called process-aware information systems (PAIS), like workflow management systems, case handling tools, and service orchestration engines. With this book, Reichert and Weber address these flexibility needs and provide an overview of PAIS with a strong focus on methods and technologies fostering flexibility for all phases of the process lifecycle (i.e., modeling, configuration, execution and evolution). Their presentation is divided into six parts. Part I starts with an introduction of fundamental PAIS concepts and establishes the context of process flexibility in the light of practical scenarios. Part II focuses on flexibility support for pre-specified processes, the currently predominant paradigm in the field of business process management (BPM). Part III details flexibility support for loosely specified processes, which only partially specify the process model at build-time, while decisions regarding the exact specification of certain model parts are deferred to the run-time. Part IV deals with user- and data-driven processes, which aim at a tight integration of processes and data, and hence enable an increased flexibility compared to traditional PAIS. Part V introduces existing technologies and systems for the realization of a flexible PAIS. Finally, Part VI summarizes the main ideas of this book and gives an outlook on advanced flexibility issues. The bookstarget groups include researchers, PhD students and Master students in the field of information systems. After reading the book, they will better understand PAIS flexibility aspects. To support the easy use as a textbook, a series of exercises is provided at the end of each chapter and slides and further teaching material are available on the books web site www.flexible-processes.com. Professionals specializing in business process management (BPM) who want to obtain a good understanding of flexibility challenges in BPM and state-of-the-art solutions will also benefit from the presentations of open source as well as commercial process management systems and related practical scenarios.\n",
            "------------------------------------\n",
            "Title :  Visual simultaneous localization and mapping: a survey\n",
            "Author/s :  J. Fuentes-Pacheco, José Ruíz Ascencio, J. M. Rendon-Mancha\n",
            "Venue :  Artificial Intelligence Review\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Parents' Source of Vaccine Information and Impact on Vaccine Attitudes, Beliefs, and Nonmedical Exemptions\n",
            "Author/s :  Abbey M. Jones, S. Omer, R. Bednarczyk, N. Halsey, L. Moulton, D. Salmon\n",
            "Venue :  Advances in Preventive Medicine\n",
            "year :  2012\n",
            "Abstract :  In recent years, use of the Internet to obtain vaccine information has increased. Historical data are necessary to evaluate current vaccine information seeking trends in context. Between 2002 and 2003, surveys were mailed to 1,630 parents of fully vaccinated children and 815 parents of children with at least one vaccine exemption; 56.1% responded. Respondents were asked about their vaccine information sources, perceptions of these sources accuracy, and their beliefs about vaccination. Parents who did not view their child's healthcare provider as a reliable vaccine information source were more likely to obtain vaccine information using the Internet. Parents who were younger, more highly educated, and opposed to school immunization requirements were more likely than their counterparts to use the Internet for vaccine information. Compared to parents who did not use the Internet for vaccine information, those who sought vaccine information on the Internet were more likely to have lower perceptions of vaccine safety (adjusted odds ratio (aOR), 1.66; 95% CI, 1.18–2.35), vaccine effectiveness (aOR, 1.83; 95% CI, 1.32–2.53), and disease susceptibility (aOR, 2.08; 95% CI, 1.49–2.90) and were more likely to have a child with a nonmedical exemption (aOR 3.53, 95% CI, 2.61–4.76). These findings provide context to interpret recent vaccine information seeking research.\n",
            "------------------------------------\n",
            "Title :  A Coordinated Approach to Channel Estimation in Large-Scale Multiple-Antenna Systems\n",
            "Author/s :  Haifan Yin, D. Gesbert, Miltiades Filippou, Yingzhuang Liu\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2012\n",
            "Abstract :  This paper addresses the problem of channel estimation in multi-cell interference-limited cellular networks. We consider systems employing multiple antennas and are interested in both the finite and large-scale antenna number regimes (so-called \"massive MIMO\"). Such systems deal with the multi-cell interference by way of per-cell beamforming applied at each base station. Channel estimation in such networks, which is known to be hampered by the pilot contamination effect, constitutes a major bottleneck for overall performance. We present a novel approach which tackles this problem by enabling a low-rate coordination between cells during the channel estimation phase itself. The coordination makes use of the additional second-order statistical information about the user channels, which are shown to offer a powerful way of discriminating across interfering users with even strongly correlated pilot sequences. Importantly, we demonstrate analytically that in the large-number-of-antennas regime, the pilot contamination effect is made to vanish completely under certain conditions on the channel covariance. Gains over the conventional channel estimation framework are confirmed by our simulations for even small antenna array sizes.\n",
            "------------------------------------\n",
            "Title :  Improving health information systems for decision making across five sub-Saharan African countries: Implementation strategies from the African Health Initiative\n",
            "Author/s :  W. Mutale, N. Chintu, C. Amoroso, Koku Awoonor-Williams, J. Phillips, C. Baynes, C. Michel, Angela Taylor, K. Sherr\n",
            "Venue :  BMC Health Services Research\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Magnon transistor for all-magnon data processing\n",
            "Author/s :  A. Chumak, A. Serga, B. Hillebrands\n",
            "Venue :  Nature Communications\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  The Generative Mechanisms of Digital Infrastructure Evolution\n",
            "Author/s :  O. Henfridsson, B. Bygstad\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  The current literature on digital infrastructure offers powerful lenses for conceptualizing the increasingly interconnected information system collectives found in contemporary organizations. However, little attention has been paid to the generative mechanisms of digital infrastructure, that is, the causal powers that explain how and why such infrastructure evolves over time. This is unfortunate, since more knowledge about what drives digital infrastructures would be highly valuable for managers and IT professionals confronted by the complexity of managing them. To this end, this paper adopts a critical realist view for developing a configurational perspective of infrastructure evolution. Our theorizing draws on a multimethod research design comprising an in-depth case study and a case survey. The in-depth case study, conducted at a Scandinavian airline, distinguishes three key mechanisms of digital infrastructure evolution: adoption, innovation, and scaling. The case survey research of 41 cases of digital infrastructure then identifies and analyzes causal paths through which configurations of these mechanisms lead to successful evolution outcomes. The study reported in this paper contributes to the infrastructure literature in two ways. First, we identify three generative mechanisms of digital infrastructure and how they contingently lead to evolution outcomes. Second, we use these mechanisms as a basis for developing a configurational perspective that advances current knowledge about why some digital infrastructures evolve successfully while others do not. In addition, the paper demonstrates and discusses the efficacy of critical realism as a philosophical tradition for developing substantive contributions in the field of information systems.\n",
            "------------------------------------\n",
            "Title :  HMDB 4.0: the human metabolome database for 2018\n",
            "Author/s :  D. Wishart, Y. D. Feunang, A. Marcu, Anchi Guo, Kevin Y. H. Liang, R. Vázquez-Fresno, Tanvir Sajed, Daniel Johnson, Carin Li, N. Karu, Zinat Sayeeda, Elvis J. Lo, Nazanin Assempour, M. Berjanskii, Sandeep Singhal, David Arndt, Yongjie Liang, Hasan Badran, J. Grant, Arnau Serra-Cayuela, Yifeng Liu, R. Mandal, V. Neveu, Allison Pon, Craig K. Knox, Michael Wilson, C. Manach, A. Scalbert\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2017\n",
            "Abstract :  Abstract The Human Metabolome Database or HMDB (www.hmdb.ca) is a web-enabled metabolomic database containing comprehensive information about human metabolites along with their biological roles, physiological concentrations, disease associations, chemical reactions, metabolic pathways, and reference spectra. First described in 2007, the HMDB is now considered the standard metabolomic resource for human metabolic studies. Over the past decade the HMDB has continued to grow and evolve in response to emerging needs for metabolomics researchers and continuing changes in web standards. This year's update, HMDB 4.0, represents the most significant upgrade to the database in its history. For instance, the number of fully annotated metabolites has increased by nearly threefold, the number of experimental spectra has grown by almost fourfold and the number of illustrated metabolic pathways has grown by a factor of almost 60. Significant improvements have also been made to the HMDB’s chemical taxonomy, chemical ontology, spectral viewing, and spectral/text searching tools. A great deal of brand new data has also been added to HMDB 4.0. This includes large quantities of predicted MS/MS and GC–MS reference spectral data as well as predicted (physiologically feasible) metabolite structures to facilitate novel metabolite identification. Additional information on metabolite-SNP interactions and the influence of drugs on metabolite levels (pharmacometabolomics) has also been added. Many other important improvements in the content, the interface, and the performance of the HMDB website have been made and these should greatly enhance its ease of use and its potential applications in nutrition, biochemistry, clinical chemistry, clinical genetics, medicine, and metabolomics science.\n",
            "------------------------------------\n",
            "Title :  How Smart, Connected Products Are Transforming Competition\n",
            "Author/s :  M. Porter, J. Heppelmann\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  Information technology is revolutionizing products, from appliances to cars to mining equipment. Products once composed solely of mechanical and electrical parts have become complex systems combining hardware, sensors, electronics, and software that connect through the internet in myriad ways. These “smart, connected products” offer exponentially expanding opportunities for new functionality, far greater reliability, and capabilities that cut across and transcend traditional product boundaries. The changing nature of products is disrupting value chains, argue Michael Porter and PTC CEO James Heppelmann, and forcing companies to rethink nearly everything they do, from how they conceive, design, and source their products; to how they manufacture, operate, and service them; to how they build and secure the necessary IT infrastructure. Smart, connected products raise a broad set of new strategic choices for companies about how value is created and captured, how to work with traditional partners and what new partnerships will be required, and how to secure competitive advantage as the new capabilities reshape industry boundaries. For many firms, smart, connected products will force the fundamental question: “What business am I in?” This article provides a framework for developing strategy and achieving competitive advantage in a smart, connected world.\n",
            "------------------------------------\n",
            "Title :  A survey of transfer learning\n",
            "Author/s :  Karl R. Weiss, T. Khoshgoftaar, Dingding Wang\n",
            "Venue :  Journal of Big Data\n",
            "year :  2016\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Empowering patients through social media: The benefits and challenges\n",
            "Author/s :  M. Househ, E. Borycki, A. Kushniruk\n",
            "Venue :  Health Informatics Journal\n",
            "year :  2014\n",
            "Abstract :  This article explores the range of social media platforms used by patients and examines the benefits and challenges of using these tools from a patient perspective. A literature review was performed to investigate the use of social media technology by patients. The MEDLINE database was searched using the terms “social media” and “patient.” The search was conducted in September 2012 and yielded 765 abstracts. Initially, 63 abstracts were selected. All articles dating from 2004 through 2012 were included. Only 12 articles were found to be relevant for the purposes of the review. The results of this research found that there appears to be an increase in the use of social media by patients across the healthcare spectrum. The research indicates a promising future for the use of social media by patients; however, evidence related to the efficacy and effectiveness of social media is currently limited. Various challenges have also been identified relating to privacy and security concerns, usability, the manipulation of identity, and misinformation. The use of social media technology is an emerging trend for patients who are seeking health information. Conclusions are that such technology holds promise for improving patient engagement and empowerment and community building. Social media has a future in healthcare, especially with regard to patient engagement and empowerment; however, there are several challenges to overcome before the technology can achieve its potential.\n",
            "------------------------------------\n",
            "Title :  Semi-Supervised Hashing for Large-Scale Search\n",
            "Author/s :  Jun Wang, Sanjiv Kumar, Shih-Fu Chang\n",
            "Venue :  IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year :  2012\n",
            "Abstract :  Hashing-based approximate nearest neighbor (ANN) search in huge databases has become popular due to its computational and memory efficiency. The popular hashing methods, e.g., Locality Sensitive Hashing and Spectral Hashing, construct hash functions based on random or principal projections. The resulting hashes are either not very accurate or are inefficient. Moreover, these methods are designed for a given metric similarity. On the contrary, semantic similarity is usually given in terms of pairwise labels of samples. There exist supervised hashing methods that can handle such semantic similarity, but they are prone to overfitting when labeled data are small or noisy. In this work, we propose a semi-supervised hashing (SSH) framework that minimizes empirical error over the labeled set and an information theoretic regularizer over both labeled and unlabeled sets. Based on this framework, we present three different semi-supervised hashing methods, including orthogonal hashing, nonorthogonal hashing, and sequential hashing. Particularly, the sequential hashing method generates robust codes in which each hash function is designed to correct the errors made by the previous ones. We further show that the sequential learning paradigm can be extended to unsupervised domains where no labeled pairs are available. Extensive experiments on four large datasets (up to 80 million samples) demonstrate the superior performance of the proposed SSH methods over state-of-the-art supervised and unsupervised hashing techniques.\n",
            "------------------------------------\n",
            "Title :  Experimentally induced innovations lead to persistent culture via conformity in wild birds\n",
            "Author/s :  L. Aplin, D. Farine, J. Morand‐Ferron, A. Cockburn, A. Thornton, B. Sheldon\n",
            "Venue :  Nature\n",
            "year :  2014\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Designing Fully Distributed Consensus Protocols for Linear Multi-Agent Systems With Directed Graphs\n",
            "Author/s :  Zhongkui Li, G. Wen, Z. Duan, W. Ren\n",
            "Venue :  IEEE Transactions on Automatic Control\n",
            "year :  2013\n",
            "Abstract :  This technical note addresses the distributed consensus protocol design problem for multi-agent systems with general linear dynamics and directed communication graphs. Existing works usually design consensus protocols using the smallest real part of the nonzero eigenvalues of the Laplacian matrix associated with the communication graph, which however is global information. In this technical note, based on only the agent dynamics and the relative states of neighboring agents, a distributed adaptive consensus protocol is designed to achieve leader-follower consensus in the presence of a leader with a zero input for any communication graph containing a directed spanning tree with the leader as the root node. The proposed adaptive protocol is independent of any global information of the communication graph and thereby is fully distributed. Extensions to the case with multiple leaders are further studied.\n",
            "------------------------------------\n",
            "Title :  Named Entity Recognition with Bidirectional LSTM-CNNs\n",
            "Author/s :  Jason P. C. Chiu, Eric Nichols\n",
            "Venue :  International Conference on Topology, Algebra and Categories in Logic\n",
            "year :  2015\n",
            "Abstract :  Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches. Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed from publicly-available sources, we establish new state of the art performance with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information.\n",
            "------------------------------------\n",
            "Title :  What, Me Worry? The Role of Affect in Information Seeking and Avoidance\n",
            "Author/s :  Z. J. Yang, L. Kahlor\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Guided by the risk information-seeking and processing model, this study examines positive and negative affect separately in their influence on information-seeking intentions and avoidance through structural equation analyses. The highlight is that information avoidance seems to be driven by positive affect, while information seeking seems to be more heavily influenced by negative affect. Another interesting finding is that informational subjective norms are positively related to both seeking and avoidance, which suggests that one’s social environment has the potential to strongly influence the way he or she handles climate change information. Implications for theory and practice are discussed.\n",
            "------------------------------------\n",
            "Title :  On the Role of Age of Information in the Internet of Things\n",
            "Author/s :  Mohamed A. Abd-Elmagid, N. Pappas, Harpreet S. Dhillon\n",
            "Venue :  IEEE Communications Magazine\n",
            "year :  2018\n",
            "Abstract :  In this article, we provide an accessible introduction to the emerging idea of Age of Information (AoI) that quantifies freshness of information and explore its possible role in the efficient design of freshness-aware Internet of Things (IoT). We start by summarizing the concept of AoI and its variants with emphasis on the differences between AoI and other well-known performance metrics in the literature, such as throughput and delay. Building on this, we explore freshness-aware IoT design for a network in which IoT devices sense potentially different physical processes and are supposed to frequently update the status of these processes at a destination node (e.g., a cellular base station). Inspired by recent interest, we also assume that these IoT devices are powered by wireless energy transfer by the destination node. For this setting, we investigate the optimal sampling policy that jointly optimizes wireless energy transfer and scheduling of update packet transmissions from IoT devices with the goal of minimizing long-term weighted sum-AoI. Using this, we characterize the achievable AoI region. We also compare this AoI-optimal policy with the one that maximizes average throughput (throughput-optimal policy), and demonstrate the impact of system state on their structures. Several promising directions for future research are also presented.\n",
            "------------------------------------\n",
            "Title :  Context-Dependent Sentiment Analysis in User-Generated Videos\n",
            "Author/s :  Soujanya Poria, E. Cambria, Devamanyu Hazarika, Navonil Majumder, Amir Zadeh, Louis-Philippe Morency\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2017\n",
            "Abstract :  Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.\n",
            "------------------------------------\n",
            "Title :  PhosphoSitePlus, 2014: mutations, PTMs and recalibrations\n",
            "Author/s :  P. Hornbeck, Bin Zhang, Beth Murray, J. Kornhauser, V. Latham, E. Skrzypek\n",
            "Venue :  Nucleic Acids Res.\n",
            "year :  2014\n",
            "Abstract :  PhosphoSitePlus® (PSP, http://www.phosphosite.org/), a knowledgebase dedicated to mammalian post-translational modifications (PTMs), contains over 330 000 non-redundant PTMs, including phospho, acetyl, ubiquityl and methyl groups. Over 95% of the sites are from mass spectrometry (MS) experiments. In order to improve data reliability, early MS data have been reanalyzed, applying a common standard of analysis across over 1 000 000 spectra. Site assignments with P > 0.05 were filtered out. Two new downloads are available from PSP. The ‘Regulatory sites’ dataset includes curated information about modification sites that regulate downstream cellular processes, molecular functions and protein-protein interactions. The ‘PTMVar’ dataset, an intersect of missense mutations and PTMs from PSP, identifies over 25 000 PTMVars (PTMs Impacted by Variants) that can rewire signaling pathways. The PTMVar data include missense mutations from UniPROTKB, TCGA and other sources that cause over 2000 diseases or syndromes (MIM) and polymorphisms, or are associated with hundreds of cancers. PTMVars include 18 548 phosphorlyation sites, 3412 ubiquitylation sites, 2316 acetylation sites, 685 methylation sites and 245 succinylation sites.\n",
            "------------------------------------\n",
            "Title :  Comprehending and Learning From Internet Sources: Processing Patterns of Better and Poorer Learners\n",
            "Author/s :  S. Goldman, Jason L. G. Braasch, J. Wiley, A. Graesser, Kamila Brodowinska\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Readers increasingly attempt to understand and learn from information sources they find on the Internet. Doing so highlights the crucial role that evaluative processes play in selecting and making sense of the information. In a prior study, Wiley et al. (2009, Experiment 1) asked undergraduates to perform a web-based inquiry task about volcanoes using multiple Internet sources. A major finding established a clear link between learning outcomes, source evaluations, and reading behaviors. The present study used think-aloud protocol methodology to better understand the processing that learners engaged in during this task: 10 better learners were contrasted with 11 poorer learners. Results indicate that better learners engaged in more sense-making, self-explanation, and comprehension-monitoring processes on reliable sites as compared with unreliable sites, and did so by a larger margin than did poorer learners. Better learners also engaged in more goal-directed navigation than poorer learners. Case studies of two better and two poorer learners further illustrate how evaluation processes contributed to navigation decisions. Findings suggest that multiple-source comprehension is a dynamic process that involves interplay among sense-making, monitoring, and evaluation processes, all of which promote strategic reading. \n",
            " \n",
            " \n",
            " \n",
            "阅读者日益想要弄明白及学习他们从互联网上各种来源所找到的信息资料。他们这样做突显出在选择和弄明白这些信息时评价过程所起的重要作用。威立等人在以前一项研究(2009,实验1)中,参与研究的大学生要利用互联网多种资源来完成一项关于火山的網路探究式学习任务。该研究的一个主要结果是建立了学习成果、信息来源评价与阅读行为之间的明确联系。本研究则使用有声思维研究方法,以深入考查学习者在参与同一个学习任务时他们处理信息的过程,并以10名表现较好的与11名表现较差的学习者作比对。结果显示,对于可靠网站上的资料,表现较好的学习者较多致力于弄明白自我解释的过程和理解监控的过程,而对于不可靠网站上的资料,这种行为则较少;他们这种行为亦远多于表现较差的学习者。此外,表现较好的学习者比表现较差的学习者较多致力于有目标的网上浏览。两个表现较好及两个表现较差的学习者的案例研究,进一步说明评价过程如何有助于在网上浏览时所作的决定。本研究结果显示,理解多种来源的信息是一个动态的过程,其中涉及弄明白、监控和评价过程之间的相互作用,而这些过程均能促进策略性阅读。 \n",
            " \n",
            " \n",
            " \n",
            "Es cada vez mas comun que lectores intenten entender y aprender de fuentes de informacion del Internet. Esto demuestra el rol crucial que los procesos de evaluacion tienen en seleccionar y sacar sentido de la informacion recibida. En un estudio anterior, Wiley et al. (2009, Experiment 1) les pidieron a subgraduados que hicieran una busqueda en la red sobre volcanes usando multiples fuentes del Internet. Un resultado clave establecio una conexion clara entre los resultados del aprendizaje, la evaluacion de las fuentes, y la manera de leer. El presente estudio uso la metodologia del protocolo de pensar en voz alta para mejor entender los procesos usados por los aprendices al cumplir dicha tarea: se compararon 10 aprendices mejores con 11 aprendices pobres. Los resultados senalan que los mejores aprendices buscaban sus propias explicaciones que hicieran sentido y procesos de monitoreo de comprension en sitios confiables comparados con los sitios que no eran confiables, y lo hacian con un margen mayor que los aprendices pobres. Un estudio de casos de dos mejores y dos pobres aprendices ilustran aun mas como los procesos de evaluacion contribuian al proceso de navegacion. Los resultados sugieren que la comprension de multiples fuentes es un proceso dinamico que requiere interaccion entre los procesos de hacer sentido, monitoreo, y evaluacion, todos de los cuales promulgan la lectura estrategica. \n",
            " \n",
            " \n",
            " \n",
            "يحاول القراء بشكل متزايد الفهم والتعلم من مصادر المعلومات التي يجدونها على شبكة الإنترنيت؛ وبذلك فهذا يسلط الضوء على الدور الحاسم الذي تلعبه عمليات التقييم في اختيار وإعطاء معنى للمعلومات. وفي دراسة سابقة طلب “وايلي” وآخرون (التجربة١،٢٠٠٩) من الطلبة الجامعيين إجراء بحث على شبكة الإنترنيت حول البراكين مستخدمين مصادر إنترنيت متعددة.تم التوصل إلى نتيجة رئيسية تقوم على أن هناك صلة واضحة بين التعلم وتقييمات المصدر وسلوكيات القراءة. استخدمت الدراسة الحالية منهجية بروتوكول التفكيير بصوت عال لفهم بشكل أفضل العمليات التي استخدمها المتعلمون أثناء هذه المهمة: تمت مقارنة ١٠من أفضل المتعلمين ب١١من أضعف المتعلمين. تشير النتائج إلى أن أفضل المتعلمين استخدموا عمليات أكثر في إعطاء معنى للتفسير الذاتي ومراقبة الفهم على مواقع موثوق بها بالمقارنة مع مواقع غير موثوق بها وفعلوا ذلك أكثر من أضعف المتعلمين. كما أن أفضل المتعلمين قد قاموا بالبحث على أهدافهم عبر الإنترنيت بصورة مباشرة. وتوضح كذلك دراسة الحالة لأفضل متعلمين وأضعف متعلمين كيف ساهمت عمليات التقييم في قرارات البحث عبر الإنترنيت. تشير النتائج إلى أن فهم المصادر المتعددة عملية فعالة تشمل التفاعل المتبادل بين إعطاء المعنى والمراقبة وعملية التقييم، وكل منها تنمي القراءة الاستراتيجية. \n",
            " \n",
            " \n",
            " \n",
            "Читaющиe люди вce чaщe oбpaщaютcя к интepнeтy кaк к иcтoчникy инфopмaции. Oднaкo, для eeгpaмoтнoгo oтбopa ивocпpиятиякpaйнeвaжнo yмeть oцeнить эти иcтoчники. B paнee пpoвeдeнныx иccлeдoвaнияx (Wiley и дp., 2009, Экcпepимeнт 1) yчeныe пpeдлoжили cтyдeнтaм млaдшиx кypcoв пoиcкaть мaтepиaл o вyлкaнax пo paзличныминтepнeт-caйтaм. B итoгe выявилacь пpямaя cвязь мeждy peзyльтaтaми yчeбнoй дeятeльнocти, yмeниeм oцeнить иcтoчники и caмим пoвeдeниeм cтyдeнтoв-читaтeлeй. B нacтoящeмиccлeдoвaнии, чтoбы лyчшe пoнять, кaк пpoиcxoдит пpoцecc oцeнивaния, иcпoльзoвaлcя мeтoд “paзмышлeниe вcлyx”, и cpaвнивaлиcь paзмышлeния дecяти лyчшиx и дecяти нaибoлee cлaбыx yчaщиxcя. Peзyльтaты пoкaзывaют, чтo cильныe yчaщиecя знaчитeльнo чaщe paбoтaют c нaдeжными caйтaми, бoльшe зaнимaютcя aнaлизoм инфopмaции и кoнтpoлиpyют coбcтвeннoe ocмыcлeниe пpoчитaннoгo. Кpoмe тoгo, caм пpoцecc иx ceтeвoгo пoиcкa бoлee цeлeнaпpaвлeн, чeм дeятeльнocть cлaбыx yчaщиxcя. B кaчecтвe иллюcтpaции oпиcaн пpoцecc oцeнивaния иcтoчникoв и cooтвeтcтвyющaя eмy тpaeктopия пoиcкa для двyx cильныx и двyx cлaбыx yчaщиxcя. Aвтopы пoлaгaют, чтo вocпpиятиe инфopмaции из мнoжecтвa иcтoчникoв – динaмичный пpoцecc, кoтopый coчeтaeт в ceбe вoccoздaниe нoвыx для читaтeля cмыcлoв, a тaкжe мoнитopинг и oцeнивaниe пpoцeccoв пoзнaния, чтo в coвoкyпнocти paзвивaeт нaвыки cтpaтeгичecкoгo чтeния. \n",
            " \n",
            " \n",
            " \n",
            "Les lecteurs essaient de plus en plus de comprendre et d'apprendre au moyen de sources d'information qu'ils trouvent sur Internet. Cette pratique souligne le role crucial que jouent les processus d’evaluation lors de la selection de l'information et du sens qu'on lui donne. Dans une etude precedente, Wiley et al. (2009, premiere experience) ont demande a des etudiants de premier cycle d'effectuer sur la Toile une recherche sur les volcans en utilisant plusieurs sources d'Internet. Des liens sont apparus clairement entre les resultats obtenus, les evaluations des sources et les comportements de lecture. L’etude presentee ici a utilise la methodologie du protocole consistant a penser a haute voix pour mieux comprendre la facon de proceder des lecteurs lors de cette tâche, ceci avec 10 eleves de bon niveau contrastes a 11 eleves de niveau faible. Les resultats montrent que les meilleurs eleves s'engagent dans des processus d'auto-explication de recherche du sens et de pilotage de la comprehension sur des sites plus fiables que d'autres, et qu'ils procedent ainsi plus largement que les moins bons eleves. Les meilleurs eleves sont aussi plus engages dans une navigation avec but que les moins bons eleves. L’etude de cas de deux bons eleves et de deux faibles permettant de mieux illustrer encore comment les processus d’evaluation contribuent aux decisions de navigation. Les resultats suggerent que la comprehension de sources multiples est un processus dynamique qui implique des interactions entre l'attribution de sens, le pilotage, et les processus d’evaluation, tous ces elements contribuant a une lecture strategique.\n",
            "------------------------------------\n",
            "Title :  Guide to Cyber Threat Information Sharing\n",
            "Author/s :  Christopher Johnson, M. Badger, David Waltermire, Julie Snyder, C. Skorupka\n",
            "Venue :  \n",
            "year :  2016\n",
            "Abstract :  Cyber threat information is any information that can help an organization identify, assess, monitor, and respond to cyber threats. Cyber threat information includes indicators of compromise; tactics, techniques, and procedures used by threat actors; suggested actions to detect, contain, or prevent attacks; and the findings from the analyses of incidents. Organizations that share cyber threat information can improve their own security postures as well as those of other organizations. This publication provides guidelines for establishing and participating in cyber threat information sharing relationships. This guidance helps organizations establish information sharing goals, identify cyber threat information sources, scope information sharing activities, develop rules that control the publication and distribution of threat information, engage with existing sharing communities, and make effective use of threat information in support of the organization’s overall cybersecurity practices.\n",
            "------------------------------------\n",
            "Title :  At Least Bias Is Bipartisan: A Meta-Analytic Comparison of Partisan Bias in Liberals and Conservatives\n",
            "Author/s :  P. Ditto, Brittany S. Liu, Cory J. Clark, S. Wojcik, Eric Chen, R. Grady, Jared B. Celniker, Joanne F. Zinger\n",
            "Venue :  Perspectives on Psychological Science\n",
            "year :  2017\n",
            "Abstract :  Both liberals and conservatives accuse their political opponents of partisan bias, but is there empirical evidence that one side of the political aisle is indeed more biased than the other? To address this question, we meta-analyzed the results of 51 experimental studies, involving over 18,000 participants, that examined one form of partisan bias—the tendency to evaluate otherwise identical information more favorably when it supports one’s political beliefs or allegiances than when it challenges those beliefs or allegiances. Two hypotheses based on previous literature were tested: an asymmetry hypothesis (predicting greater partisan bias in conservatives than in liberals) and a symmetry hypothesis (predicting equal levels of partisan bias in liberals and conservatives). Mean overall partisan bias was robust (r = .245), and there was strong support for the symmetry hypothesis: Liberals (r = .235) and conservatives (r = .255) showed no difference in mean levels of bias across studies. Moderator analyses reveal this pattern to be consistent across a number of different methodological variations and political topics. Implications of the current findings for the ongoing ideological symmetry debate and the role of partisan bias in scientific discourse and political conflict are discussed.\n",
            "------------------------------------\n",
            "Title :  The Epistemic Engine: Sequence Organization and Territories of Knowledge\n",
            "Author/s :  J. Heritage\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  This article reviews a range of conversation analytic findings concerning the role of information imbalances in the organization of conversational sequences. Considering sequences launched from knowing and unknowing epistemic stances, it considers the role of relative epistemic stance and status as warrants for the production of talk and as forces in the process of sequence production and decay.\n",
            "------------------------------------\n",
            "Title :  A foundation for the study of behavior change support systems\n",
            "Author/s :  H. Oinas-Kukkonen\n",
            "Venue :  Personal and Ubiquitous Computing\n",
            "year :  2013\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Active inference and epistemic value\n",
            "Author/s :  Karl J. Friston, Francesco Rigoli, D. Ognibene, C. Mathys, Thomas H. B. FitzGerald, G. Pezzulo\n",
            "Venue :  Cognitive neuroscience\n",
            "year :  2015\n",
            "Abstract :  We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.\n",
            "------------------------------------\n",
            "Title :  Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms\n",
            "Author/s :  K. Crawford, J. Schultz\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  The rise of “big data” analytics in the private sector poses new challenges for privacy advocates. Unlike previous computational models that exploit personally identifiable information (PII) directly, such as behavioral targeting, big data has exploded the definition of PII to make many more sources of data personally identifiable. By analyzing primarily metadata, such as a set of predictive or aggregated findings without displaying or distributing the originating data, big data approaches often operate outside of current privacy protections (Rubinstein 2013; Tene and Polonetsky 2012), effectively marginalizing regulatory schema. Big data presents substantial privacy concerns – risks of bias or discrimination based on the inappropriate generation of personal data – a risk we call “predictive privacy harm.” Predictive analysis and categorization can pose a genuine threat to individuals, especially when it is performed without their knowledge or consent. While not necessarily a harm that falls within the conventional “invasion of privacy” boundaries, such harms still center on an individual’s relationship with data about her. Big data approaches need not rely on having a person’s PII directly: a combination of techniques from social network analysis, interpreting online behaviors and predictive modeling can create a detailed, intimate picture with a high degree of accuracy. Furthermore, harms can still result when such techniques are done poorly, rendering an inaccurate picture that nonetheless is used to impact on a person’s life and livelihood. In considering how to respond to evolving big data practices, we began by examining the existing rights that individuals have to see and review records pertaining to them in areas such as health and credit information. But it is clear that these existing systems are inadequate to meet current big data challenges. Fair Information Privacy Practices and other notice-and-choice regimes fail to protect against predictive privacy risks in part because individuals are rarely aware of how their individual data is being used to their detriment, what determinations are being made about them, and because at various points in big data processes, the relationship between predictive privacy harms and originating PII may be complicated by multiple technical processes and the involvement of third parties. Thus, past privacy regulations and rights are ill equipped to face current and future big data challenges.We propose a new approach to mitigating predictive privacy harms – that of a right to procedural data due process. In the Anglo-American legal tradition, procedural due process prohibits the government from depriving an individual’s rights to life, liberty, or property without affording her access to certain basic procedural components of the adjudication process – including the rights to review and contest the evidence at issue, the right to appeal any adverse decision, the right to know the allegations presented and be heard on the issues they raise. Procedural due process also serves as an enforcer of separation of powers, prohibiting those who write laws from also adjudicating them.While some current privacy regimes offer nominal due process-like mechanisms in relation to closely defined types of data, these rarely include all of the necessary components to guarantee fair outcomes and arguably do not apply to many kinds of big data systems (Terry 2012). A more rigorous framework is needed, particularly given the inherent analytical assumptions and methodological biases built into many big data systems (boyd and Crawford 2012). Building on previous thinking about due process for public administrative computer systems (Steinbock 2005; Citron 2010), we argue that individuals who are privately and often secretly “judged” by big data should have similar rights to those judged by the courts with respect to how their personal data has been used in such adjudications. Using procedural due process principles, we analogize a system of regulation that would provide such rights against private big data actors.\n",
            "------------------------------------\n",
            "Title :  Differential Privacy as a Mutual Information Constraint\n",
            "Author/s :  P. Cuff, Lanqing Yu\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2016\n",
            "Abstract :  Differential privacy is a precise mathematical constraint meant to ensure privacy of individual pieces of information in a database even while queries are being answered about the aggregate. Intuitively, one must come to terms with what differential privacy does and does not guarantee. For example, the definition prevents a strong adversary who knows all but one entry in the database from further inferring about the last one. This strong adversary assumption can be overlooked, resulting in misinterpretation of the privacy guarantee of differential privacy. Herein we give an equivalent definition of privacy using mutual information that makes plain some of the subtleties of differential privacy. The mutual-information differential privacy is in fact sandwiched between ε-differential privacy and (ε,δ)-differential privacy in terms of its strength. In contrast to previous works using unconditional mutual information, differential privacy is fundamentally related to conditional mutual information, accompanied by a maximization over the database distribution. The conceptual advantage of using mutual information, aside from yielding a simpler and more intuitive definition of differential privacy, is that its properties are well understood. Several properties of differential privacy are easily verified for the mutual information alternative, such as composition theorems.\n",
            "------------------------------------\n",
            "Title :  Mining high utility itemsets without candidate generation\n",
            "Author/s :  Mengchi Liu, Jun-Feng Qu\n",
            "Venue :  International Conference on Information and Knowledge Management\n",
            "year :  2012\n",
            "Abstract :  High utility itemsets refer to the sets of items with high utility like profit in a database, and efficient mining of high utility itemsets plays a crucial role in many real-life applications and is an important research issue in data mining area. To identify high utility itemsets, most existing algorithms first generate candidate itemsets by overestimating their utilities, and subsequently compute the exact utilities of these candidates. These algorithms incur the problem that a very large number of candidates are generated, but most of the candidates are found out to be not high utility after their exact utilities are computed. In this paper, we propose an algorithm, called HUI-Miner (High Utility Itemset Miner), for high utility itemset mining. HUI-Miner uses a novel structure, called utility-list, to store both the utility information about an itemset and the heuristic information for pruning the search space of HUI-Miner. By avoiding the costly generation and utility computation of numerous candidate itemsets, HUI-Miner can efficiently mine high utility itemsets from the utility-lists constructed from a mined database. We compared HUI-Miner with the state-of-the-art algorithms on various databases, and experimental results show that HUI-Miner outperforms these algorithms in terms of both running time and memory consumption.\n",
            "------------------------------------\n",
            "Title :  Comparing Online and Offline Self-Disclosure: A Systematic Review\n",
            "Author/s :  M. Nguyen, Y. Bin, A. Campbell\n",
            "Venue :  Cyberpsychology, Behavior, and Social Networking\n",
            "year :  2012\n",
            "Abstract :  Disclosure of personal information is believed to be more frequent in online compared to offline communication. However, this assumption is both theoretically and empirically contested. This systematic review examined existing research comparing online and offline self-disclosure to ascertain the evidence for current theories of online communication. Studies that compared online and offline disclosures in dyadic interactions were included for review. Contrary to expectations, disclosure was not consistently found to be greater in online contexts. Factors such as the relationship between the communicators, the specific mode of communication, and the context of the interaction appear to moderate the degree of disclosure. In relation to the theories of online communication, there is support for each theory. It is argued that the overlapping predictions of each theory and the current state of empirical research highlights a need for an overarching theory of communication that can account for disclosure in both online and offline interactions.\n",
            "------------------------------------\n",
            "Title :  A classification of location privacy attacks and approaches\n",
            "Author/s :  Marius Wernke, P. Skvortsov, Frank Dürr, K. Rothermel\n",
            "Venue :  Personal and Ubiquitous Computing\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne\n",
            "Author/s :  James Allan, W. Bruce Croft, Alistair Moffat, M. Sanderson\n",
            "Venue :  SIGF\n",
            "year :  2012\n",
            "Abstract :  During a three-day workshop in February 2012, 45 Information Retrieval researchers met to discuss long-range challenges and opportunities within the field. The result of the workshop is a diverse set of research directions, project ideas, and challenge areas. This report describes the workshop format, provides summaries of broad themes that emerged, includes brief descriptions of all the ideas, and provides detailed discussion of six proposals that were voted \"most interesting\" by the participants. Key themes include the need to: move beyond ranked lists of documents to support richer dialog and presentation, represent the context of search and searchers, provide richer support for information seeking, enable retrieval of a wide range of structured and unstructured content, and develop new evaluation methodologies.\n",
            "------------------------------------\n",
            "Title :  Shaping Liquidity: On the Causal Effects of Voluntary Disclosure\n",
            "Author/s :  K. Balakrishnan, Mary Brooke Billings, B. Kelly, Alexander Ljungqvist\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Can managers influence the liquidity of their firms' shares? We use plausibly exogenous variation in the supply of public information to show that firms seek to actively shape their information environments by voluntarily disclosing more information than is mandated by market regulations and that such efforts have a sizeable and beneficial effect on liquidity. Firms respond to an exogenous loss of public information by providing more timely and informative earnings guidance. Responses appear motivated by a desire to reduce information asymmetries between retail and institutional investors. Liquidity improves as a result of voluntary disclosure and in turn increases firm value. This suggests that managers can causally influence their cost of capital via voluntary disclosure.\n",
            "------------------------------------\n",
            "Title :  Wireless Information and Power Transfer With Full Duplex Relaying\n",
            "Author/s :  C. Zhong, H. Suraweera, G. Zheng, I. Krikidis, Zhaoyang Zhang\n",
            "Venue :  IEEE Transactions on Communications\n",
            "year :  2014\n",
            "Abstract :  We consider a dual-hop full-duplex relaying system, where the energy constrained relay node is powered by radio frequency signals from the source using the time-switching architecture, both the amplify-and-forward and decode-and-forward relaying protocols are studied. Specifically, we provide an analytical characterization of the achievable throughput of three different communication modes, namely, instantaneous transmission, delay-constrained transmission, and delay tolerant transmission. In addition, the optimal time split is studied for different transmission modes. Our results reveal that, when the time split is optimized, the full-duplex relaying could substantially boost the system throughput compared to the conventional half-duplex relaying architecture for all three transmission modes. In addition, it is shown that the instantaneous transmission mode attains the highest throughput. However, compared to the delay-constrained transmission mode, the throughput gap is rather small. Unlike the instantaneous time split optimization which requires instantaneous channel state information, the optimal time split in the delay-constrained transmission mode depends only on the statistics of the channel, hence, is suitable for practical implementations.\n",
            "------------------------------------\n",
            "Title :  Deep Recurrent Q-Learning for Partially Observable MDPs\n",
            "Author/s :  Matthew J. Hausknecht, P. Stone\n",
            "Venue :  AAAI Fall Symposia\n",
            "year :  2015\n",
            "Abstract :  Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network} (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.\n",
            "------------------------------------\n",
            "Title :  An integrated map of genetic variation from 1,092 human genomes\n",
            "Author/s :  Gil A. David M. Richard M. Gonçalo R. David R. Aravind McVean Altshuler (Co-Chair) Durbin (Co-Chair) Abec, G. McVean, David M. Richard M. Gonçalo R. David R. Aravinda Andrew  Altshuler (Co-Chair) Durbin (Co-Chair) Abecasis Be, David M. Altshuler (Co-Chair), Richard M. Durbin (Co-Chair), G. Abecasis, D. Bentley, A. Chakravarti, Andrew G. Clark, P. Donnelly, Evan E. Eichler, P. Flicek, S. Gabriel, R. Gibbs, E. Green, M. Hurles, B. Knoppers, J. Korbel, Eric S. Lander, Charles Lee, H. Lehrach, E. Mardis, G. Marth, G. McVean, D. Nickerson, Jeanette P. Schmidt, S. Sherry, Jun Wang, Richard K. Wilson, Richard A. Huyen Christie Sandra Lora Donna Jeff Min Jun X Gibbs (Principal Investigator) Dinh Kovar Lee Lewi, Richard A. Huyen Christie Sandra Lora Donna Jeff Min Gibbs (Principal Investigator) Dinh Kovar Lee Lewi, Richard A. Gibbs (Principal Investigator), H. Dinh, C. Kovar, Sandra Lee, Lora Lewis, D. Muzny, Jeff Reid, Min Wang, Jun Xiaodong Xiaosen Min Hui Xin Guoqing Jingxiang Yin Wang (Principal Investigator) Fang Guo Jian Jiang , Jun Wang (Principal Investigator), X. Fang, Xiaosen Guo, Min Jian, Hui Jiang, Xin Jin, Guoqing Li, Jingxiang Li, Yingrui Li, Zhuo Li, Xinyu Liu, Yao Lu, Xuedi Ma, Zheng Su, S. Tai, M. Tang, Bo Wang, Guangbiao Wang, Honglong Wu, Renhua Wu, Ye Yin, Wenwei Zhang, Jiao Zhao, Meiru Zhao, Xiaole Zheng, Yan Zhou, Eric S. David M. Stacey B. Namrata Lander (Principal Investigator) Altshuler Gabriel , Eric S. Lander (Principal Investigator), D. Altshuler, Stacey B. Gabriel (Co-Chair), N. Gupta, Paul Laura Rasko Richard E. Xiangqun Flicek (Principal Investigator) Clarke Leinonen Sm, Paul Flicek (Principal Investigator), L. Clarke, R. Leinonen, Richard E. Smith, Xiangqun Zheng-Bradley, David R. Russell Sean Terena Zoya Bentley (Principal Investigator) Grocock Humphray , David R. Bentley (Principal Investigator), R. Grocock, S. Humphray, Terena James, Z. Kingsbury, Hans Ralf Marcus W. Vyacheslav S. Tatiana A. Matthias F Lehrach (Principal Investigator) Sudbrak (Project , Hans Lehrach (Principal Investigator), Ralf Sudbrak (Project Leader), Marcus W. Albrecht, V. Amstislavskiy, T. Borodina, M. Lienhard, F. Mertes, M. Sultan, B. Timmermann, M. Yaspo, Stephen T. Sherry (Principal Investigator), Gil A. McVean (Principal Investigator), Elaine R. Richard K. Lucinda Robert George M. Mardis (Co-Principal Investigator) (Co-Chair) Wils, Elaine R. Mardis (Co-Principal Investigator) (Co-Chair), Richard K. Wilson (Co-Principal Investigator), L. Fulton, R. Fulton, G. Weinstock, Richard M. Senduran John Petr Thomas M. Anja Shane James M Durbin (Principal Investigator) Balasubramaniam Bu, Richard M. Durbin (Principal Investigator), Senduran Balasubramaniam, J. Burton, P. Danecek, Thomas M. Keane, A. Kolb-Kokocinski, Shane A. McCarthy, J. Stalker, Michael A. Quail, Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Adam  Schmidt (Principal Investigator) Davies Gollub Web, Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Schmidt (Principal Investigator) Davies Gollub Web, Jeanette P. Schmidt (Principal Investigator), C. J. Davies, J. Gollub, Teresa A. Webster, Brant Wong, Yiping Zhan, Adam Auton (Principal Investigator), Richard A. Fuli Matthew Danny Uday S. James Donna Uma Jeff Gibbs (Principal Investigator) Yu (Project Leader), Fuli Yu (Project Leader), M. Bainbridge, Danny Challis, Uday S. Evani, James Lu, U. Nagaswamy, A. Sabo, Yi Wang, Jin Yu, Jun Lachlan J. M. Lin Xiaosen Xin Guoqing Qibin Yingru Wang (Principal Investigator) Coin Fang Guo Jin Li, L. Coin, L. Fang, Qibin Li, Zhenyu Li, Haoxiang Lin, Binghang Liu, Ruibang Luo, Nan Qin, Haojing Shao, Bingqiang Wang, Yinlong Xie, C. Ye, Chang Yu, Fan Zhang, Hancheng Zheng, Hongmei Zhu, Gabor T. Erik P. Deniz Wan-Ping Wen Alistair N. Jiantao  Marth (Principal Investigator) Garrison Kural Lee , Gabor T. Marth (Principal Investigator), Erik P Garrison, Deniz Kural, Wan-Ping Lee, Wen Fung Leong, A. Ward, Jiantao Wu, Mengyao Zhang, Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) Griffin Hsieh Mills S, Charles Lee (Principal Investigator), Lauren Griffin, Chih-heng Hsieh, R. Mills, Xinghua Shi, Marcin von Grotthuss, Chengsheng Zhang, Mark J. Mark A. David M. Eric Gaurav Mauricio O. Guille Daly (Principal Investigator) DePristo (Project Le, Mark J. Daly (Principal Investigator), Mark A. DePristo (Project Leader), E. Banks, G. Bhatia, Mauricio O. Carneiro, G. Del Angel, G. Genovese, R. Handsaker, C. Hartl, S. Mccarroll, J. Nemesh, R. Poplin, S. Schaffner, Khalid Shakir, Seungtai C. Jayon Vladimir Yoon (Principal Investigator) Lihm Makarov, Seungtai C. Yoon (Principal Investigator), J. Lihm, Vladimir Makarov, Hanjun Wook Ki Jin (Principal Investigator) Kim Cheol Kim, Hanjun Jin (Principal Investigator), Wook Kim, Ki Cheol Kim, Jan O. Tobias Korbel (Principal Investigator) Rausch, Jan O. Korbel (Principal Investigator), T. Rausch, Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin, Kathryn Beal, Fiona Cunningham, Javier Herrero, W. McLaren, G. Ritchie, Andrew G. Srikanth Alon Juan L. Clark (Principal Investigator) Gottipati Keinan Ro, Andrew G. Clark (Principal Investigator), S. Gottipati, A. Keinan, J. Rodriguez-Flores, Pardis C. Sharon R. Shervin Ridhi Sabeti (Principal Investigator) Grossman Tabrizi T, Pardis C. Sabeti (Principal Investigator), Sharon R. Grossman, S. Tabrizi, Ridhi Tariyal, David N. Edward V. Peter D. Cooper (Principal Investigator) Ball Stenson, David N. Cooper (Principal Investigator), E. Ball, P. Stenson, David R. Bret Markus R. Tony Michael Sean Scott Lisa Joh Bentley (Principal Investigator) Barnes Bauer Keir, B. Barnes, Markus Bauer, R. Keira Cheetham, Tony Cox, M. Eberle, Scott D. Kahn, Lisa J. Murray, J. Peden, Richard Shaw, Kai Ye (Principal Investigator), Mark A. Miriam K. Jerilyn A. Batzer (Principal Investigator) Konkel Walker, Mark A. Batzer (Principal Investigator), Miriam K. Konkel, Jerilyn A. Walker, Daniel G. Monkol MacArthur (Principal Investigator) Lek, Daniel G. MacArthur (Principal Investigator), M. Lek, Vyacheslav S. Ralf Sudbrak (Project Leader) Amstislavskiy Herwig, Sudbrak (Project Leader), Ralf Herwig, Mark D. Shriver (Principal Investigator), Carlos D. Jake K. Francisco M. Simon Eimear E. Jeffrey M. Bustamante (Principal Investigator) Byrnes De La V, Carlos D. Bustamante (Principal Investigator), J. Byrnes, F. M. De La Vega, S. Gravel, E. Kenny, J. Kidd, P. Lacroute, Brian K. Maples, A. Moreno-Estrada, Fouad Zakharia, Eran Yael Halperin (Principal Investigator) Baran, Eran Halperin (Principal Investigator), Yael Baran, David W. Alexis Nils Tyler Ahmet A. Shripad A. Kevin Craig (Principal Investigator) Christoforides Home, David W. Craig (Principal Investigator), Alexis Christoforides, Nils Homer, Tyler Izatt, Ahmet A. Kurdoglu, Shripad A. Sinari, Kevin Squire, Stephen T. Chunlin Sherry (Principal Investigator) Xiao, C. Xiao, Jonathan Vineet Kenny Sebat (Principal Investigator) Bafna Ye, Jonathan Sebat (Principal Investigator), V. Bafna, Kenny Q. Ye, Esteban G. Ryan D. Christopher R. Burchard (Principal Investigator) Hernandez (Princ, Esteban G. Burchard (Principal Investigator), Ryan D. Hernandez (Principal Investigator), C. Gignoux, David Sol J. W. Haussler (Principal Investigator) Katzman James Ke, David Haussler (Principal Investigator), Sol Katzman, W. James Kent, B. Howie, Andres Ruiz-Linares (Principal Investigator), Emmanouil T. Tuuli Dermitzakis (Principal Investigator) Lappalainen, Emmanouil T. Dermitzakis (Principal Investigator), T. Lappalainen, Scott E. Xinyue Ankit Luke J. Devine (Principal Investigator) Liu Maroo Tallon, Scott E. Devine (Principal Investigator), Xinyue Liu, A. Maroo, L. Tallon, Jeffrey A. Leslie P. Rosenfeld (Principal Investigator) Michelson, Jeffrey A. Rosenfeld (Principal Investigator), L. P. Michelson, Gonçalo R. Hyun Paul Andrea Abigail Tom Fabio Francesco Ch Abecasis (Principal Investigator) (Co-Chair) Min K, Gonçalo R. Abecasis (Principal Investigator) (Co-Chair), Hyun Min Kang (Project Leader), Paul Anderson, A. Angius, A. Bigham, T. Blackwell, F. Busonero, F. Cucca, C. Fuchsberger, Chris Jones, G. Jun, Yun Li, R. Lyons, A. Maschio, E. Porcu, F. Reinier, S. Sanna, David Schlessinger, C. Sidore, Adrian Tan, Mary Kate Trost, Philip Alan Awadalla (Principal Investigator) Hodgkinson, Philip Awadalla (Principal Investigator), A. Hodgkinson, Gerton Gil A. Jonathan L. Simon Claire Olivier Anjali Zam Lunter (Principal Investigator) McVean (Principal , Gerton Lunter (Principal Investigator), Gil A. McVean (Principal Investigator) (Co-Chair), Jonathan L. Marchini (Principal Investigator), Simon Myers (Principal Investigator), C. Churchhouse, O. Delaneau, Anjali Gupta-Hinch, Z. Iqbal, I. Mathieson, A. Rimmer, Dionysia K. Xifara, Taras K. Oleksyk (Principal Investigator), Yunxin Xiaoming Momiao Fu (Principal Investigator) Liu Xiong, Yunxin Fu (Principal Investigator), Xiaoming Liu, Momiao Xiong, Lynn David Jinchuan Jorde (Principal Investigator) Witherspoon Xing, Lynn Jorde (Principal Investigator), D. Witherspoon, Jinchuan Xing, Evan E. Brian L. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) Browning (Princip, Evan E. Eichler (Principal Investigator), Brian L. Browning (Principal Investigator), C. Alkan, Iman Hajirasouliha, F. Hormozdiari, Arthur Ko, P. Sudmant, Elaine R. Ken Asif Li David Daniel C. Michael D. John W.  Mardis (Co-Principal Investigator) Chen Chinwalla , Elaine R. Mardis (Co-Principal Investigator), Ken Chen, A. Chinwalla, L. Ding, D. Dooling, D. Koboldt, M. McLellan, J. Wallis, M. Wendl, Qunyuan Zhang, Richard M. Matthew E. Chris Cornelis A. Qasim Senduran Yua Durbin (Principal Investigator) Hurles (Principal , Matthew E. Hurles (Principal Investigator), Chris Tyler-Smith (Principal Investigator), C. A. Albers, Q. Ayub, Yuan Chen, A. Coffey, V. Colonna, N. Huang, L. Jostins, Heng Li, A. Scally, Klaudia Walter, Yali Xue, Yujun Zhang, Mark B. Alexej Suganthi Jieming Declan Yao Lukas Arif O Gerstein (Principal Investigator) Abyzov Balasubra, Mark B. Gerstein (Principal Investigator), A. Abyzov, S. Balasubramanian, Jieming Chen, Declan Clarke, Yao Fu, L. Habegger, A. Harmanci, Mike Jin, Ekta Khurana, Xinmeng Jasmine Mu, Cristina Sisu, Yingrui Ruibang Hongmei Charles Lauren Chih-Heng Ryan E. X Li Luo Zhu Lee (Principal Investigator) (Co-Chair), Yingrui Ruibang Hongmei Li Luo Zhu, Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) (Co-Chair) Griffin Hs, Charles Lee (Principal Investigator) (Co-Chair), Gabor T. Erik P. Deniz Wan-Ping Alistair N. Jiantao Meng Marth (Principal Investigator) Garrison Kural Lee , Steven A. David M. Eric Guillermo Giulio Robert E. Chris  McCarroll (Project Leader) Altshuler Banks del Ang, Steven A. McCarroll (Project Leader), Jeremiah D. Degenhardt, Paul Laura Richard E. Xiangqun Flicek (Principal Investigator) Clarke Smith Zheng, Jan O. Tobias Adrian M. Korbel (Principal Investigator) (Co-Chair) Rausch , Jan O. Korbel (Principal Investigator) (Co-Chair), A. Stütz, David R. Bret R. Michael Sean Scott Lisa Richard Bentley (Principal Investigator) Barnes Keira Chee, David W. Nils Craig (Principal Investigator) Homer, Deanna Chunlin Church Xiao, D. Church, Jonathan Vineet Jacob J. Kenny Sebat (Principal Investigator) Bafna Michaelson Ye, J. Michaelson, Gerton Gil A. Zamin Lunter (Principal Investigator) McVean (Principal , David Jinchuan Witherspoon Xing, Evan E. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) (Co-Chair) Alkan , Evan E. Eichler (Principal Investigator) (Co-Chair), Ken Asif Li Michael D. John W. Chen Chinwalla Ding McLellan Wallis, Matthew E. Ben Heng Sarah J. Zemin Aylwyn Klaudia Yujun Hurles (Principal Investigator) (Co-Chair) Blackbu, Matthew E. Hurles (Principal Investigator) (Co-Chair), B. Blackburne, S. Lindsay, Z. Ning, Mark B. Alexej Jieming Declan Ekta Xinmeng Cristina Gerstein (Principal Investigator) Abyzov Chen Clar, Mark B. Gerstein (Principal Investigator), Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj, Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj, Richard A. Gibbs (Principal Investigator) (Co-Chair), Xiaosen Yingrui Renhua Guo Li Wu, Gabor T. Erik P. Wen Alistair N. Marth (Principal Investigator) (Co-Chair) Garrison, Gabor T. Marth (Principal Investigator) (Co-Chair), Guillermo Mark A. Stacey B. Namrata Chris Ryan E. del Angel DePristo Gabriel Gupta Hartl Poplin, M. DePristo, Andrew G. Juan L. Clark (Principal Investigator) Rodriguez-Flores, Carlos D. Simon Bustamante (Principal Investigator) Gravel, David W. Alexis Nils Tyler Craig (Principal Investigator) Christoforides Home, Gonçalo R. Hyun Abecasis (Principal Investigator) Min Kang, Gonçalo R. Abecasis (Principal Investigator), Hyun Min Kang, Elaine R. David Lucinda Robert Daniel C. Mardis (Principal Investigator) Dooling Fulton Ful, Elaine R. Mardis (Principal Investigator), Richard M. Senduran Thomas M. Shane James Durbin (Principal Investigator) Balasubramaniam Ke, Mark B. Suganthi Lukas Gerstein (Principal Investigator) Balasubramanian , Erik P. Richard A. Matthew Donna Fuli Jin Guillermo Rob Garrison Gibbs (Principal Investigator) Bainbridge, Richard A. Matthew Donna Fuli Jin Gibbs (Principal Investigator) Bainbridge Muzny Yu, Fuli Yu, Guillermo Robert E. del Angel Handsaker, Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin, Carlos D. Francisco M. Bustamante (Principal Investigator) De La Vega, David W. Ahmet A. Craig (Principal Investigator) Kurdoglu, Chris Yuan Vincenza Adam Jennifer Yali Tyler-Smith (Principal Investigator) (Co-Chair) Ch, Chris Tyler-Smith (Principal Investigator) (Co-Chair), A. Frankish, J. Harrow, Mark B. Alexej Suganthi Jieming Declan Yao Arif O. Mike Gerstein (Principal Investigator) (Co-Chair) Abyzo, Mark B. Gerstein (Principal Investigator) (Co-Chair), Richard A. Gerald Walker Divya Christie Donna Jeff Jun Xia Gibbs (Principal Investigator) Fowler Hale Kalra K, Richard A. Gerald Walker Divya Christie Donna Jeff Gibbs (Principal Investigator) Fowler Hale Kalra K, G. Fowler, W. Hale, D. Kalra, Jun Xiaosen Guoqing Yingrui Xiaole Wang (Principal Investigator) Guo Li Li Zheng, Paul Laura Jonathan Gavin Eugene Rasko William M. Rajes Flicek (Principal Investigator) (Co-Chair) Clarke , Paul Flicek (Principal Investigator) (Co-Chair), Laura Clarke (Project Leader), Jonathan A. Barker, G. Kelman, Eugene Kulesha, Rajesh Radhakrishnan, Asier Roa, Dmitriy Smirnov, Ian Streeter, I. Toneva, Brendan Vaughan, David R. Tony Sean Scott Bentley (Principal Investigator) Cox Humphray Kahn, Ralf Marcus W. Matthias Sudbrak (Project Leader) Albrecht Lienhard, David W. Tyler Ahmet A. Craig (Principal Investigator) Izatt Kurdoglu, Stephen T. Victor Zinaida Dimitriy Nathan Chao Deanna Robe Sherry (Principal Investigator) (Co-Chair) Ananiev, Stephen T. Sherry (Principal Investigator) (Co-Chair), V. Ananiev, Zinaida Belaia, Dimitriy Beloslyudtsev, Nathan Bouk, Chao Chen, Robert Cohen, Charles Cook, John Garner, T. Hefferon, M. Kimelman, Chunlei Liu, John Lopez, Peter Meric, Chris O’Sullivan, Yu. G. Ostapchuk, Lon Phan, Sergiy Ponomarov, Valerie A. Schneider, E. Shekhtman, Karl Sirotkin, D. Slotta, Hua Zhang, Can Arthur Alkan Ko, Aravinda Bartha M. Gonçalo R. Kathleen C. Christine Esteban Chakravarti (Co-Chair) Knoppers (Co-Chair) Abecasi, Aravinda Chakravarti (Co-Chair), Bartha M. Knoppers (Co-Chair), G. Abecasis, K. Barnes, C. Beiswanger, E. Burchard, C. Bustamante, Hongyu Cai, H. Cao, R. Durbin, N. Gharani, R. Gibbs, B. Henn, Danielle Jones, L. Jorde, J. Kaye, A. Kent\n",
            "Venue :  Nature\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Information-Theoretic Planning with Trajectory Optimization for Dense 3D Mapping\n",
            "Author/s :  B. Charrow, G. Kahn, S. Patil, Sikang Liu, Ken Goldberg, P. Abbeel, Nathan Michael, Vijay R. Kumar\n",
            "Venue :  Robotics: Science and Systems\n",
            "year :  2015\n",
            "Abstract :  We propose an information-theoretic planning approach that enables mobile robots to autonomously construct dense 3D maps in a computationally efficient manner. Inspired by prior work, we accomplish this task by formulating an information-theoretic objective function based on CauchySchwarz quadratic mutual information (CSQMI) that guides robots to obtain measurements in uncertain regions of the map. We then contribute a two stage approach for active mapping. First, we generate a candidate set of trajectories using a combination of global planning and generation of local motion primitives. From this set, we choose a trajectory that maximizes the information-theoretic objective. Second, we employ a gradientbased trajectory optimization technique to locally refine the chosen trajectory such that the CSQMI objective is maximized while satisfying the robot’s motion constraints. We evaluated our approach through a series of simulations and experiments on a ground robot and an aerial robot mapping unknown 3D environments. Real-world experiments suggest our approach reduces the time to explore an environment by 70% compared to a closest frontier exploration strategy and 57% compared to an information-based strategy that uses global planning, while simulations demonstrate the approach extends to aerial robots with higher-dimensional state.\n",
            "------------------------------------\n",
            "Title :  High-speed spelling with a noninvasive brain–computer interface\n",
            "Author/s :  Xiaogang Chen, Yijun Wang, M. Nakanishi, Xiaorong Gao, T. Jung, Shangkai Gao\n",
            "Venue :  Proceedings of the National Academy of Sciences\n",
            "year :  2015\n",
            "Abstract :  Significance Brain–computer interface (BCI) technology provides a new communication channel. However, current applications have been severely limited by low communication speed. This study reports a noninvasive brain speller that achieved a multifold increase in information transfer rate compared with other existing systems. Based on extremely precise coding of frequency and phase in single-trial steady-state visual evoked potentials, this study developed a new joint frequency-phase modulation method and a user-specific decoding algorithm to implement synchronous modulation and demodulation of electroencephalograms. The resulting speller obtained high spelling rates up to 60 characters (∼12 words) per minute. The proposed methodological framework of high-speed BCI can lead to numerous applications in both patients with motor disabilities and healthy people. The past 20 years have witnessed unprecedented progress in brain–computer interfaces (BCIs). However, low communication rates remain key obstacles to BCI-based communication in humans. This study presents an electroencephalogram-based BCI speller that can achieve information transfer rates (ITRs) up to 5.32 bits per second, the highest ITRs reported in BCI spellers using either noninvasive or invasive methods. Based on extremely high consistency of frequency and phase observed between visual flickering signals and the elicited single-trial steady-state visual evoked potentials, this study developed a synchronous modulation and demodulation paradigm to implement the speller. Specifically, this study proposed a new joint frequency-phase modulation method to tag 40 characters with 0.5-s-long flickering signals and developed a user-specific target identification algorithm using individual calibration data. The speller achieved high ITRs in online spelling tasks. This study demonstrates that BCIs can provide a truly naturalistic high-speed communication channel using noninvasively recorded brain activities.\n",
            "------------------------------------\n",
            "Title :  Situation Awareness Misconceptions and Misunderstandings\n",
            "Author/s :  M. Endsley\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Situation awareness (SA) has become a widely used construct within the human factors community, the focus of considerable research over the past 25 years. This research has been used to drive the development of advanced information displays, the design of automated systems, information fusion algorithms, and new training approaches for improving SA in individuals and teams. In recent years, a number of papers criticized the Endsley model of SA on various grounds. I review those criticisms here and show them to be based on misunderstandings of the model. I also review several new models of SA, including situated SA, distributed SA, and sensemaking, in light of this discussion and show how they compare to existing models of SA in individuals and teams.\n",
            "------------------------------------\n",
            "Title :  Spectral–Spatial Classification of Hyperspectral Data Using Loopy Belief Propagation and Active Learning\n",
            "Author/s :  Jun Li, J. Bioucas-Dias, A. Plaza\n",
            "Venue :  IEEE Transactions on Geoscience and Remote Sensing\n",
            "year :  2013\n",
            "Abstract :  In this paper, we propose a new framework for spectral-spatial classification of hyperspectral image data. The proposed approach serves as an engine in the context of which active learning algorithms can exploit both spatial and spectral information simultaneously. An important contribution of our paper is the fact that we exploit the marginal probability distribution which uses the whole information in the hyperspectral data. We learn such distributions from both the spectral and spatial information contained in the original hyperspectral data using loopy belief propagation. The adopted probabilistic model is a discriminative random field in which the association potential is a multinomial logistic regression classifier and the interaction potential is a Markov random field multilevel logistic prior. Our experimental results with hyperspectral data sets collected using the National Aeronautics and Space Administration's Airborne Visible Infrared Imaging Spectrometer and the Reflective Optics System Imaging Spectrometer system indicate that the proposed framework provides state-of-the-art performance when compared to other similar developments.\n",
            "------------------------------------\n",
            "Title :  Throughput Optimization for Massive MIMO Systems Powered by Wireless Energy Transfer\n",
            "Author/s :  Gang Yang, Chin Keong Ho, Rui Zhang, Y. Guan\n",
            "Venue :  IEEE Journal on Selected Areas in Communications\n",
            "year :  2014\n",
            "Abstract :  This paper studies a wireless-energy-transfer (WET) enabled massive multiple-input-multiple-output (MIMO) system (MM) consisting of a hybrid data-and-energy access point (H-AP) and multiple single-antenna users. In the WET-MM system, the H-AP is equipped with a large number M of antennas and functions like a conventional AP in receiving data from users, but additionally supplies wireless power to the users. We consider frame-based transmissions. Each frame is divided into three phases: the uplink channel estimation (CE) phase, the downlink WET phase, as well as the uplink wireless information transmission (WIT) phase. Firstly, users use a fraction of the previously harvested energy to send pilots, while the H-AP estimates the uplink channels and obtains the downlink channels by exploiting channel reciprocity. Next, the H-AP utilizes the channel estimates just obtained to transfer wireless energy to all users in the downlink via energy beamforming. Finally, the users use a portion of the harvested energy to send data to the H-AP simultaneously in the uplink (reserving some harvested energy for sending pilots in the next frame) . To optimize the throughput and ensure rate fairness, we consider the problem of maximizing the minimum rate among all users. In the large-M regime, we obtain the asymptotically optimal solutions and some interesting insights for the optimal design of WET-MM system.\n",
            "------------------------------------\n",
            "Title :  Character-Aware Neural Language Models\n",
            "Author/s :  Yoon Kim, Yacine Jernite, D. Sontag, Alexander M. Rush\n",
            "Venue :  AAAI Conference on Artificial Intelligence\n",
            "year :  2015\n",
            "Abstract :  \n",
            " \n",
            " We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title :  Disclosure Intention of Location-Related Information in Location-Based Social Network Services\n",
            "Author/s :  Ling Zhao, Yaobin Lu, Sumeet Gupta\n",
            "Venue :  International Journal of Electronic Commerce\n",
            "year :  2012\n",
            "Abstract :  Although location-based social network (LBSN) services have developed rapidly in recent years, the reasons why people disclose location-related information under this environment have not been adequately investigated. This study builds a privacy calculus model to investigate the factors that influence LBSN users' intention to disclose location-related information in China. In addition, this study applies justice theory to investigate the role of privacy intervention approaches used by LBSN Web sites in enhancing users' perception of justice, including incentives provision, interaction promotion, privacy control, and privacy policy. Model testing using structural equation modeling reveals that perceived cost (users' privacy concerns) and perceived benefits (personalization and connectedness) influence intention to disclose location-related information. Meanwhile, providing incentives and promoting interaction enhance, respectively, personalization and connectedness. Privacy control and privacy policies both help in reducing privacy concerns. We also find that individuals' awareness of Internet privacy legislation negatively influences privacy concerns, whereas previous privacy invasions do not. Finally, we find that personal innovativeness significantly influences intention to disclose location-related information. This study not only extends the privacy research on social networking sites under mobile environments but also provides practical implications for service providers and policy makers to develop better LBSNs.\n",
            "------------------------------------\n",
            "Title :  Model Cards for Model Reporting\n",
            "Author/s :  Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, B. Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, Timnit Gebru\n",
            "Venue :  FAT\n",
            "year :  2018\n",
            "Abstract :  Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.\n",
            "------------------------------------\n",
            "Title :  Brain rhythms and neural syntax: implications for efficient coding of cognitive content and neuropsychiatric disease.\n",
            "Author/s :  G. Buzsáki, Brendon O. Watson\n",
            "Venue :  Dialogues in Clinical Neuroscience\n",
            "year :  2012\n",
            "Abstract :  The perpetual activity of the cerebral cortex is largely supported by the variety of oscillations the brain generates, spanning a number of frequencies and anatomical locations, as well as behavioral correlates. First, we review findings from animal studies showing that most forms of brain rhythms are inhibition-based, producing rhythmic volleys of inhibitory inputs to principal cell populations, thereby providing alternating temporal windows of relatively reduced and enhanced excitability in neuronal networks. These inhibition-based mechanisms offer natural temporal frames to group or “chunk” neuronal activity into cell assemblies and sequences of assemblies, with more complex multi-oscillation interactions creating syntactical rules for the effective exchange of information among cortical networks. We then review recent studies in human psychiatric patients demonstrating a variety alterations in neural oscillations across all major psychiatric diseases, and suggest possible future research directions and treatment approaches based on the fundamental properties of brain rhythms.\n",
            "------------------------------------\n",
            "Title :  A Survey of the State-of-the-Art Localization Techniques and Their Potentials for Autonomous Vehicle Applications\n",
            "Author/s :  Sampo Kuutti, Saber Fallah, K. Katsaros, M. Dianati, F. Mccullough, A. Mouzakitis\n",
            "Venue :  IEEE Internet of Things Journal\n",
            "year :  2018\n",
            "Abstract :  For an autonomous vehicle to operate safely and effectively, an accurate and robust localization system is essential. While there are a variety of vehicle localization techniques in literature, there is a lack of effort in comparing these techniques and identifying their potentials and limitations for autonomous vehicle applications. Hence, this paper evaluates the state-of-the-art vehicle localization techniques and investigates their applicability on autonomous vehicles. The analysis starts with discussing the techniques which merely use the information obtained from on-board vehicle sensors. It is shown that although some techniques can achieve the accuracy required for autonomous driving but suffer from the high cost of the sensors and also sensor performance limitations in different driving scenarios (e.g., cornering and intersections) and different environmental conditions (e.g., darkness and snow). This paper continues the analysis with considering the techniques which benefit from off-board information obtained from V2X communication channels, in addition to vehicle sensory information. The analysis shows that augmenting off-board information to sensory information has potential to design low-cost localization systems with high accuracy and robustness, however, their performance depends on penetration rate of nearby connected vehicles or infrastructure and the quality of network service.\n",
            "------------------------------------\n",
            "Title :  Information Disclosure in Financial Markets\n",
            "Author/s :  Itay Goldstein, Liyan Yang\n",
            "Venue :  \n",
            "year :  2017\n",
            "Abstract :  Information disclosure is an essential component of regulation in financial markets. In this article, we provide a cohesive analytical framework to review certain key channels through which disclosure in financial markets affects market quality, information production, efficiency of real investment decisions, and traders’ welfare. We use our framework to address four main aspects. First, we demonstrate the conventional wisdom that disclosure improves market quality in an economy with exogenous information. Second, we illustrate that disclosure can crowd out the production of private information and that its overall market-quality implications are subtle and depend on the specification of information-acquisition technology. Third, we review how disclosure affects the efficiency of real investment decisions when financial markets are not just a side show, as real decision makers can learn information from them to guide their decisions. Last, we discuss how disclosure in financial markets affects investors’ ...\n",
            "------------------------------------\n",
            "Title :  Trust and Involvement in Tourism Social Media and Web-Based Travel Information Sources\n",
            "Author/s :  Ana María Munar, J. K. S. Jacobsen\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  While utilisation of electronic social media is increasingly relevant as tourism practices, there is still a deficiency of empirical research on tourists' creation and use of various types of online content. This study maps and explores Scandinavian tourists' perceptions of Web 1.0 and Web 2.0 information sources and scrutinises influence of electronic social media on holidaymakers' information sharing, based on a summer season survey in the mature and well-known destination of Mallorca, Spain. Empirical evidence is presented on perceived trustworthiness of social media platforms and other Internet-based information. The study also examines tourists' involvement in developing and sharing of virtual content. It critically analyses technological mediation through electronic word-of-mouth and involvement factors related to virtual dissemination of travel narratives. Moreover, the paper discusses information intensity, hedonic aspects and utilitarian values of tourist information in relation to interaction aspects of social media, in a context of holiday choices and online booking.\n",
            "------------------------------------\n",
            "Title :  Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!\n",
            "Author/s :  Laura Chiticariu, Yunyao Li, Frederick Reiss\n",
            "Venue :  Conference on Empirical Methods in Natural Language Processing\n",
            "year :  2013\n",
            "Abstract :  The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape of IE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.\n",
            "------------------------------------\n",
            "Title :  Neural Collaborative Filtering\n",
            "Author/s :  Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua\n",
            "Venue :  The Web Conference\n",
            "year :  2017\n",
            "Abstract :  In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.\n",
            "------------------------------------\n",
            "Title :  Access to Management and the Informativeness of Analyst Research\n",
            "Author/s :  T. C. Green, Russell Jame, S. Markov, Musa Subasi\n",
            "Venue :  \n",
            "year :  2014\n",
            "Abstract :  We examine whether access to management at broker-hosted investor conferences leads to more informative research by analysts. We find analyst recommendation changes have larger immediate price impacts when the analyst׳s firm has a conference-hosting relation with the company. The effect increases with hosting frequency and is strongest in the days following the conference. Conference-hosting brokers also issue more informative, accurate, and timely earnings forecasts than non-hosts. Our findings suggest that access to management remains an important source of analysts׳ informational advantage in the post-Regulation Fair Disclosure world.\n",
            "------------------------------------\n",
            "Title :  A Glorious and Not-So-Short History of the Information Systems Field\n",
            "Author/s :  R. Hirschheim, H. Klein\n",
            "Venue :  Journal of the AIS\n",
            "year :  2012\n",
            "Abstract :  Research Article\n",
            "------------------------------------\n",
            "Title :  Practical extraction of disaster-relevant information from social media\n",
            "Author/s :  Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, P. Meier\n",
            "Venue :  The Web Conference\n",
            "year :  2013\n",
            "Abstract :  During times of disasters online users generate a significant amount of data, some of which are extremely valuable for relief efforts. In this paper, we study the nature of social-media content generated during two different natural disasters. We also train a model based on conditional random fields to extract valuable information from such content. We evaluate our techniques over our two datasets through a set of carefully designed experiments. We also test our methods over a non-disaster dataset to show that our extraction model is useful for extracting information from socially-generated content in general.\n",
            "------------------------------------\n",
            "Title :  Online Social Networks: Threats and Solutions\n",
            "Author/s :  Michael Fire, Roy Goldschmidt, Y. Elovici\n",
            "Venue :  IEEE Communications Surveys and Tutorials\n",
            "year :  2013\n",
            "Abstract :  Many online social network (OSN) users are unaware of the numerous security risks that exist in these networks, including privacy violations, identity theft, and sexual harassment, just to name a few. According to recent studies, OSN users readily expose personal and private details about themselves, such as relationship status, date of birth, school name, email address, phone number, and even home address. This information, if put into the wrong hands, can be used to harm users both in the virtual world and in the real world. These risks become even more severe when the users are children. In this paper, we present a thorough review of the different security and privacy risks, which threaten the well-being of OSN users in general, and children in particular. In addition, we present an overview of existing solutions that can provide better protection, security, and privacy for OSN users. We also offer simple-to-implement recommendations for OSN users, which can improve their security and privacy when using these platforms. Furthermore, we suggest future research directions.\n",
            "------------------------------------\n",
            "Title :  Why Information Grows: The Evolution of Order, from Atoms to Economies\n",
            "Author/s :  César A. Hidalgo\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Prologue: The Eternal War Introduction: From Atoms to People to Economics PART I Bits in Atoms Chapter 1. The Secret to Time Travel Chapter 2. The Body of the Meaningless Chapter 3. The Eternal Anomaly PART II Crystallized Imagination Chapter 4. Out of Our Heads! Chapter 5. Amplifiers PART III The Quantization of Knowhow Chapter 6. This Time, It's Personal Chapter 7. Links Are Not Free Chapter 8. In Links We Trust PART IV The Complexity of the Economy Chapter 9. The Evolution of Economic Complexity Chapter 10. The Sixth Substance Chapter 11. The Marriage of Knowledge, Knowhow, and Information PART V Epilogue Chapter 12. The Evolution of Physical Order, from Atoms to Economics Acknowledgments: Bleeding Words Notes Index\n",
            "------------------------------------\n",
            "Title :  Geo-indistinguishability: differential privacy for location-based systems\n",
            "Author/s :  M. Andrés, N. E. Bordenabe, K. Chatzikokolakis, C. Palamidessi\n",
            "Venue :  Conference on Computer and Communications Security\n",
            "year :  2012\n",
            "Abstract :  The growing popularity of location-based systems, allowing unknown/untrusted servers to easily collect huge amounts of information regarding users' location, has recently started raising serious privacy concerns. In this paper we introduce geoind, a formal notion of privacy for location-based systems that protects the user's exact location, while allowing approximate information -- typically needed to obtain a certain desired service -- to be released. This privacy definition formalizes the intuitive notion of protecting the user's location within a radius $r$ with a level of privacy that depends on r, and corresponds to a generalized version of the well-known concept of differential privacy. Furthermore, we present a mechanism for achieving geoind by adding controlled random noise to the user's location. We describe how to use our mechanism to enhance LBS applications with geo-indistinguishability guarantees without compromising the quality of the application results. Finally, we compare state-of-the-art mechanisms from the literature with ours. It turns out that, among all mechanisms independent of the prior, our mechanism offers the best privacy guarantees.\n",
            "------------------------------------\n",
            "Title :  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n",
            "Author/s :  Kai Sheng Tai, R. Socher, Christopher D. Manning\n",
            "Venue :  Annual Meeting of the Association for Computational Linguistics\n",
            "year :  2015\n",
            "Abstract :  Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).\n",
            "------------------------------------\n",
            "Title :  The impact of website quality on customer satisfaction and purchase intention: perceived playfulness and perceived flow as mediators\n",
            "Author/s :  Chia-Lin Hsu, Kuo-Chien Chang, Mu-Chen Chen\n",
            "Venue :  Inf. Syst. E Bus. Manag.\n",
            "year :  2012\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Robust chemical preservation of digital information on DNA in silica with error-correcting codes.\n",
            "Author/s :  R. Grass, Reinhard Heckel, M. Puddu, D. Paunescu, W. Stark\n",
            "Venue :  Angewandte Chemie\n",
            "year :  2015\n",
            "Abstract :  Information, such as text printed on paper or images projected onto microfilm, can survive for over 500 years. However, the storage of digital information for time frames exceeding 50 years is challenging. Here we show that digital information can be stored on DNA and recovered without errors for considerably longer time frames. To allow for the perfect recovery of the information, we encapsulate the DNA in an inorganic matrix, and employ error-correcting codes to correct storage-related errors. Specifically, we translated 83 kB of information to 4991 DNA segments, each 158 nucleotides long, which were encapsulated in silica. Accelerated aging experiments were performed to measure DNA decay kinetics, which show that data can be archived on DNA for millennia under a wide range of conditions. The original information could be recovered error free, even after treating the DNA in silica at 70 °C for one week. This is thermally equivalent to storing information on DNA in central Europe for 2000 years.\n",
            "------------------------------------\n",
            "Title :  BIM in facilities management applications: a case study of a large university complex\n",
            "Author/s :  M. Kassem, G. Kelly, N. Dawood, M. Serginson, S. Lockley\n",
            "Venue :  \n",
            "year :  2015\n",
            "Abstract :  Purpose – Building information modelling (BIM) in facilities management (FM) applications is an emerging area of research based on the theoretical proposition that BIM information, generated and captured during the lifecycle of a facility, can improve its management. Using this proposition as a starting point, the purpose of this paper is to investigate the value of BIM and the challenges affecting its adoption in FM applications. Design/methodology/approach – Two inter-related research methods are utilised. The literature is utilised to identify the application areas, value and challenges of BIM in FM. Due to the lack of case studies identified in the literature review, and to provide empirical evidence of the value and challenges of BIM in FM, a case study of Northumbria University’s city campus, is used to empirically explore the value and challenges of BIM in FM. Findings – The results demonstrated that BIM value in FM stems from improvement to current manual processes of information handover; improve...\n",
            "------------------------------------\n",
            "Title :  Leveraging Digital Technologies: How Information Quality Leads to Localized Capabilities and Customer Service Performance\n",
            "Author/s :  P. Setia, V. Venkatesh, Supreet Joglekar\n",
            "Venue :  MIS Q.\n",
            "year :  2013\n",
            "Abstract :  With the growing recognition of the customer's role in service creation and delivery, there is an increased impetus on building customer-centric organizations. Digital technologies play a key role in such organizations. Prior research studying digital business strategies has largely focused on building production-side competencies and there has been little focus on customer-side digital business strategies to leverage these technologies. We propose a theory to understand the effectiveness of a customer-side digital business strategy focused on localized dynamics--here, a firm's customer service units (CSUs). Specifically, we use a capabilities perspective to propose digital design as an antecedent to two customer service capabilities--namely, customer orientation capability and customer response capability--across a firm's CSUs. These two capabilities will help a firm to locally sense and respond to customer needs, respectively. Information quality from the digital design of the CSU is proposed as the antecedent to the two capabilities. Proposed capability-building dynamics are tested using data collected from multiple respondents across 170 branches of a large bank. Findings suggest that the impacts of information quality in capability-building are contingent on the local process characteristics. We offer implications for a firm's customer-side digital business strategy and present new areas for future examination of such strategies.\n",
            "------------------------------------\n",
            "Title :  Health information needs, sources, and barriers of primary care patients to achieve patient-centered care: A literature review\n",
            "Author/s :  M. Clarke, Joi L. Moore, L. Steege, R. Koopman, J. Belden, Shannon M. Canfield, S. Meadows, Susan G. Elliott, M. Kim\n",
            "Venue :  Health Informatics Journal\n",
            "year :  2016\n",
            "Abstract :  To synthesize findings from previous studies assessing information needs of primary care patients on the Internet and other information sources in a primary care setting. A systematic review of studies was conducted with a comprehensive search in multiple databases including OVID MEDLINE, CINAHL, and Scopus. The most common information needs among patients were information about an illness or medical condition and treatment methods, while the most common information sources were the Internet and patients’ physicians. Overall, patients tend to prefer the Internet for the ease of access to information, while they trust their physicians more for their clinical expertise and experience. Barriers to information access via the Internet include the following: socio-demographic variables such as age, ethnicity, income, education, and occupation; information search skills; and reliability of health information. Conclusion: Further research is warranted to assess how to create accurate and reliable health information sources for both Internet and non-Internet users.\n",
            "------------------------------------\n",
            "Title :  Wireless information and power transfer in multiuser OFDM systems\n",
            "Author/s :  Xun Zhou, Rui Zhang, Chin Keong Ho\n",
            "Venue :  Global Communications Conference\n",
            "year :  2013\n",
            "Abstract :  In this paper, we study the optimal design for simultaneous wireless information and power transfer (SWIPT) in downlink multiuser orthogonal frequency division multiplexing (OFDM) systems, where the users harvest energy and decode information using the same signals received from a fixed access point (AP). For information transmission, we consider two types of multiple access schemes, namely, time division multiple access (TDMA) and orthogonal frequency division multiple access (OFDMA). At the receiver side, due to the practical limitation that circuits for harvesting energy from radio signals are not yet able to decode the carried information directly, each user applies either time switching (TS) or power splitting (PS) to coordinate the energy harvesting (EH) and information decoding (ID) processes. For the TDMA-based information transmission, we employ TS at the receivers; for the OFDMA-based information transmission, we employ PS at the receivers. Under the above two scenarios, we address the problem of maximizing the weighted sum-rate over all users by varying the time/frequency power allocation and either TS or PS ratio, subject to a minimum harvested energy constraint on each user as well as a peak and/or total transmission power constraint. For the TS scheme, by an appropriate variable transformation the problem is reformulated as a convex problem, for which the optimal power allocation and TS ratio are obtained by the Lagrange duality method. For the PS scheme, we propose an iterative algorithm to optimize the power allocation, subcarrier allocation and the PS ratio for each user. Numerical results show that the peak power constraint imposed on each OFDM subcarrier as well as the number of users in the system play a key role in the rate-energy performance comparison by the two proposed schemes.\n",
            "------------------------------------\n",
            "Title :  Information geometry\n",
            "Author/s :  S. Amari\n",
            "Venue :  Japanese journal of mathematics\n",
            "year :  2021\n",
            "Abstract :  Information geometry has emerged from the study of the invariant structure in families of probability distributions. This invariance uniquely determines a second-order symmetric tensor g and third-order symmetric tensor T in a manifold of probability distributions. A pair of these tensors ( g, T ) defines a Riemannian metric and a pair of affine connections which together preserve the metric. Information geometry involves studying a Riemannian manifold having a pair of dual affine connections. Such a structure also arises from an asymmetric divergence function and affine differential geometry. A dually flat Riemannian manifold is particularly useful for various applications, because a generalized Pythagorean theorem and projection theorem hold. The Wasserstein distance gives another important geometry on probability distributions, which is non-invariant but responsible for the metric properties of a sample space. I attempt to construct information geometry of the entropy-regularized Wasserstein distance.\n",
            "------------------------------------\n",
            "Title :  Understanding Online Purchase Decision Making: The Effects of Unconscious Thought, Information Quality, and Information Quantity\n",
            "Author/s :  Jie Gao, Cheng Zhang, Ke Wang, Sulin Ba\n",
            "Venue :  Decision Support Systems\n",
            "year :  2012\n",
            "Abstract :  The prosperity of online shopping has led e-commerce vendors to provide increasingly rich information, particularly for experience products, to enhance consumers' shopping experience and satisfaction. However, there is little awareness that consumers may not be able to process all the information available because of human beings' limited information processing capacity. Online shoppers could be easily confused when facing rich information, particularly when the amount of information greatly exceeds their processing capacity. In contrast to previous research which has focused on the formatting of information or user interfaces to solve the information overload problem, this study explores a new solution based on the role of unconscious thought. Integrating information processing theory and the unconscious thought theory, the current study examines the different roles of information quantity, information quality and thought mode in consumers' decision satisfaction, in the presence of rich information. Our results show that unconscious thought moderates the relationship between information quality and consumer satisfaction towards their decision making when shopping experience products online, and is thus worthy of special attention in the design of e-commerce websites. The study contributes to both unconscious thought theory and information processing theory by exploring the interaction effect of the quantity and quality of information with thought mode in affecting the quality of purchasing decisions.\n",
            "------------------------------------\n",
            "Title :  The AIC model selection method applied to path analytic models compared using a d-separation test.\n",
            "Author/s :  B. Shipley\n",
            "Venue :  Ecology\n",
            "year :  2013\n",
            "Abstract :  Classical path analysis is a statistical technique used to test causal hypotheses involving multiple variables without latent variables, assuming linearity, multivariate normality, and a sufficient sample size. The d-separation (d-sep) test is a generalization of path analysis that relaxes these assumptions. Although model selection using Akaike's information criterion (AIC) is well established for classical path analysis, this model selection technique has not yet been developed for d-sep tests. In this paper, I explain how to use the AIC statistic for d-sep tests, give a worked example, and include instructions (supplemental material) to implement the analysis in the R computing language.\n",
            "------------------------------------\n",
            "Title :  DNA Fountain enables a robust and efficient storage architecture\n",
            "Author/s :  Yaniv Erlich, Dina Zielinski\n",
            "Venue :  Science\n",
            "year :  2016\n",
            "Abstract :  A reliable and efficient DNA storage architecture DNA has the potential to provide large-capacity information storage. However, current methods have only been able to use a fraction of the theoretical maximum. Erlich and Zielinski present a method, DNA Fountain, which approaches the theoretical maximum for information stored per nucleotide. They demonstrated efficient encoding of information—including a full computer operating system—into DNA that could be retrieved at scale after multiple rounds of polymerase chain reaction. Science, this issue p. 950 A resilient DNA storage strategy enables near-maximal information content per nucleotide. DNA is an attractive medium to store digital information. Here we report a storage strategy, called DNA Fountain, that is highly robust and approaches the information capacity per nucleotide. Using our approach, we stored a full computer operating system, movie, and other files with a total of 2.14 × 106 bytes in DNA oligonucleotides and perfectly retrieved the information from a sequencing coverage equivalent to a single tile of Illumina sequencing. We also tested a process that can allow 2.18 × 1015 retrievals using the original DNA sample and were able to perfectly decode the data. Finally, we explored the limit of our architecture in terms of bytes per molecule and obtained a perfect retrieval from a density of 215 petabytes per gram of DNA, orders of magnitude higher than previous reports.\n",
            "------------------------------------\n",
            "Title :  Learning from Peers' Stock Prices and Corporate Investment\n",
            "Author/s :  Thierry Foucault, Laurent Frésard\n",
            "Venue :  \n",
            "year :  2013\n",
            "Abstract :  Peers' valuation matters for firms' investment: a one standard deviation increase in peers' valuation is associated with a 5.9% increase in corporate investment. This association is stronger when a firm's stock price informativeness is lower or when its managers appear less informed. Also, the sensitivity of a firm's investment to its stock price is lower when its peers' stock price informativeness is higher or when demands for its products and its peers' products are more correlated. Furthermore, the sensitivity of firms' investment to their peers' valuation drops significantly after going public. These findings are uniquely predicted by a model in which managers learn information from their peers' valuation.\n",
            "------------------------------------\n",
            "Title :  How Much Position Information Do Convolutional Neural Networks Encode?\n",
            "Author/s :  Md. Amirul Islam, Sen Jia, Neil D. B. Bruce\n",
            "Venue :  International Conference on Learning Representations\n",
            "year :  2020\n",
            "Abstract :  In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.\n",
            "------------------------------------\n",
            "Title :  Human Information Interaction: An Ecological Approach to Information Behavior\n",
            "Author/s :  R. Fidel\n",
            "Venue :  \n",
            "year :  2012\n",
            "Abstract :  Human information interaction (HII) is an emerging area of study that investigates how people interact with information; its subfield human information behavior (HIB) is a flourishing, active discipline. Yet despite their obvious relevance to the design of information systems, these research areas have had almost no impact on systems design. One issue may be the contextual complexity of human interaction with information; another may be the difficulty in translating real-life and unstructured HII complexity into formal, linear structures necessary for systems design. In this book, Raya Fidel proposes a research approach that bridges the study of human information interaction and the design of information systems: cognitive work analysis (CWA). Developed by Jens Rasmussen and his colleagues, CWA embraces complexity and provides a conceptual framework and analytical tools that can harness it to create design requirements. CWA offers an ecological approach to design, analyzing the forces in the environment that shape human interaction with information. Fidel reviews research in HIB, focusing on its contribution to systems design, and then presents the CWA framework. She shows that CWA, with its ecological approach, can be used to overcome design challenges and lead to the development of effective systems. Researchers and designers who use CWA can increase the diversity of their analytical tools, providing them with an alternative approach when they plan research and design projects. The CWA framework enables a collaboration between design and HII that can create information systems tailored to fit human lives.\n",
            "------------------------------------\n",
            "Title :  The Impact of Social Media on Panic During the COVID-19 Pandemic in Iraqi Kurdistan: Online Questionnaire Study\n",
            "Author/s :  A. Ahmad, H. Murad\n",
            "Venue :  Journal of Medical Internet Research\n",
            "year :  2020\n",
            "Abstract :  Background In the first few months of 2020, information and news reports about the coronavirus disease (COVID-19) were rapidly published and shared on social media and social networking sites. While the field of infodemiology has studied information patterns on the Web and in social media for at least 18 years, the COVID-19 pandemic has been referred to as the first social media infodemic. However, there is limited evidence about whether and how the social media infodemic has spread panic and affected the mental health of social media users. Objective The aim of this study is to determine how social media affects self-reported mental health and the spread of panic about COVID-19 in the Kurdistan Region of Iraq. Methods To carry out this study, an online questionnaire was prepared and conducted in Iraqi Kurdistan, and a total of 516 social media users were sampled. This study deployed a content analysis method for data analysis. Correspondingly, data were analyzed using SPSS software. Results Participants reported that social media has a significant impact on spreading fear and panic related to the COVID-19 outbreak in Iraqi Kurdistan, with a potential negative influence on people’s mental health and psychological well-being. Facebook was the most used social media network for spreading panic about the COVID-19 outbreak in Iraq. We found a significant positive statistical correlation between self-reported social media use and the spread of panic related to COVID-19 (R=.8701). Our results showed that the majority of youths aged 18-35 years are facing psychological anxiety. Conclusions During lockdown, people are using social media platforms to gain information about COVID-19. The nature of the impact of social media panic among people varies depending on an individual's gender, age, and level of education. Social media has played a key role in spreading anxiety about the COVID-19 outbreak in Iraqi Kurdistan.\n",
            "------------------------------------\n",
            "Title :  Virtual memory palaces: immersion aids recall\n",
            "Author/s :  Eric Krokos, C. Plaisant, A. Varshney\n",
            "Venue :  Virtual Reality\n",
            "year :  2018\n",
            "Abstract :  None\n",
            "------------------------------------\n",
            "Title :  Coronavirus-Related Health Literacy: A Cross-Sectional Study in Adults during the COVID-19 Infodemic in Germany\n",
            "Author/s :  O. Okan, T. Bollweg, E. Berens, K. Hurrelmann, U. Bauer, D. Schaeffer\n",
            "Venue :  International Journal of Environmental Research and Public Health\n",
            "year :  2020\n",
            "Abstract :  There is an “infodemic” associated with the COVID-19 pandemic—an overabundance of valid and invalid information. Health literacy is the ability to access, understand, appraise, and apply health information, making it crucial for navigating coronavirus and COVID-19 information environments. A cross-sectional representative study of participants ≥ 16 years in Germany was conducted using an online survey. A coronavirus-related health literacy measure was developed (HLS-COVID-Q22). Internal consistency was very high (α = 0.940; ρ = 0.891) and construct validity suggests a sufficient model fit, making HLS-COVID-Q22 a feasible tool for assessing coronavirus-related health literacy in population surveys. While 49.9% of our sample had sufficient levels of coronavirus-related health literacy, 50.1% had “problematic” (15.2%) or “inadequate” (34.9%) levels. Although the overall level of health literacy is high, a vast number of participants report difficulties dealing with coronavirus and COVID-19 information. The participants felt well informed about coronavirus, but 47.8% reported having difficulties judging whether they could trust media information on COVID-19. Confusion about coronavirus information was significantly higher among those who had lower health literacy. This calls for targeted public information campaigns and promotion of population-based health literacy for better navigation of information environments during the infodemic, identification of disinformation, and decision-making based on reliable and trustworthy information.\n",
            "------------------------------------\n",
            "Title :  Eavesdropping on heterospecific alarm calls: from mechanisms to consequences\n",
            "Author/s :  R. Magrath, T. Haff, Pamela M. Fallow, A. Radford\n",
            "Venue :  Biological Reviews of The Cambridge Philosophical Society\n",
            "year :  2015\n",
            "Abstract :  Animals often gather information from other species by eavesdropping on signals intended for others. We review the extent, benefits, mechanisms, and ecological and evolutionary consequences of eavesdropping on other species' alarm calls. Eavesdropping has been shown experimentally in about 70 vertebrate species, and can entail closely or distantly related species. The benefits of eavesdropping include prompting immediate anti‐predator responses, indirect enhancement of foraging or changed habitat use, and learning about predators. Eavesdropping on heterospecifics can provide more eyes looking for danger, complementary information to that from conspecifics, and potentially information at reduced cost. The response to heterospecific calls can be unlearned or learned. Unlearned responses occur when heterospecific calls have acoustic features similar to that used to recognize conspecific calls, or acoustic properties such as harsh sounds that prompt attention and may allow recognition or facilitate learning. Learning to recognize heterospecific alarm calls is probably essential to allow recognition of the diversity of alarm calls, but the evidence is largely indirect. The value of eavesdropping on different species is affected by problems of signal interception and the relevance of heterospecific alarm calls to the listener. These constraints on eavesdropping will affect how information flows among species and thus affect community function. Some species are ‘keystone’ information producers, while others largely seek information, and these differences probably affect the formation and function of mixed‐species groups. Eavesdroppers might also integrate alarm calls from multiple species to extract relevant and reliable information. Eavesdropping appears to set the stage for the evolution of interspecific deception and communication, and potentially affects communication within species. Overall, we now know that eavesdropping on heterospecific alarm calls is an important source of information for many species across the globe, and there are ample opportunities for research on mechanisms, fitness consequences and implications for community function and signalling evolution.\n",
            "------------------------------------\n",
            "Title :  Parents' and informal caregivers' views and experiences of communication about routine childhood vaccination: a synthesis of qualitative evidence\n",
            "Author/s :  Heather Ames, C. Glenton, S. Lewin\n",
            "Venue :  Cochrane Database of Systematic Reviews\n",
            "year :  2017\n",
            "Abstract :  Abstract Background Childhood vaccination is an effective way to prevent serious childhood illnesses, but many children do not receive all the recommended vaccines. There are various reasons for this; some parents lack access because of poor quality health services, long distances or lack of money. Other parents may not trust vaccines or the healthcare workers who provide them, or they may not see the need for vaccination due to a lack of information or misinformation about how vaccinations work and the diseases they can prevent. Communication with parents about childhood vaccinations is one way of addressing these issues. Communication can take place at healthcare facilities, at home or in the community. Communication can be two‐way, for example face‐to‐face discussions between parents and healthcare providers, or one‐way, for instance via text messages, posters or radio programmes. Some types of communication enable parents to actively discuss vaccines and their benefits and harms, as well as diseases they can prevent. Other communication types simply give information about vaccination issues or when and where vaccines are available. People involved in vaccine programmes need to understand how parents experience different types of communication about vaccination and how this influences their decision to vaccinate. Objectives The specific objectives of the review were to identify, appraise and synthesise qualitative studies exploring: parents' and informal caregivers' views and experiences regarding communication about childhood vaccinations and the manner in which it is communicated; and the influence that vaccination communication has on parents' and informal caregivers' decisions regarding childhood vaccination. Search methods We searched MEDLINE (OvidSP), MEDLINE In‐process and Other Non‐Index Citations (Ovid SP), Embase (Ovid), CINAHL (EbscoHOST), and Anthropology Plus (EbscoHost) databases for eligible studies from inception to 30 August 2016. We developed search strategies for each database, using guidelines developed by the Cochrane Qualitative Research Methods Group for searching for qualitative evidence as well as modified versions of the search developed for three related reviews of effectiveness. There were no date or geographic restrictions for the search. Selection criteria We included studies that utilised qualitative methods for data collection and analysis; focused on the views and experiences of parents and informal caregivers regarding information about vaccination for children aged up to six years; and were from any setting globally where information about childhood vaccinations was communicated or distributed. Data collection and analysis We used maximum variation purposive sampling for data synthesis, using a three‐step sampling frame. We conducted a thematic analysis using a constant comparison strategy for data extraction and synthesis. We assessed our confidence in the findings using the GRADE‐CERQual approach. High confidence suggests that it is highly likely that the review finding is a reasonable representation of the phenomenon of interest, while very low confidence indicates that it is not clear whether the review finding is a reasonable representation of it. Using a matrix model, we then integrated our findings with those from other Cochrane reviews that assessed the effects of different communication strategies on parents' knowledge, attitudes and behaviour about childhood vaccination. Main results We included 38 studies, mostly from high‐income countries, many of which explored mothers' perceptions of vaccine communication. Some focused on the MMR (measles, mumps, rubella) vaccine. In general, parents wanted more information than they were getting (high confidence in the evidence). Lack of information led to worry and regret about vaccination decisions among some parents (moderate confidence). Parents wanted balanced information about vaccination benefits and harms (high confidence), presented clearly and simply (moderate confidence) and tailored to their situation (low confidence in the evidence). Parents wanted vaccination information to be available at a wider variety of locations, including outside health services (low confidence) and in good time before each vaccination appointment (moderate confidence). Parents viewed health workers as an important source of information and had specific expectations of their interactions with them (high confidence). Poor communication and negative relationships with health workers sometimes impacted on vaccination decisions (moderate confidence). Parents generally found it difficult to know which vaccination information source to trust and challenging to find information they felt was unbiased and balanced (high confidence). The amount of information parents wanted and the sources they felt could be trusted appeared to be linked to acceptance of vaccination, with parents who were more hesitant wanting more information (low to moderate confidence). Our synthesis and comparison of the qualitative evidence shows that most of the trial interventions addressed at least one or two key aspects of communication, including the provision of information prior to the vaccination appointment and tailoring information to parents' needs. None of the interventions appeared to respond to negative media stories or address parental perceptions of health worker motives. Authors' conclusions We have high or moderate confidence in the evidence contributing to several review findings. Further research, especially in rural and low‐ to middle‐income country settings, could strengthen evidence for the findings where we had low or very low confidence. Planners should consider the timing for making vaccination information available to parents, the settings where information is available, the provision of impartial and clear information tailored to parental needs, and parents' perceptions of health workers and the information provided.\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "from semanticscholar import SemanticScholar #Here we import the Semantics Scholar Library\n",
        "\n",
        "sch = SemanticScholar() #Create an instance for the semantic scholar library\n",
        "\n",
        "resultsFromSemantic = [] #Lists to hold the results from the library api call \n",
        "results = sch.search_paper('Information Retrival',year=\"2012-2023\") # We retrive the papers from year 2012 - 2023\n",
        "\n",
        "def authorFormat(authors): # This is the function to format different authors of the same paper seperated by \",\"\n",
        "  authorList = []\n",
        "  for author in authors:\n",
        "    authorList.append(author.name)\n",
        "  \n",
        "  authorSentence = \", \".join(authorList)\n",
        "  return authorSentence\n",
        "\n",
        "#Print the results of the papers with respective title,author,venue,year and abstract\n",
        "for item in results:\n",
        "  print(\"Title : \",item.title)\n",
        "  print(\"Author/s : \",authorFormat(item.authors))\n",
        "  print(\"Venue : \",item.venue)\n",
        "  print(\"year : \",item.year)\n",
        "  print(\"Abstract : \",item.abstract)\n",
        "  print(36*\"-\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ3V7Cguwql_"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twitter_scraper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "DjeUEftq2FIW",
        "outputId": "a6733015-e891-4a64-8abb-79bf9239a6c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twitter_scraper\n",
            "  Downloading twitter_scraper-0.4.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting MechanicalSoup\n",
            "  Downloading MechanicalSoup-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.8/dist-packages (from twitter_scraper) (0.10.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from MechanicalSoup->twitter_scraper) (2.25.1)\n",
            "Collecting beautifulsoup4>=4.7\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from MechanicalSoup->twitter_scraper) (4.9.2)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.0.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (0.0.1)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (2.1.1)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.19.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (1.1.1)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.8/dist-packages (from requests-html->twitter_scraper) (2.0.0)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.26.14)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (8.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (6.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (2022.12.7)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (10.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=5.0 in /usr/local/lib/python3.8/dist-packages (from fake-useragent->requests-html->twitter_scraper) (5.10.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyquery->requests-html->twitter_scraper) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->twitter_scraper) (3.12.1)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, MechanicalSoup, twitter_scraper\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed MechanicalSoup-1.2.0 beautifulsoup4-4.11.2 soupsieve-2.3.2.post1 twitter_scraper-0.4.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnMeLlgQ6lwd",
        "outputId": "b8677500-1fd9-498f-cf1a-b90fe067585a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.8/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from tweepy) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XGhxVMz_wqmA",
        "outputId": "1120611c-7059-4d84-9154-bdffc16b3279"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TweepError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-693b9e429192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpostedTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#AcheDin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2018-10-02\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_tweets_required\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mtweetsText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0muserName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTweepError\u001b[0m: Twitter error response: status code = 400"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "consumer_key = '' #consumer key for the respective developer\n",
        "consumer_secret = '' #secret key for the respective developer\n",
        "access_token = '' #access token for autentication\n",
        "access_token_secret = '' #access secret key for authentication\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "number_of_tweets_required = 1000\n",
        "tweetsText = []\n",
        "userName = []\n",
        "postedTime = []\n",
        "\n",
        "for i in tweepy.Cursor(api.search,q=\"#AcheDin\",count=100,lang=\"en\",since=\"2018-10-02\").items(number_of_tweets_required):\n",
        "  tweetsText.append(i.full_text)\n",
        "  userName.append(i.user)\n",
        "  postedTime.append(i.created_at)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}