{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhivarma-Birru-Unt/Abhivarma_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023_Abhivarma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_IxAhYrwql5"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdii6UZwql7"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIpIcpqTwql8"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "E9UTlS0Dwql8",
        "outputId": "5fe163ff-870c-4e17-b648-573da215d8ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nHere we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\\nWe choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\\n\\nHere we scrape only the basic comment users have mentioned and the respective star rating they have given.\\nThese allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\\n\\nWe collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\\n\\nSTEPS:\\n1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\\n2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\\n3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\\n4. Iterate each page dynamically until we get atleast 1000 reviews of the product\\n5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \\n6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\\n7. Print or Display the dataframe to get the respective reviews.\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Here we are going to scrape the iphone XR reviews and their ratings from Flipkart Website.\n",
        "We choose Flipkart because it allows scraping of the website, whereas amazon has strict scraping policies.\n",
        "\n",
        "Here we scrape only the basic comment users have mentioned and the respective star rating they have given.\n",
        "These allow user to easily check the reviews and allow them to decide whether or not to buy the iphone XR\n",
        "\n",
        "We collect the reviews of around 120 pages to get atleast 1000 reviews which help in analysing the product to make it worth buying.\n",
        "\n",
        "STEPS:\n",
        "1. Choose the website to scrape, over her we choose flipkart and select iphone XR which have good number of reviews.\n",
        "2. Next we go to the reviews section and check the no of reviews. Then select the device with atleast 1000 reviews.\n",
        "3. Now inspect the page or go to view page source and select the class which hold the text or value which describe about the reviews of the product in precise way.\n",
        "4. Iterate each page dynamically until we get atleast 1000 reviews of the product\n",
        "5. Using beautifulsoup, retrieve the review comment and the rating number from the respective classname. \n",
        "6. Save these values in the form of a table in a dataframe with columns \"Comment\" and \"Rating\".\n",
        "7. Print or Display the dataframe to get the respective reviews.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGRL5c6wql9"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jjrDdfv-wql-",
        "outputId": "966a9293-82ca-46cc-ee61-66ee9830e22d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Comment Rating\n",
              "0               Fabulous!      5\n",
              "1     Best in the market!      5\n",
              "2                Terrific      5\n",
              "3               Fabulous!      5\n",
              "4             Really Nice      4\n",
              "...                   ...    ...\n",
              "1195               Super!      5\n",
              "1196              Awesome      5\n",
              "1197               Super!      5\n",
              "1198            Wonderful      4\n",
              "1199            Must buy!      5\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10843bc8-bc24-4a9f-90d3-c8d853e4c737\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terrific</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>Must buy!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10843bc8-bc24-4a9f-90d3-c8d853e4c737')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10843bc8-bc24-4a9f-90d3-c8d853e4c737 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10843bc8-bc24-4a9f-90d3-c8d853e4c737');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "reviewTextHeading = [] # This list stores the generic main heading of the review\n",
        "reviewRating =[] #List to comments of the reviews\n",
        "for page in range(120):\n",
        "  linkToAmazon = \"https://www.flipkart.com/apple-iphone-xr-product-red-64-gb-includes-earpods-power-adapter/product-reviews/itmf9z7zhydhtbn5?pid=MOBF9Z7ZRWGTX3FA&lid=LSTMOBF9Z7ZRWGTX3FAWC8NB0&marketplace=FLIPKART\"+ str(page) \n",
        "  specificPage = requests.get(linkToAmazon)\n",
        "  soup = BeautifulSoup(specificPage.text,'html.parser')\n",
        "  mainReviewOfProduct=soup.find_all(class_ = '_2-N8zT')\n",
        "  reviewCommentOfProduct = soup.find_all(class_='_3LWZlK _1BLPMq')\n",
        "  for mainReview, commentOfReview in zip(mainReviewOfProduct, reviewCommentOfProduct):\n",
        "      reviewTextHeading.append(mainReview.text) \n",
        "      reviewRating.append(commentOfReview.text)\n",
        "\n",
        "dataFrameOfRating = pd.DataFrame(list(zip(reviewTextHeading, reviewRating)),columns=[\"Comment\",\"Rating\"])\n",
        "dataFrameOfRating"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrameOfRating.sort_values(\"Rating\",ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "clNYst_MDr2Q",
        "outputId": "1c3f9e70-7906-4865-8d88-49f176b4a527"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Comment Rating\n",
              "0              Fabulous!      5\n",
              "761  Best in the market!      5\n",
              "743            Fabulous!      5\n",
              "745               Super!      5\n",
              "746              Awesome      5\n",
              "..                   ...    ...\n",
              "188            Wonderful      4\n",
              "964          Really Nice      4\n",
              "688            Wonderful      4\n",
              "958            Wonderful      4\n",
              "534          Really Nice      4\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db307a85-83ac-4d6b-bc05-1c0344ac2a59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>Super!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Awesome</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>Really Nice</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db307a85-83ac-4d6b-bc05-1c0344ac2a59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db307a85-83ac-4d6b-bc05-1c0344ac2a59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db307a85-83ac-4d6b-bc05-1c0344ac2a59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyR97nQKwql-"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install semanticscholar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RVWUgbUpCu",
        "outputId": "a3d598a3-a83a-44f1-81ee-ad64b8982ce5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting semanticscholar\n",
            "  Downloading semanticscholar-0.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (2.25.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.8/dist-packages (from semanticscholar) (8.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->semanticscholar) (1.24.3)\n",
            "Installing collected packages: semanticscholar\n",
            "Successfully installed semanticscholar-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPVluKOxwql_",
        "outputId": "0c1c1861-0341-43cd-82a0-90ee319ab727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Title Heterogeneous Information Network Embedding for Recommendation\n",
            "Author [{'authorId': '144123161', 'name': 'C. Shi'}, {'authorId': '145743766', 'name': 'Binbin Hu'}, {'authorId': '2542603', 'name': 'Wayne Xin Zhao'}, {'authorId': '144019071', 'name': 'Philip S. Yu'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2017\n",
            "Abstract Due to the flexibility in modelling data heterogeneity, heterogeneous information network (HIN) has been adopted to characterize complex and heterogeneous auxiliary data in recommender systems, called HIN based recommendation. It is challenging to develop effective methods for HIN based recommendation in both extraction and exploitation of the information from HINs. Most of HIN based recommendation methods rely on path based similarity, which cannot fully mine latent structure features of users and items. In this paper, we propose a novel heterogeneous network embedding based approach for HIN based recommendation, called HERec. To embed HINs, we design a meta-path based random walk strategy to generate meaningful node sequences for network embedding. The learned node embeddings are first transformed by a set of fusion functions, and subsequently integrated into an extended matrix factorization (MF) model. The extended MF model together with fusion functions are jointly optimized for the rating prediction task. Extensive experiments on three real-world datasets demonstrate the effectiveness of the HERec model. Moreover, we show the capability of the HERec model for the cold-start problem, and reveal that the transformed embedding information from HINs can improve the recommendation performance.\n",
            "------------------------------------\n",
            "Title Public Health and Online Misinformation: Challenges and Recommendations.\n",
            "Author [{'authorId': '1416945634', 'name': 'B. Swire‐Thompson'}, {'authorId': '3185333', 'name': 'D. Lazer'}]\n",
            "Venue Annual Review of Public Health\n",
            "year 2019\n",
            "Abstract The internet has become a popular resource to learn about health and to investigate one's own health condition. However, given the large amount of inaccurate information online, people can easily become misinformed. Individuals have always obtained information from outside the formal health care system, so how has the internet changed people's engagement with health information? This review explores how individuals interact with health misinformation online, whether it be through search, user-generated content, or mobile apps. We discuss whether personal access to information is helping or hindering health outcomes and how the perceived trustworthiness of the institutions communicating health has changed over time. To conclude, we propose several constructive strategies for improving the online information ecosystem. Misinformation concerning health has particularly severe consequences with regard to people's quality of life and even their risk of mortality; therefore, understanding it within today's modern context is an extremely important task. Expected final online publication date for the Annual Review of Public Health, Volume 41 is April 1, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.\n",
            "------------------------------------\n",
            "Title Partisan Perceptual Bias and the Information Environment\n",
            "Author [{'authorId': '51516431', 'name': 'Jennifer Jerit'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Perceptual bias occurs when beliefs deviate from reality. Democrats and Republicans are thought to be especially susceptible to this type of biased-information processing. And yet we know little about the pervasiveness of perceptual bias outside the domain of ‘‘performance issues’’ (e.g., unemployment, inflation) or how individuallevel partisan motivation interacts with the information environment. We investigate these issues in two studies that examine perceptual bias on a wide range of political topics spanning two decades. Using survey data as well as an experiment with diverse subjects, we demonstrate that people perceive the world in a manner consistent with their political views. The result is a selective pattern of learning in which partisans have higher levels of knowledge for facts that confirm their world view and lower levels of knowledge for facts that challenge them. This basic relationship is exaggerated on topics receiving high levels of media coverage.\n",
            "------------------------------------\n",
            "Title Unsafe exposure analysis of mobile in-app advertisements\n",
            "Author [{'authorId': '34548699', 'name': 'Michael C. Grace'}, {'authorId': '2115341253', 'name': 'Wu Zhou'}, {'authorId': '1740888', 'name': 'Xuxian Jiang'}, {'authorId': '145897166', 'name': 'A. Sadeghi'}]\n",
            "Venue Wireless Network Security\n",
            "year 2012\n",
            "Abstract In recent years, there has been explosive growth in smartphone sales, which is accompanied with the availability of a huge number of smartphone applications (or simply apps). End users or consumers are attracted by the many interesting features offered by these devices and the associated apps. The developers of these apps are also benefited by the prospect of financial compensation, either by selling their apps directly or by embedding one of the many ad libraries available on smartphone platforms. In this paper, we focus on potential privacy and security risks posed by these embedded or in-app advertisement libraries (henceforth \"ad libraries,\" for brevity). To this end, we study the popular Android platform and collect 100,000 apps from the official Android Market in March-May, 2011. Among these apps, we identify 100 representative in-app ad libraries (embedded in 52.1% of them) and further develop a system called AdRisk to systematically identify potential risks. In particular, we first decouple the embedded ad libraries from host apps and then apply our system to statically examine the ad libraries, ranging from whether they will upload privacy-sensitive information to remote (ad) servers or whether they will download untrusted code from remote servers. Our results show that most existing ad libraries collect private information: some of them may be used for legitimate targeting purposes (i.e., the user's location) while others are hard to justify by invasively collecting the information such as the user's call logs, phone number, browser bookmarks, or even the list of installed apps on the phone. Moreover, additional ones go a step further by making use of an unsafe mechanism to directly fetch and run code from the Internet, which immediately leads to serious security risks. Our investigation indicates the symbiotic relationship between embedded ad libraries and host apps is one main reason behind these exposed risks. These results clearly show the need for better regulating the way ad libraries are integrated in Android apps.\n",
            "------------------------------------\n",
            "Title The SCONUL Seven Pillars of Information Literacy: Core Model\n",
            "Author [{'authorId': '46507527', 'name': 'Moira Bent'}, {'authorId': '49240829', 'name': 'R. Stubbings'}, {'authorId': '97417491', 'name': 'Sconul'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract This is an OER derived from The SCONUL seven pillars of information literacy core model for higher education and incorporates \"lenses\" - a Research lens, a Digital Literacy lens, an Open content lens and a lens that reflects the unique information landscape and needs of evidence-based practice (EBP) in healthcare.\n",
            "------------------------------------\n",
            "Title Wireless Information and Power Transfer: Energy Efficiency Optimization in OFDMA Systems\n",
            "Author [{'authorId': '1786350', 'name': 'Derrick Wing Kwan Ng'}, {'authorId': '34653084', 'name': 'Ernest S. Lo'}, {'authorId': '143677566', 'name': 'R. Schober'}]\n",
            "Venue IEEE Transactions on Wireless Communications\n",
            "year 2013\n",
            "Abstract This paper considers orthogonal frequency division multiple access (OFDMA) systems with simultaneous wireless information and power transfer. We study the resource allocation algorithm design for maximization of the energy efficiency of data transmission (bits/Joule delivered to the receivers). In particular, we focus on power splitting hybrid receivers which are able to split the received signals into two power streams for concurrent information decoding and energy harvesting. Two scenarios are investigated considering different power splitting abilities of the receivers. In the first scenario, we assume receivers which can split the received power into a continuous set of power streams with arbitrary power splitting ratios. In the second scenario, we examine receivers which can split the received power only into a discrete set of power streams with fixed power splitting ratios. For both scenarios, we formulate the corresponding algorithm design as a non-convex optimization problem which takes into account the circuit power consumption, the minimum data rate requirements of delay constrained services, the minimum required system data rate, and the minimum amount of power that has to be delivered to the receivers. By exploiting fractional programming and dual decomposition, suboptimal iterative resource allocation algorithms are developed to solve the non-convex problems. Simulation results illustrate that the proposed iterative resource allocation algorithms approach the optimal solution within a small number of iterations and unveil the trade-off between energy efficiency, system capacity, and wireless power transfer: (1) wireless power transfer enhances the system energy efficiency by harvesting energy in the radio frequency, especially in the interference limited regime; (2) the presence of multiple receivers is beneficial for the system capacity, but not necessarily for the system energy efficiency.\n",
            "------------------------------------\n",
            "Title miRBase: annotating high confidence microRNAs using deep sequencing data\n",
            "Author [{'authorId': '3066945', 'name': 'Ana Kozomara'}, {'authorId': '1398461217', 'name': 'S. Griffiths-Jones'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2013\n",
            "Abstract We describe an update of the miRBase database (http://www.mirbase.org/), the primary microRNA sequence repository. The latest miRBase release (v20, June 2013) contains 24 521 microRNA loci from 206 species, processed to produce 30 424 mature microRNA products. The rate of deposition of novel microRNAs and the number of researchers involved in their discovery continue to increase, driven largely by small RNA deep sequencing experiments. In the face of these increases, and a range of microRNA annotation methods and criteria, maintaining the quality of the microRNA sequence data set is a significant challenge. Here, we describe recent developments of the miRBase database to address this issue. In particular, we describe the collation and use of deep sequencing data sets to assign levels of confidence to miRBase entries. We now provide a high confidence subset of miRBase entries, based on the pattern of mapped reads. The high confidence microRNA data set is available alongside the complete microRNA collection at http://www.mirbase.org/. We also describe embedding microRNA-specific Wikipedia pages on the miRBase website to encourage the microRNA community to contribute and share textual and functional information.\n",
            "------------------------------------\n",
            "Title NCBI Taxonomy: a comprehensive update on curation, resources and tools\n",
            "Author [{'authorId': '34637610', 'name': 'C. Schoch'}, {'authorId': '3015885', 'name': 'S. Ciufo'}, {'authorId': '1860981947', 'name': 'M. Domrachev'}, {'authorId': '3829599', 'name': 'C. Hotton'}, {'authorId': '153895454', 'name': 'S. Kannan'}, {'authorId': '1861192818', 'name': 'Rogneda Khovanskaya'}, {'authorId': '3366733', 'name': 'D. Leipe'}, {'authorId': '2052127', 'name': 'Richard McVeigh'}, {'authorId': '1861174059', 'name': \"K. O'Neill\"}, {'authorId': '46429559', 'name': 'B. Robbertse'}, {'authorId': '2118511285', 'name': 'Shobha Sharma'}, {'authorId': '78771575', 'name': 'Vladimir Soussov'}, {'authorId': '153116459', 'name': 'John P. Sullivan'}, {'authorId': '2158034540', 'name': 'Lu Sun'}, {'authorId': '50527209', 'name': 'S. Turner'}, {'authorId': '1456397570', 'name': 'I. Karsch-Mizrachi'}]\n",
            "Venue Database J. Biol. Databases Curation\n",
            "year 2020\n",
            "Abstract The National Center for Biotechnology Information (NCBI) Taxonomy includes organism names and classifications for every sequence in the nucleotide and protein sequence databases of the International Nucleotide Sequence Database Collaboration. Since the last review of this resource in 2012, it has undergone several improvements. Most notable is the shift from a single SQL database to a series of linked databases tied to a framework of data called NameBank. This means that relations among data elements can be adjusted in more detail, resulting in expanded annotation of synonyms, the ability to flag names with specific nomenclatural properties, enhanced tracking of publications tied to names and improved annotation of scientific authorities and types. Additionally, practices utilized by NCBI Taxonomy curators specific to major taxonomic groups are described, terms peculiar to NCBI Taxonomy are explained, external resources are acknowledged and updates to tools and other resources are documented. Database URL: https://www.ncbi.nlm.nih.gov/taxonomy.\n",
            "------------------------------------\n",
            "Title Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\n",
            "Author [{'authorId': '144084234', 'name': 'Wei Shen'}, {'authorId': '2447408', 'name': 'Jianyong Wang'}, {'authorId': '145325584', 'name': 'Jiawei Han'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2015\n",
            "Abstract The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research. Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. Potential applications include information extraction, information retrieval, and knowledge base population. However, this task is challenging due to name variations and entity ambiguity. In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.\n",
            "------------------------------------\n",
            "Title FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\n",
            "Author [{'authorId': '3322806', 'name': 'Caner Hazirbas'}, {'authorId': '2562254', 'name': 'Lingni Ma'}, {'authorId': '1847505', 'name': 'Csaba Domokos'}, {'authorId': '1695302', 'name': 'D. Cremers'}]\n",
            "Venue Asian Conference on Computer Vision\n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A Review of Facebook Research in the Social Sciences\n",
            "Author [{'authorId': '2109032864', 'name': 'R. Wilson'}, {'authorId': '2705485', 'name': 'S. Gosling'}, {'authorId': '39871201', 'name': 'Lindsay T. Graham'}]\n",
            "Venue Perspectives on Psychological Science\n",
            "year 2012\n",
            "Abstract With over 800 million active users, Facebook is changing the way hundreds of millions of people relate to one another and share information. A rapidly growing body of research has accompanied the meteoric rise of Facebook as social scientists assess the impact of Facebook on social life. In addition, researchers have recognized the utility of Facebook as a novel tool to observe behavior in a naturalistic setting, test hypotheses, and recruit participants. However, research on Facebook emanates from a wide variety of disciplines, with results being published in a broad range of journals and conference proceedings, making it difficult to keep track of various findings. And because Facebook is a relatively recent phenomenon, uncertainty still exists about the most effective ways to do Facebook research. To address these issues, the authors conducted a comprehensive literature search, identifying 412 relevant articles, which were sorted into 5 categories: descriptive analysis of users, motivations for using Facebook, identity presentation, the role of Facebook in social interactions, and privacy and information disclosure. The literature review serves as the foundation from which to assess current findings and offer recommendations to the field for future research on Facebook and online social networks more broadly.\n",
            "------------------------------------\n",
            "Title STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets\n",
            "Author [{'authorId': '51006560', 'name': 'Damian Szklarczyk'}, {'authorId': '40833431', 'name': 'Annika L. Gable'}, {'authorId': '2059127322', 'name': 'D. Lyon'}, {'authorId': '2444056', 'name': 'Alexander Junge'}, {'authorId': '3356708', 'name': 'S. Wyder'}, {'authorId': '1402304554', 'name': 'J. Huerta-Cepas'}, {'authorId': '2161352', 'name': 'M. Simonovic'}, {'authorId': '50391572', 'name': 'Nadezhda T. Doncheva'}, {'authorId': '2116698810', 'name': 'J. Morris'}, {'authorId': '3534315', 'name': 'P. Bork'}, {'authorId': '2214567', 'name': 'L. Jensen'}, {'authorId': '2544559', 'name': 'C. V. Mering'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2018\n",
            "Abstract Abstract Proteins and their functional interactions form the backbone of the cellular machinery. Their connectivity network needs to be considered for the full understanding of biological phenomena, but the available information on protein–protein associations is incomplete and exhibits varying levels of annotation granularity and reliability. The STRING database aims to collect, score and integrate all publicly available sources of protein–protein interaction information, and to complement these with computational predictions. Its goal is to achieve a comprehensive and objective global network, including direct (physical) as well as indirect (functional) interactions. The latest version of STRING (11.0) more than doubles the number of organisms it covers, to 5090. The most important new feature is an option to upload entire, genome-wide datasets as input, allowing users to visualize subsets as interaction networks and to perform gene-set enrichment analysis on the entire input. For the enrichment analysis, STRING implements well-known classification systems such as Gene Ontology and KEGG, but also offers additional, new classification systems based on high-throughput text-mining as well as on a hierarchical clustering of the association network itself. The STRING resource is available online at https://string-db.org/.\n",
            "------------------------------------\n",
            "Title Mobile health\n",
            "Author [{'authorId': '121025444', 'name': 'A. Monteiro'}]\n",
            "Venue Radiologia Brasileira\n",
            "year 2014\n",
            "Abstract Radiol Bras. 2014 Mar/Abr;47(2):IX mHealth, or mobile health is a term associated with the daily practice of medicine and public health supported by mobile devices such as cell phones and tablets. It is an universal trend of convergence of all patients’ information and images, data banks as source of information, academic social networks, specialized remote support systems and alike, as a support to the medical practice and to the teaching of medicine. Additionally there is the possibility of access by patients to their reports, tests results and schedules. However, other low-cost technologies are available, such as Raspberry Pi, a credit-card-sized computer developed in the United Kingdom by the Raspberry Pi Foundation. Such project was aimed at facilitating and encouraging the teaching of computer sciences for children in that country, and involving the study of computer techniques, methods and tools, processes automation and development of solutions based on the use of digital processing. The suc-\n",
            "------------------------------------\n",
            "Title Dr Google and the Consumer: A Qualitative Study Exploring the Navigational Needs and Online Health Information-Seeking Behaviors of Consumers With Chronic Health Conditions\n",
            "Author [{'authorId': '2118143733', 'name': 'Kenneth Lee'}, {'authorId': '6309172', 'name': 'Kreshnik Hoti'}, {'authorId': '145094250', 'name': 'J. Hughes'}, {'authorId': '74336486', 'name': 'L. Emmerton'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2014\n",
            "Abstract Background The abundance of health information available online provides consumers with greater access to information pertinent to the management of health conditions. This is particularly important given an increasing drive for consumer-focused health care models globally, especially in the management of chronic health conditions, and in recognition of challenges faced by lay consumers with finding, understanding, and acting on health information sourced online. There is a paucity of literature exploring the navigational needs of consumers with regards to accessing online health information. Further, existing interventions appear to be didactic in nature, and it is unclear whether such interventions appeal to consumers’ needs. Objective Our goal was to explore the navigational needs of consumers with chronic health conditions in finding online health information within the broader context of consumers’ online health information-seeking behaviors. Potential barriers to online navigation were also identified. Methods Semistructured interviews were conducted with adult consumers who reported using the Internet for health information and had at least one chronic health condition. Participants were recruited from nine metropolitan community pharmacies within Western Australia, as well as through various media channels. Interviews were audio-recorded, transcribed verbatim, and then imported into QSR NVivo 10. Two established approaches to thematic analysis were adopted. First, a data-driven approach was used to minimize potential bias in analysis and improve construct and criterion validity. A theory-driven approach was subsequently used to confirm themes identified by the former approach and to ensure identified themes were relevant to the objectives. Two levels of analysis were conducted for both data-driven and theory-driven approaches: manifest-level analysis, whereby face-value themes were identified, and latent-level analysis, whereby underlying concepts were identified. Results We conducted 17 interviews, with data saturation achieved by the 14th interview. While we identified a broad range of online health information-seeking behaviors, most related to information discussed during consumer-health professional consultations such as looking for information about medication side effects. The barriers we identified included intrinsic barriers, such as limited eHealth literacy, and extrinsic barriers, such as the inconsistency of information between different online sources. The navigational needs of our participants were extrinsic in nature and included health professionals directing consumers to appropriate online resources and better filtering of online health information. Our participants’ online health information-seeking behaviors, reported barriers, and navigational needs were underpinned by the themes of trust, patient activation, and relevance. Conclusions This study suggests that existing interventions aimed to assist consumers with navigating online health information may not be what consumers want or perceive they need. eHealth literacy and patient activation appear to be prevalent concepts in the context of consumers’ online health information-seeking behaviors. Furthermore, the role for health professionals in guiding consumers to quality online health information is highlighted.\n",
            "------------------------------------\n",
            "Title The Duality of Technology: Rethinking the Concept of Technology in Organizations\n",
            "Author [{'authorId': '3164419', 'name': 'W. Orlikowski'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This paper develops a new theoretical model with which to examine the interaction between technology and organizations. Early research studies assumed technology to be an objective, external force that would have deterministic impacts on organizational properties such as structure. Later researchers focused on the human aspect of technology, seeing it as the outcome of strategic choice and social action. This paper suggests that either view is incomplete, and proposes a reconceptualization of technology that takes both perspectives into account. A theoretical model—the structurational model of technology—is built on the basis of this new conceptualization, and its workings explored through discussion of a field study of information technology. The paper suggests that the reformulation of the technology concept and the structurational model of technology allow a deeper and more dialectical understanding of the interaction between technology and organizations. This understanding provides insight into the limits and opportunities of human choice, technology development and use, and organizational design. Implications for future research of the new concept of technology and the structurational model of technology are discussed.\n",
            "------------------------------------\n",
            "Title What to Expect When the Unexpected Happens: Social Media Communications Across Crises\n",
            "Author [{'authorId': '39824354', 'name': 'Alexandra Olteanu'}, {'authorId': '3681090', 'name': 'Sarah Vieweg'}, {'authorId': '153191671', 'name': 'Carlos Castillo'}]\n",
            "Venue Conference on Computer Supported Cooperative Work\n",
            "year 2015\n",
            "Abstract The use of social media to communicate timely information during crisis situations has become a common practice in recent years. In particular, the one-to-many nature of Twitter has created an opportunity for stakeholders to disseminate crisis-relevant messages, and to access vast amounts of information they may not otherwise have. Our goal is to understand what affected populations, response agencies and other stakeholders can expect-and not expect-from these data in various types of disaster situations. Anecdotal evidence suggests that different types of crises elicit different reactions from Twitter users, but we have yet to see whether this is in fact the case. In this paper, we investigate several crises-including natural hazards and human-induced disasters-in a systematic manner and with a consistent methodology. This leads to insights about the prevalence of different information types and sources across a variety of crisis situations.\n",
            "------------------------------------\n",
            "Title Digital Economics\n",
            "Author [{'authorId': '3156782', 'name': 'Avi Goldfarb'}, {'authorId': '50696623', 'name': 'Catherine Tucker'}]\n",
            "Venue Journal of Economic Literature\n",
            "year 2017\n",
            "Abstract Digital technology is the representation of information in bits. This technology has reduced the cost of storage, computation, and transmission of data. Research on digital economics examines whether and how digital technology changes economic activity. In this review, we emphasize the reduction in five distinct economic costs associated with digital economic activity: search costs, replication costs, transportation costs, tracking costs, and verification costs. (JEL D24, D83, L86, O33, R41)\n",
            "------------------------------------\n",
            "Title Some Simple Economics of Crowdfunding\n",
            "Author [{'authorId': '48054927', 'name': 'A. Agrawal'}, {'authorId': '2142201', 'name': 'Christian Catalini'}, {'authorId': '3156782', 'name': 'Avi Goldfarb'}]\n",
            "Venue Innovation Policy and the Economy\n",
            "year 2013\n",
            "Abstract It is not surprising that the financing of early-stage creative projects and ventures is typically geographically localized since these types of funding decisions are usually predicated on personal relationships and due diligence requiring face-to-face interactions in response to high levels of risk, uncertainty, and information asymmetry. So, to economists, the recent rise of crowdfunding—raising capital from many people through an online platform—which offers little opportunity for careful due diligence and involves not only friends and family but also many strangers from near and far, is initially startling. On the eve of launching equity-based crowdfunding, a new market for early-stage finance in the United States, we provide a preliminary exploration of its underlying economics. We highlight the extent to which economic theory, in particular transaction costs, reputation, and market design, can explain the rise of nonequity crowdfunding and offer a framework for speculating on how equity-based crowdfunding may unfold. We conclude by articulating open questions related to how crowdfunding may affect social welfare and the rate and direction of innovation.\n",
            "------------------------------------\n",
            "Title A Primer in BERTology: What We Know About How BERT Works\n",
            "Author [{'authorId': '145046059', 'name': 'Anna Rogers'}, {'authorId': '152176221', 'name': 'Olga Kovaleva'}, {'authorId': '1681193', 'name': 'Anna Rumshisky'}]\n",
            "Venue Transactions of the Association for Computational Linguistics\n",
            "year 2020\n",
            "Abstract Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.\n",
            "------------------------------------\n",
            "Title COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author [{'authorId': '48072570', 'name': 'Cristina M. Pulido'}, {'authorId': '1405451231', 'name': 'Beatriz Villarejo-Carballido'}, {'authorId': '1404053936', 'name': 'Gisela Redondo-Sama'}, {'authorId': '32524958', 'name': 'Aitor Gómez'}]\n",
            "Venue \n",
            "year 2020\n",
            "Abstract The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title Advances in Social Media Research: Past, Present and Future\n",
            "Author [{'authorId': '37232810', 'name': 'Kawal Kapoor'}, {'authorId': '2191954', 'name': 'K. Tamilmani'}, {'authorId': '1688149', 'name': 'N. Rana'}, {'authorId': '27745084', 'name': 'Pushp P. Patil'}, {'authorId': '1724490', 'name': 'Yogesh Kumar Dwivedi'}, {'authorId': '2290083', 'name': 'S. Nerur'}]\n",
            "Venue Inf. Syst. Frontiers\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Semantic Image Synthesis With Spatially-Adaptive Normalization\n",
            "Author [{'authorId': '2071929129', 'name': 'Taesung Park'}, {'authorId': '39793900', 'name': 'Ming-Yu Liu'}, {'authorId': '2195314', 'name': 'Ting-Chun Wang'}, {'authorId': '2436356', 'name': 'Jun-Yan Zhu'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2019\n",
            "Abstract We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.\n",
            "------------------------------------\n",
            "Title Entanglement wedge reconstruction and the information paradox\n",
            "Author [{'authorId': '49136752', 'name': 'Geoffrey Penington'}]\n",
            "Venue Journal of High Energy Physics\n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Generalized Composite Kernel Framework for Hyperspectral Image Classification\n",
            "Author [{'authorId': '2152747957', 'name': 'Jun Li'}, {'authorId': '1932974', 'name': 'P. Marpu'}, {'authorId': '143767945', 'name': 'A. Plaza'}, {'authorId': '1399086996', 'name': 'J. Bioucas-Dias'}, {'authorId': '1682001', 'name': 'J. Benediktsson'}]\n",
            "Venue IEEE Transactions on Geoscience and Remote Sensing\n",
            "year 2013\n",
            "Abstract This paper presents a new framework for the development of generalized composite kernel machines for hyperspectral image classification. We construct a new family of generalized composite kernels which exhibit great flexibility when combining the spectral and the spatial information contained in the hyperspectral data, without any weight parameters. The classifier adopted in this work is the multinomial logistic regression, and the spatial information is modeled from extended multiattribute profiles. In order to illustrate the good performance of the proposed framework, support vector machines are also used for evaluation purposes. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible/Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the proposed framework leads to state-of-the-art classification performance in complex analysis scenarios.\n",
            "------------------------------------\n",
            "Title Signalling Theory and Equilibrium in Strategic Management Research: An Assessment and a Research Agenda\n",
            "Author [{'authorId': '96736170', 'name': 'D. Bergh'}, {'authorId': '39858579', 'name': 'Brian L. Connelly'}, {'authorId': '1741064666', 'name': 'David J. Ketchen, Jr'}, {'authorId': '116566952', 'name': 'Lu M. Shannon'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Actors within organizations commonly must make choices armed with incomplete and asymmetrically distributed information. Signalling theory seeks to explain how individuals are able to do so. This theory's primary predictive mechanism is ‘separating equilibrium’, which occurs when a signal's expectations are confirmed through experience. A content analysis finds that most strategic management signalling theory studies have not fully leveraged separating equilibrium. This presents two possible paths for future research. First, some researchers may wish to incorporate separating equilibrium. We illustrate how doing so can uncover new relationships, generate novel insights, and fortify the theory's application. Others who want to theorize about signals, but not examine separating equilibrium, could integrate ideas from signalling theory with other information perspectives. Here a signal becomes one stimulus among many that corporate actors interpret and act upon. We provide research agendas so strategy scholars can apply signalling theory most effectively to meet their research objectives.\n",
            "------------------------------------\n",
            "Title Sensor Mania! The Internet of Things, Wearable Computing, Objective Metrics, and the Quantified Self 2.0\n",
            "Author [{'authorId': '46838780', 'name': 'M. Swan'}]\n",
            "Venue J. Sens. Actuator Networks\n",
            "year 2012\n",
            "Abstract The number of devices on the Internet exceeded the number of people on the Internet in 2008, and is estimated to reach 50 billion in 2020. A wide-ranging Internet of Things (IOT) ecosystem is emerging to support the process of connecting real-world objects like buildings, roads, household appliances, and human bodies to the Internet via sensors and microprocessor chips that record and transmit data such as sound waves, temperature, movement, and other variables. The explosion in Internet-connected sensors means that new classes of technical capability and application are being created. More granular 24/7 quantified monitoring is leading to a deeper understanding of the internal and external worlds encountered by humans. New data literacy behaviors such as correlation assessment, anomaly detection, and high-frequency data processing are developing as humans adapt to the different kinds of data flows enabled by the IOT. The IOT ecosystem has four critical functional steps: data creation, information generation, meaning-making, and action-taking. This paper provides a comprehensive review of the current and rapidly emerging ecosystem of the Internet of Things (IOT).\n",
            "------------------------------------\n",
            "Title Deep supervised learning for hyperspectral data classification through convolutional neural networks\n",
            "Author [{'authorId': '2879272', 'name': 'K. Makantasis'}, {'authorId': '144542193', 'name': 'K. Karantzalos'}, {'authorId': '1746705', 'name': 'A. Doulamis'}, {'authorId': '120205775', 'name': 'N. Doulamis'}]\n",
            "Venue IEEE International Geoscience and Remote Sensing Symposium\n",
            "year 2015\n",
            "Abstract Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title Social network analysis: foundations and frontiers on advantage.\n",
            "Author [{'authorId': '3301313', 'name': 'R. Burt'}, {'authorId': '2296494', 'name': 'M. Kilduff'}, {'authorId': '34471889', 'name': 'S. Tasselli'}]\n",
            "Venue Annual Review of Psychology\n",
            "year 2013\n",
            "Abstract We provide an overview of social network analysis focusing on network advantage as a lens that touches on much of the area. For reasons of good data and abundant research, we draw heavily on studies of people in organizations. Advantage is traced to network structure as a proxy for the distribution of variably sticky information in a population. The network around a person indicates the person's access and control in the distribution. Advantage is a function of information breadth, timing, and arbitrage. Advantage is manifest in higher odds of proposing good ideas, more positive evaluations and recognition, higher compensation, and faster promotions. We discuss frontiers of advantage contingent on personality, cognition, embeddedness, and dynamics.\n",
            "------------------------------------\n",
            "Title Accounting Information Systems\n",
            "Author [{'authorId': '1460086275', 'name': 'Tawfiq Abu-Raqabeh'}]\n",
            "Venue Education and Linguistics Research\n",
            "year 2018\n",
            "Abstract Today’s swiftly changing technology, globalization, and integration of corporations has created a need for the introduction of IAS to higher education institutes. This study explores and examines the introduction of IAS to the higher education institutes. The readiness of the institutes, the problems they face to incorporate the IAS to the curriculum. The criteria utilized by ABET focuses on content and delivery of curriculum within the IS discipline. The advantages of incorporating the IAS in the curriculum for students and faculty.\n",
            "------------------------------------\n",
            "Title Social networks predict patch discovery in a wild population of songbirds\n",
            "Author [{'authorId': '4679421', 'name': 'L. Aplin'}, {'authorId': '3384335', 'name': 'D. Farine'}, {'authorId': '1399052434', 'name': 'J. Morand‐Ferron'}, {'authorId': '6799312', 'name': 'B. Sheldon'}]\n",
            "Venue Proceedings of the Royal Society B: Biological Sciences\n",
            "year 2012\n",
            "Abstract Animals use social information in a wide variety of contexts. Its extensive use by individuals to locate food patches has been documented in a number of species, and various mechanisms of discovery have been identified. However, less is known about whether individuals differ in their access to, and use of, social information to find food. We measured the social network of a wild population of three sympatric tit species (family Paridae) and then recorded individual discovery of novel food patches. By using recently developed methods for network-based diffusion analysis, we show that order of arrival at new food patches was predicted by social associations. Models based only on group searching did not explain this relationship. Furthermore, network position was correlated with likelihood of patch discovery, with central individuals more likely to locate and use novel foraging patches than those with limited social connections. These results demonstrate the utility of social network analysis as a method to investigate social information use, and suggest that the greater probability of receiving social information about new foraging patches confers a benefit on more socially connected individuals.\n",
            "------------------------------------\n",
            "Title Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\n",
            "Author [{'authorId': '49756115', 'name': 'Wenjie Luo'}, {'authorId': '47002813', 'name': 'Yujia Li'}, {'authorId': '2422559', 'name': 'R. Urtasun'}, {'authorId': '1804104', 'name': 'R. Zemel'}]\n",
            "Venue NIPS\n",
            "year 2016\n",
            "Abstract We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field size, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field size. We analyze the effective receptive field in several architecture designs, and the effect of sub-sampling, skip connections, dropout and nonlinear activations on it. This leads to suggestions for ways to address its tendency to be too small.\n",
            "------------------------------------\n",
            "Title Spectral–Spatial Hyperspectral Image Segmentation Using Subspace Multinomial Logistic Regression and Markov Random Fields\n",
            "Author [{'authorId': '2152747957', 'name': 'Jun Li'}, {'authorId': '1399086996', 'name': 'J. Bioucas-Dias'}, {'authorId': '143767945', 'name': 'A. Plaza'}]\n",
            "Venue IEEE Transactions on Geoscience and Remote Sensing\n",
            "year 2012\n",
            "Abstract This paper introduces a new supervised segmentation algorithm for remotely sensed hyperspectral image data which integrates the spectral and spatial information in a Bayesian framework. A multinomial logistic regression (MLR) algorithm is first used to learn the posterior probability distributions from the spectral information, using a subspace projection method to better characterize noise and highly mixed pixels. Then, contextual information is included using a multilevel logistic Markov-Gibbs Markov random field prior. Finally, a maximum a posteriori segmentation is efficiently computed by the min-cut-based integer optimization algorithm. The proposed segmentation approach is experimentally evaluated using both simulated and real hyperspectral data sets, exhibiting state-of-the-art performance when compared with recently introduced hyperspectral image classification methods. The integration of subspace projection methods with the MLR algorithm, combined with the use of spatial-contextual information, represents an innovative contribution in the literature. This approach is shown to provide accurate characterization of hyperspectral imagery in both the spectral and the spatial domain.\n",
            "------------------------------------\n",
            "Title What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author [{'authorId': '2480903', 'name': 'Alexis Conneau'}, {'authorId': '2067996', 'name': 'Germán Kruszewski'}, {'authorId': '1830914', 'name': 'Guillaume Lample'}, {'authorId': '2934336', 'name': 'Loïc Barrault'}, {'authorId': '145283199', 'name': 'Marco Baroni'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2018\n",
            "Abstract Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author [{'authorId': '1902078', 'name': 'G. Schryen'}]\n",
            "Venue European Journal of Information Systems\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Intelligent Reflecting Surface Aided MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer\n",
            "Author [{'authorId': '144442022', 'name': 'Cunhua Pan'}, {'authorId': '145892647', 'name': 'Hong Ren'}, {'authorId': '1878751', 'name': 'Kezhi Wang'}, {'authorId': '3283999', 'name': 'M. Elkashlan'}, {'authorId': '1709760', 'name': 'A. Nallanathan'}, {'authorId': '40382920', 'name': 'Jiangzhou Wang'}, {'authorId': '80707783', 'name': 'L. Hanzo'}]\n",
            "Venue IEEE Journal on Selected Areas in Communications\n",
            "year 2019\n",
            "Abstract An intelligent reflecting surface (IRS) is invoked for enhancing the energy harvesting performance of a simultaneous wireless information and power transfer (SWIPT) aided system. Specifically, an IRS-assisted SWIPT system is considered, where a multi-antenna aided base station (BS) communicates with several multi-antenna assisted information receivers (IRs), while guaranteeing the energy harvesting requirement of the energy receivers (ERs). To maximize the weighted sum rate (WSR) of IRs, the transmit precoding (TPC) matrices of the BS and passive phase shift matrix of the IRS should be jointly optimized. To tackle this challenging optimization problem, we first adopt the classic block coordinate descent (BCD) algorithm for decoupling the original optimization problem into several subproblems and alternately optimize the TPC matrices and the phase shift matrix. For each subproblem, we provide a low-complexity iterative algorithm, which is guaranteed to converge to the Karush-Kuhn-Tucker (KKT) point of each subproblem. The BCD algorithm is rigorously proved to converge to the KKT point of the original problem. We also conceive a feasibility checking method to study its feasibility. Our extensive simulation results confirm that employing IRSs in SWIPT beneficially enhances the system performance and the proposed BCD algorithm converges rapidly, which is appealing for practical applications.\n",
            "------------------------------------\n",
            "Title Rapid assessment of disaster damage using social media activity\n",
            "Author [{'authorId': '2418325', 'name': 'Yury Kryvasheyeu'}, {'authorId': '3251114', 'name': 'Haohui Chen'}, {'authorId': '1878375', 'name': 'Nick Obradovich'}, {'authorId': '40025432', 'name': 'E. Moro'}, {'authorId': '1692062', 'name': 'P. Van Hentenryck'}, {'authorId': '2016371', 'name': 'J. Fowler'}, {'authorId': '145512647', 'name': 'Manuel Cebrian'}]\n",
            "Venue Science Advances\n",
            "year 2016\n",
            "Abstract Researchers show a correlation between per-capita social media activity and disaster damage, facilitating its rapid assessment. Could social media data aid in disaster response and damage assessment? Countries face both an increasing frequency and an increasing intensity of natural disasters resulting from climate change. During such events, citizens turn to social media platforms for disaster-related communication and information. Social media improves situational awareness, facilitates dissemination of emergency information, enables early warning systems, and helps coordinate relief efforts. In addition, the spatiotemporal distribution of disaster-related messages helps with the real-time monitoring and assessment of the disaster itself. We present a multiscale analysis of Twitter activity before, during, and after Hurricane Sandy. We examine the online response of 50 metropolitan areas of the United States and find a strong relationship between proximity to Sandy’s path and hurricane-related social media activity. We show that real and perceived threats, together with physical disaster effects, are directly observable through the intensity and composition of Twitter’s message stream. We demonstrate that per-capita Twitter activity strongly correlates with the per-capita economic damage inflicted by the hurricane. We verify our findings for a wide range of disasters and suggest that massive online social networks can be used for rapid assessment of damage caused by a large-scale disaster.\n",
            "------------------------------------\n",
            "Title False Information on Web and Social Media: A Survey\n",
            "Author [{'authorId': '39703734', 'name': 'Srijan Kumar'}, {'authorId': '145474474', 'name': 'Neil Shah'}]\n",
            "Venue ArXiv\n",
            "year 2018\n",
            "Abstract False information can be created and spread easily through the web and social media platforms, resulting in widespread real-world impact. Characterizing how false information proliferates on social platforms and why it succeeds in deceiving readers are critical to develop efficient detection algorithms and tools for early detection. A recent surge of research in this area has aimed to address the key issues using methods based on feature engineering, graph mining, and information modeling. Majority of the research has primarily focused on two broad categories of false information: opinion-based (e.g., fake reviews), and fact-based (e.g., false news and hoaxes). Therefore, in this work, we present a comprehensive survey spanning diverse aspects of false information, namely (i) the actors involved in spreading false information, (ii) rationale behind successfully deceiving readers, (iii) quantifying the impact of false information, (iv) measuring its characteristics across different dimensions, and finally, (iv) algorithms developed to detect false information. In doing so, we create a unified framework to describe these recent methods and highlight a number of important directions for future research.\n",
            "------------------------------------\n",
            "Title Learning to Communicate with Deep Multi-Agent Reinforcement Learning\n",
            "Author [{'authorId': '145356667', 'name': 'Jakob N. Foerster'}, {'authorId': '3365565', 'name': 'Yannis Assael'}, {'authorId': '1737568', 'name': 'N. D. Freitas'}, {'authorId': '1766767', 'name': 'Shimon Whiteson'}]\n",
            "Venue NIPS\n",
            "year 2016\n",
            "Abstract We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.\n",
            "------------------------------------\n",
            "Title Rethinking segregation and integration: contributions of whole-brain modelling\n",
            "Author [{'authorId': '145333301', 'name': 'G. Deco'}, {'authorId': '1726111', 'name': 'G. Tononi'}, {'authorId': '2186036', 'name': 'M. Boly'}, {'authorId': '1988969', 'name': 'M. Kringelbach'}]\n",
            "Venue Nature Reviews Neuroscience\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Location-Aware Communications for 5G Networks: How location information can improve scalability, latency, and robustness of 5G\n",
            "Author [{'authorId': '9339652', 'name': 'R. D. Taranto'}, {'authorId': '2120832', 'name': 'L. S. Muppirisetty'}, {'authorId': '2100152', 'name': 'R. Raulefs'}, {'authorId': '145588715', 'name': 'D. Slock'}, {'authorId': '144793629', 'name': 'T. Svensson'}, {'authorId': '1697959', 'name': 'H. Wymeersch'}]\n",
            "Venue IEEE Signal Processing Magazine\n",
            "year 2014\n",
            "Abstract Fifth-generation (5G) networks will be the first generation to benefit from location information that is sufficiently precise to be leveraged in wireless network design and optimization. We argue that location information can aid in addressing several of the key challenges in 5G, complementary to existing and planned technological developments. These challenges include an increase in traffic and number of devices, robustness for mission-critical services, and a reduction in total energy consumption and latency. This article gives a broad overview of the growing research area of location-aware communications across different layers of the protocol stack. We highlight several promising trends, tradeoffs, and pitfalls.\n",
            "------------------------------------\n",
            "Title Fuzzy C-Means Clustering With Local Information and Kernel Metric for Image Segmentation\n",
            "Author [{'authorId': '144605807', 'name': 'Maoguo Gong'}, {'authorId': '145461906', 'name': 'Yan Liang'}, {'authorId': '145894051', 'name': 'Jiao Shi'}, {'authorId': '144531730', 'name': 'Wenping Ma'}, {'authorId': '47792894', 'name': 'Jingjing Ma'}]\n",
            "Venue IEEE Transactions on Image Processing\n",
            "year 2013\n",
            "Abstract In this paper, we present an improved fuzzy C-means (FCM) algorithm for image segmentation by introducing a tradeoff weighted fuzzy factor and a kernel metric. The tradeoff weighted fuzzy factor depends on the space distance of all neighboring pixels and their gray-level difference simultaneously. By using this factor, the new algorithm can accurately estimate the damping extent of neighboring pixels. In order to further enhance its robustness to noise and outliers, we introduce a kernel distance measure to its objective function. The new algorithm adaptively determines the kernel parameter by using a fast bandwidth selection rule based on the distance variance of all data points in the collection. Furthermore, the tradeoff weighted fuzzy factor and the kernel distance measure are both parameter free. Experimental results on synthetic and real images show that the new algorithm is effective and efficient, and is relatively independent of this type of noise.\n",
            "------------------------------------\n",
            "Title Localization algorithms of Wireless Sensor Networks: a survey\n",
            "Author [{'authorId': '143959165', 'name': 'Guangjie Han'}, {'authorId': '49507231', 'name': 'Huihui Xu'}, {'authorId': '1733236', 'name': 'T. Duong'}, {'authorId': '2241914', 'name': 'Jinfang Jiang'}, {'authorId': '144337552', 'name': 'T. Hara'}]\n",
            "Venue Telecommunications Systems\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Twisted photons: new quantum perspectives in high dimensions\n",
            "Author [{'authorId': '25612078', 'name': 'Manuel Erhard'}, {'authorId': '5987951', 'name': 'R. Fickler'}, {'authorId': '5906965', 'name': 'M. Krenn'}, {'authorId': '5385402', 'name': 'A. Zeilinger'}]\n",
            "Venue Light: Science & Applications\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Dynamic consent: a patient interface for twenty-first century research networks\n",
            "Author [{'authorId': '50322146', 'name': 'J. Kaye'}, {'authorId': '1749954', 'name': 'E. Whitley'}, {'authorId': '145325332', 'name': 'David Lund'}, {'authorId': '143758847', 'name': 'M. Morrison'}, {'authorId': '4495384', 'name': 'H. Teare'}, {'authorId': '6423976', 'name': 'Karen Melham'}]\n",
            "Venue European Journal of Human Genetics\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Diversity is All You Need: Learning Skills without a Reward Function\n",
            "Author [{'authorId': '8140754', 'name': 'Benjamin Eysenbach'}, {'authorId': '2129458064', 'name': 'Abhishek Gupta'}, {'authorId': '46920727', 'name': 'Julian Ibarz'}, {'authorId': '1736651', 'name': 'S. Levine'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2018\n",
            "Abstract Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN (\"Diversity is All You Need\"), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. In these environments, some of the learned skills correspond to solving the task, and each skill that solves the task does so in a distinct manner. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning\n",
            "------------------------------------\n",
            "Title The effect of electronic word of mouth on brand image and purchase intention\n",
            "Author [{'authorId': '2225249', 'name': 'M. Jalilvand'}, {'authorId': '2543537', 'name': 'Neda Samiei'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Purpose – Word‐of‐mouth (WOM) has been recognized as one of the most influential resources of information transmission. Advances in information technology and the emergence of online social network sites have changed the way information is transmitted. This phenomenon impacts consumers as this easily accessible information could greatly affect the consumption decision. The purpose of this paper is to examine the extent to which e‐WOM among consumers can influence brand image and purchase intention in the automobile industry.Design/methodology/approach – Measurement items are adapted from existing scales found in the marketing literature. Academic colleagues reviewed the items for face validity and readability. The scales are evaluated for reliability, convergent validity, and discriminant validity using data collected in a survey of Iran Khodro's prospective customers in Iran. A structural equation modeling procedure is applied to the examination of the influences of e‐WOM on brand image and purchase inte...\n",
            "------------------------------------\n",
            "Title Generalized Multiview Analysis: A discriminative latent space\n",
            "Author [{'authorId': '2109325320', 'name': 'Abhishek Sharma'}, {'authorId': '50333123', 'name': 'Abhishek Kumar'}, {'authorId': '1722360', 'name': 'Hal Daumé'}, {'authorId': '34734622', 'name': 'D. Jacobs'}]\n",
            "Venue 2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year 2012\n",
            "Abstract This paper presents a general multi-view feature extraction approach that we call Generalized Multiview Analysis or GMA. GMA has all the desirable properties required for cross-view classification and retrieval: it is supervised, it allows generalization to unseen classes, it is multi-view and kernelizable, it affords an efficient eigenvalue based solution and is applicable to any domain. GMA exploits the fact that most popular supervised and unsupervised feature extraction techniques are the solution of a special form of a quadratic constrained quadratic program (QCQP), which can be solved efficiently as a generalized eigenvalue problem. GMA solves a joint, relaxed QCQP over different feature spaces to obtain a single (non)linear subspace. Intuitively, GMA is a supervised extension of Canonical Correlational Analysis (CCA), which is useful for cross-view classification and retrieval. The proposed approach is general and has the potential to replace CCA whenever classification or retrieval is the purpose and label information is available. We outperform previous approaches for textimage retrieval on Pascal and Wiki text-image data. We report state-of-the-art results for pose and lighting invariant face recognition on the MultiPIE face dataset, significantly outperforming other approaches.\n",
            "------------------------------------\n",
            "Title FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack\n",
            "Author [{'authorId': '49968838', 'name': 'Y. Yarom'}, {'authorId': '1679867', 'name': 'K. Falkner'}]\n",
            "Venue USENIX Security Symposium\n",
            "year 2014\n",
            "Abstract Sharing memory pages between non-trusting processes is a common method of reducing the memory footprint of multi-tenanted systems. In this paper we demonstrate that, due to a weakness in the Intel X86 processors, page sharing exposes processes to information leaks. We present FLUSH+RELOAD, a cache side-channel attack technique that exploits this weakness to monitor access to memory lines in shared pages. Unlike previous cache side-channel attacks, FLUSH+RELOAD targets the Last-Level Cache (i.e. L3 on processors with three cache levels). Consequently, the attack program and the victim do not need to share the execution core. \n",
            " \n",
            "We demonstrate the efficacy of the FLUSH+RELOAD attack by using it to extract the private encryption keys from a victim program running GnuPG 1.4.13. We tested the attack both between two unrelated processes in a single operating system and between processes running in separate virtual machines. On average, the attack is able to recover 96.7% of the bits of the secret key by observing a single signature or decryption round.\n",
            "------------------------------------\n",
            "Title Climate services for society: origins, institutional arrangements, and design elements for an evaluation framework\n",
            "Author [{'authorId': '144176805', 'name': 'C. Vaughan'}, {'authorId': '5069917', 'name': 'S. Dessai'}]\n",
            "Venue Wiley Interdisciplinary Reviews: Climate Change\n",
            "year 2014\n",
            "Abstract Climate services involve the generation, provision, and contextualization of information and knowledge derived from climate research for decision making at all levels of society. These services are mainly targeted at informing adaptation to climate variability and change, widely recognized as an important challenge for sustainable development. This paper reviews the development of climate services, beginning with a historical overview, a short summary of improvements in climate information, and a description of the recent surge of interest in climate service development including, for example, the Global Framework for Climate Services, implemented by the World Meteorological Organization in October 2012. It also reviews institutional arrangements of selected emerging climate services across local, national, regional, and international scales. By synthesizing existing literature, the paper proposes four design elements of a climate services evaluation framework. These design elements include: problem identification and the decision‐making context; the characteristics, tailoring, and dissemination of the climate information; the governance and structure of the service, including the process by which it is developed; and the socioeconomic value of the service. The design elements are intended to serve as a guide to organize future work regarding the evaluation of when and whether climate services are more or less successful. The paper concludes by identifying future research questions regarding the institutional arrangements that support climate services and nascent efforts to evaluate them. WIREs Clim Change 2014, 5:587–603. doi: 10.1002/wcc.290\n",
            "------------------------------------\n",
            "Title Cortical information flow during flexible sensorimotor decisions\n",
            "Author [{'authorId': '35272407', 'name': 'M. Siegel'}, {'authorId': '2738354', 'name': 'T. J. Buschman'}, {'authorId': '2171934932', 'name': 'E. Miller'}]\n",
            "Venue Science\n",
            "year 2015\n",
            "Abstract Signal flow during sensorimotor choices Little is known about the flow of task signals across the brain. Siegel et al. simultaneously recorded from multiple units in the sensory, parietal, prefrontal, and motor cortex while monkeys were cued to perform one among two possible simple tasks. The proportion of neurons coding for stimuli, cues, tasks, and choices, and their response latency, varied across regions. Parietal and prefrontal brain regions encoded task information and choices with the same latency. Interestingly, all brain areas encoded all types of information. However, they differed functionally according to the proportions of neurons and their response latency. Science, this issue p. 1352 A dynamic network of cortical areas processing similar information but to different degrees is explored. During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.\n",
            "------------------------------------\n",
            "Title Preparing and conducting interviews to collect data.\n",
            "Author [{'authorId': '6416957', 'name': 'O. Doody'}, {'authorId': '5879877', 'name': 'M. Noonan'}]\n",
            "Venue Nurse Researcher\n",
            "year 2013\n",
            "Abstract AIM\n",
            "To describe three styles of interviews and discuss issues regarding planning and conducting interviews.\n",
            "\n",
            "\n",
            "BACKGROUND\n",
            "Interviews are probably the approach most used to collect data in studies. They are particularly useful in uncovering the story behind a participant's experiences. Researchers can follow a line of questions to gain information about a topic, or further explore responses or findings. But the researcher needs to plan and decide the format of the interview before collecting data.\n",
            "\n",
            "\n",
            "REVIEW METHODS\n",
            "The authors included papers on structured, unstructured and semi-structured interviews published in a peer-reviewed joumrnal and in English.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Interviews are one of the most common metods of data collection in qualitative research. However they require the researcher to have a sound understanding of their use and appropriateness. The ability to conduct interviews is one that develops over time and to aid the researcher in developing their interview skills they should consult with other researchers, seeking comments and advice and, critically, to appraise audio recordings.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "This article aims to support students who are undertaking research modules as part of their academic studies, writing a research proposal or novice researchers who are about to use interviews as a means of data collection.\n",
            "\n",
            "\n",
            "IMPLICATIONS FOR RESEARCH/PRACTICE\n",
            "To conduct a successful interview, researchers need to develop their interview technique, choose the right method and carefully plan for all aspects of the process.\n",
            "------------------------------------\n",
            "Title DeViSE: A Deep Visual-Semantic Embedding Model\n",
            "Author [{'authorId': '2279670', 'name': 'Andrea Frome'}, {'authorId': '32131713', 'name': 'G. Corrado'}, {'authorId': '1789737', 'name': 'Jonathon Shlens'}, {'authorId': '1751569', 'name': 'Samy Bengio'}, {'authorId': '49959210', 'name': 'J. Dean'}, {'authorId': '1706809', 'name': 'M. Ranzato'}, {'authorId': '2047446108', 'name': 'Tomas Mikolov'}]\n",
            "Venue NIPS\n",
            "year 2013\n",
            "Abstract Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.\n",
            "------------------------------------\n",
            "Title The Structural Virality of Online Diffusion\n",
            "Author [{'authorId': '143802734', 'name': 'Sharad Goel'}, {'authorId': '32071555', 'name': 'Ashton Anderson'}, {'authorId': '40368603', 'name': 'J. Hofman'}, {'authorId': '1783914', 'name': 'D. Watts'}]\n",
            "Venue Management Sciences\n",
            "year 2015\n",
            "Abstract Viral products and ideas are intuitively understood to grow through a person-to-person diffusion process analogous to the spread of an infectious disease; however, until recently it has been prohibitively difficult to directly observe purportedly viral events, and thus to rigorously quantify or characterize their structural properties. Here we propose a formal measure of what we label “structural virality” that interpolates between two conceptual extremes: content that gains its popularity through a single, large broadcast and that which grows through multiple generations with any one individual directly responsible for only a fraction of the total adoption. We use this notion of structural virality to analyze a unique data set of a billion diffusion events on Twitter, including the propagation of news stories, videos, images, and petitions. We find that across all domains and all sizes of events, online diffusion is characterized by surprising structural diversity; that is, popular events regularly grow via both broadcast and viral mechanisms, as well as essentially all conceivable combinations of the two. Nevertheless, we find that structural virality is typically low, and remains so independent of size, suggesting that popularity is largely driven by the size of the largest broadcast. Finally, we attempt to replicate these findings with a model of contagion characterized by a low infection rate spreading on a scale-free network. We find that although several of our empirical findings are consistent with such a model, it fails to replicate the observed diversity of structural virality, thereby suggesting new directions for future modeling efforts. This paper was accepted by Lorin Hitt, information systems.\n",
            "------------------------------------\n",
            "Title Cognitive Load Theory: Implications for medical education: AMEE Guide No. 86\n",
            "Author [{'authorId': '50621712', 'name': 'John Q. Young'}, {'authorId': '5013187', 'name': 'J. V. van Merrienboer'}, {'authorId': '3572700', 'name': 'S. Durning'}, {'authorId': '144999466', 'name': 'O. ten Cate'}]\n",
            "Venue Medical Teacher\n",
            "year 2014\n",
            "Abstract Abstract Cognitive Load Theory (CLT) builds upon established models of human memory that include the subsystems of sensory, working and long-term memory. Working memory (WM) can only process a limited number of information elements at any given time. This constraint creates a “bottleneck” for learning. CLT identifies three types of cognitive load that impact WM: intrinsic load (associated with performing essential aspects of the task), extraneous load (associated with non-essential aspects of the task) and germane load (associated with the deliberate use of cognitive strategies that facilitate learning). When the cognitive load associated with a task exceeds the learner’s WM capacity, performance and learning is impaired. To facilitate learning, CLT researchers have developed instructional techniques that decrease extraneous load (e.g. worked examples), titrate intrinsic load to the developmental stage of the learner (e.g. simplify task without decontextualizing) and ensure that unused WM capacity is dedicated to germane load, i.e. cognitive learning strategies. A number of instructional techniques have been empirically tested. As learners’ progress, curricula must also attend to the expertise-reversal effect. Instructional techniques that facilitate learning among early learners may not help and may even interfere with learning among more advanced learners. CLT has particular relevance to medical education because many of the professional activities to be learned require the simultaneous integration of multiple and varied sets of knowledge, skills and behaviors at a specific time and place. These activities possess high “element interactivity” and therefore impose a cognitive load that may surpass the WM capacity of the learner. Applications to various medical education settings (classroom, workplace and self-directed learning) are explored.\n",
            "------------------------------------\n",
            "Title PEGASIS : Power-Efficient Gathering in Sensor Information Systems\n",
            "Author [{'authorId': '66618645', 'name': 'A. Sankaliya'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Sensor network consisting of nodes with limited battery power and wireless communications are deployed to collect useful information from the field. The main idea in PEGASIS is for each node to receive from and transmit to close neighbors and take turns being the leader for transmission to the BS. This approach distributes the energy load evenly among the sensor nodes in the network. Sensor nodes are randomly deployed in the sensor field, and therefore, the i th node is at a random location. The nodes will be organized to form a chain, which can either be accomplished by the sensor nodes themselves using a greedy algorithm. The algorithm to resolve the unbalanced energy consumption problem caused by long distance data transmission of some nodes in a chain formed by the greedy algorithm.\n",
            "------------------------------------\n",
            "Title Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs\n",
            "Author [{'authorId': '2577847', 'name': 'Vishwanath A. Sindagi'}, {'authorId': '1741177', 'name': 'Vishal M. Patel'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2017\n",
            "Abstract We present a novel method called Contextual Pyramid CNN (CP-CNN) for generating high-quality crowd density and count estimation by explicitly incorporating global and local contextual information of crowd images. The proposed CP-CNN consists of four modules: Global Context Estimator (GCE), Local Context Estimator (LCE), Density Map Estimator (DME) and a Fusion-CNN (F-CNN). GCE is a VGG-16 based CNN that encodes global context and it is trained to classify input images into different density classes, whereas LCE is another CNN that encodes local context information and it is trained to perform patch-wise classification of input images into different density classes. DME is a multi-column architecture-based CNN that aims to generate high-dimensional feature maps from the input image which are fused with the contextual information estimated by GCE and LCE using F-CNN. To generate high resolution and high-quality density maps, F-CNN uses a set of convolutional and fractionally-strided convolutional layers and it is trained along with the DME in an end-to-end fashion using a combination of adversarial loss and pixellevel Euclidean loss. Extensive experiments on highly challenging datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title Machine Learning Models that Remember Too Much\n",
            "Author [{'authorId': '3469125', 'name': 'Congzheng Song'}, {'authorId': '1707461', 'name': 'T. Ristenpart'}, {'authorId': '1723945', 'name': 'Vitaly Shmatikov'}]\n",
            "Venue Conference on Computer and Communications Security\n",
            "year 2017\n",
            "Abstract Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data. We consider a malicious ML provider who supplies model-training code to the data holder, does \\emph{not} observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that \"memorize\" information about the training dataset in the model\\textemdash yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data.\n",
            "------------------------------------\n",
            "Title Pyramid Attention Network for Semantic Segmentation\n",
            "Author [{'authorId': '2118384504', 'name': 'Hanchao Li'}, {'authorId': '40448951', 'name': 'Pengfei Xiong'}, {'authorId': '1733982458', 'name': 'Jie An'}, {'authorId': '3418263', 'name': 'Lingxue Wang'}]\n",
            "Venue British Machine Vision Conference\n",
            "year 2018\n",
            "Abstract A Pyramid Attention Network(PAN) is proposed to exploit the impact of global contextual information in semantic segmentation. Different from most existing works, we combine attention mechanism and spatial pyramid to extract precise dense features for pixel labeling instead of complicated dilated convolution and artificially designed decoder networks. Specifically, we introduce a Feature Pyramid Attention module to perform spatial pyramid attention structure on high-level output and combining global pooling to learn a better feature representation, and a Global Attention Upsample module on each decoder layer to provide global context as a guidance of low-level features to select category localization details. The proposed approach achieves state-of-the-art performance on PASCAL VOC 2012 and Cityscapes benchmarks with a new record of mIoU accuracy 84.0% on PASCAL VOC 2012, while training without COCO dataset.\n",
            "------------------------------------\n",
            "Title A survey on information visualization: recent advances and challenges\n",
            "Author [{'authorId': '48641970', 'name': 'Shixia Liu'}, {'authorId': '1684136', 'name': 'Weiwei Cui'}, {'authorId': '121962020', 'name': 'Yingcai Wu'}, {'authorId': '145823303', 'name': 'Mengchen Liu'}]\n",
            "Venue The Visual Computer\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Activities at the Universal Protein Resource (UniProt)\n",
            "Author [{'authorId': '1722884', 'name': 'R. Apweiler'}, {'authorId': '46888415', 'name': 'A. Bateman'}, {'authorId': '46502933', 'name': 'M. Martin'}, {'authorId': '1389548621', 'name': 'C. O’Donovan'}, {'authorId': '3093838', 'name': 'M. Magrane'}, {'authorId': '1401171840', 'name': 'Y. Alam-Faruque'}, {'authorId': '2009348', 'name': 'E. Alpi'}, {'authorId': '108548032', 'name': 'R. Antunes'}, {'authorId': '113281162', 'name': 'J. Arganiska'}, {'authorId': '1507173507', 'name': 'E. Casanova'}, {'authorId': '3052035', 'name': 'B. Bely'}, {'authorId': '108038326', 'name': 'M. Bingley'}, {'authorId': '146335540', 'name': 'C. Bonilla'}, {'authorId': '35510297', 'name': 'R. Britto'}, {'authorId': '3224753', 'name': 'B. Bursteinas'}, {'authorId': '145781926', 'name': 'W. Chan'}, {'authorId': '2641497', 'name': 'G. Chavali'}, {'authorId': '1397640656', 'name': 'Elena Cibrián-Uhalte'}, {'authorId': '2110269114', 'name': 'A. D. Silva'}, {'authorId': '1615282877', 'name': 'M. D. Giorgi'}, {'authorId': '2407842', 'name': 'Tunca Dogan'}, {'authorId': '116132933', 'name': 'F. Fazzini'}, {'authorId': '145750693', 'name': 'P. Gane'}, {'authorId': '66390147', 'name': 'Lg Castro'}, {'authorId': '11852405', 'name': 'P. Garmiri'}, {'authorId': '1413140200', 'name': 'E. Hatton-Ellis'}, {'authorId': '6371470', 'name': 'R. Hieta'}, {'authorId': '1757710', 'name': 'R. Huntley'}, {'authorId': '113930130', 'name': 'D. Legge'}, {'authorId': '120639738', 'name': 'W. Liu'}, {'authorId': '2107196207', 'name': 'J. Luo'}, {'authorId': '1694551096', 'name': 'Alistair MacDougall'}, {'authorId': '3726244', 'name': 'P. Mutowo'}, {'authorId': '144057990', 'name': 'Andrew Nightingale'}, {'authorId': '143945011', 'name': 'S. Orchard'}, {'authorId': '46909123', 'name': 'K. Pichler'}, {'authorId': '2296806', 'name': 'D. Poggioli'}, {'authorId': '2595483', 'name': 'S. Pundir'}, {'authorId': '114613968', 'name': 'L. Pureza'}, {'authorId': '39589857', 'name': 'G. Qi'}, {'authorId': '2960827', 'name': 'S. Rosanoff'}, {'authorId': '1766624', 'name': 'Rabie Saidi'}, {'authorId': '1955735', 'name': 'T. Sawford'}, {'authorId': '46269547', 'name': 'A. Shypitsyna'}, {'authorId': '122507852', 'name': 'E. Turner'}, {'authorId': '115088858', 'name': 'Volynkin'}, {'authorId': '49274490', 'name': 'T. Wardell'}, {'authorId': '1979856', 'name': 'X. Watkins'}, {'authorId': '1694538098', 'name': 'H. Zellner'}, {'authorId': '47199782', 'name': 'M. Corbett'}, {'authorId': '120795058', 'name': 'M. Donnelly'}, {'authorId': '143898173', 'name': 'P. V. Rensburg'}, {'authorId': '3036080', 'name': 'M. Goujon'}, {'authorId': '2104631', 'name': 'H. McWilliam'}, {'authorId': '144037581', 'name': 'R. Lopez'}, {'authorId': '1793133', 'name': 'I. Xenarios'}, {'authorId': '31613661', 'name': 'L. Bougueleret'}, {'authorId': '145718058', 'name': 'A. Bridge'}, {'authorId': '3322351', 'name': 'S. Poux'}, {'authorId': '1876480', 'name': 'N. Redaschi'}, {'authorId': '2380233', 'name': 'L. Aimo'}, {'authorId': '38473019', 'name': 'A. Auchincloss'}, {'authorId': '2910143', 'name': 'K. Axelsen'}, {'authorId': '15660940', 'name': 'Parit Bansal'}, {'authorId': '3004899', 'name': 'Delphine Baratin'}, {'authorId': '2577986', 'name': 'P. Binz'}, {'authorId': '48999874', 'name': 'M. Blatter'}, {'authorId': '3170233', 'name': 'B. Boeckmann'}, {'authorId': '3349310', 'name': 'Jerven T. Bolleman'}, {'authorId': '2649909', 'name': 'E. Boutet'}, {'authorId': '2314654', 'name': 'L. Breuza'}, {'authorId': '1413442898', 'name': 'C. Casal-Casas'}, {'authorId': '144901947', 'name': 'E. D. Castro'}, {'authorId': '48732022', 'name': 'L. Cerutti'}, {'authorId': '2344478', 'name': 'E. Coudert'}, {'authorId': '2509510', 'name': 'Béatrice A. Cuche'}, {'authorId': '1491922007', 'name': 'M. Doche'}, {'authorId': '114107279', 'name': 'D. Dornevil'}, {'authorId': '2422635', 'name': 'Severine Duvaud'}, {'authorId': '35099951', 'name': 'A. Estreicher'}, {'authorId': '115645263', 'name': 'L. Famiglietti'}, {'authorId': '1765161', 'name': 'M. Feuermann'}, {'authorId': '1784123', 'name': 'E. Gasteiger'}, {'authorId': '3168502', 'name': 'S. Gehant'}, {'authorId': '97320356', 'name': 'Gerritsen'}, {'authorId': '2057009', 'name': 'A. Gos'}, {'authorId': '1401171798', 'name': 'N. Gruaz-Gumowski'}, {'authorId': '2480093', 'name': 'U. Hinz'}, {'authorId': '3304621', 'name': 'C. Hulo'}, {'authorId': '1405841428', 'name': 'J. James'}, {'authorId': '87711179', 'name': 'F. Jungo'}, {'authorId': '41171240', 'name': 'G. Keller'}, {'authorId': '2065578603', 'name': 'Lara'}, {'authorId': '104960556', 'name': 'P. Lemercier'}, {'authorId': '31689265', 'name': 'J. Lew'}, {'authorId': '3177854', 'name': 'D. Lieberherr'}, {'authorId': '2386460', 'name': 'T. Lombardot'}, {'authorId': '144173707', 'name': 'X. Martin'}, {'authorId': '143827678', 'name': 'P. Masson'}, {'authorId': '2258061', 'name': 'A. Morgat'}, {'authorId': '1400530264', 'name': 'T. Neto'}, {'authorId': '11541096', 'name': 'S. Paesano'}, {'authorId': '3275738', 'name': 'I. Pedruzzi'}, {'authorId': '2649548', 'name': 'S. Pilbout'}, {'authorId': '37120465', 'name': 'Monica Pozzato'}, {'authorId': '2562543', 'name': 'Manuela Pruess'}, {'authorId': '40291345', 'name': 'C. Rivoire'}, {'authorId': '1795497', 'name': 'B. Roechert'}, {'authorId': '153637488', 'name': 'Michel Schneider'}, {'authorId': '1897062', 'name': 'C. Sigrist'}, {'authorId': '1491922105', 'name': 'K. Sonesson'}, {'authorId': '113194025', 'name': 'S. Staehli'}, {'authorId': '48481464', 'name': 'A. Stutz'}, {'authorId': '40660854', 'name': 'S. Sundaram'}, {'authorId': '2224505', 'name': 'M. Tognolli'}, {'authorId': '116530309', 'name': 'L. Verbregue'}, {'authorId': '2070787', 'name': 'A. Veuthey'}, {'authorId': '1744726', 'name': 'Cathy H. Wu'}, {'authorId': '1734053', 'name': 'C. Arighi'}, {'authorId': '3177811', 'name': 'L. Arminski'}, {'authorId': '1763713', 'name': 'Chuming Chen'}, {'authorId': '2146309399', 'name': 'Youhai H. Chen'}, {'authorId': '2000634', 'name': 'J. Garavelli'}, {'authorId': '2446311', 'name': 'Hongzhan Huang'}, {'authorId': '50401356', 'name': 'K. Laiho'}, {'authorId': '3250223', 'name': 'P. McGarvey'}, {'authorId': '1776336', 'name': 'D. Natale'}, {'authorId': '3069741', 'name': 'Baris E. Suzek'}, {'authorId': '153787929', 'name': 'C. R. Vinayaka'}, {'authorId': '49110720', 'name': 'Q. Wang'}, {'authorId': '2157381270', 'name': 'Y. Wang'}, {'authorId': '38717446', 'name': 'L. Yeh'}, {'authorId': '117456035', 'name': 'Yerramalla'}, {'authorId': '9818586', 'name': 'J. Zhang'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2013\n",
            "Abstract The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to provide the scientific community with a comprehensive, high-quality and freely accessible resource of protein sequences and functional annotation. It integrates, interprets and standardizes data from literature and numerous resources to achieve the most comprehensive catalog possible of protein information. The central activities are the biocuration of the UniProt Knowledgebase and the dissemination of these data through our Web site and web services. UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR). UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.\n",
            "------------------------------------\n",
            "Title Constrained Nonnegative Matrix Factorization for Image Representation\n",
            "Author [{'authorId': '1410056390', 'name': 'Haifeng Liu'}, {'authorId': '144437322', 'name': 'Zhaohui Wu'}, {'authorId': '67180560', 'name': 'Xuelong Li'}, {'authorId': '1724421', 'name': 'Deng Cai'}, {'authorId': '153652752', 'name': 'Thomas S. Huang'}]\n",
            "Venue IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year 2012\n",
            "Abstract Nonnegative matrix factorization (NMF) is a popular technique for finding parts-based, linear representations of nonnegative data. It has been successfully applied in a wide range of applications such as pattern recognition, information retrieval, and computer vision. However, NMF is essentially an unsupervised method and cannot make use of label information. In this paper, we propose a novel semi-supervised matrix decomposition method, called Constrained Nonnegative Matrix Factorization (CNMF), which incorporates the label information as additional constraints. Specifically, we show how explicitly combining label information improves the discriminating power of the resulting matrix decomposition. We explore the proposed CNMF method with two cost function formulations and provide the corresponding update solutions for the optimization problems. Empirical experiments demonstrate the effectiveness of our novel algorithm in comparison to the state-of-the-art approaches through a set of evaluations based on real-world applications.\n",
            "------------------------------------\n",
            "Title Collaborative filtering recommender systems\n",
            "Author [{'authorId': '3095698', 'name': 'M. Nilashi'}, {'authorId': '19381012', 'name': 'Karamollah Bagherifard'}, {'authorId': '66083398', 'name': 'O. Ibrahim'}, {'authorId': '40397208', 'name': 'H. Alizadeh'}, {'authorId': '70627370', 'name': 'L. Nojeem'}, {'authorId': '70547150', 'name': 'Nazanin Roozegar'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Recommender Systems are software tools and techniques for suggesting items to users by considering their preferences in an automated fashion. The suggestions provided are aimed at support users in various decision- making processes. Technically, recommender system has their origins in different fields such as Information Retrieval (IR), text classification, machine learning and Decision Support Systems (DSS). Recommender systems are used to address the Information Overload (IO) problem by recommending potentially interesting or useful items to users. They have proven to be worthy tools for online users to deal with the IO and have become one of the most popular and powerful tools in E-commerce. Many existing recommender systems rely on the Collaborative Filtering (CF) and have been extensively used in E-commerce .They have proven to be very effective with powerful techniques in many famous E-commerce companies. This study presents an overview of the field of recommender systems with current generation of recommendation methods and examines comprehensively CF systems with its algorithms.\n",
            "------------------------------------\n",
            "Title A Survey on Network Embedding\n",
            "Author [{'authorId': '143738684', 'name': 'Peng Cui'}, {'authorId': '2118449003', 'name': 'Xiao Wang'}, {'authorId': '145525190', 'name': 'J. Pei'}, {'authorId': '145583986', 'name': 'Wenwu Zhu'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2017\n",
            "Abstract Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.\n",
            "------------------------------------\n",
            "Title Gender differences in health information behaviour: a Finnish population-based survey.\n",
            "Author [{'authorId': '3157197', 'name': 'S. Ek'}]\n",
            "Venue Health Promotion International\n",
            "year 2015\n",
            "Abstract Narrowing the gaps in health outcomes, including those between men and women, has been a pronounced goal on the agenda of the Finnish health authorities since the mid-1980s. But still there is a huge gap in favour of women when it comes to life expectancy at birth. People's health information behaviour, that is how people seek, obtain, evaluate, categorize and use relevant health-related information to perform desired health behaviours, is a critical prerequisite to appropriate and consistent performances of these behaviours. With respect to gender, it has been noted that men often are unwilling and lack the motivation to engage with health-related information. The purpose of this study was to investigate how gender affects health information behaviour in the Finnish population aged 18-65 years. The survey data were collected via a questionnaire which was posted to a representative cross section consisting of 1500 Finnish citizens. The statistical analysis consists of ANOVA F-tests and Fisher's exact tests. The results show that women were more interested in and reported much more active seeking of health-related information, paid more attention to potential worldwide pandemics and were much more attentive as to how the goods they purchase in everyday life affect their health than men did. Women also reported receiving far more informal health-related information from close family members, other kin and friends/workmates than men did. Thus, to succeed in public health promotion and interventions the measures taken should be much more sensitive to the gender gap in health information behaviour.\n",
            "------------------------------------\n",
            "Title Gene Regulatory Network Inference from Single-Cell Data Using Multivariate Information Measures\n",
            "Author [{'authorId': '26407347', 'name': 'Thalia E. Chan'}, {'authorId': '145518141', 'name': 'M. Stumpf'}, {'authorId': '3633944', 'name': 'A. Babtie'}]\n",
            "Venue bioRxiv\n",
            "year 2017\n",
            "Abstract While single-cell gene expression experiments present new challenges for data processing, the cell-to-cell variability observed also reveals statistical relationships that can be used by information theory. Here, we use multivariate information theory to explore the statistical dependencies between triplets of genes in single-cell gene expression datasets. We develop PIDC, a fast, efficient algorithm that uses partial information decomposition (PID) to identify regulatory relationships between genes. We thoroughly evaluate the performance of our algorithm and demonstrate that the higher order information captured by PIDC allows it to outperform pairwise mutual information-based algorithms when recovering true relationships present in simulated data. We also infer gene regulatory networks from three experimental single-cell data sets and illustrate how network context, choices made during analysis, and sources of variability affect network inference. PIDC tutorials and open-source software for estimating PID are available here: https://github.com/Tchanders/network_inference_tutorials. PIDC should facilitate the identification of putative functional relationships and mechanistic hypotheses from single-cell transcriptomic data.\n",
            "------------------------------------\n",
            "Title Framework for Managing the COVID-19 Infodemic: Methods and Results of an Online, Crowdsourced WHO Technical Consultation\n",
            "Author [{'authorId': '4147106', 'name': 'V. Tangcharoensathien'}, {'authorId': '4172891', 'name': 'N. Calleja'}, {'authorId': '145825234', 'name': 'Tim Nguyen'}, {'authorId': '5904629', 'name': 'T. Purnat'}, {'authorId': '1420050895', 'name': \"Marcelo D'agostino\"}, {'authorId': '1402721998', 'name': 'Sebastian Garcia-Saiso'}, {'authorId': '46655044', 'name': 'M. Landry'}, {'authorId': '5393901', 'name': 'A. Rashidian'}, {'authorId': '144592449', 'name': 'Clayton Hamilton'}, {'authorId': '1753173887', 'name': 'Abdelhalim AbdAllah'}, {'authorId': '11737239', 'name': 'I. Ghiga'}, {'authorId': '46685735', 'name': 'Alexandra Hill'}, {'authorId': '5504357', 'name': 'D. Hougendobler'}, {'authorId': '39287062', 'name': 'J. van Andel'}, {'authorId': '3877599', 'name': 'M. Nunn'}, {'authorId': '144196594', 'name': 'Ian Brooks'}, {'authorId': '3130592', 'name': 'P. Sacco'}, {'authorId': '46617468', 'name': 'M. De Domenico'}, {'authorId': '2723877', 'name': 'Philip Mai'}, {'authorId': '48569628', 'name': 'A. Gruzd'}, {'authorId': '1475786557', 'name': 'Alexandre Alaphilippe'}, {'authorId': '3782320', 'name': 'S. Briand'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2020\n",
            "Abstract Background An infodemic is an overabundance of information—some accurate and some not—that occurs during an epidemic. In a similar manner to an epidemic, it spreads between humans via digital and physical information systems. It makes it hard for people to find trustworthy sources and reliable guidance when they need it. Objective A World Health Organization (WHO) technical consultation on responding to the infodemic related to the coronavirus disease (COVID-19) pandemic was held, entirely online, to crowdsource suggested actions for a framework for infodemic management. Methods A group of policy makers, public health professionals, researchers, students, and other concerned stakeholders was joined by representatives of the media, social media platforms, various private sector organizations, and civil society to suggest and discuss actions for all parts of society, and multiple related professional and scientific disciplines, methods, and technologies. A total of 594 ideas for actions were crowdsourced online during the discussions and consolidated into suggestions for an infodemic management framework. Results The analysis team distilled the suggestions into a set of 50 proposed actions for a framework for managing infodemics in health emergencies. The consultation revealed six policy implications to consider. First, interventions and messages must be based on science and evidence, and must reach citizens and enable them to make informed decisions on how to protect themselves and their communities in a health emergency. Second, knowledge should be translated into actionable behavior-change messages, presented in ways that are understood by and accessible to all individuals in all parts of all societies. Third, governments should reach out to key communities to ensure their concerns and information needs are understood, tailoring advice and messages to address the audiences they represent. Fourth, to strengthen the analysis and amplification of information impact, strategic partnerships should be formed across all sectors, including but not limited to the social media and technology sectors, academia, and civil society. Fifth, health authorities should ensure that these actions are informed by reliable information that helps them understand the circulating narratives and changes in the flow of information, questions, and misinformation in communities. Sixth, following experiences to date in responding to the COVID-19 infodemic and the lessons from other disease outbreaks, infodemic management approaches should be further developed to support preparedness and response, and to inform risk mitigation, and be enhanced through data science and sociobehavioral and other research. Conclusions The first version of this framework proposes five action areas in which WHO Member States and actors within society can apply, according to their mandate, an infodemic management approach adapted to national contexts and practices. Responses to the COVID-19 pandemic and the related infodemic require swift, regular, systematic, and coordinated action from multiple sectors of society and government. It remains crucial that we promote trusted information and fight misinformation, thereby helping save lives.\n",
            "------------------------------------\n",
            "Title Silent Listeners: The Evolution of Privacy and Disclosure on Facebook\n",
            "Author [{'authorId': '35371463', 'name': 'F. Stutzman'}, {'authorId': '33731953', 'name': 'R. Gross'}, {'authorId': '1683053', 'name': 'A. Acquisti'}]\n",
            "Venue Journal of Privacy and Confidentiality\n",
            "year 2013\n",
            "Abstract Over the past decade, social network sites have experienced dramatic growth in popularity, reaching most demographics and providing new opportunities for interaction and socialization. Through this growth, users have been challenged to manage novel privacy concerns and balance nuanced trade-offs between disclosing and withholding personal information. To date, however, no study has documented how privacy and disclosure evolved on social network sites over an extended period of time. In this manuscript we use profile data from a longitudinal panel of 5,076 Facebook users to understand how their privacy and disclosure behavior changed between 2005---the early days of the network---and 2011. Our analysis highlights three contrasting trends. First, over time Facebook users in our dataset exhibited increasingly privacy-seeking behavior, progressively decreasing the amount of personal data shared publicly with unconnected profiles in the same network. However, and second, changes implemented by Facebook near the end of the period of time under our observation arrested or in some cases inverted that trend. Third, the amount and scope of personal information that Facebook users revealed privately to other connected profiles actually increased over time---and because of that, so did disclosures to ``silent listeners'' on the network: Facebook itself, third-party apps, and (indirectly) advertisers. These findings highlight the tension between privacy choices as expressions of individual subjective preferences, and the role of the environment in shaping those choices.\n",
            "------------------------------------\n",
            "Title Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts\n",
            "Author [{'authorId': '1790831', 'name': 'C. D. Santos'}, {'authorId': '1771662', 'name': 'M. Gatti'}]\n",
            "Venue International Conference on Computational Linguistics\n",
            "year 2014\n",
            "Abstract Sentiment analysis of short texts such as single sentences and Twitter messages is challenging because of the limited contextual information that they normally contain. Effectively solving this task requires strategies that combine the small text content with prior knowledge and use more than just bag-of-words. In this work we propose a new deep convolutional neural network that exploits from characterto sentence-level information to perform sentiment analysis of short texts. We apply our approach for two corpora of two different domains: the Stanford Sentiment Treebank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentiment corpus (STS), which contains Twitter messages. For the SSTb corpus, our approach achieves state-of-the-art results for single sentence sentiment prediction in both binary positive/negative classification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy. For the STS corpus, our approach achieves a sentiment prediction accuracy of 86.4%.\n",
            "------------------------------------\n",
            "Title An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author [{'authorId': '145751896', 'name': 'Daniel Russo'}, {'authorId': '1731282', 'name': 'Benjamin Van Roy'}]\n",
            "Venue Journal of machine learning research\n",
            "year 2014\n",
            "Abstract We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title Variable selection with stepwise and best subset approaches.\n",
            "Author [{'authorId': '7969555', 'name': 'Wentao Bao'}]\n",
            "Venue Annals of Translational Medicine\n",
            "year 2016\n",
            "Abstract While purposeful selection is performed partly by software and partly by hand, the stepwise and best subset approaches are automatically performed by software. Two R functions stepAIC() and bestglm() are well designed for stepwise and best subset regression, respectively. The stepAIC() function begins with a full or null model, and methods for stepwise regression can be specified in the direction argument with character values \"forward\", \"backward\" and \"both\". The bestglm() function begins with a data frame containing explanatory variables and response variables. The response variable should be in the last column. Varieties of goodness-of-fit criteria can be specified in the IC argument. The Bayesian information criterion (BIC) usually results in more parsimonious model than the Akaike information criterion.\n",
            "------------------------------------\n",
            "Title Towards Actualizing the Value Potential of Korea Health Insurance Review and Assessment (HIRA) Data as a Resource for Health Research: Strengths, Limitations, Applications, and Strategies for Optimal Use of HIRA Data\n",
            "Author [{'authorId': '4721986', 'name': 'Jee-Ae Kim'}, {'authorId': '2110653812', 'name': 'Seokjun Yoon'}, {'authorId': '4783347', 'name': 'L. Kim'}, {'authorId': '4852074', 'name': 'Dong Sook Kim'}]\n",
            "Venue Journal of Korean medical science\n",
            "year 2017\n",
            "Abstract Health Insurance and Review Assessment (HIRA) in South Korea, also called National Health Insurance (NHI) data, is a repository of claims data collected in the process of reimbursing healthcare providers. Under the universal coverage system, having fee-for-services covering all citizens in South Korea, HIRA contains comprehensive and rich information pertaining to healthcare services such as treatments, pharmaceuticals, procedures, and diagnoses for almost 50 million beneficiaries. This corpus of HIRA data, which constitutes a large repository of data in the healthcare sector, has enormous potential to create value in several ways: enhancing the efficiency of the healthcare delivery system without compromising quality of care; adding supporting evidence for a given intervention; and providing the information needed to prevent (or monitor) adverse events. In order to actualize this potential, HIRA data need to actively be utilized for research. Thus understanding this data would greatly enhance this potential. We introduce HIRA data as an important source for health research and provide guidelines for researchers who are currently utilizing HIRA, or interested in doing so, to answer their research questions. We present the characteristics and structure of HIRA data. We discuss strengths and limitations that should be considered in conducting research with HIRA data and suggest strategies for optimal utilization of HIRA data by reviewing published research using HIRA data.\n",
            "------------------------------------\n",
            "Title The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics\n",
            "Author [{'authorId': '1743246', 'name': 'D. Ivanov'}, {'authorId': '2768367', 'name': 'A. Dolgui'}, {'authorId': '1744453', 'name': 'B. Sokolov'}]\n",
            "Venue International Journal of Production Research\n",
            "year 2018\n",
            "Abstract The impact of digitalisation and Industry 4.0 on the ripple effect and disruption risk control analytics in the supply chain (SC) is studied. The research framework combines the results from two isolated areas, i.e. the impact of digitalisation on SC management (SCM) and the impact of SCM on the ripple effect control. To the best of our knowledge, this is the first study that connects business, information, engineering and analytics perspectives on digitalisation and SC risks. This paper does not pretend to be encyclopedic, but rather analyses recent literature and case-studies seeking to bring the discussion further with the help of a conceptual framework for researching the relationships between digitalisation and SC disruptions risks. In addition, it emerges with an SC risk analytics framework. It analyses perspectives and future transformations that can be expected in transition towards cyber-physical SCs. With these two frameworks, this study contributes to the literature by answering the questions of (1) what relations exist between big data analytics, Industry 4.0, additive manufacturing, advanced trace & tracking systems and SC disruption risks; (2) how digitalisation can contribute to enhancing ripple effect control; and (3) what digital technology-based extensions can trigger the developments towards SC risk analytics.\n",
            "------------------------------------\n",
            "Title Networked privacy: How teenagers negotiate context in social media\n",
            "Author [{'authorId': '2929988', 'name': 'Alice E. Marwick'}, {'authorId': '38818867', 'name': 'D. Boyd'}]\n",
            "Venue New Media & Society\n",
            "year 2014\n",
            "Abstract While much attention is given to young people’s online privacy practices on sites like Facebook, current theories of privacy fail to account for the ways in which social media alter practices of information-sharing and visibility. Traditional models of privacy are individualistic, but the realities of privacy reflect the location of individuals in contexts and networks. The affordances of social technologies, which enable people to share information about others, further preclude individual control over privacy. Despite this, social media technologies primarily follow technical models of privacy that presume individual information control. We argue that the dynamics of sites like Facebook have forced teens to alter their conceptions of privacy to account for the networked nature of social media. Drawing on their practices and experiences, we offer a model of networked privacy to explain how privacy is achieved in networked publics.\n",
            "------------------------------------\n",
            "Title Thermodynamics from Information\n",
            "Author [{'authorId': '9842315', 'name': 'M. N. Bera'}, {'authorId': '144131351', 'name': 'A. Winter'}, {'authorId': '145453642', 'name': 'M. Lewenstein'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Crowdsourcing, Citizen Science or Volunteered Geographic Information? The Current State of Crowdsourced Geographic Information\n",
            "Author [{'authorId': '145098716', 'name': 'L. See'}, {'authorId': '143641668', 'name': 'P. Mooney'}, {'authorId': '145181054', 'name': 'G. Foody'}, {'authorId': '1754110', 'name': 'L. Bastin'}, {'authorId': '48982395', 'name': 'A. Comber'}, {'authorId': '3194416', 'name': 'J. Estima'}, {'authorId': '144822493', 'name': 'S. Fritz'}, {'authorId': '2915345', 'name': 'N. Kerle'}, {'authorId': '144069314', 'name': 'B. Jiang'}, {'authorId': '2895530', 'name': 'Mari Laakso'}, {'authorId': '2144335183', 'name': 'Hai-Ying Liu'}, {'authorId': '2827262', 'name': 'G. Milcinski'}, {'authorId': '2476937', 'name': 'Matej Niksic'}, {'authorId': '2964690', 'name': 'M. Painho'}, {'authorId': '3413974', 'name': 'Andrea Pődör'}, {'authorId': '2882529', 'name': 'A. Raimond'}, {'authorId': '3175329', 'name': 'M. Rutzinger'}]\n",
            "Venue ISPRS Int. J. Geo Inf.\n",
            "year 2016\n",
            "Abstract Citizens are increasingly becoming an important source of geographic information, sometimes entering domains that had until recently been the exclusive realm of authoritative agencies. This activity has a very diverse character as it can, amongst other things, be active or passive, involve spatial or aspatial data and the data provided can be variable in terms of key attributes such as format, description and quality. Unsurprisingly, therefore, there are a variety of terms used to describe data arising from citizens. In this article, the expressions used to describe citizen sensing of geographic information are reviewed and their use over time explored, prior to categorizing them and highlighting key issues in the current state of the subject. The latter involved a review of ~100 Internet sites with particular focus on their thematic topic, the nature of the data and issues such as incentives for contributors. This review suggests that most sites involve active rather than passive contribution, with citizens typically motivated by the desire to aid a worthy cause, often receiving little training. As such, this article provides a snapshot of the role of citizens in crowdsourcing geographic information and a guide to the current status of this rapidly emerging and evolving subject.\n",
            "------------------------------------\n",
            "Title Resolving Information Asymmetry: Signaling, Endorsement, and Crowdfunding Success\n",
            "Author [{'authorId': '2061119023', 'name': 'Christopher Courtney'}, {'authorId': '119519881', 'name': 'Supradeep Dutta'}, {'authorId': '2154404572', 'name': 'Yong Li'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract This article draws on information economics to examine when signals and endorsements obtained from multiple information sources enhance or diminish one another's effects. We propose that signals through start–up actions (use of media) and characteristics (crowdfunding experience) can mitigate information asymmetry concerns about project quality and founder credibility, enhancing the project's likelihood of attaining funding. Further, we posit that while start–up–originated signals offset each other's effects, third–party endorsements (sentiment expressed in backer comments) validate and complement start–up–originated signals. Empirical analyses based on a comprehensive dataset of crowdfunding projects on the Kickstarter website during 2009–2015 confirm our predictions.\n",
            "------------------------------------\n",
            "Title Organizations' Information Security Policy Compliance: Stick or Carrot Approach?\n",
            "Author [{'authorId': '2144283993', 'name': 'Yan Chen'}, {'authorId': '144934675', 'name': 'K. Ramamurthy'}, {'authorId': '2117901', 'name': 'Kuang-Wei Wen'}]\n",
            "Venue Journal of Management Information Systems\n",
            "year 2012\n",
            "Abstract Companies' information security efforts are often threatened by employee negligence and insider breach. To deal with these insider issues, this study draws on the compliance theory and the general deterrence theory to propose a research model in which the relations among coercive control, which has been advocated by scholars and widely practiced by companies; remunerative control, which is generally missing in both research and practice; and certainty of control are studied. A Web-based field experiment involving real-world employees in their natural settings was used to empirically test the model. While lending further support to the general deterrence theory, our findings highlight that reward enforcement, a remunerative control mechanism in the information systems security context, could be an alternative for organizations where sanctions do not successfully prevent violation. The significant interactions between punishment and reward found in the study further indicate a need for a more comprehensive enforcement system that should include a reward enforcement scheme through which the organizational moral standards and values are established or reemphasized. The findings of this study can potentially be used to guide the design of more effective security enforcement systems that encompass remunerative control mechanisms.\n",
            "------------------------------------\n",
            "Title Image Super-Resolution Using Very Deep Residual Channel Attention Networks\n",
            "Author [{'authorId': '2410227', 'name': 'Yulun Zhang'}, {'authorId': '49243413', 'name': 'Kunpeng Li'}, {'authorId': '2158257300', 'name': 'Kai Li'}, {'authorId': '1491247995', 'name': 'Lichen Wang'}, {'authorId': '40296597', 'name': 'Bineng Zhong'}, {'authorId': '46956675', 'name': 'Y. Fu'}]\n",
            "Venue European Conference on Computer Vision\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Harvest-Then-Cooperate: Wireless-Powered Cooperative Communications\n",
            "Author [{'authorId': '143714144', 'name': 'H. Chen'}, {'authorId': '1527098599', 'name': 'Yonghui Li'}, {'authorId': '2271713', 'name': 'J. L. Rebelatto'}, {'authorId': '1725654', 'name': 'B. Filho'}, {'authorId': '1705795', 'name': 'B. Vucetic'}]\n",
            "Venue IEEE Transactions on Signal Processing\n",
            "year 2014\n",
            "Abstract In this paper, we consider a wireless-powered cooperative communication network consisting of one hybrid access-point (AP), one source, and one relay. In contrast to conventional cooperative networks, the source and relay in the considered network have no embedded energy supply. They need to rely on the energy harvested from the signals broadcasted by the AP for their cooperative information transmission. Based on this three-node reference model, we propose a harvest-then-cooperate (HTC) protocol, in which the source and relay harvest energy from the AP in the downlink and work cooperatively in the uplink for the source's information transmission. Considering a delay-limited transmission mode, the approximate closed-form expression for the average throughput of the proposed protocol is derived over Rayleigh fading channels. Subsequently, this analysis is extended to the multi-relay scenario, where the approximate throughput of the HTC protocol with two popular relay selection schemes is derived. The asymptotic analyses for the throughput performance of the considered schemes at high signal-to-noise radio are also provided. All theoretical results are validated by numerical simulations. The impacts of the system parameters, such as time allocation, relay number, and relay position, on the throughput performance are extensively investigated.\n",
            "------------------------------------\n",
            "Title Series: Practical guidance to qualitative research. Part 3: Sampling, data collection and analysis\n",
            "Author [{'authorId': '144589165', 'name': 'A. Moser'}, {'authorId': '6272499', 'name': 'I. Korstjens'}]\n",
            "Venue European Journal of General Practice\n",
            "year 2017\n",
            "Abstract Abstract In the course of our supervisory work over the years, we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The second article focused on context, research questions and designs, and referred to publications for further reading. This third article addresses FAQs about sampling, data collection and analysis. The data collection plan needs to be broadly defined and open at first, and become flexible during data collection. Sampling strategies should be chosen in such a way that they yield rich information and are consistent with the methodological approach used. Data saturation determines sample size and will be different for each study. The most commonly used data collection methods are participant observation, face-to-face in-depth interviews and focus group discussions. Analyses in ethnographic, phenomenological, grounded theory, and content analysis studies yield different narrative findings: a detailed description of a culture, the essence of the lived experience, a theory, and a descriptive summary, respectively. The fourth and final article will focus on trustworthiness and publishing qualitative research.\n",
            "------------------------------------\n",
            "Title Boardroom Centrality and Firm Performance\n",
            "Author [{'authorId': '2009644', 'name': 'D. Larcker'}, {'authorId': '31835888', 'name': 'Eric C. So'}, {'authorId': '1739339419', 'name': 'Charles C. Y. Wang'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Firms with central boards of directors earn superior risk-adjusted stock returns. A long (short) position in the most (least) central firms earns average annual returns of 4.68%. Firms with central boards also experience higher future return-on-assets growth and more positive analyst forecast errors. Return prediction, return-on-assets growth, and analyst errors are concentrated among high growth opportunity firms or firms confronting adverse circumstances, consistent with boardroom connections mattering most for firms standing to benefit most from information and resources exchanged through boardroom networks. Overall, our results suggest that director networks provide economic benefits that are not immediately reflected in stock prices.\n",
            "------------------------------------\n",
            "Title The Evolution of Social Commerce: The People, Management, Technology, and Information Dimensions\n",
            "Author [{'authorId': '9282087', 'name': 'Ching-Hsing Wang'}, {'authorId': '145736516', 'name': 'Ping Zhang'}]\n",
            "Venue Communications of the Association for Information Systems\n",
            "year 2012\n",
            "Abstract Social commerce is a form of commerce mediated by social media and is converging both online and offline environments. As a relatively new phenomenon, social commerce has evolved quickly in practice, yet has gained little attention in the IS discipline. With its pervasiveness in businesses and people’s lives, social commerce presents ample research opportunities that can have both theoretical and practical significance and implications. This article aims to capture researchers’ attention by describing the characteristics of social commerce and its potential future directions. We trace the evolutionary patterns of social commerce chronologically, based on trade articles and academic publications from 2005 to 2011. A framework that combines people, management, technology, and information dimensions is used to provide a systematic analysis of social commerce development. Our examination shows that since 2005, the year the term social commerce was incepted, assumptions and understanding of people in social commerce move from a simple and general description of human social nature to a rich exploration with different angles from social psychology, social heuristics, national culture, and economic situations. On the management dimension, business strategies and models evolve from the short-tail to long-tail thinking, with invented concepts such as branded social networks/communities, niche social networks/communities, niche brands, co-creating, team-buying, and multichannel social networks. Technologically, IT platforms and capabilities for social commerce evolve from blogs, to social networking sites, to mediasharing sites, and to smartphones. While Facebook becomes a profit-generating platform, creating the notion of f-commerce, Google and Twitter become strong competitors with great potentials. Information in social commerce evolves from peer-generated, to community-generated (crowdsourcing), to consumer and marketer co-created, and to global crowdsourced. Our examination identifies various conceptualizations, terminologies, views, and perspectives about social commerce and its relation to other wellknown concepts such as e-commerce. In light of the evolution of social commerce, we provide possible future directions for research and practice.\n",
            "------------------------------------\n",
            "Title Silent Listeners: The Evolution of Privacy and Disclosure on Facebook\n",
            "Author [{'authorId': '35371463', 'name': 'F. Stutzman'}, {'authorId': '33731953', 'name': 'R. Gross'}, {'authorId': '1683053', 'name': 'A. Acquisti'}]\n",
            "Venue Journal of Privacy and Confidentiality\n",
            "year 2013\n",
            "Abstract Over the past decade, social network sites have experienced dramatic growth in popularity, reaching most demographics and providing new opportunities for interaction and socialization. Through this growth, users have been challenged to manage novel privacy concerns and balance nuanced trade-offs between disclosing and withholding personal information. To date, however, no study has documented how privacy and disclosure evolved on social network sites over an extended period of time. In this manuscript we use profile data from a longitudinal panel of 5,076 Facebook users to understand how their privacy and disclosure behavior changed between 2005---the early days of the network---and 2011. Our analysis highlights three contrasting trends. First, over time Facebook users in our dataset exhibited increasingly privacy-seeking behavior, progressively decreasing the amount of personal data shared publicly with unconnected profiles in the same network. However, and second, changes implemented by Facebook near the end of the period of time under our observation arrested or in some cases inverted that trend. Third, the amount and scope of personal information that Facebook users revealed privately to other connected profiles actually increased over time---and because of that, so did disclosures to ``silent listeners'' on the network: Facebook itself, third-party apps, and (indirectly) advertisers. These findings highlight the tension between privacy choices as expressions of individual subjective preferences, and the role of the environment in shaping those choices.\n",
            "------------------------------------\n",
            "Title What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties\n",
            "Author [{'authorId': '2480903', 'name': 'Alexis Conneau'}, {'authorId': '2067996', 'name': 'Germán Kruszewski'}, {'authorId': '1830914', 'name': 'Guillaume Lample'}, {'authorId': '2934336', 'name': 'Loïc Barrault'}, {'authorId': '145283199', 'name': 'Marco Baroni'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2018\n",
            "Abstract Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. “Downstream” tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.\n",
            "------------------------------------\n",
            "Title The effect of electronic word of mouth on brand image and purchase intention\n",
            "Author [{'authorId': '2225249', 'name': 'M. Jalilvand'}, {'authorId': '2543537', 'name': 'Neda Samiei'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Purpose – Word‐of‐mouth (WOM) has been recognized as one of the most influential resources of information transmission. Advances in information technology and the emergence of online social network sites have changed the way information is transmitted. This phenomenon impacts consumers as this easily accessible information could greatly affect the consumption decision. The purpose of this paper is to examine the extent to which e‐WOM among consumers can influence brand image and purchase intention in the automobile industry.Design/methodology/approach – Measurement items are adapted from existing scales found in the marketing literature. Academic colleagues reviewed the items for face validity and readability. The scales are evaluated for reliability, convergent validity, and discriminant validity using data collected in a survey of Iran Khodro's prospective customers in Iran. A structural equation modeling procedure is applied to the examination of the influences of e‐WOM on brand image and purchase inte...\n",
            "------------------------------------\n",
            "Title Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts\n",
            "Author [{'authorId': '1790831', 'name': 'C. D. Santos'}, {'authorId': '1771662', 'name': 'M. Gatti'}]\n",
            "Venue International Conference on Computational Linguistics\n",
            "year 2014\n",
            "Abstract Sentiment analysis of short texts such as single sentences and Twitter messages is challenging because of the limited contextual information that they normally contain. Effectively solving this task requires strategies that combine the small text content with prior knowledge and use more than just bag-of-words. In this work we propose a new deep convolutional neural network that exploits from characterto sentence-level information to perform sentiment analysis of short texts. We apply our approach for two corpora of two different domains: the Stanford Sentiment Treebank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentiment corpus (STS), which contains Twitter messages. For the SSTb corpus, our approach achieves state-of-the-art results for single sentence sentiment prediction in both binary positive/negative classification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy. For the STS corpus, our approach achieves a sentiment prediction accuracy of 86.4%.\n",
            "------------------------------------\n",
            "Title An Information-Theoretic Analysis of Thompson Sampling\n",
            "Author [{'authorId': '145751896', 'name': 'Daniel Russo'}, {'authorId': '1731282', 'name': 'Benjamin Van Roy'}]\n",
            "Venue Journal of machine learning research\n",
            "year 2014\n",
            "Abstract We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.\n",
            "------------------------------------\n",
            "Title Diversity is All You Need: Learning Skills without a Reward Function\n",
            "Author [{'authorId': '8140754', 'name': 'Benjamin Eysenbach'}, {'authorId': '2129458064', 'name': 'Abhishek Gupta'}, {'authorId': '46920727', 'name': 'Julian Ibarz'}, {'authorId': '1736651', 'name': 'S. Levine'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2018\n",
            "Abstract Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN (\"Diversity is All You Need\"), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. In these environments, some of the learned skills correspond to solving the task, and each skill that solves the task does so in a distinct manner. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning\n",
            "------------------------------------\n",
            "Title Networked privacy: How teenagers negotiate context in social media\n",
            "Author [{'authorId': '2929988', 'name': 'Alice E. Marwick'}, {'authorId': '38818867', 'name': 'D. Boyd'}]\n",
            "Venue New Media & Society\n",
            "year 2014\n",
            "Abstract While much attention is given to young people’s online privacy practices on sites like Facebook, current theories of privacy fail to account for the ways in which social media alter practices of information-sharing and visibility. Traditional models of privacy are individualistic, but the realities of privacy reflect the location of individuals in contexts and networks. The affordances of social technologies, which enable people to share information about others, further preclude individual control over privacy. Despite this, social media technologies primarily follow technical models of privacy that presume individual information control. We argue that the dynamics of sites like Facebook have forced teens to alter their conceptions of privacy to account for the networked nature of social media. Drawing on their practices and experiences, we offer a model of networked privacy to explain how privacy is achieved in networked publics.\n",
            "------------------------------------\n",
            "Title Crowdsourcing, Citizen Science or Volunteered Geographic Information? The Current State of Crowdsourced Geographic Information\n",
            "Author [{'authorId': '145098716', 'name': 'L. See'}, {'authorId': '143641668', 'name': 'P. Mooney'}, {'authorId': '145181054', 'name': 'G. Foody'}, {'authorId': '1754110', 'name': 'L. Bastin'}, {'authorId': '48982395', 'name': 'A. Comber'}, {'authorId': '3194416', 'name': 'J. Estima'}, {'authorId': '144822493', 'name': 'S. Fritz'}, {'authorId': '2915345', 'name': 'N. Kerle'}, {'authorId': '144069314', 'name': 'B. Jiang'}, {'authorId': '2895530', 'name': 'Mari Laakso'}, {'authorId': '2144335183', 'name': 'Hai-Ying Liu'}, {'authorId': '2827262', 'name': 'G. Milcinski'}, {'authorId': '2476937', 'name': 'Matej Niksic'}, {'authorId': '2964690', 'name': 'M. Painho'}, {'authorId': '3413974', 'name': 'Andrea Pődör'}, {'authorId': '2882529', 'name': 'A. Raimond'}, {'authorId': '3175329', 'name': 'M. Rutzinger'}]\n",
            "Venue ISPRS Int. J. Geo Inf.\n",
            "year 2016\n",
            "Abstract Citizens are increasingly becoming an important source of geographic information, sometimes entering domains that had until recently been the exclusive realm of authoritative agencies. This activity has a very diverse character as it can, amongst other things, be active or passive, involve spatial or aspatial data and the data provided can be variable in terms of key attributes such as format, description and quality. Unsurprisingly, therefore, there are a variety of terms used to describe data arising from citizens. In this article, the expressions used to describe citizen sensing of geographic information are reviewed and their use over time explored, prior to categorizing them and highlighting key issues in the current state of the subject. The latter involved a review of ~100 Internet sites with particular focus on their thematic topic, the nature of the data and issues such as incentives for contributors. This review suggests that most sites involve active rather than passive contribution, with citizens typically motivated by the desire to aid a worthy cause, often receiving little training. As such, this article provides a snapshot of the role of citizens in crowdsourcing geographic information and a guide to the current status of this rapidly emerging and evolving subject.\n",
            "------------------------------------\n",
            "Title Organizations' Information Security Policy Compliance: Stick or Carrot Approach?\n",
            "Author [{'authorId': '2144283993', 'name': 'Yan Chen'}, {'authorId': '144934675', 'name': 'K. Ramamurthy'}, {'authorId': '2117901', 'name': 'Kuang-Wei Wen'}]\n",
            "Venue Journal of Management Information Systems\n",
            "year 2012\n",
            "Abstract Companies' information security efforts are often threatened by employee negligence and insider breach. To deal with these insider issues, this study draws on the compliance theory and the general deterrence theory to propose a research model in which the relations among coercive control, which has been advocated by scholars and widely practiced by companies; remunerative control, which is generally missing in both research and practice; and certainty of control are studied. A Web-based field experiment involving real-world employees in their natural settings was used to empirically test the model. While lending further support to the general deterrence theory, our findings highlight that reward enforcement, a remunerative control mechanism in the information systems security context, could be an alternative for organizations where sanctions do not successfully prevent violation. The significant interactions between punishment and reward found in the study further indicate a need for a more comprehensive enforcement system that should include a reward enforcement scheme through which the organizational moral standards and values are established or reemphasized. The findings of this study can potentially be used to guide the design of more effective security enforcement systems that encompass remunerative control mechanisms.\n",
            "------------------------------------\n",
            "Title Permutation Entropy and Its Main Biomedical and Econophysics Applications: A Review\n",
            "Author [{'authorId': '1800889', 'name': 'M. Zanin'}, {'authorId': '143669430', 'name': 'L. Zunino'}, {'authorId': '38229702', 'name': 'O. Rosso'}, {'authorId': '2857771', 'name': 'D. Papo'}]\n",
            "Venue Entropy\n",
            "year 2012\n",
            "Abstract Entropy is a powerful tool for the analysis of time series, as it allows describing the probability distributions of the possible state of a system, and therefore the information encoded in it. Nevertheless, important information may be codified also in the temporal dynamics, an aspect which is not usually taken into account. The idea of calculating entropy based on permutation patterns (that is, permutations defined by the order relations among values of a time series) has received a lot of attention in the last years, especially for the understanding of complex and chaotic systems. Permutation entropy directly accounts for the temporal information contained in the time series; furthermore, it has the quality of simplicity, robustness and very low computational cost. To celebrate the tenth anniversary of the original work, here we analyze the theoretical foundations of the permutation entropy, as well as the main recent applications to the analysis of economical markets and to the understanding of biomedical systems.\n",
            "------------------------------------\n",
            "Title Internet of Things for Enterprise Systems of Modern Manufacturing\n",
            "Author [{'authorId': '145207592', 'name': 'Z. Bi'}, {'authorId': '39466716', 'name': 'Lida Xu'}, {'authorId': '35030642', 'name': 'Chengen Wang'}]\n",
            "Venue IEEE Transactions on Industrial Informatics\n",
            "year 2014\n",
            "Abstract Design and operation of a manufacturing enterprise involve numerous types of decision-making at various levels and domains. A complex system has a large number of design variables and decision-making requires real-time data collected from machines, processes, and business environments. Enterprise systems (ESs) are used to support data acquisition, communication, and all decision-making activities. Therefore, information technology (IT) infrastructure for data acquisition and sharing affects the performance of an ES greatly. Our objective is to investigate the impact of emerging Internet of Things (IoT) on ESs in modern manufacturing. To achieve this objective, the evolution of manufacturing system paradigms is discussed to identify the requirements of decision support systems in dynamic and distributed environments; recent advances in IT are overviewed and associated with next-generation manufacturing paradigms; and the relation of IT infrastructure and ESs is explored to identify the technological gaps in adopting IoT as an IT infrastructure of ESs. The future research directions in this area are discussed.\n",
            "------------------------------------\n",
            "Title Visualization and analysis of gene expression in tissue sections by spatial transcriptomics\n",
            "Author [{'authorId': '6171810', 'name': 'P. Ståhl'}, {'authorId': '7421667', 'name': 'Fredrik Salmén'}, {'authorId': '5190784', 'name': 'S. Vickovic'}, {'authorId': '3113730', 'name': 'Anna Lundmark'}, {'authorId': '145531539', 'name': 'J. F. Navarro'}, {'authorId': '34823439', 'name': 'J. Magnusson'}, {'authorId': '4519903', 'name': 'S. Giacomello'}, {'authorId': '49796022', 'name': 'Michaela Asp'}, {'authorId': '1767884', 'name': 'J. Westholm'}, {'authorId': '2256805', 'name': 'M. Huss'}, {'authorId': '8482872', 'name': 'A. Mollbrink'}, {'authorId': '2500111', 'name': 'S. Linnarsson'}, {'authorId': '6427264', 'name': 'S. Codeluppi'}, {'authorId': '144634345', 'name': 'Å. Borg'}, {'authorId': '143810507', 'name': 'F. Pontén'}, {'authorId': '7467695', 'name': 'P. Costea'}, {'authorId': '5978924', 'name': 'P. Sahlén'}, {'authorId': '144464470', 'name': 'J. Mulder'}, {'authorId': '2636316', 'name': 'O. Bergmann'}, {'authorId': '2217647', 'name': 'J. Lundeberg'}, {'authorId': '145194787', 'name': 'J. Frisén'}]\n",
            "Venue Science\n",
            "year 2016\n",
            "Abstract Spatial structure of RNA expression RNA-seq and similar methods can record gene expression within and among cells. Current methods typically lose positional information and many require arduous single-cell isolation and sequencing. Ståhl et al. have developed a way of measuring the spatial distribution of transcripts by annealing fixed brain or cancer tissue samples directly to bar-coded reverse transcriptase primers, performing reverse transcription followed by sequencing and computational reconstruction, and they can do so for multiple genes. Science, this issue p. 78 A new technique allows visualization and quantitative analysis of the spatially resolved transcriptome across individual tissue sections. Analysis of the pattern of proteins or messengerRNAs (mRNAs) in histological tissue sections is a cornerstone in biomedical research and diagnostics. This typically involves the visualization of a few proteins or expressed genes at a time. We have devised a strategy, which we call “spatial transcriptomics,” that allows visualization and quantitative analysis of the transcriptome with spatial resolution in individual tissue sections. By positioning histological sections on arrayed reverse transcription primers with unique positional barcodes, we demonstrate high-quality RNA-sequencing data with maintained two-dimensional positional information from the mouse brain and human breast cancer. Spatial transcriptomics provides quantitative gene expression data and visualization of the distribution of mRNAs within tissue sections and enables novel types of bioinformatics analyses, valuable in research and diagnostics.\n",
            "------------------------------------\n",
            "Title Series: Practical guidance to qualitative research. Part 3: Sampling, data collection and analysis\n",
            "Author [{'authorId': '144589165', 'name': 'A. Moser'}, {'authorId': '6272499', 'name': 'I. Korstjens'}]\n",
            "Venue European Journal of General Practice\n",
            "year 2017\n",
            "Abstract Abstract In the course of our supervisory work over the years, we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The second article focused on context, research questions and designs, and referred to publications for further reading. This third article addresses FAQs about sampling, data collection and analysis. The data collection plan needs to be broadly defined and open at first, and become flexible during data collection. Sampling strategies should be chosen in such a way that they yield rich information and are consistent with the methodological approach used. Data saturation determines sample size and will be different for each study. The most commonly used data collection methods are participant observation, face-to-face in-depth interviews and focus group discussions. Analyses in ethnographic, phenomenological, grounded theory, and content analysis studies yield different narrative findings: a detailed description of a culture, the essence of the lived experience, a theory, and a descriptive summary, respectively. The fourth and final article will focus on trustworthiness and publishing qualitative research.\n",
            "------------------------------------\n",
            "Title YouTube for Information on Rheumatoid Arthritis — A Wakeup Call?\n",
            "Author [{'authorId': '145434263', 'name': 'A. Singh'}, {'authorId': '40519589', 'name': 'Siddharth Singh'}, {'authorId': '1399866500', 'name': 'Preet Paul Singh'}]\n",
            "Venue Journal of Rheumatology\n",
            "year 2012\n",
            "Abstract Objective. Rheumatoid arthritis (RA) is a common debilitating autoimmune disease, with unmet need for knowledge among patients and the general population. YouTube is a popular, consumer-generated, video-sharing website, which can be a source of information on RA. We investigated the quality of information on RA on YouTube and analyzed audience interaction. Methods. YouTube was searched using the term “Rheumatoid Arthritis,” for videos uploaded on RA. Two physicians independently classified videos as useful, misleading, or patient views, and rated them on a 5-point global quality scale (GQS; 1 = poor quality, 5 = excellent quality). Useful videos were rated for reliability and content, on a 5-point scale (higher scores represent more reliable and comprehensive videos). Source of videos was also noted. Audience interaction was assessed through video viewership. Results. A total of 102 relevant videos were identified; 54.9% were classified as useful (GQS 2.9 ± 1.0) and 30.4% deemed misleading (GQS 1.3 ± 1.6). Mean reliability and content score of useful videos was 3.2 (± 1.0) and 2.5 (± 1.2), respectively. All videos uploaded by university channels and professional organizations provided useful information but formed only 12.7% of total videos, whereas 73.9% of medical advertisements and videos by for-profit organizations were misleading. There was no difference in the viewership/day (10.0 vs 21.5; p = nonsignificant) of useful and misleading information. Conclusion. YouTube is a source of information on RA, of variable quality, with wide viewership and potential to influence patients’ knowledge and behavior. Physicians and professional organizations should be aware of and embrace this evolving technology to raise awareness about RA, and empower patients to discriminate useful from misleading information.\n",
            "------------------------------------\n",
            "Title Scalable and Secure Sharing of Personal Health Records in Cloud Computing Using Attribute-Based Encryption\n",
            "Author [{'authorId': '50652037', 'name': 'Ming Li'}, {'authorId': '34744447', 'name': 'Shucheng Yu'}, {'authorId': '46323367', 'name': 'Yao Zheng'}, {'authorId': '144222395', 'name': 'K. Ren'}, {'authorId': '145612191', 'name': 'W. Lou'}]\n",
            "Venue IEEE Transactions on Parallel and Distributed Systems\n",
            "year 2013\n",
            "Abstract Personal health record (PHR) is an emerging patient-centric model of health information exchange, which is often outsourced to be stored at a third party, such as cloud providers. However, there have been wide privacy concerns as personal health information could be exposed to those third party servers and to unauthorized parties. To assure the patients' control over access to their own PHRs, it is a promising method to encrypt the PHRs before outsourcing. Yet, issues such as risks of privacy exposure, scalability in key management, flexible access, and efficient user revocation, have remained the most important challenges toward achieving fine-grained, cryptographically enforced data access control. In this paper, we propose a novel patient-centric framework and a suite of mechanisms for data access control to PHRs stored in semitrusted servers. To achieve fine-grained and scalable data access control for PHRs, we leverage attribute-based encryption (ABE) techniques to encrypt each patient's PHR file. Different from previous works in secure data outsourcing, we focus on the multiple data owner scenario, and divide the users in the PHR system into multiple security domains that greatly reduces the key management complexity for owners and users. A high degree of patient privacy is guaranteed simultaneously by exploiting multiauthority ABE. Our scheme also enables dynamic modification of access policies or file attributes, supports efficient on-demand user/attribute revocation and break-glass access under emergency scenarios. Extensive analytical and experimental results are presented which show the security, scalability, and efficiency of our proposed scheme.\n",
            "------------------------------------\n",
            "Title Gender Differences in Searching for Health Information on the Internet and the Virtual Patient-Physician Relationship in Germany: Exploratory Results on How Men and Women Differ and Why\n",
            "Author [{'authorId': '6607601', 'name': 'Sonja Bidmon'}, {'authorId': '2308454', 'name': 'R. Terlutter'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2015\n",
            "Abstract Background Many studies have shown that women use the Internet more often for health-related information searches than men, but we have limited knowledge about the underlying reasons. We also do not know whether and how women and men differ in their current use of the Internet for communicating with their general practitioner (GP) and in their future intention to do so (virtual patient-physician relationship). Objective This study investigates (1) gender differences in health-related information search behavior by exploring underlying emotional, motivational, attitudinal as well as cognitive variables, situational involvement, and normative influences, and different personal involvement regarding health-related information searching and (2) gender differences in the virtual patient-physician relationship. Methods Gender differences were analyzed based on an empirical online survey of 1006 randomly selected German patients. The sample was drawn from an e-panel maintained by GfK HealthCare. A total of 958 usable questionnaires were analyzed. Principal component analyses were carried out for some variables. Differences between men (517/958) and women (441/958) were analyzed using t tests and Kendall’s tau-b tests. The survey instrument was guided by several research questions and was based on existing literature. Results Women were more engaged in using the Internet for health-related information searching. Gender differences were found for the frequency of usage of various Internet channels for health-related information searches. Women used the Internet for health-related information searches to a higher degree for social motives and enjoyment and they judged the usability of the Internet medium and of the information gained by health information searches higher than men did. Women had a more positive attitude toward Web 2.0 than men did, but perceived themselves as less digitally competent. Women had a higher health and nutrition awareness and a greater reluctance to make use of medical support, as well as a higher personal disposition of being well-informed as a patient. Men may be more open toward the virtual patient-physician relationship. Conclusions Women have a stronger social motive for and experience greater enjoyment in health-related information searches, explained by social role interpretations, suggesting these needs should be met when offering health-related information on the Internet. This may be interesting for governmental bodies as well as for the insurance and the pharmaceutical industries. Furthermore, women may be more easily convinced by health awareness campaigns and are, therefore, the primary target group for them. Men are more open to engaging in a virtual relationship with the GP; therefore, they could be the primary target group for additional online services offered by GPs. There were several areas for GPs to reinforce the virtual patient-physician relationship: the fixing of personal appointments, referral to other doctors, writing prescriptions, and discussions of normal test results and doctor’s notes/certificates of health.\n",
            "------------------------------------\n",
            "Title Dense Trajectories and Motion Boundary Descriptors for Action Recognition\n",
            "Author [{'authorId': '46506697', 'name': 'Heng Wang'}, {'authorId': '2909350', 'name': 'Alexander Kläser'}, {'authorId': '2462253', 'name': 'C. Schmid'}, {'authorId': '1689269', 'name': 'Cheng-Lin Liu'}]\n",
            "Venue International Journal of Computer Vision\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Internet use by pregnant women seeking pregnancy-related information: a systematic review\n",
            "Author [{'authorId': '4622394', 'name': 'P. Sayakhot'}, {'authorId': '1398356341', 'name': 'M. Carolan-Olah'}]\n",
            "Venue BMC Pregnancy and Childbirth\n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports\n",
            "Author [{'authorId': '2145742277', 'name': 'Jian Zhou'}, {'authorId': '49723920', 'name': 'Hongyu Zhang'}, {'authorId': '143960553', 'name': 'D. Lo'}]\n",
            "Venue International Conference on Software Engineering\n",
            "year 2012\n",
            "Abstract For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.\n",
            "------------------------------------\n",
            "Title Deep Learning: Methods and Applications\n",
            "Author [{'authorId': '144718788', 'name': 'L. Deng'}, {'authorId': '144580027', 'name': 'Dong Yu'}]\n",
            "Venue Foundations and Trends® in Signal Processing\n",
            "year 2014\n",
            "Abstract This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.\n",
            "------------------------------------\n",
            "Title Working Memory Underpins Cognitive Development, Learning, and Education\n",
            "Author [{'authorId': '144225308', 'name': 'N. Cowan'}]\n",
            "Venue Educational Psychology Review\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Information, Role Models and Perceived Returns to Education Experimental Evidence from Madagascar\n",
            "Author [{'authorId': '32981648', 'name': 'T. Nguyen'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract This brief summarizes the information, role models and perceived returns to education experimental evidence from Madagascar. This paper shows that increasing perceived returns to education strengthens incentives for schooling when agents underestimate the actual returns. The author conducted a field experiment in Madagascar to study alternative ways to provide additional information about the returns to education: simply providing statistics versus using a role model, an actual person sharing his and her success story. Some argue that role models may be more effective than providing statistics to a largely illiterate population. However, this proposition depends on how households update their beliefs based on the information the role model brings. Motivated by a model of belief formation, the author randomly assigns schools to the role model intervention, the statistics intervention, or a combination of both. The author fined that providing statistics reduced the large gap between perceived returns and the statistics provided. As a result, it improved average test scores by 0.2 standard deviations. For those whose initial perceived returns were below the statistics, test scores improved by 0.37 standard deviations. Student attendance in statistics schools is also 3.5 percentage points higher than attendance in schools without statistics. Consistent with the theory, seeing a role model of poor background has a larger impact on poor children's test scores than seeing someone of rich background. Combining a role model with statistics leads to smaller treatment effects than statistics alone, also consistent with the theory. The key implication of my results is that households lack information, but are able to process new information and change their decisions in a sophisticated manner.\n",
            "------------------------------------\n",
            "Title Trust-Aware Recommender Systems\n",
            "Author [{'authorId': '2143398093', 'name': 'Mohammad Ali Abbasi'}, {'authorId': '2166393740', 'name': 'J. Tang'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Recommender systems are an effective solution to the information overload problem, specially in the online world where we are constantly faced with inordinately many choices. These systems try to find the items such as books or movies that match best with users’ preferences. Based on the different approaches to finding the items of interests to users, we can classify the recommender systems into three major groups. First, content based recommender systems use content information to make a recommendation. For example, such systems might recommend a romantic movie to a user that showed interest in romantic movies in her profile. Second, collaborative filtering recommender systems rely only on the past behavior of the users such as their previous transactions or ratings. By comparing this information, a collaborative filtering recommender system finds new items or users to users. In order to address the cold-start problem and fend off various types of attacks, the third class of recommender systems, namely trust-aware recommender systems, is proposed. These systems use social media and trust information to make a recommendation, which is shown to be promising in improving the accuracy of the recommendations. In this chapter, we give an overview of state-of-theart recommender systems with a focus on trust-aware recommender systems. In particular, we describe the ways that trust information can help to improve the quality of the recommendations. In the rest of the chapter, we introduce recommender systems, then trust in social media, and next trust-aware recommender systems. Trust-Aware Recommender Systems 3 1.1 Recommender Systems With the development of Web 2.0, information has increased at an unprecedented rate which aggravates the severity of the information overload problem for online users. For example, a search for “smartphone” returns 1,664,253 results in Amazon products or a search for “best movies to watch” in Google videos returns about 219,000,000 results. Due to the information overload problem, the decision-making process becomes perplexing when one is exposed to excessive information [58, 55, 19, 1]. Therefore, with the rapidly growing amount of available information and digital items on the web, it is necessary to use tools to filter this information in order to find items that are more likely to be of interest to the users. One can use search engines to overcome the information overload problem. In this case, the user has to refine the search terms or has to pick more specific query terms to narrow down the results. Another solution to overcome the information overload problem is to use top-k recommendations. In this approach, the system keeps a list of the most popular items and utilizes the list to recommend items to the user. For example, Ted is a website that uses this technique to recommend items to users. It can be seen in Figure 1.1, users can sort items bases on the different approaches such as overall popularity (most viewed), popularity in the past week (most emailed this week), or popularity in the past month (most popular this month) among others. Similar to search engines, top-k items are not usually customized based on users’ preferences and interest. In particulate, a top-k-item system returns the same list of items to people with different preferences. Therefore, customization is the major problem associated with these two approaches. Recommender systems are introduced to tackle the information overload, and the customization problem. Recommender systems are a subclass of information filtering systems that consider users’ preferences and recommended items that match with users’ preferences and interests [23]. These systems have become extremely common in recent years and are applied in a variety of applications including recommending products, social links, and digital items. The most popular ones are probably movies, music, news, books, and products in general [58, 70, 19, 26, 60]. Further, recommender systems are frequently used on recommending social links such as recommending people to follow on Twitter, befriend on social networks or dating sites [67, 37]. Furthermore, these systems are also used to accurately estimate the degree to which a particular user (from now on termed the target user) will like a particular item (the target item) [73]. Based on the type of data that recommender systems use, we can classify 1http://www.amazon.com 2https://www.google.com/#q=best+movies+to+watch&safe=active&tbm=vid 3http://www.ted.com/ 4 Trust-Aware Recommender Systems FIGURE 1.1: Ted.com uses a top-k item recommendation approach to rank items them into two major classes: content-based and collaborative filtering based recommender systems [76, 60]. Content-based recommendation systems use items’ features and characteristics to rank the items based on the user’s preferences. Collaborative filtering recommendation systems rely on the user’s past behavior e.g., purchases or ratings, to find similar users or items and utilize this information in order to find the items of interests to the user. In general, recommender systems are utility functions that predict the rating of item i from the item set I for user u from the user set U in the form of U × I → R, where rui is the rating of the item i for the given user u. The task of recommender systems is to predict user u’s rating for the given item i for which rui is unknown and use r̂ui to represent the predicted rating. The ratings, ru,i, can be any real number but often ratings are integers in the range [1, 5]. We use R to show all of the ratings. In real-world recommender systems, only a few users rate the items of interests (this number for many recommender system is less than 1%). Matrix 1.1 shows an example of a rating matrix with missing values. The goal of recommender systems is to predict these missing values. R =  5 2 3 4 3 4 2 2 5 3 5 5 3  (1.1) Trust-Aware Recommender Systems 5 Algorithm 1 Content-based recommendation 1: Describe the items that may be recommended. 2: Create a profile of the user that describes the types of items the user likes 3: Compare items to the user profile to determine what to recommend. The profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user. 1.1.1 Content-based Recommendation Content-based recommender systems uses items’ and users’ features to create a profile for each item or user. For example, movie profile might include attributes such as gender, participating actors, director, and office box popularity. User profile includes demographic information and users’s interests [28]. These systems use supervised machine learning to induce a classifier that can discriminate between items likely to be of interest to the user and those likely to be uninteresting [52, 5, 49]. The recommender recommends an item to a user based on a description of the item and a profile of the users’ interests. Algorithm 1 shows the main steps of a content-based recommendation. We usually use vector space model to represent users’ and items’ features. In this model, every item or user is represented as a vector. i = (t1, t2, ..., tn) (1.2) where tj is the frequency of term j in item i. To model users or items more accurately, instead of frequency we can use tf-idf which can be calculated as follows: tft,i = ft,i max{fz,i : z ∈ i} idft = log N nt (1.3) wt,i = tft,i × idft (1.4) where ft,i is the frequency of term t in item i, max{fz,i : z ∈ i} is the maximum term frequency in item i, N is the total number of items, nt is the number of items where term t appears. tft,i denotes the frequency of term t in item i, and idft denotes the inverse document frequency of term t, which inversely correlates with the number of items, that term t is appeared in their descriptions. The similarity between user u and item i can be calculated using Equation 1.5. sim(u, i) = ∑ t∈T wt,uwt,i √∑ t∈T w 2 t,u √∑ t∈T w 2 t,i (1.5) where T indicates the set of terms that appeared in item and user description. 6 Trust-Aware Recommender Systems 1.1.2 Collaborative Filtering (CF) Collaborative filtering is the process of filtering the information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc [69]. Collaborative filtering systems use the user’s past behavior, and recommend items that match their taste. Collaborative filtering recommender systems can be classified into memory-based and model-based collaborative filtering. In memory-based approach we predict the missing ratings based on similarity between users or items. In model-based approach, we use given user-item ratings to construct a model and use the model to predict missing ratings. We’ll give a detailed description of these two approaches in the following sections. The main advantage of this method is that the recommender system does not need to have any information about the users and content of the items to recommend. User-item ratings are the only information the system needs to operate. The following are assumptions for collaborative filtering systems [76]: • Users with similar ratings on some items are more likely to have similar ratings on future items, and • Items with similar ratings in the past are more likely to have similar ratings in the future. Figure 1.2 illustrates this approach for a small set of users and movies. The goal is recommending a new movie to Jack. In the first step, the system finds three other users that have similar movie taste as Jack’s. The next step it looks for other movies that these users liked. All three of them liked “Once Upon a Time in the West”, and two of them liked “Spider man”. Therefore, the top recommendation would be “Once Upon a Time in the West”. 1.1.2.1 Memory-based Collaborative Filtering In a memory-based approach, the recommender system aims to predict the missing ratings based on either similarity\n",
            "------------------------------------\n",
            "Title Content Based Video Retrival System for Mexican Culture Heritage Based on Object Matching and Local-Global Descriptors\n",
            "Author [{'authorId': '1398045419', 'name': 'M. Cedillo-Hernández'}, {'authorId': '1383990753', 'name': 'F. Garcia-Ugalde'}, {'authorId': '1399165163', 'name': 'Antonio Cedillo-Hernández'}, {'authorId': '1383990672', 'name': 'M. Nakano-Miyatake'}, {'authorId': '1405508693', 'name': 'H. Perez-Meana'}]\n",
            "Venue 2014 International Conference on Mechatronics, Electronics and Automotive Engineering\n",
            "year 2014\n",
            "Abstract Multimedia data and networking technologies have had a highly growing during the last decade, with these changes users have changed from text to content based video retrieval systems due to its better performance. We propose a fast content-based video retrieval system which involves the combination of a local descriptor obtained from the speeded-up robust feature algorithm together with an effective and fast object matching operation. To save computational time, compressed video data are partially decoded in order to get discrete cosine transform coefficients of key frames, which are used to obtain sub-block coefficients and a down-sampling version of frames. The preliminary results are ranking using an efficient color descriptor based on color correlogram and dominant color descriptors. To measure the performance of the proposed technique the precision and recall metrics are used. The experimental results show the accuracy of the proposed method applied to a database of Mexican Culture Heritage videos.\n",
            "------------------------------------\n",
            "Title Information Frictions in Trade\n",
            "Author [{'authorId': '4150056', 'name': 'Treb Allen'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract It is costly to learn about market conditions elsewhere, especially in developing countries. This paper examines how such information frictions affect trade. Using data on regional agricultural trade in the Philippines, I first document a number of observed patterns in trade flows and prices that suggest the presence of information frictions. I then incorporate information frictions into a perfect competition trade model by embedding a process whereby heterogeneous producers engage in a costly sequential search process to determine where to sell their produce. I show that introducing information frictions reconciles the theory with the observed patterns in the data. Structural estimation of the model finds that information frictions are quantitatively important: roughly half the observed regional price dispersion is due to information frictions. Furthermore, incorporating information frictions improves the out‐of‐sample predictive power of the model.\n",
            "------------------------------------\n",
            "Title Unique in the shopping mall: On the reidentifiability of credit card metadata\n",
            "Author [{'authorId': '2002429', 'name': 'Y. de Montjoye'}, {'authorId': '48071255', 'name': 'Laura Radaelli'}, {'authorId': '47974933', 'name': 'V. Singh'}, {'authorId': '1682773', 'name': 'A. Pentland'}]\n",
            "Venue Science\n",
            "year 2015\n",
            "Abstract Large-scale data sets of human behavior have the potential to fundamentally transform the way we fight diseases, design cities, or perform research. Metadata, however, contain sensitive information. Understanding the privacy of these data sets is key to their broad use and, ultimately, their impact. We study 3 months of credit card records for 1.1 million people and show that four spatiotemporal points are enough to uniquely reidentify 90% of individuals. We show that knowing the price of a transaction increases the risk of reidentification by 22%, on average. Finally, we show that even data sets that provide coarse information at any or all of the dimensions provide little anonymity and that women are more reidentifiable than men in credit card metadata.\n",
            "------------------------------------\n",
            "Title Information propagation in the Bitcoin network\n",
            "Author [{'authorId': '1453509390', 'name': 'Christian Decker'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]\n",
            "Venue IEEE P2P 2013 Proceedings\n",
            "year 2013\n",
            "Abstract Bitcoin is a digital currency that unlike traditional currencies does not rely on a centralized authority. Instead Bitcoin relies on a network of volunteers that collectively implement a replicated ledger and verify transactions. In this paper we analyze how Bitcoin uses a multi-hop broadcast to propagate transactions and blocks through the network to update the ledger replicas. We then use the gathered information to verify the conjecture that the propagation delay in the network is the primary cause for blockchain forks. Blockchain forks should be avoided as they are symptomatic for inconsistencies among the replicas in the network. We then show what can be achieved by pushing the current protocol to its limit with unilateral changes to the client's behavior.\n",
            "------------------------------------\n",
            "Title Recommender systems based on user reviews: the state of the art\n",
            "Author [{'authorId': '1725490', 'name': 'Li Chen'}, {'authorId': '5671907', 'name': 'Guanliang Chen'}, {'authorId': '144742600', 'name': 'Feng Wang'}]\n",
            "Venue User modeling and user-adapted interaction\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Seeking and sharing health information online: comparing search engines and social media\n",
            "Author [{'authorId': '2583473', 'name': 'M. Choudhury'}, {'authorId': '144844426', 'name': 'M. Morris'}, {'authorId': '34286525', 'name': 'Ryen W. White'}]\n",
            "Venue International Conference on Human Factors in Computing Systems\n",
            "year 2014\n",
            "Abstract Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
            "------------------------------------\n",
            "Title CSI Phase Fingerprinting for Indoor Localization With a Deep Learning Approach\n",
            "Author [{'authorId': '1519969782', 'name': 'Xuyu Wang'}, {'authorId': '49715449', 'name': 'Lingjun Gao'}, {'authorId': '145536403', 'name': 'S. Mao'}]\n",
            "Venue IEEE Internet of Things Journal\n",
            "year 2016\n",
            "Abstract With the increasing demand of location-based services, indoor localization based on fingerprinting has become an increasingly important technique due to its high accuracy and low hardware requirement. In this paper, we propose PhaseFi, a fingerprinting system for indoor localization with calibrated channel state information (CSI) phase information. In PhaseFi, the raw phase information is first extracted from the multiple antennas and multiple subcarriers of the IEEE 802.11n network interface card by accessing the modified device driver. Then a linear transformation is applied to extract the calibrated phase information, which we prove to have a bounded variance. For the offline stage, we design a deep network with three hidden layers to train the calibrated phase data, and employ the weights of the deep network to represent fingerprints. A greedy learning algorithm is incorporated to train the weights layer-by-layer to reduce computational complexity, where a subnetwork between two consecutive layers forms a restricted Boltzmann machine. In the online stage, we use a probabilistic method based on the radial basis function for online location estimation. The proposed PhaseFi scheme is implemented and validated with extensive experiments in two representation indoor environments. It is shown to outperform three benchmark schemes based on CSI or received signal strength in both scenarios.\n",
            "------------------------------------\n",
            "Title Information Dropout: Learning Optimal Representations Through Noisy Computation\n",
            "Author [{'authorId': '16163297', 'name': 'A. Achille'}, {'authorId': '1715959', 'name': 'Stefano Soatto'}]\n",
            "Venue IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year 2016\n",
            "Abstract The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.\n",
            "------------------------------------\n",
            "Title Use of the Internet as a Health Information Resource Among French Young Adults: Results From a Nationally Representative Survey\n",
            "Author [{'authorId': '143826172', 'name': 'F. Beck'}, {'authorId': '37376572', 'name': 'J. Richard'}, {'authorId': '1403560051', 'name': 'V. Nguyen-Thanh'}, {'authorId': '3415034', 'name': 'I. Montagni'}, {'authorId': '2071310828', 'name': 'I. Parizot'}, {'authorId': '3936412', 'name': 'E. Renahy'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2014\n",
            "Abstract Background The Internet is one of the main resources of health information especially for young adults, but website content is not always trustworthy or validated. Little is known about this specific population and the importance of online health searches for use and impact. It is fundamental to assess behaviors and attitudes of young people looking for online health-related information and their level of trust in such information. Objective The objective is to describe the characteristics of Internet users aged 15-30 years who use the Web as a health information resource and their trust in it, and to define the context and the effect of such use on French young adults’ behavior in relation to their medical consultations. Methods We used the French Health Barometer 2010, a nationally representative survey of 27,653 individuals that investigates population health behaviors and concerns. Multivariate logistic regressions were performed using a subsample of 1052 young adults aged 15-30 years to estimate associations between demographics, socioeconomic, and health status and (1) the use of the Internet to search for health information, and (2) its impact on health behaviors and the physician-patient relationship. Results In 2010, 48.5% (474/977) of Web users aged 15-30 years used the Internet for health purposes. Those who did not use the Internet for health purposes reported being informed enough by other sources (75.0%, 377/503), stated they preferred seeing a doctor (74.1%, 373/503) or did not trust the information on the Internet (67.2%, 338/503). However, approximately 80% (371/474) of young online health seekers considered the information found online reliable. Women (P<.001) and people with higher sociocultural positions (OR 0.5, 95% CI 0.3-0.9 and OR 0.4, 95% CI 0.2-0.7 for employees and manual workers, respectively, vs individuals with executive or manager positions) were more likely to use the Internet for health purposes. For a subsample of women only, online health seeking was more likely among those having a child (OR 1.8, 95% CI 1.1-2.7) and experiencing psychological distress (OR 2.0, 95% CI 1.0-4.0). Finally, for online health seekers aged 15-30 years, one-third (33.3%, 157/474) reported they changed their health behaviors (eg, frequency of medical consultations, way of taking care of one’s own health) because of their online searches. Different factors were associated with different outcomes of change, but psychological distress, poor quality of life, and low income were the most common. Conclusions The Internet is a useful tool to spread health information and prevention campaigns, especially to target young adults. Young adults trust online information and consider the Internet as a valid source of health advice. Health agencies should ensure the improvement of online health information quality and the creation of health-related websites and programs dedicated to young adults.\n",
            "------------------------------------\n",
            "Title FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\n",
            "Author [{'authorId': '3322806', 'name': 'Caner Hazirbas'}, {'authorId': '2562254', 'name': 'Lingni Ma'}, {'authorId': '1847505', 'name': 'Csaba Domokos'}, {'authorId': '1695302', 'name': 'D. Cremers'}]\n",
            "Venue Asian Conference on Computer Vision\n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Adapting to Artificial Intelligence: Radiologists and Pathologists as Information Specialists.\n",
            "Author [{'authorId': '36544586', 'name': 'S. Jha'}, {'authorId': '144758045', 'name': 'E. Topol'}]\n",
            "Venue JAMA\n",
            "year 2016\n",
            "Abstract Artificial intelligence—the mimicking of human cognition by computers—was once a fable in science fiction but is becoming reality in medicine. The combination of big data and artificial intelligence, referred to by some as the fourth industrial revolution,1 will change radiology and pathology along with other medical specialties. Although reports of radiologists and pathologists being replaced by computers seem exaggerated,2 these specialties must plan strategically for a future in which artificial intelligence is part of the health care workforce. Radiologists have always revered machines and technology. In 1960, Lusted predicted “an electronic scannercomputer to examine chest photofluorograms, to separate the clearly normal chest films from the abnormal chest films.”3 Lusted further suggested that “the abnormal chest films would be marked for later study by the radiologists.”3 Lusted’s intuitions were prescient: interpreting radiographs is pattern recognition; computers can recognize patterns and may be helpful because some roentgenographic analyses can be automated. Nearly 60 years after Lusted’s prediction, Enlitic, a technology company in Silicon Valley, inputted images of normal radiographs and radiographs with fractures into a computerized database.4 Using deep learning, a refined version of artificial neural networks, the\n",
            "------------------------------------\n",
            "Title Database resources of the National Center for Biotechnology Information\n",
            "Author [{'authorId': '9309019', 'name': 'Huang Gao'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2015\n",
            "Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Additional NCBI resources focus on literature (PubMed Central (PMC), Bookshelf and PubReader), health (ClinVar, dbGaP, dbMHC, the Genetic Testing Registry, HIV-1/Human Protein Interaction Database and MedGen), genomes (BioProject, Assembly, Genome, BioSample, dbSNP, dbVar, Epigenomics, the Map Viewer, Nucleotide, Probe, RefSeq, Sequence Read Archive, the Taxonomy Browser and the Trace Archive), genes (Gene, Gene Expression Omnibus (GEO), HomoloGene, PopSet and UniGene), proteins (Protein, the Conserved Domain Database (CDD), COBALT, Conserved Domain Architecture Retrieval Tool (CDART), the Molecular Modeling Database (MMDB) and Protein Clusters) and chemicals (Biosystems and the PubChem suite of small molecule databases). The Entrez system provides search and retrieval operations for most of these databases. Augmenting many of the web applications are custom implementations of the BLAST program optimized to search specialized datasets. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title Guidance Regarding Methods for De-identification of Protected Health Information in Accordance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule\n",
            "Author [{'authorId': '145412911', 'name': 'B. Fitzgerald'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Guidance Regarding Methods for De-identification of Protected Health Information in Accordance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule This page provides guidance about methods and approaches to achieve de-identification in accordance with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Privacy Rule. The guidance explains and answers questions regarding the two methods that can be used to satisfy the Privacy Rule’s de-identification standard: Expert Determination and Safe Harbor . This guidance is intended to assist covered entities to understand what is de-identification, the general process by which de-identified information is created, and the options available for performing de-identification.\n",
            "------------------------------------\n",
            "Title Generalized Multiview Analysis: A discriminative latent space\n",
            "Author [{'authorId': '2109325320', 'name': 'Abhishek Sharma'}, {'authorId': '50333123', 'name': 'Abhishek Kumar'}, {'authorId': '1722360', 'name': 'Hal Daumé'}, {'authorId': '34734622', 'name': 'D. Jacobs'}]\n",
            "Venue 2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year 2012\n",
            "Abstract This paper presents a general multi-view feature extraction approach that we call Generalized Multiview Analysis or GMA. GMA has all the desirable properties required for cross-view classification and retrieval: it is supervised, it allows generalization to unseen classes, it is multi-view and kernelizable, it affords an efficient eigenvalue based solution and is applicable to any domain. GMA exploits the fact that most popular supervised and unsupervised feature extraction techniques are the solution of a special form of a quadratic constrained quadratic program (QCQP), which can be solved efficiently as a generalized eigenvalue problem. GMA solves a joint, relaxed QCQP over different feature spaces to obtain a single (non)linear subspace. Intuitively, GMA is a supervised extension of Canonical Correlational Analysis (CCA), which is useful for cross-view classification and retrieval. The proposed approach is general and has the potential to replace CCA whenever classification or retrieval is the purpose and label information is available. We outperform previous approaches for textimage retrieval on Pascal and Wiki text-image data. We report state-of-the-art results for pose and lighting invariant face recognition on the MultiPIE face dataset, significantly outperforming other approaches.\n",
            "------------------------------------\n",
            "Title Entanglement wedge reconstruction and the information paradox\n",
            "Author [{'authorId': '49136752', 'name': 'Geoffrey Penington'}]\n",
            "Venue Journal of High Energy Physics\n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Automatic detection of rumor on Sina Weibo\n",
            "Author [{'authorId': '2158028407', 'name': 'Fan Yang'}, {'authorId': '2152797201', 'name': 'Yang Liu'}, {'authorId': '145235707', 'name': 'Xiaohui Yu'}, {'authorId': '2110951704', 'name': 'Min Yang'}]\n",
            "Venue MDS '12\n",
            "year 2012\n",
            "Abstract The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter, the world's largest micro-blogging platform, as the premise of research. In this work, we shift the premise and study the problem of information credibility on Sina Weibo, China's leading micro-blogging service provider. With eight times more users than Twitter, Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone, and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments, the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs, and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification, and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge, this is the first study on rumor analysis and detection on Sina Weibo.\n",
            "------------------------------------\n",
            "Title Functional correlates of the lateral and medial entorhinal cortex: objects, path integration and local–global reference frames\n",
            "Author [{'authorId': '2972274', 'name': 'J. Knierim'}, {'authorId': '5863109', 'name': 'J. P. Neunuebel'}, {'authorId': '7374073', 'name': 'Sachin S. Deshmukh'}]\n",
            "Venue Philosophical Transactions of the Royal Society B: Biological Sciences\n",
            "year 2014\n",
            "Abstract The hippocampus receives its major cortical input from the medial entorhinal cortex (MEC) and the lateral entorhinal cortex (LEC). It is commonly believed that the MEC provides spatial input to the hippocampus, whereas the LEC provides non-spatial input. We review new data which suggest that this simple dichotomy between ‘where’ versus ‘what’ needs revision. We propose a refinement of this model, which is more complex than the simple spatial–non-spatial dichotomy. MEC is proposed to be involved in path integration computations based on a global frame of reference, primarily using internally generated, self-motion cues and external input about environmental boundaries and scenes; it provides the hippocampus with a coordinate system that underlies the spatial context of an experience. LEC is proposed to process information about individual items and locations based on a local frame of reference, primarily using external sensory input; it provides the hippocampus with information about the content of an experience.\n",
            "------------------------------------\n",
            "Title Spectral–Spatial Hyperspectral Image Segmentation Using Subspace Multinomial Logistic Regression and Markov Random Fields\n",
            "Author [{'authorId': '2152747957', 'name': 'Jun Li'}, {'authorId': '1399086996', 'name': 'J. Bioucas-Dias'}, {'authorId': '143767945', 'name': 'A. Plaza'}]\n",
            "Venue IEEE Transactions on Geoscience and Remote Sensing\n",
            "year 2012\n",
            "Abstract This paper introduces a new supervised segmentation algorithm for remotely sensed hyperspectral image data which integrates the spectral and spatial information in a Bayesian framework. A multinomial logistic regression (MLR) algorithm is first used to learn the posterior probability distributions from the spectral information, using a subspace projection method to better characterize noise and highly mixed pixels. Then, contextual information is included using a multilevel logistic Markov-Gibbs Markov random field prior. Finally, a maximum a posteriori segmentation is efficiently computed by the min-cut-based integer optimization algorithm. The proposed segmentation approach is experimentally evaluated using both simulated and real hyperspectral data sets, exhibiting state-of-the-art performance when compared with recently introduced hyperspectral image classification methods. The integration of subspace projection methods with the MLR algorithm, combined with the use of spatial-contextual information, represents an innovative contribution in the literature. This approach is shown to provide accurate characterization of hyperspectral imagery in both the spectral and the spatial domain.\n",
            "------------------------------------\n",
            "Title Efficient Informative Sensing using Multiple Robots\n",
            "Author [{'authorId': '2116287308', 'name': 'Amarjeet Singh'}, {'authorId': '145343838', 'name': 'Andreas Krause'}, {'authorId': '1730156', 'name': 'Carlos Guestrin'}, {'authorId': '1721984', 'name': 'W. Kaiser'}]\n",
            "Venue Journal of Artificial Intelligence Research\n",
            "year 2014\n",
            "Abstract The need for efficient monitoring of spatio-temporal dynamics in large environmental applications, such as the water quality monitoring in rivers and lakes, motivates the use of robotic sensors in order to achieve sufficient spatial coverage. Typically, these robots have bounded resources, such as limited battery or limited amounts of time to obtain measurements. Thus, careful coordination of their paths is required in order to maximize the amount of information collected, while respecting the resource constraints. In this paper, we present an efficient approach for near-optimally solving the NP-hard optimization problem of planning such informative paths. In particular, we first develop eSIP (efficient Single-robot Informative Path planning), an approximation algorithm for optimizing the path of a single robot. Hereby, we use a Gaussian Process to model the underlying phenomenon, and use the mutual information between the visited locations and remainder of the space to quantify the amount of information collected. We prove that the mutual information collected using paths obtained by using eSIP is close to the information obtained by an optimal solution. We then provide a general technique, sequential allocation, which can be used to extend any single robot planning algorithm, such as eSIP, for the multi-robot problem. This procedure approximately generalizes any guarantees for the single-robot problem to the multi-robot case. We extensively evaluate the effectiveness of our approach on several experiments performed infield for two important environmental sensing applications, lake and river monitoring, and simulation experiments performed using several real world sensor network data sets.\n",
            "------------------------------------\n",
            "Title Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty.\n",
            "Author [{'authorId': '40643070', 'name': 'G. Baele'}, {'authorId': '2120394', 'name': 'P. Lemey'}, {'authorId': '28950924', 'name': 'T. Bedford'}, {'authorId': '3006129', 'name': 'A. Rambaut'}, {'authorId': '2716962', 'name': 'M. Suchard'}, {'authorId': '34662337', 'name': 'A. Alekseyenko'}]\n",
            "Venue Molecular biology and evolution\n",
            "year 2012\n",
            "Abstract Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.\n",
            "------------------------------------\n",
            "Title What it will take to achieve the as-yet-unfulfilled promises of health information technology.\n",
            "Author [{'authorId': '47804516', 'name': 'A. Kellermann'}, {'authorId': '6348893', 'name': 'Spencer S. Jones'}]\n",
            "Venue Health Affairs\n",
            "year 2013\n",
            "Abstract A team of RAND Corporation researchers projected in 2005 that rapid adoption of health information technology (IT) could save the United States more than $81 billion annually. Seven years later the empirical data on the technology's impact on health care efficiency and safety are mixed, and annual health care expenditures in the United States have grown by $800 billion. In our view, the disappointing performance of health IT to date can be largely attributed to several factors: sluggish adoption of health IT systems, coupled with the choice of systems that are neither interoperable nor easy to use; and the failure of health care providers and institutions to reengineer care processes to reap the full benefits of health IT. We believe that the original promise of health IT can be met if the systems are redesigned to address these flaws by creating more-standardized systems that are easier to use, are truly interoperable, and afford patients more access to and control over their health data. Providers must do their part by reengineering care processes to take full advantage of efficiencies offered by health IT, in the context of redesigned payment models that favor value over volume.\n",
            "------------------------------------\n",
            "Title Social Media, Knowledge Sharing, and Innovation: Toward a Theory of Communication Visibility\n",
            "Author [{'authorId': '34602963', 'name': 'P. Leonardi'}]\n",
            "Venue Information systems research\n",
            "year 2014\n",
            "Abstract This paper offers a theory of communication visibility based on a field study of the implementation of a new enterprise social networking site in a large financial services organization. The emerging theory suggests that once invisible communication occurring between others in the organization becomes visible for third parties, those third parties could improve their metaknowledge i.e., knowledge of who knows what and who knows whom. Communication visibility, in this case made possible by the enterprise social networking site, leads to enhanced awareness of who knows what and whom through two interrelated mechanisms: message transparency and network translucence. Seeing the contents of other's messages helps third-party observers make inferences about coworkers' knowledge. Tangentially, seeing the structure of coworkers' communication networks helps third-party observers make inferences about those with whom coworkers regularly communicate. The emerging theory further suggests that enhanced metaknowledge can lead to more innovative products and services and less knowledge duplication if employees learn to work in new ways. By learning vicariously rather than through experience, workers can more effectively recombine existing ideas into new ideas and avoid duplicating work. Moreover, they can begin to proactively aggregate information perceived daily rather than engaging in reactive search after confronting a problem. I discuss the important implications of this emerging theory of communication visibility for work in the knowledge economy.\n",
            "------------------------------------\n",
            "Title Systematic Review of Factors Influencing the Adoption of Information and Communication Technologies by Healthcare Professionals\n",
            "Author [{'authorId': '49978166', 'name': 'M. Gagnon'}, {'authorId': '1897320', 'name': 'M. Desmartis'}, {'authorId': '52190951', 'name': 'M. Labrecque'}, {'authorId': '3007050', 'name': 'J. Car'}, {'authorId': '2938133', 'name': 'C. Pagliari'}, {'authorId': '1871259', 'name': 'P. Pluye'}, {'authorId': '2614188', 'name': 'P. Frémont'}, {'authorId': '36415502', 'name': 'J. Gagnon'}, {'authorId': '2065701140', 'name': 'Nadine Tremblay'}, {'authorId': '4361330', 'name': 'F. Légaré'}]\n",
            "Venue Journal of medical systems\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title OCNet: Object Context Network for Scene Parsing\n",
            "Author [{'authorId': '49521390', 'name': 'Yuhui Yuan'}, {'authorId': '1688516', 'name': 'Jingdong Wang'}]\n",
            "Venue ArXiv\n",
            "year 2018\n",
            "Abstract In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. \n",
            "We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. \n",
            "To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff\n",
            "------------------------------------\n",
            "Title Big Data for All: Privacy and User Control in the Age of Analytics\n",
            "Author [{'authorId': '2301316', 'name': 'Omer Tene'}, {'authorId': '2476781', 'name': 'Jules Polonetsky'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract We live in an age of “big data.” Data have become the raw material of production, a new source for immense economic and social value. Advances in data mining and analytics and the massive increase in computing power and data storage capacity have expanded by orders of magnitude the scope of information available for businesses and government. Data are now available for analysis in raw form, escaping the confines of structured databases and enhancing researchers’ abilities to identify correlations and conceive of new, unanticipated uses for existing information. In addition, the increasing number of people, devices, and sensors that are now connected by digital networks has revolutionized the ability to generate, communicate, share, and access data. Data creates enormous value for the world economy, driving innovation, productivity, efficiency and growth. At the same time, the “data deluge” presents privacy concerns which could stir a regulatory backlash dampening the data economy and stifling innovation. In order to craft a balance between beneficial uses of data and in individual privacy, policymakers must address some of the most fundamental concepts of privacy law, including the definition of “personally identifiable information”, the role of individual control, and the principles of data minimization and purpose limitation. This article emphasizes the importance of providing individuals with access to their data in usable format. This will let individuals share the wealth created by their information and incentivize developers to offer user-side features and applications harnessing the value of big data. Where individual access to data is impracticable, data are likely to be de-identified to an extent sufficient to diminish privacy concerns. In addition, organizations should be required to disclose their decisional criteria, since in a big data world it is often not the data but rather the inferences drawn from them that give cause for concern.\n",
            "------------------------------------\n",
            "Title Sampling-based robotic information gathering algorithms\n",
            "Author [{'authorId': '2585010', 'name': 'G. Hollinger'}, {'authorId': '1732493', 'name': 'G. Sukhatme'}]\n",
            "Venue Int. J. Robotics Res.\n",
            "year 2014\n",
            "Abstract We propose three sampling-based motion planning algorithms for generating informative mobile robot trajectories. The goal is to find a trajectory that maximizes an information quality metric (e.g. variance reduction, information gain, or mutual information) and also falls within a pre-specified budget constraint (e.g. fuel, energy, or time). Prior algorithms have employed combinatorial optimization techniques to solve these problems, but existing techniques are typically restricted to discrete domains and often scale poorly in the size of the problem. Our proposed rapidly exploring information gathering (RIG) algorithms combine ideas from sampling-based motion planning with branch and bound techniques to achieve efficient information gathering in continuous space with motion constraints. We provide analysis of the asymptotic optimality of our algorithms, and we present several conservative pruning strategies for modular, submodular, and time-varying information objectives. We demonstrate that our proposed techniques find optimal solutions more quickly than existing combinatorial solvers, and we provide a proof-of-concept field implementation on an autonomous surface vehicle performing a wireless signal strength monitoring task in a lake.\n",
            "------------------------------------\n",
            "Title Intelligent Reflecting Surface Aided MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer\n",
            "Author [{'authorId': '144442022', 'name': 'Cunhua Pan'}, {'authorId': '145892647', 'name': 'Hong Ren'}, {'authorId': '1878751', 'name': 'Kezhi Wang'}, {'authorId': '3283999', 'name': 'M. Elkashlan'}, {'authorId': '1709760', 'name': 'A. Nallanathan'}, {'authorId': '40382920', 'name': 'Jiangzhou Wang'}, {'authorId': '80707783', 'name': 'L. Hanzo'}]\n",
            "Venue IEEE Journal on Selected Areas in Communications\n",
            "year 2019\n",
            "Abstract An intelligent reflecting surface (IRS) is invoked for enhancing the energy harvesting performance of a simultaneous wireless information and power transfer (SWIPT) aided system. Specifically, an IRS-assisted SWIPT system is considered, where a multi-antenna aided base station (BS) communicates with several multi-antenna assisted information receivers (IRs), while guaranteeing the energy harvesting requirement of the energy receivers (ERs). To maximize the weighted sum rate (WSR) of IRs, the transmit precoding (TPC) matrices of the BS and passive phase shift matrix of the IRS should be jointly optimized. To tackle this challenging optimization problem, we first adopt the classic block coordinate descent (BCD) algorithm for decoupling the original optimization problem into several subproblems and alternately optimize the TPC matrices and the phase shift matrix. For each subproblem, we provide a low-complexity iterative algorithm, which is guaranteed to converge to the Karush-Kuhn-Tucker (KKT) point of each subproblem. The BCD algorithm is rigorously proved to converge to the KKT point of the original problem. We also conceive a feasibility checking method to study its feasibility. Our extensive simulation results confirm that employing IRSs in SWIPT beneficially enhances the system performance and the proposed BCD algorithm converges rapidly, which is appealing for practical applications.\n",
            "------------------------------------\n",
            "Title Quantum technologies with hybrid systems\n",
            "Author [{'authorId': '10425274', 'name': 'G. Kurizki'}, {'authorId': '4955323', 'name': 'P. Bertet'}, {'authorId': '144882702', 'name': 'Y. Kubo'}, {'authorId': '30881361', 'name': 'K. Mølmer'}, {'authorId': '48463223', 'name': 'D. Petrosyan'}, {'authorId': '3404537', 'name': 'P. Rabl'}, {'authorId': '3401801', 'name': 'J. Schmiedmayer'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2015\n",
            "Abstract An extensively pursued current direction of research in physics aims at the development of practical technologies that exploit the effects of quantum mechanics. As part of this ongoing effort, devices for quantum information processing, secure communication, and high-precision sensing are being implemented with diverse systems, ranging from photons, atoms, and spins to mesoscopic superconducting and nanomechanical structures. Their physical properties make some of these systems better suited than others for specific tasks; thus, photons are well suited for transmitting quantum information, weakly interacting spins can serve as long-lived quantum memories, and superconducting elements can rapidly process information encoded in their quantum states. A central goal of the envisaged quantum technologies is to develop devices that can simultaneously perform several of these tasks, namely, reliably store, process, and transmit quantum information. Hybrid quantum systems composed of different physical components with complementary functionalities may provide precisely such multitasking capabilities. This article reviews some of the driving theoretical ideas and first experimental realizations of hybrid quantum systems and the opportunities and challenges they present and offers a glance at the near- and long-term perspectives of this fascinating and rapidly expanding field.\n",
            "------------------------------------\n",
            "Title Spectral-Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network\n",
            "Author [{'authorId': '2153643335', 'name': 'Ying Li'}, {'authorId': '9726614', 'name': 'Haokui Zhang'}, {'authorId': '2069019990', 'name': 'Qiang Shen'}]\n",
            "Venue Remote Sensing\n",
            "year 2017\n",
            "Abstract Recent research has shown that using spectral–spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral–spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral–spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods—namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods—on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.\n",
            "------------------------------------\n",
            "Title Motivated numeracy and enlightened self-government\n",
            "Author [{'authorId': '144461051', 'name': 'D. Kahan'}, {'authorId': '1723589', 'name': 'E. Peters'}, {'authorId': '143736308', 'name': 'Erica Dawson'}, {'authorId': '2403553', 'name': 'P. Slovic'}]\n",
            "Venue Behavioural Public Policy\n",
            "year 2017\n",
            "Abstract Abstract Why does public conflict over societal risks persist in the face of compelling and widely accessible scientific evidence? We conducted an experiment to probe two alternative answers: the ‘science comprehension thesis’ (SCT), which identifies defects in the public's knowledge and reasoning capacities as the source of such controversies; and the ‘identity-protective cognition thesis’ (ICT), which treats cultural conflict as disabling the faculties that members of the public use to make sense of decision-relevant science. In our experiment, we presented subjects with a difficult problem that turned on their ability to draw valid causal inferences from empirical data. As expected, subjects highest in numeracy – a measure of the ability and disposition to make use of quantitative information – did substantially better than less numerate ones when the data were presented as results from a study of a new skin rash treatment. Also as expected, subjects’ responses became politically polarized – and even less accurate – when the same data were presented as results from the study of a gun control ban. But contrary to the prediction of SCT, such polarization did not abate among subjects highest in numeracy; instead, it increased. This outcome supported ICT, which predicted that more numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlooks. We discuss the theoretical and practical significance of these findings.\n",
            "------------------------------------\n",
            "Title Teens, Health and Technology: A National Survey\n",
            "Author [{'authorId': '2111008', 'name': 'E. Wartella'}, {'authorId': '40621199', 'name': 'V. Rideout'}, {'authorId': '145512933', 'name': 'H. Montague'}, {'authorId': '1410581415', 'name': 'Leanne Beaudoin-Ryan'}, {'authorId': '2655481', 'name': 'A. Lauricella'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract In the age of digital technology, as teens seem to be constantly connected online, via social media, and through mobile applications, it is no surprise that they increasingly turn to digital media to answer their health questions. This study is the first of its kind to survey a large, nationally-representative sample of teens to investigate how they use the newest digital technologies, including mobile apps, social networking sites, electronic gaming and wearable devices, to explore health topics. The survey covered the types of health topics teens most frequently search for, which technologies they are most likely to use and how they use them, and whether they report having changed their behaviors due to digital health information. In addition, this survey explores how the digital divide continues to impact adolescents. Results of this study indicate that teens are concerned about many health issues, ranging from fitness, sexual activity, drugs, hygiene as well as mental health and stress. As teens virtually always have a digital device at their fingertips, it is clear that public health interventions and informational campaigns must be tailored to reflect the ways that teens currently navigate digital health information and the health challenges that concern them most.\n",
            "------------------------------------\n",
            "Title Some Hesitant Fuzzy Aggregation Operators with Their Application in Group Decision Making\n",
            "Author [{'authorId': '4150451', 'name': 'M. Xia'}, {'authorId': '1741576', 'name': 'Zeshui Xu'}, {'authorId': '2118767943', 'name': 'Na Chen'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title PROV-O: The PROV Ontology\n",
            "Author [{'authorId': '1760030', 'name': 'Timothy Lebo'}, {'authorId': '2628266', 'name': 'S. Sahoo'}, {'authorId': '1679913', 'name': 'D. McGuinness'}, {'authorId': '3337287', 'name': 'Khalid Belhajjame'}, {'authorId': '144320476', 'name': 'J. Cheney'}, {'authorId': '2885049', 'name': 'D. Corsar'}, {'authorId': '1398926410', 'name': 'D. Garijo'}, {'authorId': '1399487720', 'name': 'S. Soiland-Reyes'}, {'authorId': '2582069', 'name': 'S. Zednik'}, {'authorId': '2145805969', 'name': 'Jun Zhao'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The PROV Ontology (PROV-O) expresses the PROV Data Model using the OWL2 Web Ontology Language. It provides a set of classes, properties, and restrictions that can be used to represent and interchange provenance information generated in different systems and under different contexts. It can also be specialized to create new classes and properties to model provenance information for different applications and domains.\n",
            "------------------------------------\n",
            "Title Sequence-Controlled Polymers\n",
            "Author [{'authorId': '145770783', 'name': 'J. Lutz'}, {'authorId': '4399891', 'name': 'M. Ouchi'}, {'authorId': '2949942', 'name': 'David R. Liu'}, {'authorId': '91495618', 'name': 'M. Sawamoto'}]\n",
            "Venue Science\n",
            "year 2013\n",
            "Abstract Background During the last few decades, progress has been made in manipulating the architecture of synthetic polymer materials. However, the primary structure—that is, the sequential arrangement of monomer units in a polymer chain—is generally poorly controlled in synthetic macromolecules. Common synthetic polymers are usually homopolymers, made of the same monomer unit, or copolymers with simple chain microstructures, such as random or block copolymers. These polymers are used in many areas but do not have the structural and functional complexity of sequence-defined biopolymers, such as nucleic acids or proteins. Indeed, monomer sequence regulation plays a key role in biology and is a prerequisite for crucial features of life, such as heredity, self-replication, complex self-assembly, and molecular recognition. In this context, developing synthetic polymers containing controlled monomer sequences is an important area for research. Precise molecular encoding of synthetic polymer chains. In most synthetic copolymers, monomer units (represented here as colored square boxes A, B, C, and D) are distributed randomly along the polymer chains (left). In sequence-controlled polymers, they are arranged in a speciﬁc order in all of the chains (right). Monomer sequence regularity strongly inﬂuences the molecular, supramolecular, andmacroscopic properties of polymer materials. Advances Various synthetic methods for controlling monomer sequences in polymers have been identified, and two major trends in the field of sequence-controlled polymers have emerged. Some approaches use biological concepts that have been optimized by nature for sequence regulation. For instance, DNA templates, enzymes, or even living organisms can be used to prepare sequence-defined polymers. These natural mechanisms can be adapted to tolerate nonnatural monomers. The other trend is the preparation of sequence-controlled polymers by synthetic chemistry. In the most popular approach, monomer units are attached one by one to a support, which is an efficient method but demanding in practice. Recently, some strategies have been proposed for controlling sequences in chain-growth and step-growth polymerizations. These mechanisms usually allow fast and large-scale synthesis of polymers. Specific kinetics and particular catalytic or template conditions allow sequence regulation in these processes. Outlook The possibility of controlling monomer sequences in synthetic macromolecules has many scientific and technological implications. Information can be controlled at the molecular level in synthetic polymer chains. This opens up interesting perspectives for the field of data storage. In addition, having power over monomer sequences could mean structural control of the resulting polymer, as it strongly influences macromolecular folding and self-assembly. For instance, functional synthetic assemblies that mimic the properties of globular proteins, such as enzymes and transporters, can be foreseen. Moreover, monomer sequence control influences some macroscopic properties. For example, bulk properties such as conductivity, rigidity, elasticity, or biodegradability can be finely tuned in sequence-controlled polymers. The behavior of polymers in solution, particularly in water, is also strongly dependent on monomer sequences. Thus, sequence regulation may enable a more effective control of structure-property relations in tomorrow’s polymer materials. Controlled Polymers Nature has achieved exquisite sequence control in the synthesis of polymers like DNA. In contrast, synthetic polymers rarely have the same fidelity in their chemistry or uniformity in chain-length distribution, especially when more than one monomer is involved. Lutz et al. (1238149) review the progress that has been made in making sequence-controlled polymers of increasing length and complexity. These developments have come from both advances in synthetic chemistry methods and the exploitation of biological machinery. Sequence-controlled polymers are macromolecules in which monomer units of different chemical nature are arranged in an ordered fashion. The most prominent examples are biological and have been studied and used primarily by molecular biologists and biochemists. However, recent progress in protein- and DNA-based nanotechnologies has shown the relevance of sequence-controlled polymers to nonbiological applications, including data storage, nanoelectronics, and catalysis. In addition, synthetic polymer chemistry has provided interesting routes for preparing nonnatural sequence-controlled polymers. Although these synthetic macromolecules do not yet compare in functional scope with their natural counterparts, they open up opportunities for controlling the structure, self-assembly, and macroscopic properties of polymer materials.\n",
            "------------------------------------\n",
            "Title Smart Meter Privacy: A Theoretical Framework\n",
            "Author [{'authorId': '144711127', 'name': 'L. Sankar'}, {'authorId': '2054537548', 'name': 'S. Rajagopalan'}, {'authorId': '1729082', 'name': 'S. Mohajer'}, {'authorId': '145967056', 'name': 'H. Poor'}]\n",
            "Venue IEEE Transactions on Smart Grid\n",
            "year 2013\n",
            "Abstract The solutions offered to-date for end-user privacy in smart meter measurements, a well-known challenge in the smart grid, have been tied to specific technologies such as batteries or assumptions on data usage without quantifying the loss of benefit (utility) that results from any such approach. Using tools from information theory and a hidden Markov model for the measurements, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. For a stationary Gaussian model of the electricity load, it is shown that for a desired mean-square distortion (utility) measure between the measured and revealed data, the optimal privacy-preserving solution: i) exploits the presence of high-power but less private appliance spectra as implicit distortion noise, and ii) filters out frequency components with lower power relative to a distortion threshold; this approach encompasses many previously proposed approaches to smart meter privacy.\n",
            "------------------------------------\n",
            "Title Patient Portals and Patient Engagement: A State of the Science Review\n",
            "Author [{'authorId': '8641215', 'name': 'Taya Irizarry'}, {'authorId': '4392659', 'name': 'A. D. DeVito Dabbs'}, {'authorId': '33059471', 'name': 'C. Curran'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2015\n",
            "Abstract Background Patient portals (ie, electronic personal health records tethered to institutional electronic health records) are recognized as a promising mechanism to support greater patient engagement, yet questions remain about how health care leaders, policy makers, and designers can encourage adoption of patient portals and what factors might contribute to sustained utilization. Objective The purposes of this state of the science review are to (1) present the definition, background, and how current literature addresses the encouragement and support of patient engagement through the patient portal, and (2) provide a summary of future directions for patient portal research and development to meaningfully impact patient engagement. Methods We reviewed literature from 2006 through 2014 in PubMed, Ovid Medline, and PsycInfo using the search terms “patient portal” OR “personal health record” OR “electronic personal health record”. Final inclusion criterion dictated that studies report on the patient experience and/or ways that patients may be supported to make competent health care decisions and act on those decisions using patient portal functionality. Results We found 120 studies that met the inclusion criteria. Based on the research questions, explicit and implicit aims of the studies, and related measures addressed, the studies were grouped into five major topics (patient adoption, provider endorsement, health literacy, usability, and utility). We discuss the findings and conclusions of studies that address the five topical areas. Conclusions Current research has demonstrated that patients’ interest and ability to use patient portals is strongly influenced by personal factors such age, ethnicity, education level, health literacy, health status, and role as a caregiver. Health care delivery factors, mainly provider endorsement and patient portal usability also contribute to patient’s ability to engage through and with the patient portal. Future directions of research should focus on identifying specific populations and contextual considerations that would benefit most from a greater degree of patient engagement through a patient portal. Ultimately, adoption by patients and endorsement by providers will come when existing patient portal features align with patients’ and providers’ information needs and functionality.\n",
            "------------------------------------\n",
            "Title New media landscapes and the science information consumer\n",
            "Author [{'authorId': '3030164', 'name': 'D. Brossard'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2013\n",
            "Abstract Individuals are increasingly turning to online environments to find information about science and to follow scientific developments. It is therefore crucial for scientists and scientific institutions to consider empirical findings from research in online science communication when thinking about science in the public sphere. After providing a snapshot of the current media landscape, this paper reviews recent major research findings related to science communication in the online environment and their implications for science in the 21st century. Particular emphasis is given to the bias introduced by search engines, the nature of scientific content encountered online, and the potential impact of the Internet on audiences’ knowledge and attitudes toward science.\n",
            "------------------------------------\n",
            "Title Infoglut: How Too Much Information Is Changing the Way We Think and Know\n",
            "Author [{'authorId': '50056732', 'name': 'M. Andrejevic'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Today, more mediated information is available to more people than at any other time in human history. New and revitalized sense-making strategies multiply in response to the challenges of \"cutting through the clutter\" of competing narratives and taming the avalanche of information. Data miners, \"sentiment analysts,\" and decision markets offer to help bodies of data \"speak for themselves\"making sense of their own patterns so we dont have to. Neuromarketers and body language experts promise to peer behind peoples words to see what their brains are really thinking and feeling. New forms of information processing promise to displace the need for expertise and even comprehensionat least for those with access to the data. Infoglut explores the connections between these wide-ranging sense-making strategies for an era of information overload and \"big data,\" and the new forms of control they enable. Andrejevic critiques the popular embrace of deconstructive debunkery, calling into question the post-truth, post-narrative, and post-comprehension politics it underwrites, and tracing a way beyond them.\n",
            "------------------------------------\n",
            "Title Positioning and Presenting Design Science Research for Maximum Impact\n",
            "Author [{'authorId': '2743113', 'name': 'S. Gregor'}, {'authorId': '1933556', 'name': 'A. Hevner'}]\n",
            "Venue MIS Q.\n",
            "year 2013\n",
            "Abstract Design science research (DSR) has staked its rightful ground as an important and legitimate Information Systems (IS) research paradigm. We contend that DSR has yet to attain its full potential impact on the development and use of information systems due to gaps in the understanding and application of DSR concepts and methods. This essay aims to help researchers (1) appreciate the levels of artifact abstractions that may be DSR contributions, (2) identify appropriate ways of consuming and producing knowledge when they are preparing journal articles or other scholarly works, (3) understand and position the knowledge contributions of their research projects, and (4) structure a DSR article so that it emphasizes significant contributions to the knowledge base. Our focal contribution is the DSR knowledge contribution framework with two dimensions based on the existing state of knowledge in both the problem and solution domains for the research opportunity under study. In addition, we propose a DSR communication schema with similarities to more conventional publication patterns, but which substitutes the description of the DSR artifact in place of a traditional results section. We evaluate the DSR contribution framework and the DSR communication schema via examinations of DSR exemplar publications.\n",
            "------------------------------------\n",
            "Title What Does BERT Look at? An Analysis of BERT’s Attention\n",
            "Author [{'authorId': '144358401', 'name': 'Kevin Clark'}, {'authorId': '3030219', 'name': 'Urvashi Khandelwal'}, {'authorId': '39455775', 'name': 'Omer Levy'}, {'authorId': '144783904', 'name': 'Christopher D. Manning'}]\n",
            "Venue BlackboxNLP@ACL\n",
            "year 2019\n",
            "Abstract Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\n",
            "------------------------------------\n",
            "Title VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback\n",
            "Author [{'authorId': '2933399', 'name': 'Ruining He'}, {'authorId': '35660011', 'name': 'Julian McAuley'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2015\n",
            "Abstract \n",
            " \n",
            " Modern recommender systems model people and items by discovering or `teasing apart' the underlying dimensions that encode the properties of items and users' preferences toward them. Critically, such dimensions are uncovered based on user feedback, often in implicit form (such as purchase histories, browsing logs, etc.); in addition, some recommender systems make use of side information, such as product attributes, temporal information, or review text.However one important feature that is typically ignored by existing personalized recommendation and ranking methods is the visual appearance of the items being considered. In this paper we propose a scalable factorization model to incorporate visual signals into predictors of people's opinions, which we apply to a selection of large, real-world datasets. We make use of visual features extracted from product images using (pre-trained) deep networks, on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people's feedback. This not only leads to significantly more accurate personalized ranking methods, but also helps to alleviate cold start issues, and qualitatively to analyze the visual dimensions that influence people's opinions.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title The Evolution of Social Commerce: The People, Management, Technology, and Information Dimensions\n",
            "Author [{'authorId': '9282087', 'name': 'Ching-Hsing Wang'}, {'authorId': '145736516', 'name': 'Ping Zhang'}]\n",
            "Venue Communications of the Association for Information Systems\n",
            "year 2012\n",
            "Abstract Social commerce is a form of commerce mediated by social media and is converging both online and offline environments. As a relatively new phenomenon, social commerce has evolved quickly in practice, yet has gained little attention in the IS discipline. With its pervasiveness in businesses and people’s lives, social commerce presents ample research opportunities that can have both theoretical and practical significance and implications. This article aims to capture researchers’ attention by describing the characteristics of social commerce and its potential future directions. We trace the evolutionary patterns of social commerce chronologically, based on trade articles and academic publications from 2005 to 2011. A framework that combines people, management, technology, and information dimensions is used to provide a systematic analysis of social commerce development. Our examination shows that since 2005, the year the term social commerce was incepted, assumptions and understanding of people in social commerce move from a simple and general description of human social nature to a rich exploration with different angles from social psychology, social heuristics, national culture, and economic situations. On the management dimension, business strategies and models evolve from the short-tail to long-tail thinking, with invented concepts such as branded social networks/communities, niche social networks/communities, niche brands, co-creating, team-buying, and multichannel social networks. Technologically, IT platforms and capabilities for social commerce evolve from blogs, to social networking sites, to mediasharing sites, and to smartphones. While Facebook becomes a profit-generating platform, creating the notion of f-commerce, Google and Twitter become strong competitors with great potentials. Information in social commerce evolves from peer-generated, to community-generated (crowdsourcing), to consumer and marketer co-created, and to global crowdsourced. Our examination identifies various conceptualizations, terminologies, views, and perspectives about social commerce and its relation to other wellknown concepts such as e-commerce. In light of the evolution of social commerce, we provide possible future directions for research and practice.\n",
            "------------------------------------\n",
            "Title Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks\n",
            "Author [{'authorId': '144779781', 'name': 'Z. Cai'}, {'authorId': '7686798', 'name': 'Zaobo He'}, {'authorId': '2066617014', 'name': 'Xin Guan'}, {'authorId': '51166394', 'name': 'Yingshu Li'}]\n",
            "Venue IEEE Transactions on Dependable and Secure Computing\n",
            "year 2018\n",
            "Abstract Releasing social network data could seriously breach user privacy. User profile and friendship relations are inherently private. Unfortunately, sensitive information may be predicted out of released data through data mining techniques. Therefore, sanitizing network data prior to release is necessary. In this paper, we explore how to launch an inference attack exploiting social networks with a mixture of non-sensitive attributes and social relationships. We map this issue to a collective classification problem and propose a collective inference model. In our model, an attacker utilizes user profile and social relationships in a collective manner to predict sensitive information of related victims in a released social network dataset. To protect against such attacks, we propose a data sanitization method collectively manipulating user profile and friendship relations. Besides sanitizing friendship relations, the proposed method can take advantages of various data-manipulating methods. We show that we can easily reduce adversary’s prediction accuracy on sensitive information, while resulting in less accuracy decrease on non-sensitive information towards three social network datasets. This is the first work to employ collective methods involving various data-manipulating methods and social relationships to protect against inference attacks in social networks.\n",
            "------------------------------------\n",
            "Title Revisiting IS business value research: what we already know, what we still need to know, and how we can get there\n",
            "Author [{'authorId': '1902078', 'name': 'G. Schryen'}]\n",
            "Venue European Journal of Information Systems\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title The Supply Chain Has No Clothes: Technology Adoption of Blockchain for Supply Chain Transparency\n",
            "Author [{'authorId': '102072994', 'name': 'Kristoffer Francisco'}, {'authorId': '143706156', 'name': 'David Swanson'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Blockchain technology, popularized by Bitcoin cryptocurrency, is characterized as an open-source, decentralized, distributed database for storing transaction information. Rather than relying on centralized intermediaries (e.g., banks) this technology allows two parties to transact directly using duplicate, linked ledgers called blockchains. This makes transactions considerably more transparent than those provided by centralized systems. As a result, transactions are executed without relying on explicit trust [of a third party], but on the distributed trust based on the consensus of the network (i.e., other blockchain users). Applying this technology to improve supply chain transparency has many possibilities. Every product has a long and storied history. However, much of this history is presently obscured. Often, when negative practices are exposed, they quickly escalate to scandalous, and financially crippling proportions. There are many recent examples, such as the exposure of child labor upstream in the manufacturing process and the unethical use of rainforest resources. Blockchain may bring supply chain transparency to a new level, but presently academic and managerial adoption of blockchain technologies is limited by our understanding. To address this issue, this research uses the Unified Theory of Acceptance and Use of Technology (UTAUT) and the concept of technology innovation adoption as a foundational framework for supply chain traceability. A conceptual model is developed and the research culminates with supply chain implications of blockchain that are inspired by theory and literature review.\n",
            "------------------------------------\n",
            "Title Addressing the Personalization-Privacy Paradox: An Empirical Assessment from a Field Experiment on Smartphone Users\n",
            "Author [{'authorId': '2381445', 'name': 'J. Sutanto'}, {'authorId': '46459677', 'name': 'Elia Palme'}, {'authorId': '1786225', 'name': 'Chuan-Hoo Tan'}, {'authorId': '1978098', 'name': 'C. Phang'}]\n",
            "Venue MIS Q.\n",
            "year 2013\n",
            "Abstract Privacy has been an enduring concern associated with commercial information technology (IT) applications, in particular regarding the issue of personalization. IT-enabled personalization, while potentially making the user computing experience more gratifying, often relies heavily on the user's personal information to deliver individualized services, which raises the user's privacy concerns. We term the tension between personalization and privacy, which follows from marketers exploiting consumers' data to offer personalized product information, the personalization--privacy paradox. To better understand this paradox, we build on the theoretical lenses of uses and gratification theory and information boundary theory to conceptualize the extent to which privacy impacts the process and content gratifications derived from personalization, and how an IT solution can be designed to alleviate privacy concerns. \n",
            " \n",
            "Set in the context of personalized advertising applications for smartphones, we propose and prototype an IT solution, referred to as a personalized, privacy-safe application, that retains users' information locally on their smartphones while still providing them with personalized product messages. We validated this solution through a field experiment by benchmarking it against two more conventional applications: a base nonpersonalized application that broadcasts non-personalized product information to users, and a personalized, nonprivacy safe application that transmits user information to a central marketer's server. The results show that (compared to the non-personalized application), while personalized, privacy-safe or not increased application usage (reflecting process gratification), it was only when it was privacy-safe that users saved product messages (reflecting content gratification) more frequently. Follow-up surveys corroborated these nuanced findings and further revealed the users' psychological states, which explained our field experiment results. We found that saving advertisements for content gratification led to a perceived intrusion of information boundary that made users reluctant to do so. Overall our proposed IT solution, which delivers a personalized service but avoids transmitting users' personal information to third parties, reduces users' perceptions that their information boundaries are being intruded upon, thus mitigating the personalization--privacy paradox and increasing both process and content gratification.\n",
            "------------------------------------\n",
            "Title A survey on information visualization: recent advances and challenges\n",
            "Author [{'authorId': '48641970', 'name': 'Shixia Liu'}, {'authorId': '1684136', 'name': 'Weiwei Cui'}, {'authorId': '121962020', 'name': 'Yingcai Wu'}, {'authorId': '145823303', 'name': 'Mengchen Liu'}]\n",
            "Venue The Visual Computer\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A scoping review of rapid review methods\n",
            "Author [{'authorId': '145087336', 'name': 'A. Tricco'}, {'authorId': '145012744', 'name': 'J. Antony'}, {'authorId': '5347809', 'name': 'W. Zarin'}, {'authorId': '6876906', 'name': 'L. Strifler'}, {'authorId': '33970094', 'name': 'M. Ghassemi'}, {'authorId': '28975389', 'name': 'J. Ivory'}, {'authorId': '153628046', 'name': 'L. Perrier'}, {'authorId': '1789815', 'name': 'B. Hutton'}, {'authorId': '1825473', 'name': 'D. Moher'}, {'authorId': '32108070', 'name': 'S. Straus'}]\n",
            "Venue BMC Medicine\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Signalling Theory and Equilibrium in Strategic Management Research: An Assessment and a Research Agenda\n",
            "Author [{'authorId': '96736170', 'name': 'D. Bergh'}, {'authorId': '39858579', 'name': 'Brian L. Connelly'}, {'authorId': '1741064666', 'name': 'David J. Ketchen, Jr'}, {'authorId': '116566952', 'name': 'Lu M. Shannon'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Actors within organizations commonly must make choices armed with incomplete and asymmetrically distributed information. Signalling theory seeks to explain how individuals are able to do so. This theory's primary predictive mechanism is ‘separating equilibrium’, which occurs when a signal's expectations are confirmed through experience. A content analysis finds that most strategic management signalling theory studies have not fully leveraged separating equilibrium. This presents two possible paths for future research. First, some researchers may wish to incorporate separating equilibrium. We illustrate how doing so can uncover new relationships, generate novel insights, and fortify the theory's application. Others who want to theorize about signals, but not examine separating equilibrium, could integrate ideas from signalling theory with other information perspectives. Here a signal becomes one stimulus among many that corporate actors interpret and act upon. We provide research agendas so strategy scholars can apply signalling theory most effectively to meet their research objectives.\n",
            "------------------------------------\n",
            "Title Learning Discrete Representations via Information Maximizing Self-Augmented Training\n",
            "Author [{'authorId': '48594758', 'name': 'Weihua Hu'}, {'authorId': '3213400', 'name': 'Takeru Miyato'}, {'authorId': '3117618', 'name': 'Seiya Tokui'}, {'authorId': '8252749', 'name': 'Eiichi Matsumoto'}, {'authorId': '67154907', 'name': 'Masashi Sugiyama'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2017\n",
            "Abstract Learning discrete representations of data is a central machine learning task because of the compactness of the representations and ease of interpretation. The task includes clustering and hash learning as special cases. Deep neural networks are promising to be used because they can model the non-linearity of data and scale to large datasets. However, their model complexity is huge, and therefore, we need to carefully regularize the networks in order to learn useful representations that exhibit intended invariance for applications of interest. To this end, we propose a method called Information Maximizing Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose the invari-ance on discrete representations. More specifically, we encourage the predicted representations of augmented data points to be close to those of the original data points in an end-to-end fashion. At the same time, we maximize the information-theoretic dependency between data and their predicted discrete representations. Extensive experiments on benchmark datasets show that IMSAT produces state-of-the-art results for both clustering and unsupervised hash learning.\n",
            "------------------------------------\n",
            "Title Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\n",
            "Author [{'authorId': '40940512', 'name': 'Jun Liu'}, {'authorId': '3000984', 'name': 'Amir Shahroudy'}, {'authorId': '1510477221', 'name': 'Dong Xu'}, {'authorId': '2096527', 'name': 'G. Wang'}]\n",
            "Venue European Conference on Computer Vision\n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A social diffusion model of misinformation and disinformation for understanding human information behaviour\n",
            "Author [{'authorId': '145852202', 'name': 'N. Karlova'}, {'authorId': '143621152', 'name': 'K. Fisher'}]\n",
            "Venue Information Research\n",
            "year 2013\n",
            "Abstract Introduction. People enjoy sharing information, even when they do not believe it. Thus, misinformation (inaccurate information) and disinformation (deceptive information) diffuse throughout social networks, as misinforming and disinforming are varieties of information behaviour. Social media have made such diffusion easier and faster. Many information behaviour models, however, suggest a normative model of information as true, accurate, complete, despite the ubiquity of misinformation and disinformation. Analysis. Misinformation and disinformation are defined and we show how they extend the concept of information through their informativeness. Table 1 summarizes the features of information, misinformation, and disinformation. Figure 1 illustrates the social diffusion process by which misinforming and disinforming function as types of information behaviour. Conclusion. Misinformation and disinformation are closely linked to information literacy, especially in terms of how they are diffused and shared and how people use both cues to credibility and cues to deception to make judgements. Misinformation and disinformation present both challenges and opportunities for individuals, businesses, and governments. Future work in immersive, 3D virtual worlds takes a naturalistic approach to understand the principal elements of cues to misinformation and disinformation.\n",
            "------------------------------------\n",
            "Title Sensing as a service model for smart cities supported by Internet of Things\n",
            "Author [{'authorId': '143742327', 'name': 'Charith Perera'}, {'authorId': '52425525', 'name': 'A. Zaslavsky'}, {'authorId': '145188508', 'name': 'P. Christen'}, {'authorId': '1782841', 'name': 'Dimitrios Georgakopoulos'}]\n",
            "Venue Transactions on Emerging Telecommunications Technologies\n",
            "year 2013\n",
            "Abstract The world population is growing at a rapid pace. Towns and cities are accommodating half of the world's population thereby creating tremendous pressure on every aspect of urban living. Cities are known to have large concentration of resources and facilities. Such environments attract people from rural areas. However, unprecedented attraction has now become an overwhelming issue for city governance and politics. The enormous pressure towards efficient city management has triggered various Smart City initiatives by both government and private sector businesses to invest in information and communication technologies to find sustainable solutions to the growing issues. The Internet of Things (IoT) has also gained significant attention over the past decade. IoT envisions to connect billions of sensors to the Internet and expects to use them for efficient and effective resource management in Smart Cities. Today, infrastructure, platforms and software applications are offered as services using cloud technologies. In this paper, we explore the concept of sensing as a service and how it fits with the IoT. Our objective is to investigate the concept of sensing as a service model in technological, economical and social perspectives and identify the major open challenges and issues. Copyright © 2013 John Wiley & Sons, Ltd.\n",
            "------------------------------------\n",
            "Title Influence of fake news in Twitter during the 2016 US presidential election\n",
            "Author [{'authorId': '40685732', 'name': 'A. Bovet'}, {'authorId': '2337765', 'name': 'H. Makse'}]\n",
            "Venue Nature Communications\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Gated-SCNN: Gated Shape CNNs for Semantic Segmentation\n",
            "Author [{'authorId': '150324836', 'name': 'Towaki Takikawa'}, {'authorId': '145360004', 'name': 'David Acuna'}, {'authorId': '2745026', 'name': 'V. Jampani'}, {'authorId': '37895334', 'name': 'S. Fidler'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2019\n",
            "Abstract Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.\n",
            "------------------------------------\n",
            "Title News Recommendations from Social Media Opinion Leaders: Effects on Media Trust and Information Seeking\n",
            "Author [{'authorId': '50537497', 'name': 'J. Turcotte'}, {'authorId': '12425155', 'name': 'Chance York'}, {'authorId': '1398095459', 'name': 'Jacob Irving'}, {'authorId': '40435797', 'name': 'Rosanne M. Scholl'}, {'authorId': '2002461', 'name': 'Raymond J. Pingree'}]\n",
            "Venue J. Comput. Mediat. Commun.\n",
            "year 2015\n",
            "Abstract Polls show a strong decline in public trust of traditional news outlets; however, social media offers new avenues for receiving news content. This experiment used the Facebook API to manipulate whether a news story appeared to have been posted on Facebook by one of the respondent's real-life Facebook friends. Results show that social media recommendations improve levels of media trust, and also make people want to follow more news from that particular media outlet in the future. Moreover, these effects are amplified when the real-life friend sharing the story on social media is perceived as an opinion leader. Implications for democracy and the news business are discussed.\n",
            "------------------------------------\n",
            "Title Research Note - The Impact of External Word-of-Mouth Sources on Retailer Sales of High-Involvement Products\n",
            "Author [{'authorId': '144385173', 'name': 'B. Gu'}, {'authorId': '50001617', 'name': 'Jaehong Park'}, {'authorId': '1739328', 'name': 'Prabhudev Konana'}]\n",
            "Venue Information systems research\n",
            "year 2012\n",
            "Abstract Online word-of-mouth (WOM) such as consumer opinions, user experiences, and product reviews has become a major information source in consumer purchase decisions. Prior research on online WOM effect has focused mostly on low-involvement products such as books or CDs. For these products, retailer-hosted (internal) WOM is shown to influence sales overwhelmingly. Numerous surveys, however, suggest consumers often conduct pre-purchase searches for high-involvement products (e.g., digital cameras) and visit external WOM websites during the search process. In this study, we analyze the relative impact of external and internal WOMs on retailer sales for high-involvement products using a panel of sales and WOM data for 148 digital cameras from Amazon.com and three external WOM websites (Cnet, DpReview, and Epinions) over a four-month period. The results suggest that a retailer's internal WOM has a limited influence on its sales of high-involvement products, while external WOM sources have a significant impact on the retailer's sales. The findings imply that external WOM sources play an important role in the information search process.\n",
            "------------------------------------\n",
            "Title Dynamic consent: a patient interface for twenty-first century research networks\n",
            "Author [{'authorId': '50322146', 'name': 'J. Kaye'}, {'authorId': '1749954', 'name': 'E. Whitley'}, {'authorId': '145325332', 'name': 'David Lund'}, {'authorId': '143758847', 'name': 'M. Morrison'}, {'authorId': '4495384', 'name': 'H. Teare'}, {'authorId': '6423976', 'name': 'Karen Melham'}]\n",
            "Venue European Journal of Human Genetics\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Convolutional Matrix Factorization for Document Context-Aware Recommendation\n",
            "Author [{'authorId': '2145183039', 'name': 'Donghyun Kim'}, {'authorId': '2109120259', 'name': 'Chanyoung Park'}, {'authorId': '2031932', 'name': 'Jinoh Oh'}, {'authorId': '31273100', 'name': 'Sungyoung Lee'}, {'authorId': '1723357', 'name': 'Hwanjo Yu'}]\n",
            "Venue ACM Conference on Recommender Systems\n",
            "year 2016\n",
            "Abstract Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.\n",
            "------------------------------------\n",
            "Title INSAT-3D vertical profile retrievals at IMDPS, New Delhi : A preliminary evaluation\n",
            "Author [{'authorId': '2052388247', 'name': 'A. K. Mitra'}, {'authorId': '48867189', 'name': 'S. Bhan'}, {'authorId': '2109670168', 'name': 'Anubha Sharma'}, {'authorId': '2065986399', 'name': 'N. Kaushik'}, {'authorId': '96211046', 'name': 'Shailesh Parihar'}, {'authorId': '118161799', 'name': 'R. Mahandru'}, {'authorId': '49923722', 'name': 'P. K. Kundu'}]\n",
            "Venue Mausam\n",
            "year 2021\n",
            "Abstract Successful launch of indigenous geostationary satellite INSAT-3D on 26 July, 2013 with advanced meteorological payloads onboard, has provided a new opportunity to the Indian meteorologists. A new payload, atmospheric sounder, has been launched for the first time in Indian satellite to provide the vertical profiles of temperature and humidity in the atmosphere. It is possible to obtain continuous upper level temperature and moisture profiles with a spatial resolution of 30 × 30 km and temporal resolution of one hour. The INSAT-3D temperature and moisture retrievals derived from routine application of sounder data processing algorithm installed at INSAT Meteorological Data Processing System (IMDPS), New Delhi were compared with collocated GPS sonde observations (GPOB), and National Oceanic and Atmospheric Administration (NOAA) polar orbiting satellites (N-18 and N-19) derived profiles to assess retrieval performance. The INSAT-3D temperature profiles show the positive bias throughout from surface to 30 hPa against the GPOB. The overall temperature between retrivals exhibited a systematic bias error at almost all the levels. Bias ranges from 2 to 4 °C between 1000 to 100 hPa levels. The levels of maximum positive bias, where INSAT-3D values are too warm, are near the surface and 100 hPa. This can be attributed to the inability of the retrieval scheme to precisely locate the change in the lapse rate associated with the tropopause due to general disagreement at higher levels. However, the moisture profiles showed somewhat lower accuracy against the GPOB. INSAT-3D and GPOB derived Total Perceptible Water (TPW) were also compared and showed that correlation of INSAT-3D TPW agree well with GPOB TPW to some extent than the level specific LI.\n",
            "------------------------------------\n",
            "Title Fixing a Broken ELBO\n",
            "Author [{'authorId': '122113652', 'name': 'Alexander A. Alemi'}, {'authorId': '16443937', 'name': 'Ben Poole'}, {'authorId': '33091759', 'name': 'Ian S. Fischer'}, {'authorId': '2403637', 'name': 'Joshua V. Dillon'}, {'authorId': '2278009', 'name': 'R. Saurous'}, {'authorId': '1702318', 'name': 'K. Murphy'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2017\n",
            "Abstract Recent work in unsupervised representation learning has focused on learning deep directed latent-variable models. Fitting these models by maximizing the marginal likelihood or evidence is typically intractable, thus a common approximation is to maximize the evidence lower bound (ELBO) instead. However, maximum likelihood training (whether exact or approximate) does not necessarily result in a good latent representation, as we demonstrate both theoretically and empirically. In particular, we derive variational lower and upper bounds on the mutual information between the input and the latent variable, and use these bounds to derive a rate-distortion curve that characterizes the tradeoff between compression and reconstruction accuracy. Using this framework, we demonstrate that there is a family of models with identical ELBO, but different quantitative and qualitative characteristics. Our framework also suggests a simple new method to ensure that latent variable models with powerful stochastic decoders do not ignore their latent code.\n",
            "------------------------------------\n",
            "Title The role of data privacy in marketing\n",
            "Author [{'authorId': '46662068', 'name': 'Kelly D. Martin'}, {'authorId': '145215321', 'name': 'P. Murphy'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Quantum Fisher information matrix and multiparameter estimation\n",
            "Author [{'authorId': '2153465660', 'name': 'Jing Liu'}, {'authorId': '2151334140', 'name': 'Haidong Yuan'}, {'authorId': '48574681', 'name': 'Xiao-Ming Lu'}, {'authorId': '1524728320', 'name': 'Xiaoguang Wang'}]\n",
            "Venue Journal of Physics A: Mathematical and Theoretical\n",
            "year 2019\n",
            "Abstract Quantum Fisher information matrix (QFIM) is a core concept in theoretical quantum metrology due to the significant importance of quantum Cramér–Rao bound in quantum parameter estimation. However, studies in recent years have revealed wide connections between QFIM and other aspects of quantum mechanics, including quantum thermodynamics, quantum phase transition, entanglement witness, quantum speed limit and non-Markovianity. These connections indicate that QFIM is more than a concept in quantum metrology, but rather a fundamental quantity in quantum mechanics. In this paper, we summarize the properties and existing calculation techniques of QFIM for various cases, and review the development of QFIM in some aspects of quantum mechanics apart from quantum metrology. On the other hand, as the main application of QFIM, the second part of this paper reviews the quantum multiparameter Cramér–Rao bound, its attainability condition and the associated optimal measurements. Moreover, recent developments in a few typical scenarios of quantum multiparameter estimation and the quantum advantages are also thoroughly discussed in this part.\n",
            "------------------------------------\n",
            "Title STITCH 5: augmenting protein–chemical interaction networks with tissue and affinity data\n",
            "Author [{'authorId': '51006560', 'name': 'Damian Szklarczyk'}, {'authorId': '145130121', 'name': 'Alberto Santos'}, {'authorId': '2544559', 'name': 'C. V. Mering'}, {'authorId': '2214567', 'name': 'L. Jensen'}, {'authorId': '3534315', 'name': 'P. Bork'}, {'authorId': '31883087', 'name': 'Michael Kuhn'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2015\n",
            "Abstract Interactions between proteins and small molecules are an integral part of biological processes in living organisms. Information on these interactions is dispersed over many databases, texts and prediction methods, which makes it difficult to get a comprehensive overview of the available evidence. To address this, we have developed STITCH (‘Search Tool for Interacting Chemicals’) that integrates these disparate data sources for 430 000 chemicals into a single, easy-to-use resource. In addition to the increased scope of the database, we have implemented a new network view that gives the user the ability to view binding affinities of chemicals in the interaction network. This enables the user to get a quick overview of the potential effects of the chemical on its interaction partners. For each organism, STITCH provides a global network; however, not all proteins have the same pattern of spatial expression. Therefore, only a certain subset of interactions can occur simultaneously. In the new, fifth release of STITCH, we have implemented functionality to filter out the proteins and chemicals not associated with a given tissue. The STITCH database can be downloaded in full, accessed programmatically via an extensive API, or searched via a redesigned web interface at http://stitch.embl.de.\n",
            "------------------------------------\n",
            "Title Bayesian Persuasion and Information Design\n",
            "Author [{'authorId': '2968902', 'name': 'Emir Kamenica'}]\n",
            "Venue Annual Review of Economics\n",
            "year 2019\n",
            "Abstract A school may improve its students’ job outcomes if it issues only coarse grades. Google can reduce congestion on roads by giving drivers noisy information about the state of traffic. A social planner might raise everyone's welfare by providing only partial information about solvency of banks. All of this can happen even when everyone is fully rational and understands the data-generating process. Each of these examples raises questions of what is the (socially or privately) optimal information that should be revealed. In this article, I review the literature that answers such questions.\n",
            "------------------------------------\n",
            "Title COVID-19 infodemic: More retweets for science-based information on coronavirus than for false information\n",
            "Author [{'authorId': '48072570', 'name': 'Cristina M. Pulido'}, {'authorId': '1405451231', 'name': 'Beatriz Villarejo-Carballido'}, {'authorId': '1404053936', 'name': 'Gisela Redondo-Sama'}, {'authorId': '32524958', 'name': 'Aitor Gómez'}]\n",
            "Venue \n",
            "year 2020\n",
            "Abstract The World Health Organization has not only signaled the health risks of COVID-19, but also labeled the situation as infodemic, due to the amount of information, true and false, circulating around this topic. Research shows that, in social media, falsehood is shared far more than evidence-based information. However, there is less research analyzing the circulation of false and evidence-based information during health emergencies. Thus, the present study aims at shedding new light on the type of tweets that circulated on Twitter around the COVID-19 outbreak for two days, in order to analyze how false and true information was shared. To that end, 1000 tweets have been analyzed. Results show that false information is tweeted more but retweeted less than science-based evidence or fact-checking tweets, while science-based evidence and fact-checking tweets capture more engagement than mere facts. These findings bring relevant insights to inform public health policies.\n",
            "------------------------------------\n",
            "Title Characterizing the Propagation of Situational Information in Social Media During COVID-19 Epidemic: A Case Study on Weibo\n",
            "Author [{'authorId': '2107914309', 'name': 'Lifang Li'}, {'authorId': '34698178', 'name': 'Qingpeng Zhang'}, {'authorId': '153315870', 'name': 'Xiao Wang'}, {'authorId': '2155659664', 'name': 'J. Zhang'}, {'authorId': '2156632333', 'name': 'Tao Wang'}, {'authorId': '2072687801', 'name': 'Tian-Lu Gao'}, {'authorId': '2106607071', 'name': 'Wei Duan'}, {'authorId': '145158945', 'name': 'K. Tsoi'}, {'authorId': '2148954297', 'name': 'Fei-yue Wang'}]\n",
            "Venue IEEE Transactions on Computational Social Systems\n",
            "year 2020\n",
            "Abstract During the ongoing outbreak of coronavirus disease (COVID-19), people use social media to acquire and exchange various types of information at a historic and unprecedented scale. Only the situational information are valuable for the public and authorities to response to the epidemic. Therefore, it is important to identify such situational information and to understand how it is being propagated on social media, so that appropriate information publishing strategies can be informed for the COVID-19 epidemic. This article sought to fill this gap by harnessing Weibo data and natural language processing techniques to classify the COVID-19-related information into seven types of situational information. We found specific features in predicting the reposted amount of each type of information. The results provide data-driven insights into the information need and public attention.\n",
            "------------------------------------\n",
            "Title Missing Information Reconstruction of Remote Sensing Data: A Technical Review\n",
            "Author [{'authorId': '32309758', 'name': 'Huanfeng Shen'}, {'authorId': '50079922', 'name': 'Xinghua Li'}, {'authorId': '2055428402', 'name': 'Qing Cheng'}, {'authorId': '2055608950', 'name': 'Chao Zeng'}, {'authorId': '2109701270', 'name': 'Gang Yang'}, {'authorId': '26157918', 'name': 'Huifang Li'}, {'authorId': '9802604', 'name': 'Liangpei Zhang'}]\n",
            "Venue IEEE Geoscience and Remote Sensing Magazine\n",
            "year 2015\n",
            "Abstract Because of sensor malfunction and poor atmospheric conditions, there is usually a great deal of missing information in optical remote sensing data, which reduces the usage rate and hinders the follow-up interpretation. In the past decades, missing information reconstruction of remote sensing data has become an active research field, and a large number of algorithms have been developed. However, to the best of our knowledge, there has not, to date, been a study that has been aimed at expatiating and summarizing the current situation. This is therefore our motivation in this review. This paper provides an introduction to the principles and theories of missing information reconstruction of remote sensing data. We classify the established and emerging algorithms into four main categories, followed by a comprehensive comparison of them from both experimental and theoretical perspectives. This paper also predicts the promising future research directions.\n",
            "------------------------------------\n",
            "Title You are facing the Mona Lisa: spot localization using PHY layer information\n",
            "Author [{'authorId': '2115761715', 'name': 'Souvik Sen'}, {'authorId': '2757057', 'name': 'B. Radunovic'}, {'authorId': '1694368', 'name': 'Romit Roy Choudhury'}, {'authorId': '52626911', 'name': 'T. Minka'}]\n",
            "Venue ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services\n",
            "year 2012\n",
            "Abstract This paper explores the viability of precise indoor localization using physical layer information in WiFi systems. We find evidence that channel responses from multiple OFDM subcarriers can be a promising location signature. While these signatures certainly vary over time and environmental mobility, we notice that their core structure preserves certain properties that are amenable to localization. We attempt to harness these opportunities through a functional system called PinLoc, implemented on off-the-shelf Intel 5300 cards. We evaluate the system in a busy engineering building, a crowded student center, a cafeteria, and at the Duke University museum, and demonstrate localization accuracies in the granularity of 1m x 1m boxes, called \"spots\". Results from 100 spots show that PinLoc is able to localize users to the correct spot with 89% mean accuracy, while incurring less than 6% false positives. We believe this is an important step forward, compared to the best indoor localization schemes of today, such as Horus.\n",
            "------------------------------------\n",
            "Title Digital Divide\n",
            "Author [{'authorId': '1404920817', 'name': 'Peter A. Chow-White'}, {'authorId': '65842273', 'name': 'Betty Ackah'}, {'authorId': '108539183', 'name': 'Philippa R. Adams'}]\n",
            "Venue Oxford Bibliographies Online Datasets\n",
            "year 2018\n",
            "Abstract the Internet for older people by Peter Millward Focussing upon the elderly, this article utilises data discovered as researcher for Age Concern in Wigan (U.K.) and examines the feelings of older people toward the Internet. It explores the reasons why some clients and volunteers choose to use the Internet, whilst others do not, relating these perspectives to the organisations, alongside broader national (U.K.) and EU, commitments to reduce the digital divide. The article argues that for the elderly Internet usability is based upon more than availability of technology. Instead a lack of Web skills among the elderly leads to an opinion that information and communication technologies are for the young, leading to a long-term damage lack of interest in using the Internet.\n",
            "------------------------------------\n",
            "Title Science, New Media, and the Public\n",
            "Author [{'authorId': '3030164', 'name': 'D. Brossard'}, {'authorId': '2994143', 'name': 'D. Scheufele'}]\n",
            "Venue Science\n",
            "year 2013\n",
            "Abstract A better understanding is needed about how the online environment affects the communication of science information to the public. Nine in 10 internet users in the United States turn to search engines to find information (1), and 60% of the U.S. public seeking information about specific scientific issues lists the Internet as their primary source of information (2). This has created a new urgency for scientists to pay attention to these trends and to the emerging scholarly literature about communicating science in this brave new “online” world.\n",
            "------------------------------------\n",
            "Title The role of e-learning, the advantages and disadvantages of its adoption in Higher Education.\n",
            "Author [{'authorId': '83355830', 'name': 'Valentina Arkorful'}, {'authorId': '98377625', 'name': 'N. Abaidoo'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This study investigates the effectiveness of using e-learning in teaching in tertiary institutions. In institutions of higher education, the issue of utilizing modern information and communication technologies for teaching and learning is very important. This study reviews literature and gives a scholarly background to the study by reviewing some contributions made by various researchers and institutions on the concept of e-learning, particularly its usage in teaching and learning in higher educational institutions. It unveils some views that people and institutions have shared globally on the adoption and integration of e-learning technologies in education through surveys and other observations. It looks at the meaning or definitions of e-learning as given by different researchers and the role that e-learning plays in higher educational institutions in relation to teaching and learning processes, and the advantages and disadvantages of its adoption and implemention.\n",
            "------------------------------------\n",
            "Title Should Banks' Stress Test Results Be Disclosed? An Analysis of the Costs and Benefits\n",
            "Author [{'authorId': '3073437', 'name': 'Itay Goldstein'}, {'authorId': '3271283', 'name': 'H. Sapra'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Stress tests have become an important component of the supervisory toolkit. However, the extent of disclosure of stress-test results remains controversial. We argue that while stress tests uncover unique information to outsiders – because banks operate in second-best environments with multiple imperfections – there are potential endogenous costs associated with such disclosure.First, disclosure might interfere with the operation of the interbank market and the risk sharing provided in this market. Second, while disclosure might improve price efficiency and hence market discipline, it might also induce sub-optimal behavior in banks. Third, disclosure might induce ex post market externalities that lead to excessive and inefficient reaction to public news. Fourth, disclosure might also reduce traders incentives to gather information, which reduces market discipline because it hampers the ability of supervisors to learn from market data for their regulatory actions.Overall, we believe that disclosure of stress-test results is beneficial because it promotes financial stability. However, in promoting financial stability, such disclosures may exacerbate bank-specific inefficiencies. We provide some guidance on how such inefficiencies could be minimized.\n",
            "------------------------------------\n",
            "Title Assessing the Probability of Bankruptcy\n",
            "Author [{'authorId': '121307368', 'name': 'Jarom Heaps'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Knowing whether or not a company is financial stable has always been a top concern for analysts and money managers. This paper compares the effectiveness of default prediction using two different types of measures: accounting and market based. Accounting measures have been the most popular even though, according to theory, a market based measure reflects all available information. Theory goes as far to say that accounting measures can add no incremental value to a market based measure. In my research I found that accounting based measures can be effective in their predictive power; the market-based measure (BSM) results were much more difficult to estimate within the limits of this research project.\n",
            "------------------------------------\n",
            "Title Gene Ontology Consortium: going forward\n",
            "Author [{'authorId': '1699320', 'name': 'J. Blake'}, {'authorId': '145366645', 'name': 'Kim M Rutherford'}, {'authorId': '39570037', 'name': 'J. Chan'}, {'authorId': '3034434', 'name': 'R. Kishore'}, {'authorId': '1808359', 'name': 'P. Sternberg'}, {'authorId': '2215707', 'name': 'K. V. Auken'}, {'authorId': '144038105', 'name': 'Hans-Michael Müller'}, {'authorId': '32029087', 'name': 'J. Done'}, {'authorId': '2110540217', 'name': 'Yanhong Li'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2014\n",
            "Abstract The Gene Ontology (GO; http://www.geneontology.org) is a community-based bioinformatics resource that supplies information about gene product function using ontologies to represent biological knowledge. Here we describe improvements and expansions to several branches of the ontology, as well as updates that have allowed us to more efficiently disseminate the GO and capture feedback from the research community. The Gene Ontology Consortium (GOC) has expanded areas of the ontology such as cilia-related terms, cell-cycle terms and multicellular organism processes. We have also implemented new tools for generating ontology terms based on a set of logical rules making use of templates, and we have made efforts to increase our use of logical definitions. The GOC has a new and improved web site summarizing new developments and documentation, serving as a portal to GO data. Users can perform GO enrichment analysis, and search the GO for terms, annotations to gene products, and associated metadata across multiple species using the all-new AmiGO 2 browser. We encourage and welcome the input of the research community in all biological areas in our continued effort to improve the Gene Ontology.\n",
            "------------------------------------\n",
            "Title Preparing for Life in a Digital Age: The IEA International Computer and Information Literacy Study International Report\n",
            "Author [{'authorId': '47946182', 'name': 'J. Fraillon'}, {'authorId': '80863696', 'name': 'J. Ainley'}, {'authorId': '40007442', 'name': 'Wolfram Schulz'}, {'authorId': '30211646', 'name': 'Tim Friedman'}, {'authorId': '12503728', 'name': 'E. Gebhardt'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Ability to use information and communication technologies (ICT) is an imperative for effective participation in todays digital age. Schools worldwide are responding to the need to provide young people with that ability. But how effective are they in this regard? The IEA International Computer and Information Literacy Study (ICILS) responded to this question by studying the extent to which young people have developed computer and information literacy (CIL), which is defined as the ability to use computers to investigate, create and communicate with others at home, school, the workplace and in society.The study was conducted under the auspices of the International Association for the Evaluation of Educational Achievement (IEA) and builds on a series of earlier IEA studies focusing on ICT in education.Data were gathered from almost 60,000 Grade 8 students in more than 3,300 schools from 21 education systems. This information was augmented by data from almost 35,000 teachers in those schools and by contextual data collected from school ICT-coordinators, school principals and the ICILS national research centers.The IEA ICILS team systematically investigated differences among the participating countries in students CIL outcomes, how participating countries were providing CIL-related education and how confident teachers were in using ICT in their pedagogical practice. The team also explored differences within and across countries with respect to relationships between CIL education outcomes and student characteristics and school contexts.In general, the study findings presented in this international report challenge the notion of young people as digital natives with a self-developed capacity to use digital technology. The large variations in CIL proficiency within and across the ICILS countries suggest it is naive to expect young people to develop CIL in the absence of coherent learning programs. Findings also indicate that system- and school-level planning needs to focus on increasing teacher expertise in using ICT for pedagogical purposes if such programs are to have the desired effect.The report furthermore presents an empirically derived scale and description of CIL learning that educational stakeholders can reference when deliberating about CIL education and use to monitor change in CIL over time.\n",
            "------------------------------------\n",
            "Title Room-Temperature Quantum Bit Memory Exceeding One Second\n",
            "Author [{'authorId': '47762783', 'name': 'P. Maurer'}, {'authorId': '4301543', 'name': 'G. Kucsko'}, {'authorId': '3955152', 'name': 'C. Latta'}, {'authorId': '2157755743', 'name': 'L. Jiang'}, {'authorId': '4138853', 'name': 'N. Yao'}, {'authorId': '1745630', 'name': 'S. Bennett'}, {'authorId': '2610119', 'name': 'F. Pastawski'}, {'authorId': '5894239', 'name': 'D. Hunger'}, {'authorId': '92647742', 'name': 'N. Chisholm'}, {'authorId': '3118150', 'name': 'M. Markham'}, {'authorId': '34595505', 'name': 'D. Twitchen'}, {'authorId': '5290828', 'name': 'J. Cirac'}, {'authorId': '145572474', 'name': 'M. Lukin'}]\n",
            "Venue Science\n",
            "year 2012\n",
            "Abstract Extending Quantum Memory Practical applications in quantum communication and quantum computation require the building blocks—quantum bits and quantum memory—to be sufficiently robust and long-lived to allow for manipulation and storage (see the Perspective by Boehme and McCarney). Steger et al. (p. 1280) demonstrate that the nuclear spins of 31P impurities in an almost isotopically pure sample of 28Si can have a coherence time of as long as 192 seconds at a temperature of ∼1.7 K. In diamond at room temperature, Maurer et al. (p. 1283) show that a spin-based qubit system comprised of an isotopic impurity (13C) in the vicinity of a color defect (a nitrogen-vacancy center) could be manipulated to have a coherence time exceeding one second. Such lifetimes promise to make spin-based architectures feasible building blocks for quantum information science. Defects in diamond can be operated as quantum memories at room temperature. Stable quantum bits, capable both of storing quantum information for macroscopic time scales and of integration inside small portable devices, are an essential building block for an array of potential applications. We demonstrate high-fidelity control of a solid-state qubit, which preserves its polarization for several minutes and features coherence lifetimes exceeding 1 second at room temperature. The qubit consists of a single 13C nuclear spin in the vicinity of a nitrogen-vacancy color center within an isotopically purified diamond crystal. The long qubit memory time was achieved via a technique involving dissipative decoupling of the single nuclear spin from its local environment. The versatility, robustness, and potential scalability of this system may allow for new applications in quantum information science.\n",
            "------------------------------------\n",
            "Title Orthogonal Frequency Division Multiplexing With Index Modulation\n",
            "Author [{'authorId': '34685155', 'name': 'E. Başar'}, {'authorId': '1741408', 'name': 'Ü. Aygölü'}, {'authorId': '1748253', 'name': 'E. Panayirci'}, {'authorId': '145967056', 'name': 'H. Poor'}]\n",
            "Venue IEEE Transactions on Signal Processing\n",
            "year 2012\n",
            "Abstract In this paper, a novel orthogonal frequency division multiplexing (OFDM) scheme, called OFDM with index modulation (OFDM-IM), is proposed for operation over frequency-selective and rapidly time-varying fading channels. In this scheme, the information is conveyed not only by M-ary signal constellations as in classical OFDM, but also by the indices of the subcarriers, which are activated according to the incoming bit stream. Different low complexity transceiver structures based on maximum likelihood detection or log-likelihood ratio calculation are proposed and a theoretical error performance analysis is provided for the new scheme operating under ideal channel conditions. Then, the proposed scheme is adapted to realistic channel conditions such as imperfect channel state information and very high mobility cases by modifying the receiver structure. The approximate pairwise error probability of OFDM-IM is derived under channel estimation errors. For the mobility case, several interference unaware/aware detection methods are proposed for the new scheme. It is shown via computer simulations that the proposed scheme achieves significantly better error performance than classical OFDM due to the information bits carried by the indices of OFDM subcarriers under both ideal and realistic channel conditions.\n",
            "------------------------------------\n",
            "Title Prominent Features of Rumor Propagation in Online Social Media\n",
            "Author [{'authorId': '2399803', 'name': 'Sejeong Kwon'}, {'authorId': '1775511', 'name': 'M. Cha'}, {'authorId': '1731707', 'name': 'Kyomin Jung'}, {'authorId': None, 'name': 'Wei Chen'}, {'authorId': '2115646925', 'name': 'Yajun Wang'}]\n",
            "Venue 2013 IEEE 13th International Conference on Data Mining\n",
            "year 2013\n",
            "Abstract The problem of identifying rumors is of practical importance especially in online social networks, since information can diffuse more rapidly and widely than the offline counterpart. In this paper, we identify characteristics of rumors by examining the following three aspects of diffusion: temporal, structural, and linguistic. For the temporal characteristics, we propose a new periodic time series model that considers daily and external shock cycles, where the model demonstrates that rumor likely have fluctuations over time. We also identify key structural and linguistic differences in the spread of rumors and non-rumors. Our selected features classify rumors with high precision and recall in the range of 87% to 92%, that is higher than other states of the arts on rumor classification.\n",
            "------------------------------------\n",
            "Title DeepStack: Expert-level artificial intelligence in heads-up no-limit poker\n",
            "Author [{'authorId': '35208406', 'name': 'Matej Moravcík'}, {'authorId': '8649018', 'name': 'Martin Schmid'}, {'authorId': '2625574', 'name': 'Neil Burch'}, {'authorId': '1759154', 'name': 'V. Lisý'}, {'authorId': '2551974', 'name': 'Dustin Morrill'}, {'authorId': '2294262', 'name': 'Nolan Bard'}, {'authorId': '48112534', 'name': 'Trevor Davis'}, {'authorId': '144514513', 'name': 'K. Waugh'}, {'authorId': '1681530', 'name': 'Michael Bradley Johanson'}, {'authorId': '143913104', 'name': 'Michael H. Bowling'}]\n",
            "Venue Science\n",
            "year 2017\n",
            "Abstract Computer code based on continual problem re-solving beats human professional poker players at a two-player variant of poker. Artificial intelligence masters poker Computers can beat humans at games as complex as chess or go. In these and similar games, both players have access to the same information, as displayed on the board. Although computers have the ultimate poker face, it has been tricky to teach them to be good at poker, where players cannot see their opponents' cards. Moravčík et al. built a code dubbed DeepStack that managed to beat professional poker players at a two-player poker variant called heads-up no-limit Texas hold'em. Instead of devising its strategy beforehand, DeepStack recalculated it at each step, taking into account the current state of the game. The principles behind DeepStack may enable advances in solving real-world problems that involve information asymmetry. Science, this issue p. 508 Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold’em. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.\n",
            "------------------------------------\n",
            "Title Visual localization within LIDAR maps for automated urban driving\n",
            "Author [{'authorId': '2809076', 'name': 'R. W. Wolcott'}, {'authorId': '1721484', 'name': 'R. Eustice'}]\n",
            "Venue 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
            "year 2014\n",
            "Abstract This paper reports on the problem of map-based visual localization in urban environments for autonomous vehicles. Self-driving cars have become a reality on roadways and are going to be a consumer product in the near future. One of the most significant road-blocks to autonomous vehicles is the prohibitive cost of the sensor suites necessary for localization. The most common sensor on these platforms, a three-dimensional (3D) light detection and ranging (LIDAR) scanner, generates dense point clouds with measures of surface reflectivity-which other state-of-the-art localization methods have shown are capable of centimeter-level accuracy. Alternatively, we seek to obtain comparable localization accuracy with significantly cheaper, commodity cameras. We propose to localize a single monocular camera within a 3D prior ground-map, generated by a survey vehicle equipped with 3D LIDAR scanners. To do so, we exploit a graphics processing unit to generate several synthetic views of our belief environment. We then seek to maximize the normalized mutual information between our real camera measurements and these synthetic views. Results are shown for two different datasets, a 3.0 km and a 1.5 km trajectory, where we also compare against the state-of-the-art in LIDAR map-based localization.\n",
            "------------------------------------\n",
            "Title Integrated Risk Information System\n",
            "Author [{'authorId': '121249268', 'name': 'Ord'}, {'authorId': '72552630', 'name': 'Ncea'}, {'authorId': '71191503', 'name': 'Irisd'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract EPA's Integrated Risk Information System (IRIS) is a human health assessment program that evaluates information on health effects that may result from exposure to environmental contaminants.\n",
            "------------------------------------\n",
            "Title KGAT: Knowledge Graph Attention Network for Recommendation\n",
            "Author [{'authorId': '98285513', 'name': 'Xiang Wang'}, {'authorId': '7792071', 'name': 'Xiangnan He'}, {'authorId': '2112867078', 'name': 'Yixin Cao'}, {'authorId': '2152972434', 'name': 'Meng Liu'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2019\n",
            "Abstract To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method named Knowledge Graph Attention Network (KGAT) which explicitly models the high-order connectivities in KG in an end-to-end fashion. It recursively propagates the embeddings from a node's neighbors (which can be users, items, or attributes) to refine the node's embedding, and employs an attention mechanism to discriminate the importance of the neighbors. Our KGAT is conceptually advantageous to existing KG-based recommendation methods, which either exploit high-order relations by extracting paths or implicitly modeling them with regularization. Empirical results on three public benchmarks show that KGAT significantly outperforms state-of-the-art methods like Neural FM and RippleNet. Further studies verify the efficacy of embedding propagation for high-order relation modeling and the interpretability benefits brought by the attention mechanism. We release the codes and datasets at https://github.com/xiangwang1223/knowledge_graph_attention_network.\n",
            "------------------------------------\n",
            "Title Multimodal learning with deep Boltzmann machines\n",
            "Author [{'authorId': '2897313', 'name': 'Nitish Srivastava'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]\n",
            "Venue Journal of machine learning research\n",
            "year 2012\n",
            "Abstract Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.\n",
            "------------------------------------\n",
            "Title Do Prices Reveal the Presence of Informed Trading?\n",
            "Author [{'authorId': '1399041937', 'name': 'P. Collin-Dufresne'}, {'authorId': '2234485', 'name': 'Vyacheslav Fos'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Using a comprehensive sample of trades by Schedule 13D filers, who possess valuable private information when they accumulate stocks of targeted companies, this paper studies whether several liquidity measures reveal the presence of informed trading. The evidence suggests that when Schedule 13D filers trade aggressively, both high-frequency and low-frequency measures of stock liquidity indicate a higher stock liquidity. Importantly, measures that have been used as direct proxies for adverse selection, such the Kyle (1985) lambda, the Easley et al. (1996) pin measure, and the Amihud (2002) illiquidity measure, suggest that the adverse selection is lower when informed trading takes place. The evidence is consistent with informed traders being more aggressive when measured stock liquidity is high.\n",
            "------------------------------------\n",
            "Title INSAT-3D vertical profile retrievals at IMDPS, New Delhi : A preliminary evaluation\n",
            "Author [{'authorId': '2052388247', 'name': 'A. K. Mitra'}, {'authorId': '48867189', 'name': 'S. Bhan'}, {'authorId': '2109670168', 'name': 'Anubha Sharma'}, {'authorId': '2065986399', 'name': 'N. Kaushik'}, {'authorId': '96211046', 'name': 'Shailesh Parihar'}, {'authorId': '118161799', 'name': 'R. Mahandru'}, {'authorId': '49923722', 'name': 'P. K. Kundu'}]\n",
            "Venue Mausam\n",
            "year 2021\n",
            "Abstract Successful launch of indigenous geostationary satellite INSAT-3D on 26 July, 2013 with advanced meteorological payloads onboard, has provided a new opportunity to the Indian meteorologists. A new payload, atmospheric sounder, has been launched for the first time in Indian satellite to provide the vertical profiles of temperature and humidity in the atmosphere. It is possible to obtain continuous upper level temperature and moisture profiles with a spatial resolution of 30 × 30 km and temporal resolution of one hour. The INSAT-3D temperature and moisture retrievals derived from routine application of sounder data processing algorithm installed at INSAT Meteorological Data Processing System (IMDPS), New Delhi were compared with collocated GPS sonde observations (GPOB), and National Oceanic and Atmospheric Administration (NOAA) polar orbiting satellites (N-18 and N-19) derived profiles to assess retrieval performance. The INSAT-3D temperature profiles show the positive bias throughout from surface to 30 hPa against the GPOB. The overall temperature between retrivals exhibited a systematic bias error at almost all the levels. Bias ranges from 2 to 4 °C between 1000 to 100 hPa levels. The levels of maximum positive bias, where INSAT-3D values are too warm, are near the surface and 100 hPa. This can be attributed to the inability of the retrieval scheme to precisely locate the change in the lapse rate associated with the tropopause due to general disagreement at higher levels. However, the moisture profiles showed somewhat lower accuracy against the GPOB. INSAT-3D and GPOB derived Total Perceptible Water (TPW) were also compared and showed that correlation of INSAT-3D TPW agree well with GPOB TPW to some extent than the level specific LI.\n",
            "------------------------------------\n",
            "Title Information Systems Success Measurement\n",
            "Author [{'authorId': '3035043', 'name': 'William H. DeLone'}, {'authorId': '2400363', 'name': 'E. McLean'}]\n",
            "Venue Found. Trends Inf. Syst.\n",
            "year 2016\n",
            "Abstract Researchers and practitioners alike face a daunting challenge when evaluating the \"success\" of information systems. The purpose of this monograph is to deepen, researchers and practitioners, understanding of the complex nature of IS success measurement driven by the constantly changing role and use of information technology. This monograph covers the history of IS success measurement as well as recent trends and future expectations for IS success measurement. The monograph also identifies the critical success factors that drive information system success and provides measurement and evaluation guidance for practitioners. This comprehensive study of IS success measurement is designed to improve measurement practice among researchers and managers.\n",
            "------------------------------------\n",
            "Title PROV-O: The PROV Ontology\n",
            "Author [{'authorId': '1760030', 'name': 'Timothy Lebo'}, {'authorId': '2628266', 'name': 'S. Sahoo'}, {'authorId': '1679913', 'name': 'D. McGuinness'}, {'authorId': '3337287', 'name': 'Khalid Belhajjame'}, {'authorId': '144320476', 'name': 'J. Cheney'}, {'authorId': '2885049', 'name': 'D. Corsar'}, {'authorId': '1398926410', 'name': 'D. Garijo'}, {'authorId': '1399487720', 'name': 'S. Soiland-Reyes'}, {'authorId': '2582069', 'name': 'S. Zednik'}, {'authorId': '2145805969', 'name': 'Jun Zhao'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The PROV Ontology (PROV-O) expresses the PROV Data Model using the OWL2 Web Ontology Language. It provides a set of classes, properties, and restrictions that can be used to represent and interchange provenance information generated in different systems and under different contexts. It can also be specialized to create new classes and properties to model provenance information for different applications and domains.\n",
            "------------------------------------\n",
            "Title Efficient Informative Sensing using Multiple Robots\n",
            "Author [{'authorId': '2116287308', 'name': 'Amarjeet Singh'}, {'authorId': '145343838', 'name': 'Andreas Krause'}, {'authorId': '1730156', 'name': 'Carlos Guestrin'}, {'authorId': '1721984', 'name': 'W. Kaiser'}]\n",
            "Venue Journal of Artificial Intelligence Research\n",
            "year 2014\n",
            "Abstract The need for efficient monitoring of spatio-temporal dynamics in large environmental applications, such as the water quality monitoring in rivers and lakes, motivates the use of robotic sensors in order to achieve sufficient spatial coverage. Typically, these robots have bounded resources, such as limited battery or limited amounts of time to obtain measurements. Thus, careful coordination of their paths is required in order to maximize the amount of information collected, while respecting the resource constraints. In this paper, we present an efficient approach for near-optimally solving the NP-hard optimization problem of planning such informative paths. In particular, we first develop eSIP (efficient Single-robot Informative Path planning), an approximation algorithm for optimizing the path of a single robot. Hereby, we use a Gaussian Process to model the underlying phenomenon, and use the mutual information between the visited locations and remainder of the space to quantify the amount of information collected. We prove that the mutual information collected using paths obtained by using eSIP is close to the information obtained by an optimal solution. We then provide a general technique, sequential allocation, which can be used to extend any single robot planning algorithm, such as eSIP, for the multi-robot problem. This procedure approximately generalizes any guarantees for the single-robot problem to the multi-robot case. We extensively evaluate the effectiveness of our approach on several experiments performed infield for two important environmental sensing applications, lake and river monitoring, and simulation experiments performed using several real world sensor network data sets.\n",
            "------------------------------------\n",
            "Title The Filter Bubble\n",
            "Author [{'authorId': '96905757', 'name': 'Eli Pariser'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract : Introduced by tech entrepreneur and activist Eli Pariser in 2011, the ‘filter bubble’ is a persistent concept which suggests that search engines and social media, together with their recommendation and personalisation algorithms, are centrally culpable for the societal and ideological polarisation experienced in many countries: we no longer encounter a balanced and healthy information diet, but only see information that targets our established interests and reinforces our existing worldviews. Filter bubbles are seen as critical enablers of Brexit, Trump, Bolsonaro, and other populist political phenomena, and search and social media companies have been criticised for failing to prevent their development. Yet, there is scant empirical evidence for their existence, or for the related concept of ‘echo chambers’: indeed, search and social media users generally appear to encounter a highly centrist media diet that is, if anything, more diverse than that of non-users. However, the persistent use of these concepts in mainstream media and political debates has now created its own discursive reality that continues to impact materially on societal institutions, media and communication platforms, and ordinary users themselves. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to redirect scholarly attention from far more critical areas of enquiry.\n",
            "------------------------------------\n",
            "Title Decoding neural representational spaces using multivariate pattern analysis.\n",
            "Author [{'authorId': '2327323', 'name': 'J. Haxby'}, {'authorId': '3281317', 'name': 'Andrew C. Connolly'}, {'authorId': '2663356', 'name': 'J. S. Guntupalli'}]\n",
            "Venue Annual Review of Neuroscience\n",
            "year 2014\n",
            "Abstract A major challenge for systems neuroscience is to break the neural code. Computational algorithms for encoding information into neural activity and extracting information from measured activity afford understanding of how percepts, memories, thought, and knowledge are represented in patterns of brain activity. The past decade and a half has seen significant advances in the development of methods for decoding human neural activity, such as multivariate pattern classification, representational similarity analysis, hyperalignment, and stimulus-model-based encoding and decoding. This article reviews these advances and integrates neural decoding methods into a common framework organized around the concept of high-dimensional representational spaces.\n",
            "------------------------------------\n",
            "Title Does Corruption Information Inspire the Fight or Quash the Hope? A Field Experiment in Mexico on Voter Turnout, Choice, and Party Identification\n",
            "Author [{'authorId': '2058487137', 'name': 'Alberto Chong'}, {'authorId': '7683442', 'name': 'A. De La O'}, {'authorId': '3019739', 'name': 'D. Karlan'}, {'authorId': '74378164', 'name': 'Léonard Wantchekon'}]\n",
            "Venue Journal of Politics\n",
            "year 2014\n",
            "Abstract Retrospective voting models assume that offering more information to voters about their incumbents’ performance strengthens electoral accountability. However, it is unclear whether incumbent corruption information translates into higher political participation and increased support for challengers. We provide experimental evidence that such information not only decreases incumbent party support in local elections in Mexico, but also decreases voter turnout and support for the challenger party, as well as erodes partisan attachments. While information clearly is necessary to improve accountability, corruption information is not sufficient because voters may respond to it by withdrawing from the political process. We conclude with a discussion of the implications of our findings for studies of voting behavior.\n",
            "------------------------------------\n",
            "Title Framework for Managing the COVID-19 Infodemic: Methods and Results of an Online, Crowdsourced WHO Technical Consultation\n",
            "Author [{'authorId': '4147106', 'name': 'V. Tangcharoensathien'}, {'authorId': '4172891', 'name': 'N. Calleja'}, {'authorId': '145825234', 'name': 'Tim Nguyen'}, {'authorId': '5904629', 'name': 'T. Purnat'}, {'authorId': '1420050895', 'name': \"Marcelo D'agostino\"}, {'authorId': '1402721998', 'name': 'Sebastian Garcia-Saiso'}, {'authorId': '46655044', 'name': 'M. Landry'}, {'authorId': '5393901', 'name': 'A. Rashidian'}, {'authorId': '144592449', 'name': 'Clayton Hamilton'}, {'authorId': '1753173887', 'name': 'Abdelhalim AbdAllah'}, {'authorId': '11737239', 'name': 'I. Ghiga'}, {'authorId': '46685735', 'name': 'Alexandra Hill'}, {'authorId': '5504357', 'name': 'D. Hougendobler'}, {'authorId': '39287062', 'name': 'J. van Andel'}, {'authorId': '3877599', 'name': 'M. Nunn'}, {'authorId': '144196594', 'name': 'Ian Brooks'}, {'authorId': '3130592', 'name': 'P. Sacco'}, {'authorId': '46617468', 'name': 'M. De Domenico'}, {'authorId': '2723877', 'name': 'Philip Mai'}, {'authorId': '48569628', 'name': 'A. Gruzd'}, {'authorId': '1475786557', 'name': 'Alexandre Alaphilippe'}, {'authorId': '3782320', 'name': 'S. Briand'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2020\n",
            "Abstract Background An infodemic is an overabundance of information—some accurate and some not—that occurs during an epidemic. In a similar manner to an epidemic, it spreads between humans via digital and physical information systems. It makes it hard for people to find trustworthy sources and reliable guidance when they need it. Objective A World Health Organization (WHO) technical consultation on responding to the infodemic related to the coronavirus disease (COVID-19) pandemic was held, entirely online, to crowdsource suggested actions for a framework for infodemic management. Methods A group of policy makers, public health professionals, researchers, students, and other concerned stakeholders was joined by representatives of the media, social media platforms, various private sector organizations, and civil society to suggest and discuss actions for all parts of society, and multiple related professional and scientific disciplines, methods, and technologies. A total of 594 ideas for actions were crowdsourced online during the discussions and consolidated into suggestions for an infodemic management framework. Results The analysis team distilled the suggestions into a set of 50 proposed actions for a framework for managing infodemics in health emergencies. The consultation revealed six policy implications to consider. First, interventions and messages must be based on science and evidence, and must reach citizens and enable them to make informed decisions on how to protect themselves and their communities in a health emergency. Second, knowledge should be translated into actionable behavior-change messages, presented in ways that are understood by and accessible to all individuals in all parts of all societies. Third, governments should reach out to key communities to ensure their concerns and information needs are understood, tailoring advice and messages to address the audiences they represent. Fourth, to strengthen the analysis and amplification of information impact, strategic partnerships should be formed across all sectors, including but not limited to the social media and technology sectors, academia, and civil society. Fifth, health authorities should ensure that these actions are informed by reliable information that helps them understand the circulating narratives and changes in the flow of information, questions, and misinformation in communities. Sixth, following experiences to date in responding to the COVID-19 infodemic and the lessons from other disease outbreaks, infodemic management approaches should be further developed to support preparedness and response, and to inform risk mitigation, and be enhanced through data science and sociobehavioral and other research. Conclusions The first version of this framework proposes five action areas in which WHO Member States and actors within society can apply, according to their mandate, an infodemic management approach adapted to national contexts and practices. Responses to the COVID-19 pandemic and the related infodemic require swift, regular, systematic, and coordinated action from multiple sectors of society and government. It remains crucial that we promote trusted information and fight misinformation, thereby helping save lives.\n",
            "------------------------------------\n",
            "Title DroidScope: Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android Malware Analysis\n",
            "Author [{'authorId': '40022069', 'name': 'Lok K. Yan'}, {'authorId': '145503585', 'name': 'Heng Yin'}]\n",
            "Venue USENIX Security Symposium\n",
            "year 2012\n",
            "Abstract The prevalence of mobile platforms, the large market share of Android, plus the openness of the Android Market makes it a hot target for malware attacks. Once a malware sample has been identified, it is critical to quickly reveal its malicious intent and inner workings. In this paper we present DroidScope, an Android analysis platform that continues the tradition of virtualization-based malware analysis. Unlike current desktop malware analysis platforms, DroidScope reconstructs both the OS-level and Java-level semantics simultaneously and seamlessly. To facilitate custom analysis, DroidScope exports three tiered APIs that mirror the three levels of an Android device: hardware, OS and Dalvik Virtual Machine. On top of DroidScope, we further developed several analysis tools to collect detailed native and Dalvik instruction traces, profile API-level activity, and track information leakage through both the Java and native components using taint analysis. These tools have proven to be effective in analyzing real world malware samples and incur reasonably low performance overheads.\n",
            "------------------------------------\n",
            "Title The Information . A History , a Theory , a Flood\n",
            "Author [{'authorId': '144778787', 'name': 'J. Rivera'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The book is full of interesting references to the history of information theory, but unfortunately lacks the theoretical rigor of an academic account of the topic. The reader can find really inspiring stories and draw out powerful insights about what information means, but also finds awkward reflections about its essence and about how the concept should be understood. On the positive side, we can mention the relevance of redundancy in language, a point that is wonderfully explained in the description of the drums' communication language, as well as in the process of breaking cryptographic codes. On the negative side, we should mention the Epilogue and its loose reflection around the meaning of meaning, that ultimately confuses information with knowledge, and thus presents networks and “the internet” as a social agent that “is changing the world”.\n",
            "------------------------------------\n",
            "Title Exploring the Space of Topic Coherence Measures\n",
            "Author [{'authorId': '40506049', 'name': 'Michael Röder'}, {'authorId': '1697447', 'name': 'A. Both'}, {'authorId': '1972250', 'name': 'A. Hinneburg'}]\n",
            "Venue Web Search and Data Mining\n",
            "year 2015\n",
            "Abstract Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.\n",
            "------------------------------------\n",
            "Title Specification of the IP Flow Information Export (IPFIX) Protocol for the Exchange of Flow Information\n",
            "Author [{'authorId': '3089997', 'name': 'B. Claise'}, {'authorId': '2299514', 'name': 'B. Trammell'}, {'authorId': '39678401', 'name': 'P. Aitken'}]\n",
            "Venue Request for Comments\n",
            "year 2013\n",
            "Abstract This document specifies the IP Flow Information Export (IPFIX) protocol, which serves as a means for transmitting Traffic Flow information over the network. In order to transmit Traffic Flow information from an Exporting Process to a Collecting Process, a common representation of flow data and a standard means of communicating them are required. This document describes how the IPFIX Data and Template Records are carried over a number of transport protocols from an IPFIX Exporting Process to an IPFIX Collecting Process. This document obsoletes RFC 5101.\n",
            "------------------------------------\n",
            "Title New Literacies: A Dual-Level Theory of the Changing Nature of Literacy, Instruction, and Assessment\n",
            "Author [{'authorId': '33169483', 'name': 'D. Leu'}, {'authorId': '2230663', 'name': 'C. Kinzer'}, {'authorId': '52539201', 'name': 'Julie Coiro'}, {'authorId': '52420588', 'name': 'Jill Castek'}, {'authorId': '40358186', 'name': 'L. Henry'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract Today, the nature of literacy has become deictic. This simple idea carries important implications for literacy theory, research, and instruction that our field must begin to address. Deixis is a term used by linguists (Fillmore, 1966; Murphy, 1986; Traut & Kazzazi, 1996) to define words whose meanings change rapidly as their context changes. Tomorrow, for example, is a deictic term; the meaning of “tomorrow” becomes “today” every 24 hours. The meaning of literacy has also become deictic because we live in an age of rapidly changing information and communication technologies, each of which requires new literacies (Leu, 1997, 2000). Thus, to have been literate yesterday, in a world defined primarily by relatively static book technologies, does not ensure that one is fully literate today where we encounter new technologies such as Google docs, Skype, iMovie, Contribute, Basecamp, Dropbox, Facebook, Google, foursquare, Chrome, educational video games, or thousands of mobile apps. To be literate tomorrow will be defined by even newer technologies that have yet to appear and even newer discourses and social practices that will be created to meet future needs. Thus, when we speak of new literacies, we mean that literacy is not just new today; it becomes new every day of our lives. How should we theorize the new literacies that will define our future, when literacy has become deictic? The answer is important because our concept of literacy defines both who we are and who we shall become. But there is a conundrum here. How can we possibly develop adequate theory when the object that we seek to study is itself ephemeral, continuously being redefined by a changing context? This is an important theoretical challenge that our field has not previously faced. The purpose of this chapter is to advance theory in a world where literacy has become deictic. It suggests that a dual-level theory of New Literacies is a useful approach to theory building in a world where the nature of literacy continuously changes. We begin by making a central point: Social contexts have always shaped both the function and form of literate practices and been shaped by them in return. We discuss the social context of the current period and explain how this has produced new information and communication technologies (ICTs), and the new literacies that these technologies demand. Second, we explore several lowercase new literacies perspectives that are emerging. We argue that a dual-level New Literacies theory is essential to take full advantage of this important and diverse work. Third, we identify a set of principles, drawn from research, that inform an uppercase theory of New Literacies. Then, we present one lowercase theory of new literacies, the new literacies of online research and comprehension, to illustrate how a dual-level theory of New Literacies can inform new literacies research that takes related but different theoretical perspectives. We conclude by considering the implications of a dual-level theory of New Literacies for both research and practice.\n",
            "------------------------------------\n",
            "Title Cyberchondria: towards a better understanding of excessive health-related Internet use\n",
            "Author [{'authorId': '4498861', 'name': 'V. Starcevic'}, {'authorId': '6286650', 'name': 'D. Berle'}]\n",
            "Venue Expert Review of Neurotherapeutics\n",
            "year 2013\n",
            "Abstract Looking for information about symptoms and illnesses on the Internet is common and often serves useful purposes. However, a number of people who are overly distressed or anxious about their health perform excessive or repeated health-related searches on the Internet, only to become more distressed or frightened – a pattern defined here as cyberchondria. This behavior, which can also be construed as a form of reassurance seeking and occurs as a manifestation of health anxiety and hypochondriasis, is the focus of this article. The antecedents of cyberchondria, factors that maintain it and its consequences are examined conceptually and in light of the relatively little research that has been performed so far. Managing cyberchondria poses a challenge, and several approaches as part of the treatment of health anxiety and hypochondriasis are described. The article makes suggestions for further research on cyberchondria.\n",
            "------------------------------------\n",
            "Title Spectre Attacks: Exploiting Speculative Execution\n",
            "Author [{'authorId': '2211239', 'name': 'P. Kocher'}, {'authorId': '2062558', 'name': 'Daniel Genkin'}, {'authorId': '2015792', 'name': 'D. Gruss'}, {'authorId': '1752878595', 'name': 'Werner Haas'}, {'authorId': '37584482', 'name': 'Michael Hamburg'}, {'authorId': '49981379', 'name': 'Moritz Lipp'}, {'authorId': '1743786', 'name': 'S. Mangard'}, {'authorId': '32135494', 'name': 'Thomas Prescher'}, {'authorId': '145694844', 'name': 'Michael Schwarz'}, {'authorId': '49968838', 'name': 'Y. Yarom'}]\n",
            "Venue IEEE Symposium on Security and Privacy\n",
            "year 2018\n",
            "Abstract Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.\n",
            "------------------------------------\n",
            "Title Big Data for All: Privacy and User Control in the Age of Analytics\n",
            "Author [{'authorId': '2301316', 'name': 'Omer Tene'}, {'authorId': '2476781', 'name': 'Jules Polonetsky'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract We live in an age of “big data.” Data have become the raw material of production, a new source for immense economic and social value. Advances in data mining and analytics and the massive increase in computing power and data storage capacity have expanded by orders of magnitude the scope of information available for businesses and government. Data are now available for analysis in raw form, escaping the confines of structured databases and enhancing researchers’ abilities to identify correlations and conceive of new, unanticipated uses for existing information. In addition, the increasing number of people, devices, and sensors that are now connected by digital networks has revolutionized the ability to generate, communicate, share, and access data. Data creates enormous value for the world economy, driving innovation, productivity, efficiency and growth. At the same time, the “data deluge” presents privacy concerns which could stir a regulatory backlash dampening the data economy and stifling innovation. In order to craft a balance between beneficial uses of data and in individual privacy, policymakers must address some of the most fundamental concepts of privacy law, including the definition of “personally identifiable information”, the role of individual control, and the principles of data minimization and purpose limitation. This article emphasizes the importance of providing individuals with access to their data in usable format. This will let individuals share the wealth created by their information and incentivize developers to offer user-side features and applications harnessing the value of big data. Where individual access to data is impracticable, data are likely to be de-identified to an extent sufficient to diminish privacy concerns. In addition, organizations should be required to disclose their decisional criteria, since in a big data world it is often not the data but rather the inferences drawn from them that give cause for concern.\n",
            "------------------------------------\n",
            "Title Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty.\n",
            "Author [{'authorId': '40643070', 'name': 'G. Baele'}, {'authorId': '2120394', 'name': 'P. Lemey'}, {'authorId': '28950924', 'name': 'T. Bedford'}, {'authorId': '3006129', 'name': 'A. Rambaut'}, {'authorId': '2716962', 'name': 'M. Suchard'}, {'authorId': '34662337', 'name': 'A. Alekseyenko'}]\n",
            "Venue Molecular biology and evolution\n",
            "year 2012\n",
            "Abstract Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.\n",
            "------------------------------------\n",
            "Title Examining the Role of Social Media in Effective Crisis Management\n",
            "Author [{'authorId': '50442760', 'name': 'Yan Jin'}, {'authorId': '14486311', 'name': 'B. Liu'}, {'authorId': '40083779', 'name': 'Lucinda L. Austin'}]\n",
            "Venue Communication Research\n",
            "year 2014\n",
            "Abstract Publics increasingly use social media during crises and, consequently, crisis communication professionals need to understand how to strategically optimize these tools. Despite this need, there is scarce theory-grounded research to understand key factors that affect how publics consume crisis information via social media compared to other sources. To fill this gap, an emerging model helps crisis managers understand how publics produce, consume, and/or share crisis information via social media and other sources: the social-mediated crisis communication model (SMCC). This study tests essential components of the SMCC model through a 3 (crisis information form) x 2 (crisis information source) x 2 (crisis origin) mixed-design experiment (N = 338). The findings indicate the key role of crisis origin in affecting publics’ preferred information form (social media, traditional media, or word-of-mouth communication) and source (organization in crisis or third party), which influences how publics anticipate an organization should respond to a crisis and what crisis emotions they are likely to feel when exposed to crisis information.\n",
            "------------------------------------\n",
            "Title Promoting transparency and accountability through ICTs, social media, and collaborative e‐government\n",
            "Author [{'authorId': '3005122', 'name': 'J. Bertot'}, {'authorId': '143762896', 'name': 'P. Jaeger'}, {'authorId': '25943188', 'name': 'J. Grimes'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Purpose – The purpose of this paper is to examine the ways in which governments build social media and information and communication technologies (ICTs) into e‐government transparency initiatives, to promote collaboration with members of the public and the ways in members of the public are able to employ the same social media to monitor government activities.Design/methodology/approach – This study used an iterative strategy that involved conducting a literature review, content analysis, and web site analysis, offering multiple perspectives on government transparency efforts, the role of ICTs and social media in these efforts, and the ability of e‐government initiatives to foster collaborative transparency through embedded ICTs and social media.Findings – The paper identifies key initiatives, potential impacts, and future challenges for collaborative e‐government as a means of transparency.Originality/value – The paper is one of the first to examine the interrelationships between ICTs, social media, and c...\n",
            "------------------------------------\n",
            "Title An Overview of Multi-task Learning\n",
            "Author [{'authorId': '46867608', 'name': 'Yu Zhang'}, {'authorId': '153096457', 'name': 'Qiang Yang'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.\n",
            "------------------------------------\n",
            "Title Business Intelligence in Blogs: Understanding Consumer Interactions and Communities\n",
            "Author [{'authorId': '145884195', 'name': 'M. Chau'}, {'authorId': '1790425', 'name': 'J. Xu'}]\n",
            "Venue MIS Q.\n",
            "year 2012\n",
            "Abstract The increasing popularity of Web 2.0 has led to exponential growth of user-generated content in both volume and significance. One important type of user-generated content is the blog. Blogs encompass useful information (e.g., insightful product reviews and information-rich consumer communities) that could potentially be a gold mine for business intelligence, bringing great opportunities for both academic research and business applications. However, performing business intelligence on blogs is quite challenging because of the vast amount of information and the lack of commonly adopted methodology for effectively collecting and analyzing such information. In this paper, we propose a framework for gathering business intelligence from blogs by automatically collecting and analyzing blog contents and bloggers' interaction networks. Through a system developed using the framework, we conducted two case studies with one case focusing on a consumer product and the other on a company. Our case studies demonstrate how to use the framework and appropriate techniques to effectively collect, extract, and analyze blogs related to the topics of interest, reveal novel patterns in the blogger interactions and communities, and answer important business intelligence questions in the domains. The framework is sufficiently generic and can be applied to any topics of interest, organizations, and products. Future academic research and business applications related to the topics examined in the two cases can also be built using the findings of this study.\n",
            "------------------------------------\n",
            "Title Political Parties, Motivated Reasoning, and Public Opinion Formation\n",
            "Author [{'authorId': '51880987', 'name': 'Thomas J. Leeper'}, {'authorId': '9690494', 'name': 'Rune Slothuus'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract A key characteristic of democratic politics is competition between groups, first of all political parties. Yet, the unavoidably partisan nature of political conflict has had too little influence on scholarship on political psychology. Despite more than 50 years of research on political parties and citizens, we continue to lack a systematic understanding of when and how political parties influence public opinion. We suggest that alternative approaches to political parties and public opinion can be best reconciled and examined through a richer theoretical perspective grounded in motivated reasoning theory. Clearly, parties shape citizens' opinions by mobilizing, influencing, and structuring choices among political alternatives. But the answer to when and how parties influence citizens' reasoning and political opinions depends on an interaction between citizens' motivations, effort, and information generated from the political environment (particularly through competition between parties). The contribution of motivated reasoning, as we describe it, is to provide a coherent theoretical framework for understanding partisan influence on citizens' political opinions. We review recent empirical work consistent with this framework. We also point out puzzles ripe for future research and discuss how partisan-motivated reasoning provides a useful point of departure for such work.\n",
            "------------------------------------\n",
            "Title A Survey: Digital Image Watermarking Techniques\n",
            "Author [{'authorId': '6178796', 'name': 'P. Parashar'}, {'authorId': '2115743960', 'name': 'R. Singh'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Multimedia security is extremely significant concern for the internet technology because of the ease of the duplication, distribution and manipulation of the multimedia data. The digital watermarking is a field of information hiding which hide the crucial information in the original data for protection illegal duplication and distribution of multimedia data. This paper presents a survey on the existing digital image watermarking techniques. The results of various digital image watermarking techniques have been compared on the basis of outputs. In the digital watermarking the secret information are implanted into the original data for protecting the ownership rights of the multimedia data. The image watermarking techniques may divide on the basis of domain like spatial domain or transform domain or on the basis of wavelets. The spatial domain techniques directly work on the pixels and the frequency domain works on the transform coefficients of the image. This survey elaborates the most important methods of spatial domain and transform domain and focuses the merits and demerits of these techniques.\n",
            "------------------------------------\n",
            "Title Object lens: a “spreadsheet” for cooperative work\n",
            "Author [{'authorId': '2657449', 'name': 'Kum-Yew Lai'}, {'authorId': '145850249', 'name': 'T. Malone'}, {'authorId': '2150342241', 'name': 'Keh-Chiang Yu'}]\n",
            "Venue TOIS\n",
            "year 2018\n",
            "Abstract Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times.\n",
            "The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.\n",
            "------------------------------------\n",
            "Title ERNIE: Enhanced Language Representation with Informative Entities\n",
            "Author [{'authorId': '2621696', 'name': 'Zhengyan Zhang'}, {'authorId': '48506411', 'name': 'Xu Han'}, {'authorId': '49293587', 'name': 'Zhiyuan Liu'}, {'authorId': '145820291', 'name': 'Xin Jiang'}, {'authorId': '1753344', 'name': 'Maosong Sun'}, {'authorId': '1688015', 'name': 'Qun Liu'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2019\n",
            "Abstract Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.\n",
            "------------------------------------\n",
            "Title Health information on the Internet: gold mine or minefield?\n",
            "Author [{'authorId': '49279828', 'name': 'Tabitha Tonsaker'}, {'authorId': '50664327', 'name': 'G. Bartlett'}, {'authorId': '48945036', 'name': 'C. Trpkov'}]\n",
            "Venue Canadian family physician Medecin de famille canadien\n",
            "year 2014\n",
            "Abstract The Internet has revolutionized the way information is shared and accessed. Information retrieval is easier now than ever before. Since the rise of modern search engines, social networks, and ubiquitous access through devices such as smartphones and tablet or laptop computers, information is\n",
            "------------------------------------\n",
            "Title Content Based Video Retrival System for Mexican Culture Heritage Based on Object Matching and Local-Global Descriptors\n",
            "Author [{'authorId': '1398045419', 'name': 'M. Cedillo-Hernández'}, {'authorId': '1383990753', 'name': 'F. Garcia-Ugalde'}, {'authorId': '1399165163', 'name': 'Antonio Cedillo-Hernández'}, {'authorId': '1383990672', 'name': 'M. Nakano-Miyatake'}, {'authorId': '1405508693', 'name': 'H. Perez-Meana'}]\n",
            "Venue 2014 International Conference on Mechatronics, Electronics and Automotive Engineering\n",
            "year 2014\n",
            "Abstract Multimedia data and networking technologies have had a highly growing during the last decade, with these changes users have changed from text to content based video retrieval systems due to its better performance. We propose a fast content-based video retrieval system which involves the combination of a local descriptor obtained from the speeded-up robust feature algorithm together with an effective and fast object matching operation. To save computational time, compressed video data are partially decoded in order to get discrete cosine transform coefficients of key frames, which are used to obtain sub-block coefficients and a down-sampling version of frames. The preliminary results are ranking using an efficient color descriptor based on color correlogram and dominant color descriptors. To measure the performance of the proposed technique the precision and recall metrics are used. The experimental results show the accuracy of the proposed method applied to a database of Mexican Culture Heritage videos.\n",
            "------------------------------------\n",
            "Title Recurrent Convolutional Network for Video-Based Person Re-identification\n",
            "Author [{'authorId': '2554953', 'name': 'Niall McLaughlin'}, {'authorId': '2248667', 'name': 'J. M. D. Rincón'}, {'authorId': '145460322', 'name': 'P. Miller'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2016\n",
            "Abstract In this paper we propose a novel recurrent neural network architecture for video-based person re-identification. Given the video sequence of a person, features are extracted from each frame using a convolutional neural network that incorporates a recurrent final layer, which allows information to flow between time-steps. The features from all timesteps are then combined using temporal pooling to give an overall appearance feature for the complete sequence. The convolutional network, recurrent layer, and temporal pooling layer, are jointly trained to act as a feature extractor for video-based re-identification using a Siamese network architecture. Our approach makes use of colour and optical flow information in order to capture appearance and motion information which is useful for video re-identification. Experiments are conduced on the iLIDS-VID and PRID-2011 datasets to show that this approach outperforms existing methods of video-based re-identification.\n",
            "------------------------------------\n",
            "Title Advances in Hyperspectral Image Classification: Earth Monitoring with Statistical Learning Methods\n",
            "Author [{'authorId': '1397959153', 'name': 'Gustau Camps-Valls'}, {'authorId': '2977931', 'name': 'D. Tuia'}, {'authorId': '1698844', 'name': 'L. Bruzzone'}, {'authorId': '1682001', 'name': 'J. Benediktsson'}]\n",
            "Venue IEEE Signal Processing Magazine\n",
            "year 2013\n",
            "Abstract The technological evolution of optical sensors over the last few decades has provided remote sensing analysts with rich spatial, spectral, and temporal information. In particular, the increase in spectral resolution of hyperspectral images (HSIs) and infrared sounders opens the doors to new application domains and poses new methodological challenges in data analysis. HSIs allow the characterization of objects of interest (e.g., land-cover classes) with unprecedented accuracy, and keeps inventories up to date. Improvements in spectral resolution have called for advances in signal processing and exploitation algorithms. This article focuses on the challenging problem of hyperspectral image classification, which has recently gained in popularity and attracted the interest of other scientific disciplines such as machine learning, image processing, and computer vision. In the remote sensing community, the term classification is used to denote the process that assigns single pixels to a set of classes, while the term segmentation is used for methods aggregating pixels into objects and then assigned to a class.\n",
            "------------------------------------\n",
            "Title InfoVAE: Information Maximizing Variational Autoencoders\n",
            "Author [{'authorId': '3303970', 'name': 'Shengjia Zhao'}, {'authorId': '51453887', 'name': 'Jiaming Song'}, {'authorId': '2490652', 'name': 'S. Ermon'}]\n",
            "Venue ArXiv\n",
            "year 2017\n",
            "Abstract A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.\n",
            "------------------------------------\n",
            "Title SEISMIC: A Self-Exciting Point Process Model for Predicting Tweet Popularity\n",
            "Author [{'authorId': '49033211', 'name': 'Qingyuan Zhao'}, {'authorId': '2090630', 'name': 'Murat A. Erdogdu'}, {'authorId': '1999037', 'name': 'Hera Y. He'}, {'authorId': '69484854', 'name': 'A. Rajaraman'}, {'authorId': '1702139', 'name': 'J. Leskovec'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2015\n",
            "Abstract Social networking websites allow users to create and share content. Big information cascades of post resharing can form as users of these sites reshare others' posts with their friends and followers. One of the central challenges in understanding such cascading behaviors is in forecasting information outbreaks, where a single post becomes widely popular by being reshared by many users. In this paper, we focus on predicting the final number of reshares of a given post. We build on the theory of self-exciting point processes to develop a statistical model that allows us to make accurate predictions. Our model requires no training or expensive feature engineering. It results in a simple and efficiently computable formula that allows us to answer questions, in real-time, such as: Given a post's resharing history so far, what is our current estimate of its final number of reshares? Is the post resharing cascade past the initial stage of explosive growth? And, which posts will be the most reshared in the future? We validate our model using one month of complete Twitter data and demonstrate a strong improvement in predictive accuracy over existing approaches. Our model gives only 15% relative error in predicting final size of an average information cascade after observing it for just one hour.\n",
            "------------------------------------\n",
            "Title Advances in Quantum Cryptography\n",
            "Author [{'authorId': '1773054', 'name': 'S. Pirandola'}, {'authorId': '2068992', 'name': 'U. Andersen'}, {'authorId': '144299779', 'name': 'L. Banchi'}, {'authorId': '145615383', 'name': 'M. Berta'}, {'authorId': '51034522', 'name': 'D. Bunandar'}, {'authorId': '145439738', 'name': 'R. Colbeck'}, {'authorId': '3399114', 'name': 'D. Englund'}, {'authorId': '46604512', 'name': 'T. Gehring'}, {'authorId': '47976273', 'name': 'C. Lupo'}, {'authorId': '34563394', 'name': 'C. Ottaviani'}, {'authorId': '48121235', 'name': 'Jason L. Pereira'}, {'authorId': '40396971', 'name': 'M. Razavi'}, {'authorId': '2896742', 'name': 'J. S. Shaari'}, {'authorId': '2147926', 'name': 'M. Tomamichel'}, {'authorId': '2025181', 'name': 'Vladyslav C. Usenko'}, {'authorId': '37019234', 'name': 'G. Vallone'}, {'authorId': '2751903', 'name': 'P. Villoresi'}, {'authorId': '3349333', 'name': 'P. Wallden'}]\n",
            "Venue \n",
            "year 2019\n",
            "Abstract Quantum cryptography is arguably the fastest growing area in quantum information science. Novel theoretical protocols are designed on a regular basis, security proofs are constantly improving, and experiments are gradually moving from proof-of-principle lab demonstrations to in-field implementations and technological prototypes. In this review, we provide both a general introduction and a state of the art description of the recent advances in the field, both theoretically and experimentally. We start by reviewing protocols of quantum key distribution based on discrete variable systems. Next we consider aspects of device independence, satellite challenges, and high rate protocols based on continuous variable systems. We will then discuss the ultimate limits of point-to-point private communications and how quantum repeaters and networks may overcome these restrictions. Finally, we will discuss some aspects of quantum cryptography beyond standard quantum key distribution, including quantum data locking and quantum digital signatures.\n",
            "------------------------------------\n",
            "Title The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power\n",
            "Author [{'authorId': '2684210', 'name': 'Shoshana Zuboff'}]\n",
            "Venue \n",
            "year 2019\n",
            "Abstract Society is at a turning point. The heady optimism that accompanied the advent of the Internet has gone, replaced with a deep unease as technology, capitalism and an unequal society combine to create the perfect storm. Tech companies are gathering our information online and selling it to the highest bidder, whether government or retailer. In this world of surveillance capitalism, profit depends not only on predicting but modifying our online behaviour. How will this fusion of capitalism and the digital shape the values that define our future?\n",
            "------------------------------------\n",
            "Title Flow-Guided Feature Aggregation for Video Object Detection\n",
            "Author [{'authorId': '2578924', 'name': 'Xizhou Zhu'}, {'authorId': '2115658160', 'name': 'Yujie Wang'}, {'authorId': '3304536', 'name': 'Jifeng Dai'}, {'authorId': '145347147', 'name': 'Lu Yuan'}, {'authorId': '1732264', 'name': 'Yichen Wei'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2017\n",
            "Abstract Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong singleframe baselines in ImageNet VID [33], especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The code would be released.\n",
            "------------------------------------\n",
            "Title A Review of “Doing Case Study Research: A Practical Guide for Beginning Researchers”\n",
            "Author [{'authorId': '1456396436', 'name': 'L. Vernon-Dotson'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract I n Doing Case Study Research: A Practical Guide for Beginning Researchers, Hancock and Algozzine provide a concrete, step-by-step process for beginning researchers who are conducting case study research. The authors claim that Doing Case Study Research is not a “case study research for dummies” (p. xii) manual, and I absolutely concur. They are successful in stripping away the theories and attacking case study research in a very rudimentary manner, hence providing readers a prescriptive approach. It is a practical look at doing case study research—a solid companion for those teaching, facilitating, or conducting introductory qualitative research. Doing Case Study Research is divided into three sections: “Foundations” (Chapters 1–2), “Stages of Doing Case Study Research” (Chapters 3–11), and “Putting It All Together” (Chapters 12–13). In the first part, Hancock and Algozzine provide insights into the purposes and processes of research, in general, and offer their readers an overview of basic types of qualitative and quantitative research. The authors fittingly provide the reader with guidance in selecting the appropriate research within the two broad traditions. Comprising 59 of the book’s 114 pages, the second section is truly the “nuts and bolts” of conducting case study research. In this section, the authors outline their prescriptive, step-by-step process, which spans from literature review and research design through data collection and interpretation and then ending with reporting and confirming the findings. Each chapter in this section is thorough, with just enough information as to not overwhelm novice researchers. For example, Chapter 4 (“Determining What We Know”) beautifully illustrates and iterates the rationale for the conceptual framework and outlines a seminal and well-documented process for writing a literature review. For instance, the authors suggest following Galvan’s (1999, 2009) key directions for writing literature reviews by first selecting a topic and identifying the literature to review followed by analyzing, criticizing, synthesizing, and documenting the literature. The final section focuses on preparing proposals and disseminating research. These last two chapters bring the book full circle by providing the reader with steps for the typical outlets of their completed work. This book is an easy, quick read and is very user friendly. Hancock and Algozzine offer a variety of cross-disciplinary examples from published works to support their basic process for doing case study research. For example, in Chapter 3 (“Setting the Stage”) the authors provide the readers with examples of published studies from researchers who utilized case study research through 18 brief descriptions of events, situations, programs, and activities across several disciplines including, but not limited to education, social work, counseling, technology, adult education, criminal justice, and psychology. At the conclusion of each chapter, the authors deliver questions (Content Review) and activities to facilitate understanding (Activities and Applications for Prospective Researchers). I greatly appreciated the attention to research design (Chapter 5: “Selecting a Design”); in many qualitative texts, this seems to be overlooked or lacking specificity within the context of case study research. I have reviewed several manuscripts submitted for publication where “case study research” was indicated as the “design.” It seems that beginning researchers (and some veterans) fail to realize that, as Hancock and Algozzine indicated, “[d]oing case study research means selecting a design that matches the disciplinary perspective of the investigation” (p. 37). Not only did the authors distinguish between the classifications, types, and orientations of case study research designs, they also provided 12 different examples that clearly illustrated these different designs. Although this is a practical guide for implementing case study research, a few weaknesses should be noted. First, Hancock and Algozzine make it sound easy. They do mention that qualitative research is a time-consuming task in the first section of the book; however, the time factor is not otherwise stressed. Further, the data analysis section just scratches the surface of what needs to be done to effectively interpret mass amounts of data typically gathered over a long period of time. With that said, the authors appropriately emphasize the need to remain focused on the research questions when sifting through the data—something both beginning and seasoned qualitative researchers tend to forget. Finally, a chapter on the uses, pros, and cons of qualitative data management systems versus just mentioning them in passing (Chapter 9: “Summarizing and Interpreting the Information”) may be helpful to novice researchers who may mistakenly believe that the software (e.g., NVivo, NUDIST, Atlis-ti) actually analyze the data with the click of a button. The lack of context and theory in Doing Case Study Research is both purposeful and effective. Hancock and Algozzine fill a gap in the literature with regard to case study research and their book makes a very useful accompaniment to qualitative research courses. It may not teach some old research dogs new tricks, but Doing Case Study Research is definitely a useful resource to pass along to more novice researchers.\n",
            "------------------------------------\n",
            "Title Continuous Variable Quantum Information: Gaussian States and Beyond\n",
            "Author [{'authorId': '2922587', 'name': 'G. Adesso'}, {'authorId': '2288206', 'name': 'Sammy Ragy'}, {'authorId': '39138940', 'name': 'Antony R. Lee'}]\n",
            "Venue Open systems & information dynamics\n",
            "year 2014\n",
            "Abstract The study of Gaussian states has arisen to a privileged position in contin- uous variable quantum information in recent years. This is due to vehemently pursued experimental realisations and a magnificently elegant mathematical framework. In this paper, we provide a brief, and hopefully didactic, exposition of Gaussian state quantum information and its contemporary uses, including sometimes omitted crucial details. After introducing the subject material and outlining the essential toolbox of continuous variable systems, we define the basic notions needed to understand Gaussian states and Gaussian operations. In particular, emphasis is placed on the mathematical structure combining notions of algebra and symplectic geometry fundamental to a complete understanding of Gaussian informatics. Furthermore, we discuss the quantification of different forms of cor- relations (including entanglement and quantum discord) for Gaussian states, paying special attention to recently developed measures. The paper is concluded by succinctly expressing the main Gaussian state limitations and outlining a selection of possible future lines for quantum information processing with continuous variable systems.\n",
            "------------------------------------\n",
            "Title Seeking and sharing health information online: comparing search engines and social media\n",
            "Author [{'authorId': '2583473', 'name': 'M. Choudhury'}, {'authorId': '144844426', 'name': 'M. Morris'}, {'authorId': '34286525', 'name': 'Ryen W. White'}]\n",
            "Venue International Conference on Human Factors in Computing Systems\n",
            "year 2014\n",
            "Abstract Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
            "------------------------------------\n",
            "Title Belief Echoes: The Persistent Effects of Corrected Misinformation\n",
            "Author [{'authorId': '26668235', 'name': 'Emily A. Thorson'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Across three separate experiments, I find that exposure to negative political information continues to shape attitudes even after the information has been effectively discredited. I call these effects “belief echoes.” Results suggest that belief echoes can be created through an automatic or deliberative process. Belief echoes occur even when the misinformation is corrected immediately, the “gold standard” of journalistic fact-checking. The existence of belief echoes raises ethical concerns about journalists’ and fact-checking organizations’ efforts to publicly correct false claims.\n",
            "------------------------------------\n",
            "Title Do Independent Directors Cause Improvements in Firm Transparency?\n",
            "Author [{'authorId': '4048463', 'name': 'C. Armstrong'}, {'authorId': '13187515', 'name': 'J. Core'}, {'authorId': '70623039', 'name': 'W. Guay'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Although recent research documents a positive relation between corporate transparency and the proportion of independent directors, the direction of causality is unclear. We examine a regulatory shock that substantially increased board independence for some firms, and find that information asymmetry, and to some extent management disclosure and financial intermediation, changed at firms affected by this shock. We also examine whether these effects vary as a function of management entrenchment, information processing costs, and required changes to audit committee independence. Our results suggest that firms can alter their corporate transparency to suit the informational demands of a particular board structure.\n",
            "------------------------------------\n",
            "Title An investigation of visibility and flexibility as complements to supply chain analytics: An organizational information processing theory perspective\n",
            "Author [{'authorId': '2105859910', 'name': 'R. Srinivasan'}, {'authorId': '145554678', 'name': 'M. Swink'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Many businesses are seeking to develop and exploit analytics capabilities today. Using organizational information processing theory (OIPT), we study demand visibility and supply visibility as foundational resources for analytics capability, and organizational flexibility as a complementary capability. We further examine relationships among these factors under varying conditions of market volatility, a type of environmental uncertainty. The results from our analysis of data from 191 global firms indicate that both demand and supply visibility are associated with the development of analytics capability. In turn, analytics capability is shown to be more strongly associated with operational performance when supply chain organizations also possess organizational flexibility needed to act upon analytics-generated insights quickly and efficiently. Furthermore, the empirical results indicate that analytics capability and organizational flexibility are more valuable as complementary capabilities for firms who operate in volatile markets, rather than in stable ones. These findings extend OIPT to create a better understanding of contemporary applications of information processing technologies, while also providing theoretically grounded guidance to managers in the development of analytics capabilities within their firms. \n",
            " \n",
            "This article is protected by copyright. All rights reserved.\n",
            "------------------------------------\n",
            "Title Understanding customers' repeat purchase intentions in B2C e‐commerce: the roles of utilitarian value, hedonic value and perceived risk\n",
            "Author [{'authorId': '1717257', 'name': 'Chao-Min Chiu'}, {'authorId': '143877061', 'name': 'Eric T. G. Wang'}, {'authorId': '2634408', 'name': 'Yu-Hui Fang'}, {'authorId': '144968084', 'name': 'Hsin-Yi Huang'}]\n",
            "Venue Information Systems Journal\n",
            "year 2014\n",
            "Abstract Customer loyalty or repeat purchasing is critical for the survival and success of any store. By focusing on online stores, this study investigates the repeat purchase intention of experienced online buyers based on means‐end chain theory and prospect theory. In the research model, both utilitarian value and hedonic value are hypothesised to affect repeat purchase intention positively. Perceived risk is hypothesised to affect repeat purchase intention negatively and moderate the effects of utilitarian and hedonic values on repeat purchase intention. Utilitarian value is proposed as a formative second‐order construct formed by product offerings, product information, monetary savings and convenience. Hedonic value is also proposed as a formative second‐order construct formed by the six hedonic benefits that have been identified in prior research. Data collected from 782 Yahoo!Kimo customers provide strong support for the research model. The results indicate that both the utilitarian value and hedonic value are positively associated with buyers' repeat purchase intention. A higher level of perceived risk reduces the effect of utilitarian value and increases the effect of hedonic value on repeat purchase intention. Implications for theory and practice and suggestions for future research are provided.\n",
            "------------------------------------\n",
            "Title ExFuse: Enhancing Feature Fusion for Semantic Segmentation\n",
            "Author [{'authorId': '2157126418', 'name': 'Zhenli Zhang'}, {'authorId': '1771551', 'name': 'X. Zhang'}, {'authorId': '2113567716', 'name': 'Chao Peng'}, {'authorId': '48573140', 'name': 'Dazhi Cheng'}, {'authorId': None, 'name': 'Jian Sun'}]\n",
            "Venue European Conference on Computer Vision\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Psychological Frictions and the Incomplete Take-Up of Social Benefits: Evidence from an IRS Field Experiment\n",
            "Author [{'authorId': '2079458', 'name': 'Saurabh Bhargava'}, {'authorId': '3799782', 'name': 'Dayanand Manoli'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract We address the role of “psychological frictions” in the incomplete take-up of EITC benefits with an IRS field experiment. We specifically assess the influence of program confusion, informational complexity, and stigma by evaluating response to experimental mailings distributed to 35,050 tax filers who failed to claim $26 million despite an initial notice. While the mere receipt of the mailing, simplification, and the heightened salience of benefits led to substantial additional claiming, attempts to reduce perceived costs of stigma, application, and audits did not. The study, and accompanying surveys, suggests that low program awareness/understanding and informational complexity contribute to the puzzle of low take-up. (JEL C93, D03, H24, M38)\n",
            "------------------------------------\n",
            "Title Extracting information from the text of electronic medical records to improve case detection: a systematic review\n",
            "Author [{'authorId': '144265063', 'name': 'E. Ford'}, {'authorId': '144708727', 'name': 'J. Carroll'}, {'authorId': '2110916717', 'name': 'Helen E. Smith'}, {'authorId': '145817168', 'name': 'D. Scott'}, {'authorId': '36629323', 'name': 'J. Cassell'}]\n",
            "Venue J. Am. Medical Informatics Assoc.\n",
            "year 2016\n",
            "Abstract Abstract Background Electronic medical records (EMRs) are revolutionizing health-related research. One key issue for study quality is the accurate identification of patients with the condition of interest. Information in EMRs can be entered as structured codes or unstructured free text. The majority of research studies have used only coded parts of EMRs for case-detection, which may bias findings, miss cases, and reduce study quality. This review examines whether incorporating information from text into case-detection algorithms can improve research quality. Methods A systematic search returned 9659 papers, 67 of which reported on the extraction of information from free text of EMRs with the stated purpose of detecting cases of a named clinical condition. Methods for extracting information from text and the technical accuracy of case-detection algorithms were reviewed. Results Studies mainly used US hospital-based EMRs, and extracted information from text for 41 conditions using keyword searches, rule-based algorithms, and machine learning methods. There was no clear difference in case-detection algorithm accuracy between rule-based and machine learning methods of extraction. Inclusion of information from text resulted in a significant improvement in algorithm sensitivity and area under the receiver operating characteristic in comparison to codes alone (median sensitivity 78% (codes + text) vs 62% (codes), P  = .03; median area under the receiver operating characteristic 95% (codes + text) vs 88% (codes), P  = .025). Conclusions Text in EMRs is accessible, especially with open source information extraction algorithms, and significantly improves case detection when combined with codes. More harmonization of reporting within EMR studies is needed, particularly standardized reporting of algorithm accuracy metrics like positive predictive value (precision) and sensitivity (recall).\n",
            "------------------------------------\n",
            "Title Information Sharing in a Supply Chain with a Common Retailer\n",
            "Author [{'authorId': '3064212', 'name': 'Weixin Shang'}, {'authorId': '1974591', 'name': 'Albert Y. Ha'}, {'authorId': '2035278869', 'name': 'Shilu Tong'}]\n",
            "Venue Management Sciences\n",
            "year 2013\n",
            "Abstract We study the problem of information sharing in a supply chain with two competing manufacturers selling substitutable products through a common retailer. Our analysis shows that the retailer’s incentive to share information strongly depends on nonlinear production cost, competition intensity, and whether the retailer can offer a contract to charge a payment for the information. Without information contracting, the retailer has an incentive to share information for free when production economy is large but has no incentive to do so when there is production diseconomy. With information contracting, the retailer has an incentive to share information when either production diseconomy/economy is large or competition is intense. We characterize the conditions under which the retailer shares information with none, one, or both of the manufacturers. We also show that the retailer prefers to sell information sequentially rather than concurrently to the manufacturers, whereas the manufacturers’ preferences are reversed. This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title Hierarchical recurrent neural network for skeleton based action recognition\n",
            "Author [{'authorId': '2111867908', 'name': 'Yong Du'}, {'authorId': None, 'name': 'Wei Wang'}, {'authorId': '123865558', 'name': 'Liang Wang'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2015\n",
            "Abstract Human actions can be represented by the trajectories of skeleton joints. Traditional methods generally model the spatial structure and temporal dynamics of human skeleton with hand-crafted features and recognize human actions by well-designed classifiers. In this paper, considering that recurrent neural network (RNN) can model the long-term contextual information of temporal sequences well, we propose an end-to-end hierarchical RNN for skeleton based action recognition. Instead of taking the whole skeleton as the input, we divide the human skeleton into five parts according to human physical structure, and then separately feed them to five subnets. As the number of layers increases, the representations extracted by the subnets are hierarchically fused to be the inputs of higher layers. The final representations of the skeleton sequences are fed into a single-layer perceptron, and the temporally accumulated output of the perceptron is the final decision. We compare with five other deep RNN architectures derived from our model to verify the effectiveness of the proposed network, and also compare with several other methods on three publicly available datasets. Experimental results demonstrate that our model achieves the state-of-the-art performance with high computational efficiency.\n",
            "------------------------------------\n",
            "Title Infoglut: How Too Much Information Is Changing the Way We Think and Know\n",
            "Author [{'authorId': '50056732', 'name': 'M. Andrejevic'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Today, more mediated information is available to more people than at any other time in human history. New and revitalized sense-making strategies multiply in response to the challenges of \"cutting through the clutter\" of competing narratives and taming the avalanche of information. Data miners, \"sentiment analysts,\" and decision markets offer to help bodies of data \"speak for themselves\"making sense of their own patterns so we dont have to. Neuromarketers and body language experts promise to peer behind peoples words to see what their brains are really thinking and feeling. New forms of information processing promise to displace the need for expertise and even comprehensionat least for those with access to the data. Infoglut explores the connections between these wide-ranging sense-making strategies for an era of information overload and \"big data,\" and the new forms of control they enable. Andrejevic critiques the popular embrace of deconstructive debunkery, calling into question the post-truth, post-narrative, and post-comprehension politics it underwrites, and tracing a way beyond them.\n",
            "------------------------------------\n",
            "Title Learning Discrete Representations via Information Maximizing Self-Augmented Training\n",
            "Author [{'authorId': '48594758', 'name': 'Weihua Hu'}, {'authorId': '3213400', 'name': 'Takeru Miyato'}, {'authorId': '3117618', 'name': 'Seiya Tokui'}, {'authorId': '8252749', 'name': 'Eiichi Matsumoto'}, {'authorId': '67154907', 'name': 'Masashi Sugiyama'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2017\n",
            "Abstract Learning discrete representations of data is a central machine learning task because of the compactness of the representations and ease of interpretation. The task includes clustering and hash learning as special cases. Deep neural networks are promising to be used because they can model the non-linearity of data and scale to large datasets. However, their model complexity is huge, and therefore, we need to carefully regularize the networks in order to learn useful representations that exhibit intended invariance for applications of interest. To this end, we propose a method called Information Maximizing Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose the invari-ance on discrete representations. More specifically, we encourage the predicted representations of augmented data points to be close to those of the original data points in an end-to-end fashion. At the same time, we maximize the information-theoretic dependency between data and their predicted discrete representations. Extensive experiments on benchmark datasets show that IMSAT produces state-of-the-art results for both clustering and unsupervised hash learning.\n",
            "------------------------------------\n",
            "Title Infographics: The Power of Visual Storytelling\n",
            "Author [{'authorId': '69568437', 'name': 'Jason Lankow'}, {'authorId': '47339286', 'name': 'J. Ritchie'}, {'authorId': '69333227', 'name': 'Ross Crooks'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Intro 1. Introduction 010 A Brief History of Infographics 014 The Purpose of This Book 018 What This Book Is Not 018 A Note on Terminology 019 How to Use This Book 024 Chapter 01. Importance and Efficacy: Why Our Brains Love Infographics 028 Varied Perspectives on Information Design: A Brief History 031 Objectives of Visualization 038 Appeal 040 Comprehension 044 Retention 050 Chapter 02. Infographic Formats: Choosing the Right Vehicle for Your Message 056 Static Infographics 060 Motion Graphics 074 Interactive Infographics 082 Chapter 03. The Visual Storytelling Spectrum: An Objective Approach 088 Understanding the Visual Storytelling Spectrum 090 Chapter 04. Editorial Infographics 112 What Are Editorial Infographics? 114 Origins of Editorial Infographics 122 Editorial Infographic Production 128 Chapter 05. Content Distribtion: Sharing Your Story 146 Posting on Your Site 149 Distribution Your Content 152 Patience Pays Dividends 159\n",
            "------------------------------------\n",
            "Title Peningkatan Kemampuan Menulis Teks Deskripsi Siswa Kelas VII SMP Berdasarkan Level Pemula Menggunakan Teknik Retrival Jaringan Semantik\n",
            "Author [{'authorId': '148225083', 'name': 'Tobias Nggaruaka'}, {'authorId': '108230552', 'name': 'A. Hermansyah'}, {'authorId': '2005689902', 'name': 'Santi Monika'}]\n",
            "Venue \n",
            "year 2020\n",
            "Abstract Kemampuan menulis teks deskripsi siswa kelas VII SMP YPPGI Geradus Adii Merauke masih rendah. Berdasarkan permasalahan tersebut tujuan penelitian ini adalah meningkatkan kemampuan menulis teks deskripsi dengan menggunakan teknik retrival jaringan semantik. Penelitian ini menggunakan jenis penelitian kualitatif dengan rancangan penelitian tindakan kelas (PTK). Rancangan penelitian yang digunakan meliputi: observasi, analisis, perencanaan, pelaksanaan, refleksi, dan evaluasi. Data penelitian ini adalah berupa data proses dan data hasil penilaian pembelajaran. Data tersebut dikumpulkan dengan menggunakan instrumen penelitian yaitu; hasil pengamatan, wawancara, hasil tindakan, catatan lapangan, dan dokumentasi. Hasil penelitian menunjukkan bahwa pembelajaran pada siklus I pertemuan I dengan presentasi 28,57%. Sedangkan pada pertemuan II siklus I hasil pembelajaran meningkat menjadi 57,14%. Hasil pembelajaran pada siklus II pertemuan I meningkat menjadi 85,71%. Sedangkan pada pertemuan II siklus II meningkat menjadi 100% dengan kriteria ketuntasan minimal.\n",
            "------------------------------------\n",
            "Title Sustainability reports as simulacra? A counter-account of A and A+ GRI reports\n",
            "Author [{'authorId': '3338337', 'name': 'O. Boiral'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Purpose - – The purpose of this paper is to examine the extent to which sustainability reporting can be viewed as a simulacrum used to camouflage real sustainable-development problems and project an idealized view of the firms' situations. Design/methodology/approach - – The method was based on the content analysis and counter accounting of 23 sustainability reports from firms in the energy and mining sectors which had received application levels of A or A+ from the Global Reporting Initiative (GRI). The information disclosed in some 2,700 pages of reports was structured around 92 GRI indicators and compared with 116 significant news events that clearly addressed the responsibility of these firms in sustainable development problems. Moreover, the 1,258 pictures included in sustainability reports were categorized into recurring themes from an inductive perspective. Findings - – A total of 90 per cent of the significant negative events were not reported, contrary to the principles of balance, completeness and transparency of GRI reports. Moreover, the pictures included in these reports showcase various simulacra clearly disconnected with the impact of business activities. Originality/value - – The paper shows the relevance of the counter accounting approach in assessing the quality of sustainability reports and question the reliability of the GRI's A or A+ application levels. It contributes to debates concerning the transparency of sustainability reports in light of Debord's and Baudrillard's critical perspective. The paper reveals the underexplored role of images in the emergence of several types of simulacra.\n",
            "------------------------------------\n",
            "Title Gated-SCNN: Gated Shape CNNs for Semantic Segmentation\n",
            "Author [{'authorId': '150324836', 'name': 'Towaki Takikawa'}, {'authorId': '145360004', 'name': 'David Acuna'}, {'authorId': '2745026', 'name': 'V. Jampani'}, {'authorId': '37895334', 'name': 'S. Fidler'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2019\n",
            "Abstract Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.\n",
            "------------------------------------\n",
            "Title TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence of User Trust and of Item Ratings\n",
            "Author [{'authorId': '38896551', 'name': 'G. Guo'}, {'authorId': '36611093', 'name': 'Jie Zhang'}, {'authorId': '1402807089', 'name': 'N. Yorke-Smith'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2015\n",
            "Abstract \n",
            " \n",
            " Collaborative filtering suffers from the problems of data sparsity and cold start, which dramatically degrade recommendation performance. To help resolve these issues, we propose TrustSVD, a trust-based matrix factorization technique. By analyzing the social trust data from four real-world data sets, we conclude that not only the explicit but also the implicit influence of both ratings and trust should be taken into consideration in a recommendation model. Hence, we build on top of a state-of-the-art recommendation algorithm SVD++ which inherently involves the explicit and implicit influence of rated items, by further incorporating both the explicit and implicit influence of trusted users on the prediction of items for an active user. To our knowledge, the work reported is the first to extend SVD++ with social trust information. Experimental results on the four data sets demonstrate that our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title Real-World Evidence - What Is It and What Can It Tell Us?\n",
            "Author [{'authorId': '152908180', 'name': 'Rachel E. Sherman'}, {'authorId': '30270866', 'name': 'S. Anderson'}, {'authorId': '4647275', 'name': 'G. D. Dal Pan'}, {'authorId': '145266194', 'name': 'Gerry W Gray'}, {'authorId': '39067492', 'name': 'T. Gross'}, {'authorId': '2069947159', 'name': 'Nina L. Hunter'}, {'authorId': '4968089', 'name': 'L. LaVange'}, {'authorId': '1399076287', 'name': 'D. Marinac-Dabic'}, {'authorId': '152163112', 'name': 'P. Marks'}, {'authorId': '2587349', 'name': 'M. Robb'}, {'authorId': '4330403', 'name': 'J. Shuren'}, {'authorId': '30596913', 'name': 'R. Temple'}, {'authorId': '144983682', 'name': 'J. Woodcock'}, {'authorId': '11632900', 'name': 'L. Yue*'}, {'authorId': '2052004', 'name': 'R. Califf'}]\n",
            "Venue New England Journal of Medicine\n",
            "year 2016\n",
            "Abstract The FDA is developing guidance on the use of “real-world evidence” — health care information from atypical sources, including electronic health records, billing databases, and product and disease registries — to assess the safety and effectiveness of drugs and devices.\n",
            "------------------------------------\n",
            "Title Variable selection – A review and recommendations for the practicing statistician\n",
            "Author [{'authorId': '2255160', 'name': 'G. Heinze'}, {'authorId': '12707063', 'name': 'C. Wallisch'}, {'authorId': '2333290', 'name': 'D. Dunkler'}]\n",
            "Venue Biometrical journal. Biometrische Zeitschrift\n",
            "year 2018\n",
            "Abstract Statistical models support medical research by facilitating individualized outcome prognostication conditional on independent variables or by estimating effects of risk factors adjusted for covariates. Theory of statistical models is well‐established if the set of independent variables to consider is fixed and small. Hence, we can assume that effect estimates are unbiased and the usual methods for confidence interval estimation are valid. In routine work, however, it is not known a priori which covariates should be included in a model, and often we are confronted with the number of candidate variables in the range 10–30. This number is often too large to be considered in a statistical model. We provide an overview of various available variable selection methods that are based on significance or information criteria, penalized likelihood, the change‐in‐estimate criterion, background knowledge, or combinations thereof. These methods were usually developed in the context of a linear regression model and then transferred to more generalized linear models or models for censored survival data. Variable selection, in particular if used in explanatory modeling where effect estimates are of central interest, can compromise stability of a final model, unbiasedness of regression coefficients, and validity of p‐values or confidence intervals. Therefore, we give pragmatic recommendations for the practicing statistician on application of variable selection methods in general (low‐dimensional) modeling problems and on performing stability investigations and inference. We also propose some quantities based on resampling the entire variable selection process to be routinely reported by software packages offering automated variable selection algorithms.\n",
            "------------------------------------\n",
            "Title Spindle Net: Person Re-identification with Human Body Region Guided Feature Decomposition and Fusion\n",
            "Author [{'authorId': '49453102', 'name': 'Haiyu Zhao'}, {'authorId': '26320319', 'name': 'Maoqing Tian'}, {'authorId': '2115306116', 'name': 'Shuyang Sun'}, {'authorId': '1388486428', 'name': 'Jing Shao'}, {'authorId': '1721677', 'name': 'Junjie Yan'}, {'authorId': '2447593', 'name': 'Shuai Yi'}, {'authorId': '31843833', 'name': 'Xiaogang Wang'}, {'authorId': '50295995', 'name': 'Xiaoou Tang'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2017\n",
            "Abstract Person re-identification (ReID) is an important task in video surveillance and has various applications. It is non-trivial due to complex background clutters, varying illumination conditions, and uncontrollable camera settings. Moreover, the person body misalignment caused by detectors or pose variations is sometimes too severe for feature matching across images. In this study, we propose a novel Convolutional Neural Network (CNN), called Spindle Net, based on human body region guided multi-stage feature decomposition and tree-structured competitive feature fusion. It is the first time human body structure information is considered in a CNN framework to facilitate feature learning. The proposed Spindle Net brings unique advantages: 1) it separately captures semantic features from different body regions thus the macro-and micro-body features can be well aligned across images, 2) the learned region features from different semantic regions are merged with a competitive scheme and discriminative features can be well preserved. State of the art performance can be achieved on multiple datasets by large margins. We further demonstrate the robustness and effectiveness of the proposed Spindle Net on our proposed dataset SenseReID without fine-tuning.\n",
            "------------------------------------\n",
            "Title Teens, Health and Technology: A National Survey\n",
            "Author [{'authorId': '2111008', 'name': 'E. Wartella'}, {'authorId': '40621199', 'name': 'V. Rideout'}, {'authorId': '145512933', 'name': 'H. Montague'}, {'authorId': '1410581415', 'name': 'Leanne Beaudoin-Ryan'}, {'authorId': '2655481', 'name': 'A. Lauricella'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract In the age of digital technology, as teens seem to be constantly connected online, via social media, and through mobile applications, it is no surprise that they increasingly turn to digital media to answer their health questions. This study is the first of its kind to survey a large, nationally-representative sample of teens to investigate how they use the newest digital technologies, including mobile apps, social networking sites, electronic gaming and wearable devices, to explore health topics. The survey covered the types of health topics teens most frequently search for, which technologies they are most likely to use and how they use them, and whether they report having changed their behaviors due to digital health information. In addition, this survey explores how the digital divide continues to impact adolescents. Results of this study indicate that teens are concerned about many health issues, ranging from fitness, sexual activity, drugs, hygiene as well as mental health and stress. As teens virtually always have a digital device at their fingertips, it is clear that public health interventions and informational campaigns must be tailored to reflect the ways that teens currently navigate digital health information and the health challenges that concern them most.\n",
            "------------------------------------\n",
            "Title Direct and Mediated Associations among Earnings Quality, Information Asymmetry, and the Cost of Equity\n",
            "Author [{'authorId': '36204231', 'name': 'Nilabhra Bhattacharya'}, {'authorId': '2841782', 'name': 'Frank Ecker'}, {'authorId': '108133666', 'name': 'Per Olsson'}, {'authorId': '4605811', 'name': 'K. Schipper'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract ABSTRACT: Using path analysis, we investigate the direct and indirect links between three measures of earnings quality and the cost of equity. Our investigation is motivated by analytical models that specify both a direct link and an indirect link that is mediated by information asymmetry, but do not suggest which link would be more important empirically. We measure information asymmetry as both the adverse selection component of the bid-ask spread and the probability of informed trading (PIN). For a large sample of Value Line firms during 1993–2005, we find statistically reliable evidence of both a direct path from earnings quality to the cost of equity, and an indirect path that is mediated by information asymmetry, with the weight of the evidence favoring the direct path as the more important.\n",
            "------------------------------------\n",
            "Title The Human Phenotype Ontology project: linking molecular biology and disease through phenotype data\n",
            "Author [{'authorId': '49511024', 'name': 'S. Köhler'}, {'authorId': '2235515', 'name': 'S. Doelken'}, {'authorId': '52038267', 'name': 'C. Mungall'}, {'authorId': '49161276', 'name': 'Sebastian Bauer'}, {'authorId': '1860258', 'name': 'H. Firth'}, {'authorId': '1400527253', 'name': 'I. Bailleul-Forestier'}, {'authorId': '35061932', 'name': 'G. Black'}, {'authorId': '2115444410', 'name': 'Danielle L. Brown'}, {'authorId': '1861681', 'name': 'M. Brudno'}, {'authorId': '37794383', 'name': 'Jennifer Campbell'}, {'authorId': '48541428', 'name': 'D. Fitzpatrick'}, {'authorId': '39855252', 'name': 'J. Eppig'}, {'authorId': '2670555', 'name': 'A. Jackson'}, {'authorId': '3199576', 'name': 'K. Freson'}, {'authorId': '2946179', 'name': 'M. Gîrdea'}, {'authorId': '2935949', 'name': 'I. Helbig'}, {'authorId': '2626207', 'name': 'J. Hurst'}, {'authorId': '1991958', 'name': 'J. Jähn'}, {'authorId': '2593889', 'name': 'L. Jackson'}, {'authorId': '39482063', 'name': 'A. Kelly'}, {'authorId': '145116828', 'name': 'D. Ledbetter'}, {'authorId': '50692584', 'name': 'S. Mansour'}, {'authorId': '39981604', 'name': 'C. Martin'}, {'authorId': '2081275752', 'name': 'C. Moss'}, {'authorId': '46513221', 'name': 'A. Mumford'}, {'authorId': '2386312', 'name': 'W. Ouwehand'}, {'authorId': '14966554', 'name': 'Soo-Mi Park'}, {'authorId': '35145039', 'name': 'E. Riggs'}, {'authorId': '152694332', 'name': 'R. Scott'}, {'authorId': '143734722', 'name': 'S. Sisodiya'}, {'authorId': '7592698', 'name': 'S. V. Vooren'}, {'authorId': '3099850', 'name': 'R. Wapner'}, {'authorId': '40369895', 'name': 'A. Wilkie'}, {'authorId': '2826428', 'name': 'C. Wright'}, {'authorId': '7611125', 'name': 'A. V. Silfhout'}, {'authorId': '32264232', 'name': 'N. Leeuw'}, {'authorId': '144188236', 'name': 'B. Vries'}, {'authorId': '2333742', 'name': 'N. Washington'}, {'authorId': '2110203418', 'name': 'Cynthia L. Smith'}, {'authorId': '144836840', 'name': 'M. Westerfield'}, {'authorId': '145680505', 'name': 'P. Schofield'}, {'authorId': '2371472', 'name': 'B. Ruef'}, {'authorId': '47052047', 'name': 'G. Gkoutos'}, {'authorId': '1976792', 'name': 'M. Haendel'}, {'authorId': '1899930', 'name': 'D. Smedley'}, {'authorId': '144765698', 'name': 'S. Lewis'}, {'authorId': '2149814981', 'name': 'P. Robinson'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2013\n",
            "Abstract The Human Phenotype Ontology (HPO) project, available at http://www.human-phenotype-ontology.org, provides a structured, comprehensive and well-defined set of 10,088 classes (terms) describing human phenotypic abnormalities and 13,326 subclass relations between the HPO classes. In addition we have developed logical definitions for 46% of all HPO classes using terms from ontologies for anatomy, cell types, function, embryology, pathology and other domains. This allows interoperability with several resources, especially those containing phenotype information on model organisms such as mouse and zebrafish. Here we describe the updated HPO database, which provides annotations of 7,278 human hereditary syndromes listed in OMIM, Orphanet and DECIPHER to classes of the HPO. Various meta-attributes such as frequency, references and negations are associated with each annotation. Several large-scale projects worldwide utilize the HPO for describing phenotype information in their datasets. We have therefore generated equivalence mappings to other phenotype vocabularies such as LDDB, Orphanet, MedDRA, UMLS and phenoDB, allowing integration of existing datasets and interoperability with multiple biomedical resources. We have created various ways to access the HPO database content using flat files, a MySQL database, and Web-based tools. All data and documentation on the HPO project can be found online.\n",
            "------------------------------------\n",
            "Title Information-theoretic analysis of generalization capability of learning algorithms\n",
            "Author [{'authorId': '2173432', 'name': 'Aolin Xu'}, {'authorId': '1693598', 'name': 'M. Raginsky'}]\n",
            "Venue NIPS\n",
            "year 2017\n",
            "Abstract We derive upper bounds on the generalization error of a learning algorithm in terms of the mutual information between its input and output. The bounds provide an information-theoretic understanding of generalization in learning problems, and give theoretical guidelines for striking the right balance between data fit and generalization by controlling the input-output mutual information. We propose a number of methods for this purpose, among which are algorithms that regularize the ERM algorithm with relative entropy or with random noise. Our work extends and leads to nontrivial improvements on the recent results of Russo and Zou.\n",
            "------------------------------------\n",
            "Title Recommender systems based on user reviews: the state of the art\n",
            "Author [{'authorId': '1725490', 'name': 'Li Chen'}, {'authorId': '5671907', 'name': 'Guanliang Chen'}, {'authorId': '144742600', 'name': 'Feng Wang'}]\n",
            "Venue User modeling and user-adapted interaction\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title The End of Framing as we Know it … and the Future of Media Effects\n",
            "Author [{'authorId': '32998833', 'name': 'M. Cacciatore'}, {'authorId': '2994143', 'name': 'D. Scheufele'}, {'authorId': '39120083', 'name': 'S. Iyengar'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Framing has become one of the most popular areas of research for scholars in communication and a wide variety of other disciplines, such as psychology, behavioral economics, political science, and sociology. Particularly in the communication discipline, however, ambiguities surrounding how we conceptualize and therefore operationalize framing have begun to overlap with other media effects models to a point that is dysfunctional. This article provides an in-depth examination of framing and positions the theory in the context of recent evolutions in media effects research. We begin by arguing for changes in how communication scholars approach framing as a theoretical construct. We urge scholars to abandon the general term “framing” altogether and instead distinguish between different types of framing. We also propose that, as a field, we refocus attention on the concept's original theoretical foundations and, more important, the potential empirical contributions that the concept can make to our field and our understanding of media effects. Finally, we discuss framing as a bridge between paradigms as we shift from an era of mass communication to one of echo chambers, tailored information and microtargeting in the new media environment.\n",
            "------------------------------------\n",
            "Title Data Resource Profile: The Korea National Health and Nutrition Examination Survey (KNHANES)\n",
            "Author [{'authorId': '49167491', 'name': 'Sanghui Kweon'}, {'authorId': '2119451582', 'name': 'Yuna Kim'}, {'authorId': '2055006895', 'name': 'Myoung-jin Jang'}, {'authorId': '2117904179', 'name': 'Yoonjung Kim'}, {'authorId': '4083485', 'name': 'Kirang Kim'}, {'authorId': '6410251', 'name': 'Sunhye Choi'}, {'authorId': '38740096', 'name': 'Chaemin Chun'}, {'authorId': '5181120', 'name': 'Y. Khang'}, {'authorId': '3958747', 'name': 'Kyungwon Oh'}]\n",
            "Venue International Journal of Epidemiology\n",
            "year 2014\n",
            "Abstract The Korea National Health and Nutrition Examination Survey (KNHANES) is a national surveillance system that has been assessing the health and nutritional status of Koreans since 1998. Based on the National Health Promotion Act, the surveys have been conducted by the Korea Centers for Disease Control and Prevention (KCDC). This nationally representative cross-sectional survey includes approximately 10 000 individuals each year as a survey sample and collects information on socioeconomic status, health-related behaviours, quality of life, healthcare utilization, anthropometric measures, biochemical and clinical profiles for non-communicable diseases and dietary intakes with three component surveys: health interview, health examination and nutrition survey. The health interview and health examination are conducted by trained staff members, including physicians, medical technicians and health interviewers, at a mobile examination centre, and dieticians’ visits to the homes of the study participants are followed up. KNHANES provides statistics for health-related policies in Korea, which also serve as the research infrastructure for studies on risk factors and diseases by supporting over 500 publications. KCDC has also supported researchers in Korea by providing annual workshops for data users. KCDC has published the Korea Health Statistics each year, and microdata are publicly available through the KNHANES website (http://knhanes.cdc.go.kr).\n",
            "------------------------------------\n",
            "Title Influence of fake news in Twitter during the 2016 US presidential election\n",
            "Author [{'authorId': '40685732', 'name': 'A. Bovet'}, {'authorId': '2337765', 'name': 'H. Makse'}]\n",
            "Venue Nature Communications\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Impact of Online Information on Self-Isolation Intention During the COVID-19 Pandemic: Cross-Sectional Study\n",
            "Author [{'authorId': '1500579563', 'name': 'Ali Farooq'}, {'authorId': '22423711', 'name': 'Samuli Laato'}, {'authorId': '143886814', 'name': 'A. Islam'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2020\n",
            "Abstract Background During the coronavirus disease (COVID-19) pandemic, governments issued movement restrictions and placed areas into quarantine to combat the spread of the disease. In addition, individuals were encouraged to adopt personal health measures such as social isolation. Information regarding the disease and recommended avoidance measures were distributed through a variety of channels including social media, news websites, and emails. Previous research suggests that the vast amount of available information can be confusing, potentially resulting in overconcern and information overload. Objective This study investigates the impact of online information on the individual-level intention to voluntarily self-isolate during the pandemic. Using the protection-motivation theory as a framework, we propose a model outlining the effects of cyberchondria and information overload on individuals’ perceptions and motivations. Methods To test the proposed model, we collected data with an online survey (N=225) and analyzed it using partial least square-structural equation modeling. The effects of social media and living situation were tested through multigroup analysis. Results Cyberchondria and information overload had a significant impact on individuals’ threat and coping perceptions, and through them on self-isolation intention. Among the appraisal constructs, perceived severity (P=.002) and self-efficacy (P=.003) positively impacted self-isolation intention, while response cost (P<.001) affected the intention negatively. Cyberchondria (P=.003) and information overload (P=.003) indirectly affected self-isolation intention through the aforementioned perceptions. Using social media as an information source increased both cyberchondria and information overload. No differences in perceptions were found between people living alone and those living with their families. Conclusions During COVID-19, frequent use of social media contributed to information overload and overconcern among individuals. To boost individuals’ motivation to adopt preventive measures such as self-isolation, actions should focus on lowering individuals’ perceived response costs in addition to informing them about the severity of the situation.\n",
            "------------------------------------\n",
            "Title Interactive information complexity\n",
            "Author [{'authorId': '143803467', 'name': 'M. Braverman'}]\n",
            "Venue Symposium on the Theory of Computing\n",
            "year 2012\n",
            "Abstract The primary goal of this paper is to define and study the interactive information complexity of functions. Let f(x,y) be a function, and suppose Alice is given x and Bob is given y. Informally, the interactive information complexity IC(f) of f is the least amount of information Alice and Bob need to reveal to each other to compute f. Previously, information complexity has been defined with respect to a prior distribution on the input pairs (x,y). Our first goal is to give a definition that is independent of the prior distribution. We show that several possible definitions are essentially equivalent.\n",
            " We establish some basic properties of the interactive information complexity IC(f). In particular, we show that IC(f) is equal to the amortized (randomized) communication complexity of f. We also show a direct sum theorem for IC(f) and give the first general connection between information complexity and (non-amortized) communication complexity. This connection implies that a non-trivial exchange of information is required when solving problems that have non-trivial communication complexity.\n",
            " We explore the information complexity of two specific problems - Equality and Disjointness. We show that only a constant amount of information needs to be exchanged when solving Equality with no errors, while solving Disjointness with a constant error probability requires the parties to reveal a linear amount of information to each other.\n",
            "------------------------------------\n",
            "Title A meta-analysis of executive components of working memory.\n",
            "Author [{'authorId': '2496261', 'name': 'D. E. Nee'}, {'authorId': '1388954491', 'name': 'Joshua W. Brown'}, {'authorId': '145301636', 'name': 'Mary K. Askren'}, {'authorId': '3130159', 'name': 'M. Berman'}, {'authorId': '2285466', 'name': 'E. Demiralp'}, {'authorId': '3237638', 'name': 'A. Krawitz'}, {'authorId': '1869771', 'name': 'J. Jonides'}]\n",
            "Venue Cerebral Cortex\n",
            "year 2013\n",
            "Abstract Working memory (WM) enables the online maintenance and manipulation of information and is central to intelligent cognitive functioning. Much research has investigated executive processes of WM in order to understand the operations that make WM \"work.\" However, there is yet little consensus regarding how executive processes of WM are organized. Here, we used quantitative meta-analysis to summarize data from 36 experiments that examined executive processes of WM. Experiments were categorized into 4 component functions central to WM: protecting WM from external distraction (distractor resistance), preventing irrelevant memories from intruding into WM (intrusion resistance), shifting attention within WM (shifting), and updating the contents of WM (updating). Data were also sorted by content (verbal, spatial, object). Meta-analytic results suggested that rather than dissociating into distinct functions, 2 separate frontal regions were recruited across diverse executive demands. One region was located dorsally in the caudal superior frontal sulcus and was especially sensitive to spatial content. The other was located laterally in the midlateral prefrontal cortex and showed sensitivity to nonspatial content. We propose that dorsal-\"where\"/ventral-\"what\" frameworks that have been applied to WM maintenance also apply to executive processes of WM. Hence, WM can largely be simplified to a dual selection model.\n",
            "------------------------------------\n",
            "Title SlowFast Networks for Video Recognition\n",
            "Author [{'authorId': '2322150', 'name': 'Christoph Feichtenhofer'}, {'authorId': '146884473', 'name': 'Haoqi Fan'}, {'authorId': '143751119', 'name': 'Jitendra Malik'}, {'authorId': '39353098', 'name': 'Kaiming He'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2018\n",
            "Abstract We present SlowFast networks for video recognition. Our model involves (i) a Slow pathway, operating at low frame rate, to capture spatial semantics, and (ii) a Fast pathway, operating at high frame rate, to capture motion at fine temporal resolution. The Fast pathway can be made very lightweight by reducing its channel capacity, yet can learn useful temporal information for video recognition. Our models achieve strong performance for both action classification and detection in video, and large improvements are pin-pointed as contributions by our SlowFast concept. We report state-of-the-art accuracy on major video recognition benchmarks, Kinetics, Charades and AVA. Code has been made available at: https://github.com/facebookresearch/SlowFast.\n",
            "------------------------------------\n",
            "Title How Virtualization, Decentralization and Network Building Change the Manufacturing Landscape: An Industry 4.0 Perspective\n",
            "Author [{'authorId': '2566102', 'name': 'Malte Brettel'}, {'authorId': '71163411', 'name': 'Niklas Friederichsen'}, {'authorId': '50337677', 'name': 'M. Keller'}, {'authorId': '143746253', 'name': 'Marius Rosenberg'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract : The German manufacturing industry has to withstand an increasing global competition on product quality and production costs. As labor costs are high, several industries have suffered severely under the relocation of production facilities towards aspiring countries, which have managed to close the productivity and quality gap substantially. Established manufacturing companies have recognized that customers are not willing to pay large price premiums for incremental quality improvements. As a consequence, many companies from the German manufacturing industry adjust their production focusing on customized products and fast time to market. Leveraging the advantages of novel production strategies such as Agile Manufacturing and Mass Customization, manufacturing companies transform into integrated networks, in which companies unite their core competencies. Hereby, virtualization of the process- and supply-chain ensures smooth inter-company operations providing real-time access to relevant product and production information for all participating entities. Boundaries of companies deteriorate, as autonomous systems exchange data, gained by embedded systems throughout the entire value chain. By including Cyber-Physical-Systems, advanced communication between machines is tantamount to their dialogue with humans. The increasing utilization of information and communication technology allows digital engineering of products and production processes alike. Modular simulation and modeling techniques allow decentralized units to flexibly alter products and thereby enable rapid product innovation. The present article describes the developments of Industry 4.0 within the literature and reviews the associated research streams. Hereby, we analyze eight scientific journals with regards to the following research fields: Individualized production, end-to-end engineering in a virtual process chain and production networks. We employ cluster analysis to assign sub-topics into the respective research field. To assess the practical implications, we conducted face-to-face interviews with managers from the industry as well as from the consulting business using a structured interview guideline. The results reveal reasons for the adaption and refusal of Industry 4.0 practices from a managerial point of view. Our findings contribute to the upcoming research stream of Industry 4.0 and support decision-makers to assess their need for transformation towards Industry 4.0 practices.\n",
            "------------------------------------\n",
            "Title InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization\n",
            "Author [{'authorId': '51447186', 'name': 'Fan-Yun Sun'}, {'authorId': '46616544', 'name': 'Jordan Hoffmann'}, {'authorId': '152226504', 'name': 'Jian Tang'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2019\n",
            "Abstract This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.\n",
            "------------------------------------\n",
            "Title The Evolving Role of the Public Information Officer: An Examination of Social Media in Emergency Management\n",
            "Author [{'authorId': '2523772', 'name': 'Amanda Lee Hughes'}, {'authorId': '1759447', 'name': 'L. Palen'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Abstract This work examines how the introduction of social media has affected the role of the Public Information Officer (PIO)—the public relations component of the National Incident Management System (NIMS). Through analysis of 25 PIO interviews, we examine the work practice of PIOs and find that social media expand not only the scope and type of PIO work activity, but also the “information pathways” that exist between PIOs, the media, and members of the public. We model these changes and examine how the presence of social media challenges previous conceptualizations of PIO work. Lastly, we present a view of how PIO work could be better imagined for the future of emergency management organizations.\n",
            "------------------------------------\n",
            "Title EltonTraits 1.0: Species-level foraging attributes of the world's birds and mammals\n",
            "Author [{'authorId': '40697863', 'name': 'H. Wilman'}, {'authorId': '3761822', 'name': 'J. Belmaker'}, {'authorId': '37710231', 'name': 'J. Simpson'}, {'authorId': '2082444491', 'name': 'C. Rosa'}, {'authorId': '46635089', 'name': 'M. Rivadeneira'}, {'authorId': '3799786', 'name': 'W. Jetz'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Species are characterized by physiological, behavioral, and ecological attributes that are all subject to varying evolutionary and ecological constraints and jointly determine species' role and function in ecosystems. Attributes such as diet, foraging strata, foraging time, and body size, in particular, characterize a large portion of the “Eltonian” niches of species. Here we present a global species-level compilation of these key attributes for all 9993 and 5400 extant bird and mammal species derived from key literature sources. Global handbooks and monographs allowed the consistent sourcing of attributes for most species. For diet and foraging stratum we followed a defined protocol to translate the verbal descriptions into standardized, semiquantitative information about relative importance of different categories. Together with body size (continuous) and activity time (categorical) this enables a much finer distinction of species' foraging ecology than typical categorical guild assignments allow. Attri...\n",
            "------------------------------------\n",
            "Title How Technology Is Changing Work and Organizations\n",
            "Author [{'authorId': '48546117', 'name': 'W. Cascio'}, {'authorId': '2069855', 'name': 'Ramiro Montealegre'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four ...\n",
            "------------------------------------\n",
            "Title Machine Learning Models that Remember Too Much\n",
            "Author [{'authorId': '3469125', 'name': 'Congzheng Song'}, {'authorId': '1707461', 'name': 'T. Ristenpart'}, {'authorId': '1723945', 'name': 'Vitaly Shmatikov'}]\n",
            "Venue Conference on Computer and Communications Security\n",
            "year 2017\n",
            "Abstract Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data. We consider a malicious ML provider who supplies model-training code to the data holder, does \\emph{not} observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that \"memorize\" information about the training dataset in the model\\textemdash yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data.\n",
            "------------------------------------\n",
            "Title RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems\n",
            "Author [{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2642200', 'name': 'Fuzheng Zhang'}, {'authorId': '2109656553', 'name': 'Jialin Wang'}, {'authorId': '2152527702', 'name': 'Miao Zhao'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '1697293', 'name': 'M. Guo'}]\n",
            "Venue International Conference on Information and Knowledge Management\n",
            "year 2018\n",
            "Abstract To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple \"ripples\" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.\n",
            "------------------------------------\n",
            "Title EVOLUTION OF THE WORLD WIDE WEB : FROM WEB 1.0 TO WEB 4.0\n",
            "Author [{'authorId': '144699313', 'name': 'Sareh Aghaei'}, {'authorId': '10095748', 'name': 'M. Nematbakhsh'}, {'authorId': '2255722', 'name': 'Hadi Khosravi Farsani'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract The World Wide Web as the largest information construct has had much progress since its advent. This paper provides a background of the evolution of the web from web 1.0 to web 4.0. Web 1.0 as a web of information connections, Web 2.0 as a web of people connections, Web 3.0 as a web of knowledge connections and web 4.0 as a web of intelligence connections are described as four generations of the web in the paper.\n",
            "------------------------------------\n",
            "Title SpotFi: Decimeter Level Localization Using WiFi\n",
            "Author [{'authorId': '40657287', 'name': 'Manikanta Kotaru'}, {'authorId': '3256955', 'name': 'K. Joshi'}, {'authorId': '2061177', 'name': 'Dinesh Bharadia'}, {'authorId': '2546322', 'name': 'S. Katti'}]\n",
            "Venue Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication\n",
            "year 2015\n",
            "Abstract This paper presents the design and implementation of SpotFi, an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes, yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First, SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second, it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath.\n",
            "------------------------------------\n",
            "Title PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks\n",
            "Author [{'authorId': '145357803', 'name': 'Jian Tang'}, {'authorId': '145252498', 'name': 'Meng Qu'}, {'authorId': '1743469', 'name': 'Q. Mei'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2015\n",
            "Abstract Unsupervised text embedding methods, such as Skip-gram and Paragraph Vector, have been attracting increasing attention due to their simplicity, scalability, and effectiveness. However, comparing to sophisticated deep learning architectures such as convolutional neural networks, these methods usually yield inferior results when applied to particular machine learning tasks. One possible reason is that these text embedding methods learn the representation of text in a fully unsupervised way, without leveraging the labeled information available for the task. Although the low dimensional representations learned are applicable to many different tasks, they are not particularly tuned for any task. In this paper, we fill this gap by proposing a semi-supervised representation learning method for text data, which we call the predictive text embedding (PTE). Predictive text embedding utilizes both labeled and unlabeled data to learn the embedding of text. The labeled information and different levels of word co-occurrence information are first represented as a large-scale heterogeneous text network, which is then embedded into a low dimensional space through a principled and efficient algorithm. This low dimensional embedding not only preserves the semantic closeness of words and documents, but also has a strong predictive power for the particular task. Compared to recent supervised approaches based on convolutional neural networks, predictive text embedding is comparable or more effective, much more efficient, and has fewer parameters to tune.\n",
            "------------------------------------\n",
            "Title Giving too much social support: social overload on social networking sites\n",
            "Author [{'authorId': '1735380', 'name': 'C. Maier'}, {'authorId': '1734224', 'name': 'Sven Laumer'}, {'authorId': '143910850', 'name': 'Andreas Eckhardt'}, {'authorId': '1684996', 'name': 'Tim Weitzel'}]\n",
            "Venue European Journal of Information Systems\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Graph Convolutional Matrix Completion\n",
            "Author [{'authorId': '9965217', 'name': 'Rianne van den Berg'}, {'authorId': '41016725', 'name': 'Thomas Kipf'}, {'authorId': '1678311', 'name': 'M. Welling'}]\n",
            "Venue ArXiv\n",
            "year 2017\n",
            "Abstract We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title Patient Portals and Patient Engagement: A State of the Science Review\n",
            "Author [{'authorId': '8641215', 'name': 'Taya Irizarry'}, {'authorId': '4392659', 'name': 'A. D. DeVito Dabbs'}, {'authorId': '33059471', 'name': 'C. Curran'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2015\n",
            "Abstract Background Patient portals (ie, electronic personal health records tethered to institutional electronic health records) are recognized as a promising mechanism to support greater patient engagement, yet questions remain about how health care leaders, policy makers, and designers can encourage adoption of patient portals and what factors might contribute to sustained utilization. Objective The purposes of this state of the science review are to (1) present the definition, background, and how current literature addresses the encouragement and support of patient engagement through the patient portal, and (2) provide a summary of future directions for patient portal research and development to meaningfully impact patient engagement. Methods We reviewed literature from 2006 through 2014 in PubMed, Ovid Medline, and PsycInfo using the search terms “patient portal” OR “personal health record” OR “electronic personal health record”. Final inclusion criterion dictated that studies report on the patient experience and/or ways that patients may be supported to make competent health care decisions and act on those decisions using patient portal functionality. Results We found 120 studies that met the inclusion criteria. Based on the research questions, explicit and implicit aims of the studies, and related measures addressed, the studies were grouped into five major topics (patient adoption, provider endorsement, health literacy, usability, and utility). We discuss the findings and conclusions of studies that address the five topical areas. Conclusions Current research has demonstrated that patients’ interest and ability to use patient portals is strongly influenced by personal factors such age, ethnicity, education level, health literacy, health status, and role as a caregiver. Health care delivery factors, mainly provider endorsement and patient portal usability also contribute to patient’s ability to engage through and with the patient portal. Future directions of research should focus on identifying specific populations and contextual considerations that would benefit most from a greater degree of patient engagement through a patient portal. Ultimately, adoption by patients and endorsement by providers will come when existing patient portal features align with patients’ and providers’ information needs and functionality.\n",
            "------------------------------------\n",
            "Title Organizations' Information Security Policy Compliance: Stick or Carrot Approach?\n",
            "Author [{'authorId': '2144283993', 'name': 'Yan Chen'}, {'authorId': '144934675', 'name': 'K. Ramamurthy'}, {'authorId': '2117901', 'name': 'Kuang-Wei Wen'}]\n",
            "Venue Journal of Management Information Systems\n",
            "year 2012\n",
            "Abstract Companies' information security efforts are often threatened by employee negligence and insider breach. To deal with these insider issues, this study draws on the compliance theory and the general deterrence theory to propose a research model in which the relations among coercive control, which has been advocated by scholars and widely practiced by companies; remunerative control, which is generally missing in both research and practice; and certainty of control are studied. A Web-based field experiment involving real-world employees in their natural settings was used to empirically test the model. While lending further support to the general deterrence theory, our findings highlight that reward enforcement, a remunerative control mechanism in the information systems security context, could be an alternative for organizations where sanctions do not successfully prevent violation. The significant interactions between punishment and reward found in the study further indicate a need for a more comprehensive enforcement system that should include a reward enforcement scheme through which the organizational moral standards and values are established or reemphasized. The findings of this study can potentially be used to guide the design of more effective security enforcement systems that encompass remunerative control mechanisms.\n",
            "------------------------------------\n",
            "Title Understanding the Factors That Influence the Adoption and Meaningful Use of Social Media by Physicians to Share Medical Information\n",
            "Author [{'authorId': '2060622571', 'name': 'B. Mcgowan'}, {'authorId': '38938099', 'name': 'M. Wasko'}, {'authorId': '6035263', 'name': 'B. Vartabedian'}, {'authorId': '1400120490', 'name': 'Robert S. Miller'}, {'authorId': '6166874', 'name': 'Desirae D Freiherr'}, {'authorId': '4916149', 'name': 'M. Abdolrasulnia'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2012\n",
            "Abstract Background Within the medical community there is persistent debate as to whether the information available through social media is trustworthy and valid, and whether physicians are ready to adopt these technologies and ultimately embrace them as a format for professional development and lifelong learning. Objective To identify how physicians are using social media to share and exchange medical information with other physicians, and to identify the factors that influence physicians’ use of social media as a component of their lifelong learning and continuing professional development. Methods We developed a survey instrument based on the Technology Acceptance Model, hypothesizing that technology usage is best predicted by a physician’s attitudes toward the technology, perceptions about the technology’s usefulness and ease of use, and individual factors such as personal innovativeness. The survey was distributed via email to a random sample of 1695 practicing oncologists and primary care physicians in the United States in March 2011. Responses from 485 physicians were analyzed (response rate 28.61%). Results Overall, 117 of 485 (24.1%) of respondents used social media daily or many times daily to scan or explore medical information, whereas 69 of 485 (14.2%) contributed new information via social media on a daily basis. On a weekly basis or more, 296 of 485 (61.0%) scanned and 223 of 485 (46.0%) contributed. In terms of attitudes toward the use of social media, 279 of 485 respondents (57.5%) perceived social media to be beneficial, engaging, and a good way to get current, high-quality information. In terms of usefulness, 281 of 485 (57.9%) of respondents stated that social media enabled them to care for patients more effectively, and 291 of 485 (60.0%) stated it improved the quality of patient care they delivered. The main factors influencing a physician’s usage of social media to share medical knowledge with other physicians were perceived ease of use and usefulness. Respondents who had positive attitudes toward the use of social media were more likely to use social media and to share medical information with other physicians through social media. Neither age nor gender had a significant impact on adoption or usage of social media. Conclusions Based on the results of this study, the use of social media applications may be seen as an efficient and effective method for physicians to keep up-to-date and to share newly acquired medical knowledge with other physicians within the medical community and to improve the quality of patient care. Future studies are needed to examine the impact of the meaningful use of social media on physicians’ knowledge, attitudes, skills, and behaviors in practice.\n",
            "------------------------------------\n",
            "Title Knowledge Graph Convolutional Networks for Recommender Systems\n",
            "Author [{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2152527702', 'name': 'Miao Zhao'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '1697293', 'name': 'M. Guo'}]\n",
            "Venue The Web Conference\n",
            "year 2019\n",
            "Abstract To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.\n",
            "------------------------------------\n",
            "Title Comprehending and Learning From Internet Sources: Processing Patterns of Better and Poorer Learners\n",
            "Author [{'authorId': '39221711', 'name': 'S. Goldman'}, {'authorId': '29401868', 'name': 'Jason L. G. Braasch'}, {'authorId': '33951735', 'name': 'J. Wiley'}, {'authorId': '1769251', 'name': 'A. Graesser'}, {'authorId': '71062897', 'name': 'Kamila Brodowinska'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Readers increasingly attempt to understand and learn from information sources they find on the Internet. Doing so highlights the crucial role that evaluative processes play in selecting and making sense of the information. In a prior study, Wiley et al. (2009, Experiment 1) asked undergraduates to perform a web-based inquiry task about volcanoes using multiple Internet sources. A major finding established a clear link between learning outcomes, source evaluations, and reading behaviors. The present study used think-aloud protocol methodology to better understand the processing that learners engaged in during this task: 10 better learners were contrasted with 11 poorer learners. Results indicate that better learners engaged in more sense-making, self-explanation, and comprehension-monitoring processes on reliable sites as compared with unreliable sites, and did so by a larger margin than did poorer learners. Better learners also engaged in more goal-directed navigation than poorer learners. Case studies of two better and two poorer learners further illustrate how evaluation processes contributed to navigation decisions. Findings suggest that multiple-source comprehension is a dynamic process that involves interplay among sense-making, monitoring, and evaluation processes, all of which promote strategic reading. \n",
            " \n",
            " \n",
            " \n",
            "阅读者日益想要弄明白及学习他们从互联网上各种来源所找到的信息资料。他们这样做突显出在选择和弄明白这些信息时评价过程所起的重要作用。威立等人在以前一项研究(2009,实验1)中,参与研究的大学生要利用互联网多种资源来完成一项关于火山的網路探究式学习任务。该研究的一个主要结果是建立了学习成果、信息来源评价与阅读行为之间的明确联系。本研究则使用有声思维研究方法,以深入考查学习者在参与同一个学习任务时他们处理信息的过程,并以10名表现较好的与11名表现较差的学习者作比对。结果显示,对于可靠网站上的资料,表现较好的学习者较多致力于弄明白自我解释的过程和理解监控的过程,而对于不可靠网站上的资料,这种行为则较少;他们这种行为亦远多于表现较差的学习者。此外,表现较好的学习者比表现较差的学习者较多致力于有目标的网上浏览。两个表现较好及两个表现较差的学习者的案例研究,进一步说明评价过程如何有助于在网上浏览时所作的决定。本研究结果显示,理解多种来源的信息是一个动态的过程,其中涉及弄明白、监控和评价过程之间的相互作用,而这些过程均能促进策略性阅读。 \n",
            " \n",
            " \n",
            " \n",
            "Es cada vez mas comun que lectores intenten entender y aprender de fuentes de informacion del Internet. Esto demuestra el rol crucial que los procesos de evaluacion tienen en seleccionar y sacar sentido de la informacion recibida. En un estudio anterior, Wiley et al. (2009, Experiment 1) les pidieron a subgraduados que hicieran una busqueda en la red sobre volcanes usando multiples fuentes del Internet. Un resultado clave establecio una conexion clara entre los resultados del aprendizaje, la evaluacion de las fuentes, y la manera de leer. El presente estudio uso la metodologia del protocolo de pensar en voz alta para mejor entender los procesos usados por los aprendices al cumplir dicha tarea: se compararon 10 aprendices mejores con 11 aprendices pobres. Los resultados senalan que los mejores aprendices buscaban sus propias explicaciones que hicieran sentido y procesos de monitoreo de comprension en sitios confiables comparados con los sitios que no eran confiables, y lo hacian con un margen mayor que los aprendices pobres. Un estudio de casos de dos mejores y dos pobres aprendices ilustran aun mas como los procesos de evaluacion contribuian al proceso de navegacion. Los resultados sugieren que la comprension de multiples fuentes es un proceso dinamico que requiere interaccion entre los procesos de hacer sentido, monitoreo, y evaluacion, todos de los cuales promulgan la lectura estrategica. \n",
            " \n",
            " \n",
            " \n",
            "يحاول القراء بشكل متزايد الفهم والتعلم من مصادر المعلومات التي يجدونها على شبكة الإنترنيت؛ وبذلك فهذا يسلط الضوء على الدور الحاسم الذي تلعبه عمليات التقييم في اختيار وإعطاء معنى للمعلومات. وفي دراسة سابقة طلب “وايلي” وآخرون (التجربة١،٢٠٠٩) من الطلبة الجامعيين إجراء بحث على شبكة الإنترنيت حول البراكين مستخدمين مصادر إنترنيت متعددة.تم التوصل إلى نتيجة رئيسية تقوم على أن هناك صلة واضحة بين التعلم وتقييمات المصدر وسلوكيات القراءة. استخدمت الدراسة الحالية منهجية بروتوكول التفكيير بصوت عال لفهم بشكل أفضل العمليات التي استخدمها المتعلمون أثناء هذه المهمة: تمت مقارنة ١٠من أفضل المتعلمين ب١١من أضعف المتعلمين. تشير النتائج إلى أن أفضل المتعلمين استخدموا عمليات أكثر في إعطاء معنى للتفسير الذاتي ومراقبة الفهم على مواقع موثوق بها بالمقارنة مع مواقع غير موثوق بها وفعلوا ذلك أكثر من أضعف المتعلمين. كما أن أفضل المتعلمين قد قاموا بالبحث على أهدافهم عبر الإنترنيت بصورة مباشرة. وتوضح كذلك دراسة الحالة لأفضل متعلمين وأضعف متعلمين كيف ساهمت عمليات التقييم في قرارات البحث عبر الإنترنيت. تشير النتائج إلى أن فهم المصادر المتعددة عملية فعالة تشمل التفاعل المتبادل بين إعطاء المعنى والمراقبة وعملية التقييم، وكل منها تنمي القراءة الاستراتيجية. \n",
            " \n",
            " \n",
            " \n",
            "Читaющиe люди вce чaщe oбpaщaютcя к интepнeтy кaк к иcтoчникy инфopмaции. Oднaкo, для eeгpaмoтнoгo oтбopa ивocпpиятиякpaйнeвaжнo yмeть oцeнить эти иcтoчники. B paнee пpoвeдeнныx иccлeдoвaнияx (Wiley и дp., 2009, Экcпepимeнт 1) yчeныe пpeдлoжили cтyдeнтaм млaдшиx кypcoв пoиcкaть мaтepиaл o вyлкaнax пo paзличныминтepнeт-caйтaм. B итoгe выявилacь пpямaя cвязь мeждy peзyльтaтaми yчeбнoй дeятeльнocти, yмeниeм oцeнить иcтoчники и caмим пoвeдeниeм cтyдeнтoв-читaтeлeй. B нacтoящeмиccлeдoвaнии, чтoбы лyчшe пoнять, кaк пpoиcxoдит пpoцecc oцeнивaния, иcпoльзoвaлcя мeтoд “paзмышлeниe вcлyx”, и cpaвнивaлиcь paзмышлeния дecяти лyчшиx и дecяти нaибoлee cлaбыx yчaщиxcя. Peзyльтaты пoкaзывaют, чтo cильныe yчaщиecя знaчитeльнo чaщe paбoтaют c нaдeжными caйтaми, бoльшe зaнимaютcя aнaлизoм инфopмaции и кoнтpoлиpyют coбcтвeннoe ocмыcлeниe пpoчитaннoгo. Кpoмe тoгo, caм пpoцecc иx ceтeвoгo пoиcкa бoлee цeлeнaпpaвлeн, чeм дeятeльнocть cлaбыx yчaщиxcя. B кaчecтвe иллюcтpaции oпиcaн пpoцecc oцeнивaния иcтoчникoв и cooтвeтcтвyющaя eмy тpaeктopия пoиcкa для двyx cильныx и двyx cлaбыx yчaщиxcя. Aвтopы пoлaгaют, чтo вocпpиятиe инфopмaции из мнoжecтвa иcтoчникoв – динaмичный пpoцecc, кoтopый coчeтaeт в ceбe вoccoздaниe нoвыx для читaтeля cмыcлoв, a тaкжe мoнитopинг и oцeнивaниe пpoцeccoв пoзнaния, чтo в coвoкyпнocти paзвивaeт нaвыки cтpaтeгичecкoгo чтeния. \n",
            " \n",
            " \n",
            " \n",
            "Les lecteurs essaient de plus en plus de comprendre et d'apprendre au moyen de sources d'information qu'ils trouvent sur Internet. Cette pratique souligne le role crucial que jouent les processus d’evaluation lors de la selection de l'information et du sens qu'on lui donne. Dans une etude precedente, Wiley et al. (2009, premiere experience) ont demande a des etudiants de premier cycle d'effectuer sur la Toile une recherche sur les volcans en utilisant plusieurs sources d'Internet. Des liens sont apparus clairement entre les resultats obtenus, les evaluations des sources et les comportements de lecture. L’etude presentee ici a utilise la methodologie du protocole consistant a penser a haute voix pour mieux comprendre la facon de proceder des lecteurs lors de cette tâche, ceci avec 10 eleves de bon niveau contrastes a 11 eleves de niveau faible. Les resultats montrent que les meilleurs eleves s'engagent dans des processus d'auto-explication de recherche du sens et de pilotage de la comprehension sur des sites plus fiables que d'autres, et qu'ils procedent ainsi plus largement que les moins bons eleves. Les meilleurs eleves sont aussi plus engages dans une navigation avec but que les moins bons eleves. L’etude de cas de deux bons eleves et de deux faibles permettant de mieux illustrer encore comment les processus d’evaluation contribuent aux decisions de navigation. Les resultats suggerent que la comprehension de sources multiples est un processus dynamique qui implique des interactions entre l'attribution de sens, le pilotage, et les processus d’evaluation, tous ces elements contribuant a une lecture strategique.\n",
            "------------------------------------\n",
            "Title Training Very Deep Networks\n",
            "Author [{'authorId': '2100612', 'name': 'R. Srivastava'}, {'authorId': '3035541', 'name': 'Klaus Greff'}, {'authorId': '145341374', 'name': 'J. Schmidhuber'}]\n",
            "Venue NIPS\n",
            "year 2015\n",
            "Abstract Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.\n",
            "------------------------------------\n",
            "Title Image Quality Assessment Based on Gradient Similarity\n",
            "Author [{'authorId': '47773786', 'name': 'Anmin Liu'}, {'authorId': '144968898', 'name': 'Weisi Lin'}, {'authorId': '1758088', 'name': 'Manish Narwaria'}]\n",
            "Venue IEEE Transactions on Image Processing\n",
            "year 2012\n",
            "Abstract In this paper, we propose a new image quality assessment (IQA) scheme, with emphasis on gradient similarity. Gradients convey important visual information and are crucial to scene understanding. Using such information, structural and contrast changes can be effectively captured. Therefore, we use the gradient similarity to measure the change in contrast and structure in images. Apart from the structural/contrast changes, image quality is also affected by luminance changes, which must be also accounted for complete and more robust IQA. Hence, the proposed scheme considers both luminance and contrast-structural changes to effectively assess image quality. Furthermore, the proposed scheme is designed to follow the masking effect and visibility threshold more closely, i.e., the case when both masked and masking signals are small is more effectively tackled by the proposed scheme. Finally, the effects of the changes in luminance and contrast-structure are integrated via an adaptive method to obtain the overall image quality score. Extensive experiments conducted with six publicly available subject-rated databases (comprising of diverse images and distortion types) have confirmed the effectiveness, robustness, and efficiency of the proposed scheme in comparison with the relevant state-of-the-art schemes.\n",
            "------------------------------------\n",
            "Title Tri-Party Deep Network Representation\n",
            "Author [{'authorId': '2585415', 'name': 'Shirui Pan'}, {'authorId': '153171677', 'name': 'Jia Wu'}, {'authorId': '1694121', 'name': 'Xingquan Zhu'}, {'authorId': '48934799', 'name': 'Chengqi Zhang'}, {'authorId': '46396571', 'name': 'Yang Wang'}]\n",
            "Venue International Joint Conference on Artificial Intelligence\n",
            "year 2016\n",
            "Abstract Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title The New Ambiguity of 'Open Government'\n",
            "Author [{'authorId': '1788843', 'name': 'Harlan Yu'}, {'authorId': '1788843', 'name': 'Harlan Yu'}, {'authorId': '1788843', 'name': 'Harlan Yu'}, {'authorId': '144440321', 'name': 'D. G. Robinson'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract “Open government” used to carry a hard political edge: it referred to politically sensitive disclosures of government information. The phrase was first used in the 1950s, in the debates leading up to passage of the Freedom of Information Act. But over the last few years, that traditional meaning has blurred, and has shifted toward technology. Open technologies involve sharing data over the Internet, and all kinds of governments can use them, for all kinds of reasons. Recent public policies have stretched the label “open government” to reach any public sector use of these technologies. Thus, “open government data” might refer to data that makes the government as a whole more open (that is, more accountable to the public), but might equally well refer to politically neutral public sector disclosures that are easy to reuse, but that may have nothing to do with public accountability. Today a regime can call itself “open” if it builds the right kind of web site — even if it does not become more accountable. This shift in vocabulary makes it harder for policymakers and activists to articulate clear priorities and make cogent demands.This essay proposes a more useful way for participants on all sides to frame the debate: We separate the politics of open government from the technologies of open data. Technology can make public information more adaptable, empowering third parties to contribute in exciting new ways across many aspects of civic life. But technological enhancements will not resolve debates about the best priorities for civic life, and enhancements to government services are no substitute for public accountability.\n",
            "------------------------------------\n",
            "Title Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment\n",
            "Author [{'authorId': '3398079', 'name': 'K. Huckvale'}, {'authorId': '5007242', 'name': 'José Tomás Prieto'}, {'authorId': '49925676', 'name': 'M. Tilney'}, {'authorId': '15661982', 'name': 'Pierre Benghozi'}, {'authorId': '3007050', 'name': 'J. Car'}]\n",
            "Venue BMC Medicine\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Curated Flows: A Framework for Mapping Media Exposure in the Digital Age\n",
            "Author [{'authorId': '3197918', 'name': 'Kjerstin Thorson'}, {'authorId': '38681947', 'name': 'Chris Wells'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Advancing theory in media exposure and effects requires contending with an increasing level of complexity and contingency. Building on established theoretical concerns and the research possibilities enabled by large social datasets, we propose a framework for mapping information exposure of digitally situated individuals. We argue that from the perspective of an individual's personal communication network, comparable processes of “curation” are undertaken by a variety of actors—not only conventional newsmakers but also individual media users, social contacts, advertisers, and computer algorithms. Detecting the competition, intersection, and overlap of these flows is crucial to understanding media exposure and effects today. Our approach reframes research questions in debates such as polarization, selective and incidental exposure, participation, and conceptual orientations for computational approaches.\n",
            "------------------------------------\n",
            "Title Political News in the News Feed: Learning Politics from Social Media\n",
            "Author [{'authorId': '39052095', 'name': 'L. Bode'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Although literature about the relationship between social media and political behaviors has expanded in recent years, little is known about the roles of social media as a source of political information. To fill this gap, this article considers the question of whether and to what extent learning political information occurs via Facebook and Twitter. Theory suggests that social media may play a significant role in the learning of political information within the modern media environment. Making use of a combination of experimental and survey-based studies, the data suggest that the potential for users to learn political information from social media exists but is not always realized within the general population.\n",
            "------------------------------------\n",
            "Title Orthogonal Frequency Division Multiplexing With Index Modulation\n",
            "Author [{'authorId': '34685155', 'name': 'E. Başar'}, {'authorId': '1741408', 'name': 'Ü. Aygölü'}, {'authorId': '1748253', 'name': 'E. Panayirci'}, {'authorId': '145967056', 'name': 'H. Poor'}]\n",
            "Venue IEEE Transactions on Signal Processing\n",
            "year 2012\n",
            "Abstract In this paper, a novel orthogonal frequency division multiplexing (OFDM) scheme, called OFDM with index modulation (OFDM-IM), is proposed for operation over frequency-selective and rapidly time-varying fading channels. In this scheme, the information is conveyed not only by M-ary signal constellations as in classical OFDM, but also by the indices of the subcarriers, which are activated according to the incoming bit stream. Different low complexity transceiver structures based on maximum likelihood detection or log-likelihood ratio calculation are proposed and a theoretical error performance analysis is provided for the new scheme operating under ideal channel conditions. Then, the proposed scheme is adapted to realistic channel conditions such as imperfect channel state information and very high mobility cases by modifying the receiver structure. The approximate pairwise error probability of OFDM-IM is derived under channel estimation errors. For the mobility case, several interference unaware/aware detection methods are proposed for the new scheme. It is shown via computer simulations that the proposed scheme achieves significantly better error performance than classical OFDM due to the information bits carried by the indices of OFDM subcarriers under both ideal and realistic channel conditions.\n",
            "------------------------------------\n",
            "Title Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment\n",
            "Author [{'authorId': '3398079', 'name': 'K. Huckvale'}, {'authorId': '5007242', 'name': 'José Tomás Prieto'}, {'authorId': '49925676', 'name': 'M. Tilney'}, {'authorId': '15661982', 'name': 'Pierre Benghozi'}, {'authorId': '3007050', 'name': 'J. Car'}]\n",
            "Venue BMC Medicine\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title How Much Information?: Effects of Transparency on Trust in an Algorithmic Interface\n",
            "Author [{'authorId': '2633430', 'name': 'René F. Kizilcec'}]\n",
            "Venue International Conference on Human Factors in Computing Systems\n",
            "year 2016\n",
            "Abstract The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online field experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justification of perceived inconsistency. Designing for trust requires balanced interface transparency - not too little and not too much.\n",
            "------------------------------------\n",
            "Title Graph Convolutional Matrix Completion\n",
            "Author [{'authorId': '9965217', 'name': 'Rianne van den Berg'}, {'authorId': '41016725', 'name': 'Thomas Kipf'}, {'authorId': '1678311', 'name': 'M. Welling'}]\n",
            "Venue ArXiv\n",
            "year 2017\n",
            "Abstract We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title Tri-Party Deep Network Representation\n",
            "Author [{'authorId': '2585415', 'name': 'Shirui Pan'}, {'authorId': '153171677', 'name': 'Jia Wu'}, {'authorId': '1694121', 'name': 'Xingquan Zhu'}, {'authorId': '48934799', 'name': 'Chengqi Zhang'}, {'authorId': '46396571', 'name': 'Yang Wang'}]\n",
            "Venue International Joint Conference on Artificial Intelligence\n",
            "year 2016\n",
            "Abstract Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n",
            "------------------------------------\n",
            "Title Curated Flows: A Framework for Mapping Media Exposure in the Digital Age\n",
            "Author [{'authorId': '3197918', 'name': 'Kjerstin Thorson'}, {'authorId': '38681947', 'name': 'Chris Wells'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Advancing theory in media exposure and effects requires contending with an increasing level of complexity and contingency. Building on established theoretical concerns and the research possibilities enabled by large social datasets, we propose a framework for mapping information exposure of digitally situated individuals. We argue that from the perspective of an individual's personal communication network, comparable processes of “curation” are undertaken by a variety of actors—not only conventional newsmakers but also individual media users, social contacts, advertisers, and computer algorithms. Detecting the competition, intersection, and overlap of these flows is crucial to understanding media exposure and effects today. Our approach reframes research questions in debates such as polarization, selective and incidental exposure, participation, and conceptual orientations for computational approaches.\n",
            "------------------------------------\n",
            "Title Political News in the News Feed: Learning Politics from Social Media\n",
            "Author [{'authorId': '39052095', 'name': 'L. Bode'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Although literature about the relationship between social media and political behaviors has expanded in recent years, little is known about the roles of social media as a source of political information. To fill this gap, this article considers the question of whether and to what extent learning political information occurs via Facebook and Twitter. Theory suggests that social media may play a significant role in the learning of political information within the modern media environment. Making use of a combination of experimental and survey-based studies, the data suggest that the potential for users to learn political information from social media exists but is not always realized within the general population.\n",
            "------------------------------------\n",
            "Title WiFall: Device-free fall detection by wireless networks\n",
            "Author [{'authorId': '2115829921', 'name': 'Yuxi Wang'}, {'authorId': '8584850', 'name': 'Kaishun Wu'}, {'authorId': '1726587', 'name': 'L. Ni'}]\n",
            "Venue IEEE Conference on Computer Communications\n",
            "year 2017\n",
            "Abstract The world population is in the midst of a unique and irreversible process of aging. Fall, which is one of the major health threats and obstacles to independent living of elders, will aggravate the global pressure in elders' health care and injury rescue. Thus, automatic fall detection is highly in need. Current proposed fall detection systems either need hardware installation or disrupt people's daily life. These limitations make it hard to widely deploy fall detection systems in residential settings. In this work, we analyze the wireless signal propagation model considering human activities influence. We then propose a novel and truly unobtrusive detection method based on the advanced wireless technologies, which we call as WiFall. WiFall employs the time variability and special diversity of Channel State Information (CSI) as the indicator of human activities. As CSI is readily available in prevalent in-use wireless infrastructures, WiFall withdraws the need for hardware modification, environmental setup and worn or taken devices. We implement WiFall on laptops equipped with commercial 802.11n NICs. Two typical indoor scenarios and several layout schemes are examined. As demonstrated by the experimental results, WiFall yielded 87% detection precision with false alarm rate of 18% in average.\n",
            "------------------------------------\n",
            "Title A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior\n",
            "Author [{'authorId': '40511615', 'name': 'A. Casali'}, {'authorId': '2438197', 'name': 'O. Gosseries'}, {'authorId': '3210174', 'name': 'M. Rosanova'}, {'authorId': '2186036', 'name': 'M. Boly'}, {'authorId': '1694098', 'name': 'S. Sarasso'}, {'authorId': '4886398', 'name': 'K. Casali'}, {'authorId': '3294004', 'name': 'S. Casarotto'}, {'authorId': '5710310', 'name': 'M. Bruno'}, {'authorId': '32092273', 'name': 'Steven Laureys'}, {'authorId': '1726111', 'name': 'G. Tononi'}, {'authorId': '145621396', 'name': 'M. Massimini'}]\n",
            "Venue Science Translational Medicine\n",
            "year 2013\n",
            "Abstract A theory-derived index of consciousness, which quantifies the complexity of the brain’s response to a stimulus, measures the level of consciousness in awake, sleeping, anesthetized, and brain-damaged subjects. Quantifying the Unquantifiable Manipulation of consciousness is an everyday medical trick—think anesthesia—but physicians have only the crudest of tools to detect when a person is not aware. The usual question or physical stimulus does not always provide reliable reactions, and a more precise index is needed to avoid, for example, the conclusion that people who have locked-in syndrome (in which they are aware but cannot respond) are unconscious. Here, Casali et al. have extended their previous work on electrical correlates of consciousness to define an electroencephalographic-derived index of human consciousness [the perturbational complexity index (PCI)] that reflects the information content of the brain’s response to a magnetic stimulus. The PCI could allow tracking of consciousness in individual patients. The authors used data already collected from previous experiments, in which they had stimulated people’s brains with transcranial magnetic stimulation. By calculating the likely brain regional sources of the signals and then comparing the unique information in each, the authors derived PCI values. The values ranged from 0.44 to 0.67 in 32 awake healthy people, but fell to 0.18 to 0.28 during nonrapid eye movement (NREM) sleep. Then, to see whether a completely different way of inducing unconsciousness had the same effect on PCI, the authors assessed data from patients given various amounts of the anesthetics midazolam, xenon, and propofol. These agents too caused low “unconscious” values for the PCI: midazolam deep sedation, 0.23 to 0.31; propofol, 0.13 to 0.30; and xenon, 0.12 to 0.31. However, what about patients who suffer brain damage and who exhibit various levels of consciousness by conventional assessment methods? In these people, consciousness varies widely, as does the underlying damage from stroke or trauma. Here, too, the authors found promising results in those who had emerged from coma but were in a vegetative state or minimally conscious state, or exhibited locked-in syndrome. The PCI values from these patients clearly reflected the state of their consciousness, with the six patients in a vegetative state clearly unconscious (0.19 to 0.31), the two with locked-in syndrome clearly aware (0.51 to 0.62), and those in a minimally conscious state showing intermediate values (0.32 to 0.49). The validity of PCI for clinical application will need to be assessed in prospective trials, but it has the advantage of being derived from a simple noninvasive measurement. The new index reported by Casali et al. appears to be a robust measure that distinguishes conscious from unconscious states well enough to be used on an individual basis, a prerequisite for deployment in the clinic. One challenging aspect of the clinical assessment of brain-injured, unresponsive patients is the lack of an objective measure of consciousness that is independent of the subject’s ability to interact with the external environment. Theoretical considerations suggest that consciousness depends on the brain’s ability to support complex activity patterns that are, at once, distributed among interacting cortical areas (integrated) and differentiated in space and time (information-rich). We introduce and test a theory-driven index of the level of consciousness called the perturbational complexity index (PCI). PCI is calculated by (i) perturbing the cortex with transcranial magnetic stimulation (TMS) to engage distributed interactions in the brain (integration) and (ii) compressing the spatiotemporal pattern of these electrocortical responses to measure their algorithmic complexity (information). We test PCI on a large data set of TMS-evoked potentials recorded in healthy subjects during wakefulness, dreaming, nonrapid eye movement sleep, and different levels of sedation induced by anesthetic agents (midazolam, xenon, and propofol), as well as in patients who had emerged from coma (vegetative state, minimally conscious state, and locked-in syndrome). PCI reliably discriminated the level of consciousness in single individuals during wakefulness, sleep, and anesthesia, as well as in patients who had emerged from coma and recovered a minimal level of consciousness. PCI can potentially be used for objective determination of the level of consciousness at the bedside.\n",
            "------------------------------------\n",
            "Title The Ease of Language Understanding (ELU) model: theoretical, empirical, and clinical advances\n",
            "Author [{'authorId': '3349532', 'name': 'J. Rönnberg'}, {'authorId': '2651874', 'name': 'T. Lunner'}, {'authorId': '3472783', 'name': 'A. Zekveld'}, {'authorId': '2749726', 'name': 'Patrik Sörqvist'}, {'authorId': '2545000', 'name': 'H. Danielsson'}, {'authorId': '3329067', 'name': 'B. Lyxell'}, {'authorId': '1814670', 'name': 'Ö. Dahlström'}, {'authorId': '4737262', 'name': 'Carine Signoret'}, {'authorId': '1815968', 'name': 'S. Stenfelt'}, {'authorId': '1398616939', 'name': 'M. Pichora-Fuller'}, {'authorId': '2232849', 'name': 'M. Rudner'}]\n",
            "Venue Frontiers in Systems Neuroscience\n",
            "year 2013\n",
            "Abstract Working memory is important for online language processing during conversation. We use it to maintain relevant information, to inhibit or ignore irrelevant information, and to attend to conversation selectively. Working memory helps us to keep track of and actively participate in conversation, including taking turns and following the gist. This paper examines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg, 2003; Rönnberg et al., 2008) in light of new behavioral and neural findings concerning the role of working memory capacity (WMC) in uni-modal and bimodal language processing. The new ELU model is a meaning prediction system that depends on phonological and semantic interactions in rapid implicit and slower explicit processing mechanisms that both depend on WMC albeit in different ways. It is based on findings that address the relationship between WMC and (a) early attention processes in listening to speech, (b) signal processing in hearing aids and its effects on short-term memory, (c) inhibition of speech maskers and its effect on episodic long-term memory, (d) the effects of hearing impairment on episodic and semantic long-term memory, and finally, (e) listening effort. New predictions and clinical implications are outlined. Comparisons with other WMC and speech perception models are made.\n",
            "------------------------------------\n",
            "Title Photonic quantum information processing: a review\n",
            "Author [{'authorId': '50495245', 'name': 'F. Flamini'}, {'authorId': '35933774', 'name': 'N. Spagnolo'}, {'authorId': '102982226', 'name': 'F. Sciarrino'}]\n",
            "Venue Reports on progress in physics. Physical Society\n",
            "year 2018\n",
            "Abstract Photonic quantum technologies represent a promising platform for several applications, ranging from long-distance communications to the simulation of complex phenomena. Indeed, the advantages offered by single photons do make them the candidate of choice for carrying quantum information in a broad variety of areas with a versatile approach. Furthermore, recent technological advances are now enabling first concrete applications of photonic quantum information processing. The goal of this manuscript is to provide the reader with a comprehensive review of the state of the art in this active field, with a due balance between theoretical, experimental and technological results. When more convenient, we will present significant achievements in tables or in schematic figures, in order to convey a global perspective of the several horizons that fall under the name of photonic quantum information.\n",
            "------------------------------------\n",
            "Title Multimodal learning with deep Boltzmann machines\n",
            "Author [{'authorId': '2897313', 'name': 'Nitish Srivastava'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]\n",
            "Venue Journal of machine learning research\n",
            "year 2012\n",
            "Abstract Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.\n",
            "------------------------------------\n",
            "Title Dual-Function Radar-Communications: Information Embedding Using Sidelobe Control and Waveform Diversity\n",
            "Author [{'authorId': '1772878', 'name': 'A. Hassanien'}, {'authorId': '1742209', 'name': 'M. Amin'}, {'authorId': '2108440432', 'name': 'Yimin D. Zhang'}, {'authorId': '34978083', 'name': 'F. Ahmad'}]\n",
            "Venue IEEE Transactions on Signal Processing\n",
            "year 2016\n",
            "Abstract We develop a new technique for a dual-function system with joint radar and communication platforms. Sidelobe control of the transmit beamforming in tandem with waveform diversity enables communication links using the same pulse radar spectrum. Multiple simultaneously transmitted orthogonal waveforms are used for embedding a sequence of LB bits during each radar pulse. Two weight vectors are designed to achieve two transmit spatial power distribution patterns, which have the same main radar beam, but differ in sidelobe levels towards the intended communication receivers. The receiver interpretation of the bit is based on its radiated beam. The proposed technique allows information delivery to single or multiple communication directions outside the mainlobe of the radar. It is shown that the communication process is inherently secure against intercept from directions other than the pre-assigned communication directions. The employed waveform diversity scheme supports a multiple-input multiple-output radar operation mode. The performance of the proposed technique is investigated in terms of the bit error rate.\n",
            "------------------------------------\n",
            "Title Digital twin-driven product design, manufacturing and service with big data\n",
            "Author [{'authorId': '50556355', 'name': 'F. Tao'}, {'authorId': '49776606', 'name': 'Jiangfeng Cheng'}, {'authorId': '29011153', 'name': 'Qinglin Qi'}, {'authorId': '47474337', 'name': 'Meng Zhang'}, {'authorId': '2153527172', 'name': 'He Zhang'}, {'authorId': '50470670', 'name': 'Fangyuan Sui'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Psychological Frictions and the Incomplete Take-Up of Social Benefits: Evidence from an IRS Field Experiment\n",
            "Author [{'authorId': '2079458', 'name': 'Saurabh Bhargava'}, {'authorId': '3799782', 'name': 'Dayanand Manoli'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract We address the role of “psychological frictions” in the incomplete take-up of EITC benefits with an IRS field experiment. We specifically assess the influence of program confusion, informational complexity, and stigma by evaluating response to experimental mailings distributed to 35,050 tax filers who failed to claim $26 million despite an initial notice. While the mere receipt of the mailing, simplification, and the heightened salience of benefits led to substantial additional claiming, attempts to reduce perceived costs of stigma, application, and audits did not. The study, and accompanying surveys, suggests that low program awareness/understanding and informational complexity contribute to the puzzle of low take-up. (JEL C93, D03, H24, M38)\n",
            "------------------------------------\n",
            "Title Optimal Resource Allocation in Full-Duplex Wireless-Powered Communication Network\n",
            "Author [{'authorId': '1719623', 'name': 'Hyungsik Ju'}, {'authorId': '144142357', 'name': 'Rui Zhang'}]\n",
            "Venue IEEE Transactions on Communications\n",
            "year 2014\n",
            "Abstract This paper studies optimal resource allocation in the wireless-powered communication network (WPCN), where one hybrid access point (H-AP) operating in full duplex (FD) broadcasts wireless energy to a set of distributed users in the downlink (DL) and, at the same time, receives independent information from the users via time-division multiple access in the uplink (UL). We design an efficient protocol to support simultaneous wireless energy transfer (WET) in the DL and wireless information transmission (WIT) in the UL for the proposed FD-WPCN. We jointly optimize the time allocations to the H-AP for DL WET and different users for UL WIT and the transmit power allocations over time at the H-AP to maximize the users' weighted sum rate of UL information transmission with harvested energy. We consider both the cases with perfect and imperfect self-interference cancellation (SIC) at the H-AP, for which we obtain optimal and suboptimal time and power allocation solutions, respectively. Furthermore, we consider the half-duplex (HD) WPCN as a baseline scheme and derive its optimal resource allocation solution. Simulation results show that the FD-WPCN outperforms the HD-WPCN when effective SIC can be implemented and more stringent peak power constraint is applied at the H-AP.\n",
            "------------------------------------\n",
            "Title Competing spreading processes on multiplex networks: awareness and epidemics\n",
            "Author [{'authorId': '35559595', 'name': 'C. Granell'}, {'authorId': '144166503', 'name': 'S. Gómez'}, {'authorId': '116787621', 'name': 'A. Arenas'}]\n",
            "Venue Physical review. E, Statistical, nonlinear, and soft matter physics\n",
            "year 2014\n",
            "Abstract Epidemiclike spreading processes on top of multilayered interconnected complex networks reveal a rich phase diagram of intertwined competition effects. A recent study by the authors [C. Granell et al., Phys. Rev. Lett. 111, 128701 (2013).] presented an analysis of the interrelation between two processes accounting for the spreading of an epidemic, and the spreading of information awareness to prevent infection, on top of multiplex networks. The results in the case in which awareness implies total immunization to the disease revealed the existence of a metacritical point at which the critical onset of the epidemics starts, depending on completion of the awareness process. Here we present a full analysis of these critical properties in the more general scenario where the awareness spreading does not imply total immunization, and where infection does not imply immediate awareness of it. We find the critical relation between the two competing processes for a wide spectrum of parameters representing the interaction between them. We also analyze the consequences of a massive broadcast of awareness (mass media) on the final outcome of the epidemic incidence. Importantly enough, the mass media make the metacritical point disappear. The results reveal that the main finding, i.e., existence of a metacritical point, is rooted in the competition principle and holds for a large set of scenarios.\n",
            "------------------------------------\n",
            "Title Information Sharing and Financial Sector Development in Africa\n",
            "Author [{'authorId': '84569301', 'name': 'Vanessa S. Tchamyou'}, {'authorId': '5102164', 'name': 'S. Asongu'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract ABSTRACT This study investigates the effect information sharing has on financial sector development in 53 African countries for the period 2004 to 2011. Information sharing is measured with private credit bureaus and public credit registries. Hitherto unexplored dimensions of financial sector development are employed, namely: financial sector dynamics of formalization, informalization, and non-formalization. The empirical evidence is based on Ordinary Least Squares (OLS) and Generalized Method of Moments (GMM). The following findings are established. Information-sharing bureaus increase (reduce) formal (informal/non-formal) financial sector development. In order to ensure that information-sharing bureaus improve (decrease) formal (informal/non-formal) financial development, public credit registries should have between 45.45 and 50% coverage while private credit bureaus should have at least 26.25% coverage.\n",
            "------------------------------------\n",
            "Title Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\n",
            "Author [{'authorId': '3099139', 'name': 'Zuxuan Wu'}, {'authorId': '2108250445', 'name': 'Xi Wang'}, {'authorId': '1717861', 'name': 'Yu-Gang Jiang'}, {'authorId': '151486061', 'name': 'Hao Ye'}, {'authorId': '145905953', 'name': 'X. Xue'}]\n",
            "Venue ACM Multimedia\n",
            "year 2015\n",
            "Abstract Classifying videos according to content semantics is an important problem with a wide range of applications. In this paper, we propose a hybrid deep learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos. Specifically, the spatial and the short-term motion features are extracted separately by two Convolutional Neural Networks (CNN). These two types of CNN-based features are then combined in a regularized feature fusion network for classification, which is able to learn and utilize feature relationships for improved performance. In addition, Long Short Term Memory (LSTM) networks are applied on top of the two features to further model longer-term temporal clues. The main contribution of this work is the hybrid learning framework that can model several important aspects of the video data. We also show that (1) combining the spatial and the short-term motion features in the regularized fusion network is better than direct classification and fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is highly complementary to the traditional classification strategy without considering the temporal frame orders. Extensive experiments are conducted on two popular and challenging benchmarks, the UCF-101 Human Actions and the Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves very competitive performance: 91.3% on the UCF-101 and 83.5% on the CCV.\n",
            "------------------------------------\n",
            "Title Working Memory Underpins Cognitive Development, Learning, and Education\n",
            "Author [{'authorId': '144225308', 'name': 'N. Cowan'}]\n",
            "Venue Educational Psychology Review\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Mining big data: current status, and forecast to the future\n",
            "Author [{'authorId': '2113532503', 'name': 'Wei Fan'}, {'authorId': '1762931', 'name': 'A. Bifet'}]\n",
            "Venue SKDD\n",
            "year 2013\n",
            "Abstract Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.\n",
            "------------------------------------\n",
            "Title Literature review of Industry 4.0 and related technologies\n",
            "Author [{'authorId': '2930666', 'name': 'Ercan Öztemel'}, {'authorId': '78798560', 'name': 'S. Gursev'}]\n",
            "Venue Journal of Intelligent Manufacturing\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A Group Incremental Approach to Feature Selection Applying Rough Set Technique\n",
            "Author [{'authorId': '3300112', 'name': 'Jiye Liang'}, {'authorId': '2145756090', 'name': 'Feng Wang'}, {'authorId': '1721071', 'name': 'C. Dang'}, {'authorId': '1771193', 'name': 'Y. Qian'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2014\n",
            "Abstract Many real data increase dynamically in size. This phenomenon occurs in several fields including economics, population studies, and medical research. As an effective and efficient mechanism to deal with such data, incremental technique has been proposed in the literature and attracted much attention, which stimulates the result in this paper. When a group of objects are added to a decision table, we first introduce incremental mechanisms for three representative information entropies and then develop a group incremental rough feature selection algorithm based on information entropy. When multiple objects are added to a decision table, the algorithm aims to find the new feature subset in a much shorter time. Experiments have been carried out on eight UCI data sets and the experimental results show that the algorithm is effective and efficient.\n",
            "------------------------------------\n",
            "Title ClinVar: public archive of interpretations of clinically relevant variants\n",
            "Author [{'authorId': '3218124', 'name': 'M. Landrum'}, {'authorId': '2108441407', 'name': 'Jennifer M. Lee'}, {'authorId': '2057961586', 'name': 'M. Benson'}, {'authorId': '2148612924', 'name': 'Garth R. Brown'}, {'authorId': '41170163', 'name': 'Chen Chao'}, {'authorId': '2238195', 'name': 'S. Chitipiralla'}, {'authorId': '2052182323', 'name': 'Baoshan Gu'}, {'authorId': '144951362', 'name': 'Jennifer Hart'}, {'authorId': '146499947', 'name': 'Douglas Hoffman'}, {'authorId': '2065316669', 'name': 'Jeffrey Hoover'}, {'authorId': '50027016', 'name': 'W. Jang'}, {'authorId': '1997190', 'name': 'K. Katz'}, {'authorId': '3333288', 'name': 'M. Ovetsky'}, {'authorId': '35625261', 'name': 'George R. Riley'}, {'authorId': '153626744', 'name': 'Amanjeev Sethi'}, {'authorId': '36967624', 'name': 'R. E. Tully'}, {'authorId': '1405373084', 'name': 'Ricardo Villamarín-Salomón'}, {'authorId': '2862785', 'name': 'W. Rubinstein'}, {'authorId': '1758049', 'name': 'D. Maglott'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2015\n",
            "Abstract ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) at the National Center for Biotechnology Information (NCBI) is a freely available archive for interpretations of clinical significance of variants for reported conditions. The database includes germline and somatic variants of any size, type or genomic location. Interpretations are submitted by clinical testing laboratories, research laboratories, locus-specific databases, OMIM®, GeneReviews™, UniProt, expert panels and practice guidelines. In NCBI's Variation submission portal, submitters upload batch submissions or use the Submission Wizard for single submissions. Each submitted interpretation is assigned an accession number prefixed with SCV. ClinVar staff review validation reports with data types such as HGVS (Human Genome Variation Society) expressions; however, clinical significance is reported directly from submitters. Interpretations are aggregated by variant-condition combination and assigned an accession number prefixed with RCV. Clinical significance is calculated for the aggregate record, indicating consensus or conflict in the submitted interpretations. ClinVar uses data standards, such as HGVS nomenclature for variants and MedGen identifiers for conditions. The data are available on the web as variant-specific views; the entire data set can be downloaded via ftp. Programmatic access for ClinVar records is available through NCBI's E-utilities. Future development includes providing a variant-centric XML archive and a web page for details of SCV submissions.\n",
            "------------------------------------\n",
            "Title Measuring the impact of COVID-19 vaccine misinformation on vaccination intent in the UK and USA\n",
            "Author [{'authorId': '32560031', 'name': 'Sahil Loomba'}, {'authorId': '6496175', 'name': 'A. de Figueiredo'}, {'authorId': '2052181982', 'name': 'S. Piatek'}, {'authorId': '1381420852', 'name': 'K. de Graaf'}, {'authorId': '3369825', 'name': 'H. Larson'}]\n",
            "Venue Nature Human Behaviour\n",
            "year 2021\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title The Capacity of Private Information Retrieval\n",
            "Author [{'authorId': '143844138', 'name': 'Hua Sun'}, {'authorId': '145486824', 'name': 'S. Jafar'}]\n",
            "Venue Global Communications Conference\n",
            "year 2016\n",
            "Abstract In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N^2 + &#183; &#183; &#183; + 1/N({K&#8722;1})^{&#8722;1}. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.\n",
            "------------------------------------\n",
            "Title An Optimization of Allocation of Information Granularity in the Interpretation of Data Structures: Toward Granular Fuzzy Clustering\n",
            "Author [{'authorId': '1731634', 'name': 'W. Pedrycz'}, {'authorId': '2804290', 'name': 'A. Bargiela'}]\n",
            "Venue IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)\n",
            "year 2012\n",
            "Abstract Clustering forms one of the most visible conceptual and algorithmic framework of developing information granules. In spite of the algorithm being used, the representation of information granules-clusters is predominantly numeric (coming in the form of prototypes, partition matrices, dendrograms, etc.). In this paper, we consider a concept of granular prototypes that generalizes the numeric representation of the clusters and, in this way, helps capture more details about the data structure. By invoking the granulation-degranulation scheme, we design granular prototypes being reflective of the structure of data to a higher extent than the representation that is provided by their numeric counterparts (prototypes). The design is formulated as an optimization problem, which is guided by the coverage criterion, meaning that we maximize the number of data for which their granular realization includes the original data. The granularity of the prototypes themselves is treated as an important design asset; hence, its allocation to the individual prototypes is optimized so that the coverage criterion becomes maximized. With this regard, several schemes of optimal allocation of information granularity are investigated, where interval-valued prototypes are formed around the already produced numeric representatives. Experimental studies are provided in which the design of granular prototypes of interval format is discussed and characterized.\n",
            "------------------------------------\n",
            "Title A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula\n",
            "Author [{'authorId': '2054557', 'name': 'Robin A. A. Ince'}, {'authorId': '3248511', 'name': 'Bruno L. Giordano'}, {'authorId': '144679212', 'name': 'C. Kayser'}, {'authorId': '2532970', 'name': 'G. Rousselet'}, {'authorId': '37427902', 'name': 'J. Gross'}, {'authorId': '2287417', 'name': 'P. Schyns'}]\n",
            "Venue bioRxiv\n",
            "year 2016\n",
            "Abstract We begin by reviewing the statistical framework of information theory as applicable to neuroimaging data analysis. A major factor hindering wider adoption of this framework in neuroimaging is the difficulty of estimating information theoretic quantities in practice. We present a novel estimation technique that combines the statistical theory of copulas with the closed form solution for the entropy of Gaussian variables. This results in a general, computationally efficient, flexible, and robust multivariate statistical framework that provides effect sizes on a common meaningful scale, allows for unified treatment of discrete, continuous, uni-and multi-dimensional variables, and enables direct comparisons of representations from behavioral and brain responses across any recording modality. We validate the use of this estimate as a statistical test within a neuroimaging context, considering both discrete stimulus classes and continuous stimulus features. We also present examples of analyses facilitated by these developments, including application of multivariate analyses to MEG planar magnetic field gradients, and pairwise temporal interactions in evoked EEG responses. We show the benefit of considering the instantaneous temporal derivative together with the raw values of M/EEG signals as a multivariate response, how we can separately quantify modulations of amplitude and direction for vector quantities, and how we can measure the emergence of novel information over time in evoked responses. Open-source Matlab and Python code implementing the new methods accompanies this article. Highlights Novel estimator for mutual information and other information theoretic quantities Provides general, efficient, flexible and robust multivariate statistical framework Validated statistical performance on EEG and MEG data Applications to spectral power and phase, 2D magnetic field gradients, temporal derivatives Interaction information relates information content in different responses\n",
            "------------------------------------\n",
            "Title Giving too much social support: social overload on social networking sites\n",
            "Author [{'authorId': '1735380', 'name': 'C. Maier'}, {'authorId': '1734224', 'name': 'Sven Laumer'}, {'authorId': '143910850', 'name': 'Andreas Eckhardt'}, {'authorId': '1684996', 'name': 'Tim Weitzel'}]\n",
            "Venue European Journal of Information Systems\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Semantic trajectories modeling and analysis\n",
            "Author [{'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1694224', 'name': 'C. Renso'}, {'authorId': '50663909', 'name': 'G. Andrienko'}, {'authorId': '1780833', 'name': 'N. Andrienko'}, {'authorId': '1706154', 'name': 'V. Bogorny'}, {'authorId': '1824832', 'name': 'M. Damiani'}, {'authorId': '1400458662', 'name': 'A. Gkoulalas-Divanis'}, {'authorId': '145007156', 'name': 'J. Macêdo'}, {'authorId': '1807507', 'name': 'N. Pelekis'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '4013198', 'name': 'Zhixian Yan'}]\n",
            "Venue CSUR\n",
            "year 2013\n",
            "Abstract Focus on movement data has increased as a consequence of the larger availability of such data due to current GPS, GSM, RFID, and sensors techniques. In parallel, interest in movement has shifted from raw movement data analysis to more application-oriented ways of analyzing segments of movement suitable for the specific purposes of the application. This trend has promoted semantically rich trajectories, rather than raw movement, as the core object of interest in mobility studies. This survey provides the definitions of the basic concepts about mobility data, an analysis of the issues in mobility data management, and a survey of the approaches and techniques for: (i) constructing trajectories from movement tracks, (ii) enriching trajectories with semantic information to enable the desired interpretations of movements, and (iii) using data mining to analyze semantic trajectories and extract knowledge about their characteristics, in particular the behavioral patterns of the moving objects. Last but not least, the article surveys the new privacy issues that arise due to the semantic aspects of trajectories.\n",
            "------------------------------------\n",
            "Title Fused Matrix Factorization with Geographical and Social Influence in Location-Based Social Networks\n",
            "Author [{'authorId': '1801613', 'name': 'Chen-Kuang Cheng'}, {'authorId': '1702456', 'name': 'Haiqin Yang'}, {'authorId': '145310663', 'name': 'Irwin King'}, {'authorId': '1785083', 'name': 'Michael R. Lyu'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2012\n",
            "Abstract \n",
            " \n",
            " Recently, location-based social networks (LBSNs), such as Gowalla, Foursquare, Facebook, and Brightkite, etc., have attracted millions of users to share their social friendship and their locations via check-ins. The available check-in information makes it possible to mine users’ preference on locations and to provide favorite recommendations. Personalized Point-of-interest (POI) recommendation is a significant task in LBSNs since it can help targeted users explore their surroundings as well as help third-party developers to provide personalized services. To solve this task, matrix factorization is a promising tool due to its success in recommender systems. However, previously proposed matrix factorization (MF) methods do not explore geographical influence, e.g., multi-center check-in property, which yields suboptimal solutions for the recommendation. In this paper, to the best of our knowledge, we are the first to fuse MF with geographical and social influence for POI recommendation in LBSNs. We first capture the geographical influence via modeling the probability of a user’s check-in on a location as a Multi-center Gaussian Model (MGM). Next, we include social information and fuse the geographical influence into a generalized matrix factorization framework. Our solution to POI recommendation is efficient and scales linearly with the number of observations. Finally, we conduct thorough experiments on a large-scale real-world LBSNs dataset and demonstrate that the fused matrix factorization framework with MGM utilizes the distance information sufficiently and outperforms other state-of-the-art methods significantly.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title Interactive information complexity\n",
            "Author [{'authorId': '143803467', 'name': 'M. Braverman'}]\n",
            "Venue Symposium on the Theory of Computing\n",
            "year 2012\n",
            "Abstract The primary goal of this paper is to define and study the interactive information complexity of functions. Let f(x,y) be a function, and suppose Alice is given x and Bob is given y. Informally, the interactive information complexity IC(f) of f is the least amount of information Alice and Bob need to reveal to each other to compute f. Previously, information complexity has been defined with respect to a prior distribution on the input pairs (x,y). Our first goal is to give a definition that is independent of the prior distribution. We show that several possible definitions are essentially equivalent.\n",
            " We establish some basic properties of the interactive information complexity IC(f). In particular, we show that IC(f) is equal to the amortized (randomized) communication complexity of f. We also show a direct sum theorem for IC(f) and give the first general connection between information complexity and (non-amortized) communication complexity. This connection implies that a non-trivial exchange of information is required when solving problems that have non-trivial communication complexity.\n",
            " We explore the information complexity of two specific problems - Equality and Disjointness. We show that only a constant amount of information needs to be exchanged when solving Equality with no errors, while solving Disjointness with a constant error probability requires the parties to reveal a linear amount of information to each other.\n",
            "------------------------------------\n",
            "Title Empirical Studies in Information Visualization: Seven Scenarios\n",
            "Author [{'authorId': '8358143', 'name': 'Heidi Lam'}, {'authorId': '1519978914', 'name': 'E. Bertini'}, {'authorId': '1767660', 'name': 'P. Isenberg'}, {'authorId': '1764846', 'name': 'C. Plaisant'}, {'authorId': '144189259', 'name': 'M. Carpendale'}]\n",
            "Venue IEEE Transactions on Visualization and Computer Graphics\n",
            "year 2012\n",
            "Abstract We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.\n",
            "------------------------------------\n",
            "Title How to win in an Omnichannel world\n",
            "Author [{'authorId': '152466760', 'name': 'David R. Bell'}, {'authorId': '2192628', 'name': 'Santiago Gallino'}, {'authorId': '152142558', 'name': 'Antonio Moreno'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract The omnichannel environment presents new challenges and opportunities for both information and product fulfillment. While all retailers need to effectively and efficiently manage fulfillment and information provision, there are important nuances to how this happens, depending on where and how the retailer got started and what kinds of improvement create the most leverage. This article delivers a customer-focused framework showing how to win in the omni-channel environment through critical innovations in information delivery and product fulfillment. The framework emerged from our research with both traditional and nontraditional retailers. To thrive in the new environment, retailers of all stripes and origins need to deploy information and fulfillment strategies that reduce friction in every phase of the buying process. This means simultaneously providing, in a cost-effective and narrative-enhancing way\n",
            "------------------------------------\n",
            "Title Accounting information systems\n",
            "Author [{'authorId': '3220663', 'name': 'S. Altschuller'}, {'authorId': '2168984276', 'name': 'Shaya Altschuller'}]\n",
            "Venue The Routledge Companion to Risk, Crisis and Security in Business\n",
            "year 2018\n",
            "Abstract Accounting Information Systems Introduction The development of information technology impacts significantly on various fields and activities. The biggest impact can be seen in accounting practice. The changes are becoming more and more complex as there are shifts in business activities, such as in organization management, the concept of change management, and integration activities making closer ties among suppliers, customers and even competitors (Computing Curricula 2005, Information System).\n",
            "------------------------------------\n",
            "Title Social Media, Political Polarization, and Political Disinformation: A Review of the Scientific Literature\n",
            "Author [{'authorId': '49124793', 'name': 'Joshua A. Tucker'}, {'authorId': '67045794', 'name': 'A. Guess'}, {'authorId': '47206305', 'name': 'Pablo Barberá'}, {'authorId': '33295892', 'name': 'Cristian Vaccari'}, {'authorId': '145641729', 'name': 'A. Siegel'}, {'authorId': '31359858', 'name': 'Sergey Sanovich'}, {'authorId': '30886806', 'name': 'D. Stukal'}, {'authorId': '2064358', 'name': 'B. Nyhan'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract The following report is intended to provide an overview of the current state of the literature on the relationship between social media; political polarization; and political “disinformation,” a term used to encompass a wide range of types of information about politics found online, including “fake news,” rumors, deliberately factually incorrect information, inadvertently factually incorrect information, politically slanted information, and “hyperpartisan” news. The review of the literature is provided in six separate sections, each of which can be read individually but that cumulatively are intended to provide an overview of what is known—and unknown—about the relationship between social media, political polarization, and disinformation. The report concludes by identifying key gaps in our understanding of these phenomena and the data that are needed to address them.\n",
            "------------------------------------\n",
            "Title Unmet adolescent and young adult cancer survivors information and service needs: a population-based cancer registry study\n",
            "Author [{'authorId': '1930259', 'name': 'T. Keegan'}, {'authorId': '4418091', 'name': 'D. Lichtensztajn'}, {'authorId': '4507566', 'name': 'I. Kato'}, {'authorId': '5109912', 'name': 'E. Kent'}, {'authorId': '2154602619', 'name': 'Xiao-Cheng Wu'}, {'authorId': '2112757294', 'name': 'Michelle M. West'}, {'authorId': '144549856', 'name': 'A. Hamilton'}, {'authorId': '6612778', 'name': 'B. Zebrack'}, {'authorId': '5336882', 'name': 'K. Bellizzi'}, {'authorId': '152286513', 'name': 'Ashley Wilder Smith'}, {'authorId': '146079505', 'name': 'and the Uic Experiences of Care Project Group'}]\n",
            "Venue Journal of cancer survivorship\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks\n",
            "Author [{'authorId': '145357803', 'name': 'Jian Tang'}, {'authorId': '145252498', 'name': 'Meng Qu'}, {'authorId': '1743469', 'name': 'Q. Mei'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2015\n",
            "Abstract Unsupervised text embedding methods, such as Skip-gram and Paragraph Vector, have been attracting increasing attention due to their simplicity, scalability, and effectiveness. However, comparing to sophisticated deep learning architectures such as convolutional neural networks, these methods usually yield inferior results when applied to particular machine learning tasks. One possible reason is that these text embedding methods learn the representation of text in a fully unsupervised way, without leveraging the labeled information available for the task. Although the low dimensional representations learned are applicable to many different tasks, they are not particularly tuned for any task. In this paper, we fill this gap by proposing a semi-supervised representation learning method for text data, which we call the predictive text embedding (PTE). Predictive text embedding utilizes both labeled and unlabeled data to learn the embedding of text. The labeled information and different levels of word co-occurrence information are first represented as a large-scale heterogeneous text network, which is then embedded into a low dimensional space through a principled and efficient algorithm. This low dimensional embedding not only preserves the semantic closeness of words and documents, but also has a strong predictive power for the particular task. Compared to recent supervised approaches based on convolutional neural networks, predictive text embedding is comparable or more effective, much more efficient, and has fewer parameters to tune.\n",
            "------------------------------------\n",
            "Title \"Meaningful Information\" and the Right to Explanation\n",
            "Author [{'authorId': '46432110', 'name': 'Andrew D. Selbst'}, {'authorId': '35535043', 'name': 'Julia E. Powles'}]\n",
            "Venue FAT\n",
            "year 2017\n",
            "Abstract There is no single, neat statutory provision labeled the “right to explanation” in Europe’s new General Data Protection Regulation (GDPR). But nor is such a right illusory. \n",
            "Responding to two prominent papers that, in turn, conjure and critique the right to explanation in the context of automated decision-making, we advocate a return to the text of the GDPR. \n",
            "Articles 13-15 provide rights to “meaningful information about the logic involved” in automated decisions. This is a right to explanation, whether one uses the phrase or not. \n",
            "The right to explanation should be interpreted functionally, flexibly, and should, at a minimum, enable a data subject to exercise his or her rights under the GDPR and human rights law.\n",
            "------------------------------------\n",
            "Title Neural Evidence for a Distinction between Short-term Memory and the Focus of Attention\n",
            "Author [{'authorId': '1401833932', 'name': 'J. Lewis-Peacock'}, {'authorId': '16165769', 'name': 'A. Drysdale'}, {'authorId': '2128289', 'name': 'K. Oberauer'}, {'authorId': '2884176', 'name': 'B. Postle'}]\n",
            "Venue Journal of Cognitive Neuroscience\n",
            "year 2012\n",
            "Abstract It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.\n",
            "------------------------------------\n",
            "Title Is the privacy paradox a relic of the past? An in‐depth analysis of privacy attitudes and privacy behaviors\n",
            "Author [{'authorId': '3342561', 'name': 'T. Dienlin'}, {'authorId': '2706289', 'name': 'Sabine Trepte'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract The privacy paradox states that online privacy concerns do not sufficiently explain online privacy behaviors on social network sites (SNSs). In this study, it was first asked whether the privacy paradox would still exist when analyzed as in prior research. Second, it was hypothesized that the privacy paradox would disappear when analyzed in a new approach. The new approach featured a multidimensional operationalization of privacy by differentiating between informational, social, and psychological privacy. Next to privacy concerns, also, privacy attitudes and privacy intentions were analyzed. With the aim to improve methodological aspects, all items were designed on the basis of the theory of planned behavior. In an online questionnaire with N = 595 respondents, it was found that online privacy concerns were not significantly related to specific privacy behaviors, such as the frequency or content of disclosures on SNSs (e.g., name, cell-phone number, or religious views). This demonstrated that the privacy paradox still exists when it is operationalized as in prior research. With regard to the new approach, all hypotheses were confirmed: Results showed both a direct relation and an indirect relation between privacy attitudes and privacy behaviors, the latter mediated by privacy intentions. In addition, also an indirect relation between privacy concerns and privacy behaviors was found, mediated by privacy attitudes and privacy intentions. Therefore, privacy behaviors can be explained sufficiently when using privacy attitudes, privacy concerns, and privacy intentions within the theory of planned behavior. The behaviors of SNS users are not as paradoxical as was once believed. Copyright © 2014 John Wiley & Sons, Ltd.\n",
            "------------------------------------\n",
            "Title A Survey of Text Similarity Approaches\n",
            "Author [{'authorId': '1986886', 'name': 'W. H. Gomaa'}, {'authorId': '33838038', 'name': 'A. Fahmy'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract ABSTRACT Measuring the similarity between words, sentences, paragraphs and documents is an important component in various tasks such as information retrieval, document clustering, word-sense disambiguation, automatic essay scoring, short answer grading, machine translation and text summarization. This survey discusses the existing works on text similarity through partitioning them into three approaches; String-based, Corpus-based and Knowledge-based similarities. Furthermore, samples of combination between these similarities are presented. General Terms Text Mining, Natural Language Processing. Keywords BasedText Similarity, Semantic Similarity, String-Based Similarity, Corpus-Based Similarity, Knowledge-Based Similarity. NeedlemanWunsch 1. INTRODUCTION Text similarity measures play an increasingly important role in text related research and applications in tasks Nsuch as information retrieval, text classification, document clustering, topic detection, topic tracking, questions generation, question answering, essay scoring, short answer scoring, machine translation, text summarization and others. Finding similarity between words is a fundamental part of text similarity which is then used as a primary stage for sentence, paragraph and document similarities. Words can be similar in two ways lexically and semantically. Words are similar lexically if they have a similar character sequence. Words are similar semantically if they have the same thing, are opposite of each other, used in the same way, used in the same context and one is a type of another. DistanceLexical similarity is introduced in this survey though different String-Based algorithms, Semantic similarity is introduced through Corpus-Based and Knowledge-Based algorithms. String-Based measures operate on string sequences and character composition. A string metric is a metric that measures similarity or dissimilarity (distance) between two text strings for approximate string matching or comparison. Corpus-Based similarity is a semantic similarity measure that determines the similarity between words according to information gained from large corpora. Knowledge-Based similarity is a semantic similarity measure that determines the degree of similarity between words using information derived from semantic networks. The most popular for each type will be presented briefly. This paper is organized as follows: Section two presents String-Based algorithms by partitioning them into two types character-based and term-based measures. Sections three and four introduce Corpus-Based and knowledge-Based algorithms respectively. Samples of combinations between similarity algorithms are introduced in section five and finally section six presents conclusion of the survey.\n",
            "------------------------------------\n",
            "Title The Ethics of Information\n",
            "Author [{'authorId': '1982425', 'name': 'L. Floridi'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract PREFACE 1. ETHICS AFTER THE INFORMATION REVOLUTION 2. WHAT IS INFORMATION ETHICS? 3. THE METHOD OF ABSTRACTION 4. INFORMATION ETHICS AS E-NVIRONMENTAL ETHICS 5. INFORMATION ETHICS AND THE FOUNDATIONALIST DEBATE 6. THE INTRINSIC VALUE OF THE INFOSPHERE 7. THE MORALITY OF ARTIFICIAL AGENTS 8. THE CONSTRUCTIONIST VALUES OF HOMO POIETICUS 9. ARTIFICIAL EVIL 10. THE TRAGEDY OF THE GOOD WILL 11. THE INFORMATIONAL NATURE OF SELVES 12. THE ONTOLOGICAL INTERPRETATION OF INFORMATIONAL PRIVACY 13. DISTRIBUTED MORALITY 14. INFORMATION BUSINESS ETHICS 15. GLOBAL INFORMATION ETHICS 16. A DEFENCE OF INFORMATION ETHICS EPILOGUE REFERENCES INDEX\n",
            "------------------------------------\n",
            "Title AIDR: artificial intelligence for disaster response\n",
            "Author [{'authorId': '151491159', 'name': 'Muhammad Imran'}, {'authorId': '153191671', 'name': 'Carlos Castillo'}, {'authorId': '2081346', 'name': 'J. Lucas'}, {'authorId': '49317293', 'name': 'P. Meier'}, {'authorId': '3681090', 'name': 'Sarah Vieweg'}]\n",
            "Venue The Web Conference\n",
            "year 2014\n",
            "Abstract We present AIDR (Artificial Intelligence for Disaster Response), a platform designed to perform automatic classification of crisis-related microblog communications. AIDR enables humans and machines to work together to apply human intelligence to large-scale data at high speed. The objective of AIDR is to classify messages that people post during disasters into a set of user-defined categories of information (e.g., \"needs\", \"damage\", etc.) For this purpose, the system continuously ingests data from Twitter, processes it (i.e., using machine learning classification techniques) and leverages human-participation (through crowdsourcing) in real-time. AIDR has been successfully tested to classify informative vs. non-informative tweets posted during the 2013 Pakistan Earthquake. Overall, we achieved a classification quality (measured using AUC) of 80%. AIDR is available at http://aidr.qcri.org/.\n",
            "------------------------------------\n",
            "Title Big data: A review\n",
            "Author [{'authorId': '2686091', 'name': 'Ş. Sağiroğlu'}, {'authorId': '2570691', 'name': 'Duygu Sinanc'}]\n",
            "Venue International Conference on Collaboration Technologies and Systems\n",
            "year 2013\n",
            "Abstract Big data is a term for massive data sets having large, more varied and complex structure with the difficulties of storing, analyzing and visualizing for further processes or results. The process of research into massive amounts of data to reveal hidden patterns and secret correlations named as big data analytics. These useful informations for companies or organizations with the help of gaining richer and deeper insights and getting an advantage over the competition. For this reason, big data implementations need to be analyzed and executed as accurately as possible. This paper presents an overview of big data's content, scope, samples, methods, advantages and challenges and discusses privacy concern on it.\n",
            "------------------------------------\n",
            "Title Work and information processing in a solvable model of Maxwell’s demon\n",
            "Author [{'authorId': '47352014', 'name': 'D. Mandal'}, {'authorId': '145848757', 'name': 'C. Jarzynski'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2012\n",
            "Abstract We describe a minimal model of an autonomous Maxwell demon, a device that delivers work by rectifying thermal fluctuations while simultaneously writing information to a memory register. We solve exactly for the steady-state behavior of our model, and we construct its phase diagram. We find that our device can also act as a “Landauer eraser”, using externally supplied work to remove information from the memory register. By exposing an explicit, transparent mechanism of operation, our model offers a simple paradigm for investigating the thermodynamics of information processing by small systems.\n",
            "------------------------------------\n",
            "Title Scaling the Ion Trap Quantum Processor\n",
            "Author [{'authorId': '50856718', 'name': 'C. Monroe'}, {'authorId': '1924091', 'name': 'J. Kim'}]\n",
            "Venue Science\n",
            "year 2013\n",
            "Abstract Trapped atomic ions are standards for quantum information processing, serving as quantum memories, hosts of quantum gates in quantum computers and simulators, and nodes of quantum communication networks. Quantum bits based on trapped ions enjoy a rare combination of attributes: They have exquisite coherence properties, they can be prepared and measured with nearly 100% efficiency, and they are readily entangled with each other through the Coulomb interaction or remote photonic interconnects. The outstanding challenge is the scaling of trapped ions to hundreds or thousands of qubits and beyond, at which scale quantum processors can outperform their classical counterparts in certain applications. We review the latest progress and prospects in that effort, with the promise of advanced architectures and new technologies, such as microfabricated ion traps and integrated photonics.\n",
            "------------------------------------\n",
            "Title The Rise of the Network Society - The Information Age: Economy, Society, and Culture\n",
            "Author [{'authorId': '72218219', 'name': 'Taner Kizilhan'}, {'authorId': '1581541888', 'name': 'Sevil Bal Kızılhan'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Castell’s book is the first part of his milstone “The Information Age: Economy Society, and Culture” work. The author states that, the triology was prepared to be a single book, but then with the contributions of the editor, it was divided into three books by making each part of the study a separate book. In this particular book, Castells presents an easily understandable and comprehensive analysis by examining the economic, social, and cultural changes that caused by the Network Society. He does this by being as realistic as possible and reaching a clear conclusion by supporting all of his claims with various statistics and examples.\n",
            "------------------------------------\n",
            "Title Mobile devices in medicine: a survey of how medical students, residents, and faculty use smartphones and other mobile devices to find information.\n",
            "Author [{'authorId': '32431433', 'name': 'J. Boruff'}, {'authorId': '4868072', 'name': 'D. Storie'}]\n",
            "Venue Journal of the Medical Library Association\n",
            "year 2014\n",
            "Abstract OBJECTIVES\n",
            "The research investigated the extent to which students, residents, and faculty members in Canadian medical faculties use mobile devices, such as smartphones (e.g., iPhone, Android, Blackberry) and tablet computers (e.g., iPad), to answer clinical questions and find medical information. The results of this study will inform how health libraries can effectively support mobile technology and collections.\n",
            "\n",
            "\n",
            "METHODS\n",
            "An electronic survey was distributed by medical librarians at four Canadian universities to medical students, residents, and faculty members via departmental email discussion lists, personal contacts, and relevant websites. It investigated the types of information sought, facilitators to mobile device use in medical information seeking, barriers to access, support needs, familiarity with institutionally licensed resources, and most frequently used resources.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The survey of 1,210 respondents indicated widespread use of smartphones and tablets in clinical settings in 4 Canadian universities. Third- and fourth-year undergraduate students (i.e., those in their clinical clerkships) and medical residents, compared to other graduate students and faculty, used their mobile devices more often, used them for a broader range of activities, and purchased more resources for their devices.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Technological and intellectual barriers do not seem to prevent medical trainees and faculty from regularly using mobile devices for their medical information searches; however, barriers to access and lack of awareness might keep them from using reliable, library-licensed resources.\n",
            "\n",
            "\n",
            "IMPLICATIONS\n",
            "Libraries should focus on providing access to a smaller number of highly used mobile resources instead of a huge collection until library-licensed mobile resources have streamlined authentication processes.\n",
            "------------------------------------\n",
            "Title A survey of context data distribution for mobile ubiquitous systems\n",
            "Author [{'authorId': '1740127', 'name': 'P. Bellavista'}, {'authorId': '144765161', 'name': 'Antonio Corradi'}, {'authorId': '153564036', 'name': 'M. Fanelli'}, {'authorId': '1748978', 'name': 'L. Foschini'}]\n",
            "Venue CSUR\n",
            "year 2012\n",
            "Abstract The capacity to gather and timely deliver to the service level any relevant information that can characterize the service-provisioning environment, such as computing resources/capabilities, physical device location, user preferences, and time constraints, usually defined as context-awareness, is widely recognized as a core function for the development of modern ubiquitous and mobile systems. Much work has been done to enable context-awareness and to ease the diffusion of context-aware services; at the same time, several middleware solutions have been designed to transparently implement context management and provisioning in the mobile system. However, to the best of our knowledge, an in-depth analysis of the context data distribution, namely, the function in charge of distributing context data to interested entities, is still missing. Starting from the core assumption that only effective and efficient context data distribution can pave the way to the deployment of truly context-aware services, this article aims at putting together current research efforts to derive an original and holistic view of the existing literature. We present a unified architectural model and a new taxonomy for context data distribution by considering and comparing a large number of solutions. Finally, based on our analysis, we draw some of the research challenges still unsolved and identify some possible directions for future work.\n",
            "------------------------------------\n",
            "Title Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University From RSSI to CSI: Indoor localization via channel response From RSSI to CSI: Indoor localization via channel response\n",
            "Author [{'authorId': '2149231516', 'name': 'Zhengju Yang'}, {'authorId': '70184954', 'name': 'Zimu'}]\n",
            "Venue \n",
            "year 2020\n",
            "Abstract The spatial features of emitted wireless signals are the basis of location distinction and determination for wireless indoor localization. Available in mainstream wireless signal measurements, the Received Signal Strength Indicator (RSSI) has been adopted in vast indoor localization systems. However, it suffers from dramatic performance degradation in complex situations due to multipath fading and temporal dynamics. Break-through techniques resort to ﬁner-grained wireless channel measurement than RSSI. Different from RSSI, the PHY layer power feature, channel response, is able to discriminate multipath characteristics, and thus holds the potential for the convergence of accurate and pervasive indoor localization. Channel State Information (CSI, reﬂecting channel response in 802.11 a/g/n) has attracted many research efforts and some pioneer works have demonstrated submeter or even centimeter-level accuracy. In this article, we survey this new trend of channel response in localization. The differences between CSI and RSSI are highlighted with respect to network layering, time resolution, frequency resolution, stability, and accessibility. Furthermore, we investigate a large body of recent works and classify them overall into three categories according to how to use CSI. For each category, we emphasize the basic principles and address future directions of research in this new and largely open area.\n",
            "------------------------------------\n",
            "Title Extracting information from the text of electronic medical records to improve case detection: a systematic review\n",
            "Author [{'authorId': '144265063', 'name': 'E. Ford'}, {'authorId': '144708727', 'name': 'J. Carroll'}, {'authorId': '2110916717', 'name': 'Helen E. Smith'}, {'authorId': '145817168', 'name': 'D. Scott'}, {'authorId': '36629323', 'name': 'J. Cassell'}]\n",
            "Venue J. Am. Medical Informatics Assoc.\n",
            "year 2016\n",
            "Abstract Abstract Background Electronic medical records (EMRs) are revolutionizing health-related research. One key issue for study quality is the accurate identification of patients with the condition of interest. Information in EMRs can be entered as structured codes or unstructured free text. The majority of research studies have used only coded parts of EMRs for case-detection, which may bias findings, miss cases, and reduce study quality. This review examines whether incorporating information from text into case-detection algorithms can improve research quality. Methods A systematic search returned 9659 papers, 67 of which reported on the extraction of information from free text of EMRs with the stated purpose of detecting cases of a named clinical condition. Methods for extracting information from text and the technical accuracy of case-detection algorithms were reviewed. Results Studies mainly used US hospital-based EMRs, and extracted information from text for 41 conditions using keyword searches, rule-based algorithms, and machine learning methods. There was no clear difference in case-detection algorithm accuracy between rule-based and machine learning methods of extraction. Inclusion of information from text resulted in a significant improvement in algorithm sensitivity and area under the receiver operating characteristic in comparison to codes alone (median sensitivity 78% (codes + text) vs 62% (codes), P  = .03; median area under the receiver operating characteristic 95% (codes + text) vs 88% (codes), P  = .025). Conclusions Text in EMRs is accessible, especially with open source information extraction algorithms, and significantly improves case detection when combined with codes. More harmonization of reporting within EMR studies is needed, particularly standardized reporting of algorithm accuracy metrics like positive predictive value (precision) and sensitivity (recall).\n",
            "------------------------------------\n",
            "Title The longitudinal integrated database for health insurance and labour market studies (LISA) and its use in medical research\n",
            "Author [{'authorId': '144310215', 'name': 'J. Ludvigsson'}, {'authorId': '4255670', 'name': 'P. Svedberg'}, {'authorId': '3852176', 'name': 'O. Olén'}, {'authorId': '10442672', 'name': 'G. Bruze'}, {'authorId': '2918935', 'name': 'M. Neovius'}]\n",
            "Venue European Journal of Epidemiology\n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title On the joys of missing data.\n",
            "Author [{'authorId': '2462877', 'name': 'T. Little'}, {'authorId': '39273203', 'name': 'T. Jorgensen'}, {'authorId': '31846263', 'name': 'Kyle M Lang'}, {'authorId': '33074531', 'name': 'E. Moore'}]\n",
            "Venue Journal of Pediatric Psychology\n",
            "year 2014\n",
            "Abstract We provide conceptual introductions to missingness mechanisms--missing completely at random, missing at random, and missing not at random--and state-of-the-art methods of handling missing data--full-information maximum likelihood and multiple imputation--followed by a discussion of planned missing designs: Multiform questionnaire protocols, 2-method measurement models, and wave-missing longitudinal designs. We reviewed 80 articles of empirical studies published in the 2012 issues of the Journal of Pediatric Psychology to present a picture of how adequately missing data are currently handled in this field. To illustrate the benefits of using multiple imputation or full-information maximum likelihood and incorporating planned missingness into study designs, we provide example analyses of empirical data gathered using a 3-form planned missing design.\n",
            "------------------------------------\n",
            "Title What's in a hashtag?: content based prediction of the spread of ideas in microblogging communities\n",
            "Author [{'authorId': '1842598', 'name': 'Oren Tsur'}, {'authorId': '145009917', 'name': 'A. Rappoport'}]\n",
            "Venue Web Search and Data Mining\n",
            "year 2012\n",
            "Abstract Current social media research mainly focuses on temporal trends of the information flow and on the topology of the social graph that facilitates the propagation of information. In this paper we study the effect of the content of the idea on the information propagation. We present an efficient hybrid approach based on a linear regression for predicting the spread of an idea in a given time frame. We show that a combination of content features with temporal and topological features minimizes prediction error.\n",
            " Our algorithm is evaluated on Twitter hashtags extracted from a dataset of more than 400 million tweets. We analyze the contribution and the limitations of the various feature types to the spread of information, demonstrating that content aspects can be used as strong predictors thus should not be disregarded. We also study the dependencies between global features such as graph topology and content features.\n",
            "------------------------------------\n",
            "Title Direct and Mediated Associations among Earnings Quality, Information Asymmetry, and the Cost of Equity\n",
            "Author [{'authorId': '36204231', 'name': 'Nilabhra Bhattacharya'}, {'authorId': '2841782', 'name': 'Frank Ecker'}, {'authorId': '108133666', 'name': 'Per Olsson'}, {'authorId': '4605811', 'name': 'K. Schipper'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract ABSTRACT: Using path analysis, we investigate the direct and indirect links between three measures of earnings quality and the cost of equity. Our investigation is motivated by analytical models that specify both a direct link and an indirect link that is mediated by information asymmetry, but do not suggest which link would be more important empirically. We measure information asymmetry as both the adverse selection component of the bid-ask spread and the probability of informed trading (PIN). For a large sample of Value Line firms during 1993–2005, we find statistically reliable evidence of both a direct path from earnings quality to the cost of equity, and an indirect path that is mediated by information asymmetry, with the weight of the evidence favoring the direct path as the more important.\n",
            "------------------------------------\n",
            "Title The role of collaboration in supply chain resilience\n",
            "Author [{'authorId': '72039716', 'name': 'K. Scholten'}, {'authorId': '120834556', 'name': 'Sanne Schilder'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Purpose \n",
            " \n",
            " \n",
            " \n",
            "– This paper aims to explore how collaboration influences supply chain resilience. Collaborative activities and their underlying mechanisms in relation to visibility, velocity and flexibility are investigated. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            "– An exploratory case study consisting of eight buyer–supplier relationships in the food processing industry was conducted. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            "– Key findings show how specific collaborative activities (information-sharing, collaborative communication, mutually created knowledge and joint relationship efforts) increase supply chain resilience via increased visibility, velocity and flexibility. Underlying mechanisms and interdependencies of these factors within the supply chain network are identified. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            "– This is one of the first papers to provide in-depth insights into collaboration as a formative element of resilience in a supply chain setting. A series of propositions explain the specific influence of collaborative activities on supply chain resilience beyond a single company perspective.\n",
            "------------------------------------\n",
            "Title CSI-Based Indoor Localization\n",
            "Author [{'authorId': '8584850', 'name': 'Kaishun Wu'}, {'authorId': '145974115', 'name': 'Jiang Xiao'}, {'authorId': '2398386', 'name': 'Youwen Yi'}, {'authorId': '2547930', 'name': 'Dihu Chen'}, {'authorId': '144361019', 'name': 'Xiaonan Luo'}, {'authorId': '1726587', 'name': 'L. Ni'}]\n",
            "Venue IEEE Transactions on Parallel and Distributed Systems\n",
            "year 2013\n",
            "Abstract Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in orthogonal frequency division multiplexing systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to build a propagation model and a fingerprinting system at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.\n",
            "------------------------------------\n",
            "Title RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments\n",
            "Author [{'authorId': '1791800', 'name': 'Peter Henry'}, {'authorId': '2576619', 'name': 'Michael Krainin'}, {'authorId': '6376655', 'name': 'E. Herbst'}, {'authorId': '2114833718', 'name': 'Xiaofeng Ren'}, {'authorId': '145197953', 'name': 'D. Fox'}]\n",
            "Venue Int. J. Robotics Res.\n",
            "year 2012\n",
            "Abstract RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.\n",
            "------------------------------------\n",
            "Title Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths\n",
            "Author [{'authorId': '48615144', 'name': 'Yan Xu'}, {'authorId': '38956216', 'name': 'Lili Mou'}, {'authorId': '1410115257', 'name': 'Ge Li'}, {'authorId': '1691213', 'name': 'Yunchuan Chen'}, {'authorId': '1818378366', 'name': 'Hao Peng'}, {'authorId': '1700880', 'name': 'Zhi Jin'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2015\n",
            "Abstract Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an $F_1$-score of 83.7\\%, higher than competing methods in the literature.\n",
            "------------------------------------\n",
            "Title Multi-View Intact Space Learning\n",
            "Author [{'authorId': '145371957', 'name': 'Chang Xu'}, {'authorId': '143719920', 'name': 'D. Tao'}, {'authorId': '31796215', 'name': 'Chao Xu'}]\n",
            "Venue IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year 2015\n",
            "Abstract It is practical to assume that an individual view is unlikely to be sufficient for effective multi-view learning. Therefore, integration of multi-view information is both valuable and necessary. In this paper, we propose the Multi-view Intact Space Learning (MISL) algorithm, which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data. Even though each view on its own is insufficient, we show theoretically that by combing multiple views we can obtain abundant information for latent intact space learning. Employing the Cauchy loss (a technique used in statistical learning) as the error measurement strengthens robustness to outliers. We propose a new definition of multi-view stability and then derive the generalization error bound based on multi-view stability and Rademacher complexity, and show that the complementarity between multiple views is beneficial for the stability and generalization. MISL is efficiently optimized using a novel Iteratively Reweight Residuals (IRR) technique, whose convergence is theoretically analyzed. Experiments on synthetic data and real-world datasets demonstrate that MISL is an effective and promising algorithm for practical applications.\n",
            "------------------------------------\n",
            "Title Socio-Economic Impact of Mobile Phones on Indian Agriculture\n",
            "Author [{'authorId': '50847709', 'name': 'Surabhi Mittal'}, {'authorId': '2061331683', 'name': 'S. Gandhi'}, {'authorId': '46706195', 'name': 'G. Tripathi'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Deficits in physical infrastructure, problems with availability of agricultural inputs and poor access to agriculture-related information are the major constraints on the growth of agricultural productivity in India. The more rapid growth of mobile telephony as compared to fixed line telephony and the recent introduction of mobileenabled information services provide a means to overcome existing information asymmetry. It also helps, at least partially, to bridge the gap between the availability and delivery of agricultural inputs and agriculture infrastructure. This paper investigates a series of questions that explore this topic : What kind of information do farmers value the most to improve agricultural productivity? Do mobile phones and mobile-enabled agricultural services have an impact on agriculture? What are the factors that impede the realisation of the full productivity enhancing potential of mobile phones? The answers to these questions have important implications for mobile operators, for information service providers, and for policymakers. The quality of information, its timeliness and trustworthiness are the three important features that have to be ensured to enable farmers to use it effectively to improve productivity. The study found evidence that mobiles are being used in ways which contribute to productivity enhancement. However, to leverage the full potential of information dissemination enabled by mobile telephony will require significant improvements in supporting infrastructure and capacity building amongst farmers to enable them to use the information they access effectively. As mobile penetration continues to increase among farming communities and information services continue to adapt and proliferate, the scope exists for a much greater rural productivity impact in the future.\n",
            "------------------------------------\n",
            "Title Learning Character-level Representations for Part-of-Speech Tagging\n",
            "Author [{'authorId': '1790831', 'name': 'C. D. Santos'}, {'authorId': '1735228', 'name': 'B. Zadrozny'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2014\n",
            "Abstract Distributed word representations have recently been proven to be an invaluable resource for NLP. These representations are normally learned using neural networks and capture syntactic and semantic information about words. Information about word morphology and shape is normally ignored when learning word representations. However, for tasks like part-of-speech tagging, intra-word information is extremely useful, specially when dealing with morphologically rich languages. In this paper, we propose a deep neural network that learns character-level representation of words and associate them with usual word representations to perform POS tagging. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for two languages: English, with 97.32% accuracy on the Penn Treebank WSJ corpus; and Portuguese, with 97.47% accuracy on the Mac-Morpho corpus, where the latter represents an error reduction of 12.2% on the best previous known result.\n",
            "------------------------------------\n",
            "Title Smart Meter Privacy: A Theoretical Framework\n",
            "Author [{'authorId': '144711127', 'name': 'L. Sankar'}, {'authorId': '2054537548', 'name': 'S. Rajagopalan'}, {'authorId': '1729082', 'name': 'S. Mohajer'}, {'authorId': '145967056', 'name': 'H. Poor'}]\n",
            "Venue IEEE Transactions on Smart Grid\n",
            "year 2013\n",
            "Abstract The solutions offered to-date for end-user privacy in smart meter measurements, a well-known challenge in the smart grid, have been tied to specific technologies such as batteries or assumptions on data usage without quantifying the loss of benefit (utility) that results from any such approach. Using tools from information theory and a hidden Markov model for the measurements, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. For a stationary Gaussian model of the electricity load, it is shown that for a desired mean-square distortion (utility) measure between the measured and revealed data, the optimal privacy-preserving solution: i) exploits the presence of high-power but less private appliance spectra as implicit distortion noise, and ii) filters out frequency components with lower power relative to a distortion threshold; this approach encompasses many previously proposed approaches to smart meter privacy.\n",
            "------------------------------------\n",
            "Title The development of student feedback literacy: enabling uptake of feedback\n",
            "Author [{'authorId': '51458791', 'name': 'D. Carless'}, {'authorId': '3753458', 'name': 'D. Boud'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Abstract Student feedback literacy denotes the understandings, capacities and dispositions needed to make sense of information and use it to enhance work or learning strategies. In this conceptual paper, student responses to feedback are reviewed and a number of barriers to student uptake of feedback are discussed. Four inter-related features are proposed as a framework underpinning students’ feedback literacy: appreciating feedback; making judgments; managing affect; and taking action. Two well-established learning activities, peer feedback and analysing exemplars, are discussed to illustrate how this framework can be operationalized. Some ways in which these two enabling activities can be re-focused more explicitly towards developing students’ feedback literacy are elaborated. Teachers are identified as playing important facilitating roles in promoting student feedback literacy through curriculum design, guidance and coaching. The implications and conclusion summarise recommendations for teaching and set out an agenda for further research.\n",
            "------------------------------------\n",
            "Title What is consciousness, and could machines have it?\n",
            "Author [{'authorId': '1787332', 'name': 'S. Dehaene'}, {'authorId': '46873178', 'name': 'H. Lau'}, {'authorId': '1730493', 'name': 'S. Kouider'}]\n",
            "Venue Science\n",
            "year 2017\n",
            "Abstract The controversial question of whether machines may ever be conscious must be based on a careful consideration of how consciousness arises in the only physical system that undoubtedly possesses it: the human brain. We suggest that the word “consciousness” conflates two different types of information-processing computations in the brain: the selection of information for global broadcasting, thus making it flexibly available for computation and report (C1, consciousness in the first sense), and the self-monitoring of those computations, leading to a subjective sense of certainty or error (C2, consciousness in the second sense). We argue that despite their recent successes, current machines are still mostly implementing computations that reflect unconscious processing (C0) in the human brain. We review the psychological and neural science of unconscious (C0) and conscious computations (C1 and C2) and outline how they may inspire novel machine architectures.\n",
            "------------------------------------\n",
            "Title Motivations for sharing information and social support in social media: A comparative analysis of Facebook, Twitter, Delicious, YouTube, and Flickr\n",
            "Author [{'authorId': '34317493', 'name': 'Sanghee Oh'}, {'authorId': '2832844', 'name': 'Sue Yeon Syn'}]\n",
            "Venue J. Assoc. Inf. Sci. Technol.\n",
            "year 2015\n",
            "Abstract The success or failure of social media is highly dependent on the active participation of its users. In order to examine the influential factors that inspire dynamic and eager participation, this study investigates what motivates social media users to share their personal experiences, information, and social support with anonymous others. A variety of information‐sharing activities in social media, including creating postings, photos, and videos in 5 different types of social media: Facebook, Twitter, Delicious, YouTube, and Flickr, were observed. Ten factors: enjoyment, self‐efficacy, learning, personal gain, altruism, empathy, social engagement, community interest, reciprocity, and reputation, were tested to identify the motivations of social media users based on reviews of major motivation theories and models. Findings from this study indicate that all of the 10 motivations are influential in encouraging users' information sharing to some degree and strongly correlate with one another. At the same time, motivations differ across the 5 types of social media, given that they deliver different information content and serve different purposes. Understanding such differences in motivations could benefit social media developers and those organizations or institutes that would like to use social media to facilitate communication among their community members; appropriate types of social media could be chosen that would fit their own purposes and they could develop strategies that would encourage their members to contribute to their communities through social media.\n",
            "------------------------------------\n",
            "Title Multicriteria decision-making method using the correlation coefficient under single-valued neutrosophic environment\n",
            "Author [{'authorId': '144030861', 'name': 'Jun Ye'}]\n",
            "Venue International Journal of General Systems\n",
            "year 2013\n",
            "Abstract The paper presents the correlation and correlation coefficient of single-valued neutrosophic sets (SVNSs) based on the extension of the correlation of intuitionistic fuzzy sets and demonstrates that the cosine similarity measure is a special case of the correlation coefficient in SVNS. Then a decision-making method is proposed by the use of the weighted correlation coefficient or the weighted cosine similarity measure of SVNSs, in which the evaluation information for alternatives with respect to criteria is carried out by truth-membership degree, indeterminacy-membership degree, and falsity-membership degree under single-valued neutrosophic environment. We utilize the weighted correlation coefficient or the weighted cosine similarity measure between each alternative and the ideal alternative to rank the alternatives and to determine the best one(s). Finally, an illustrative example demonstrates the application of the proposed decision-making method.\n",
            "------------------------------------\n",
            "Title Characterizing nonclassical correlations via local quantum uncertainty.\n",
            "Author [{'authorId': '9830344', 'name': 'D. Girolami'}, {'authorId': '9875396', 'name': 'T. Tufarelli'}, {'authorId': '2922587', 'name': 'G. Adesso'}]\n",
            "Venue Physical Review Letters\n",
            "year 2012\n",
            "Abstract Quantum mechanics predicts that measurements of incompatible observables carry a minimum uncertainty which is independent of technical deficiencies of the measurement apparatus or incomplete knowledge of the state of the system. Nothing yet seems to prevent a single physical quantity, such as one spin component, from being measured with arbitrary precision. Here, we show that an intrinsic quantum uncertainty on a single observable is ineludible in a number of physical situations. When revealed on local observables of a bipartite system, such uncertainty defines an entire class of bona fide measures of nonclassical correlations. For the case of 2 × d systems, we find that a unique measure is defined, which we evaluate in closed form. We then discuss the role that these correlations, which are of the \"discord\" type, can play in the context of quantum metrology. We show in particular that the amount of discord present in a bipartite mixed probe state guarantees a minimum precision, as quantified by the quantum Fisher information, in the optimal phase estimation protocol.\n",
            "------------------------------------\n",
            "Title Data Resource Profile: The Korea National Health and Nutrition Examination Survey (KNHANES)\n",
            "Author [{'authorId': '49167491', 'name': 'Sanghui Kweon'}, {'authorId': '2119451582', 'name': 'Yuna Kim'}, {'authorId': '2055006895', 'name': 'Myoung-jin Jang'}, {'authorId': '2117904179', 'name': 'Yoonjung Kim'}, {'authorId': '4083485', 'name': 'Kirang Kim'}, {'authorId': '6410251', 'name': 'Sunhye Choi'}, {'authorId': '38740096', 'name': 'Chaemin Chun'}, {'authorId': '5181120', 'name': 'Y. Khang'}, {'authorId': '3958747', 'name': 'Kyungwon Oh'}]\n",
            "Venue International Journal of Epidemiology\n",
            "year 2014\n",
            "Abstract The Korea National Health and Nutrition Examination Survey (KNHANES) is a national surveillance system that has been assessing the health and nutritional status of Koreans since 1998. Based on the National Health Promotion Act, the surveys have been conducted by the Korea Centers for Disease Control and Prevention (KCDC). This nationally representative cross-sectional survey includes approximately 10 000 individuals each year as a survey sample and collects information on socioeconomic status, health-related behaviours, quality of life, healthcare utilization, anthropometric measures, biochemical and clinical profiles for non-communicable diseases and dietary intakes with three component surveys: health interview, health examination and nutrition survey. The health interview and health examination are conducted by trained staff members, including physicians, medical technicians and health interviewers, at a mobile examination centre, and dieticians’ visits to the homes of the study participants are followed up. KNHANES provides statistics for health-related policies in Korea, which also serve as the research infrastructure for studies on risk factors and diseases by supporting over 500 publications. KCDC has also supported researchers in Korea by providing annual workshops for data users. KCDC has published the Korea Health Statistics each year, and microdata are publicly available through the KNHANES website (http://knhanes.cdc.go.kr).\n",
            "------------------------------------\n",
            "Title Misleading Health-Related Information Promoted Through Video-Based Social Media: Anorexia on YouTube\n",
            "Author [{'authorId': '1395921809', 'name': 'S. Syed-Abdul'}, {'authorId': '81780580', 'name': 'L. Fernández-Luque'}, {'authorId': '2797875', 'name': 'W. Jian'}, {'authorId': '2142450296', 'name': 'Yu-chuan Li'}, {'authorId': '35184300', 'name': 'S. Crain'}, {'authorId': '144965653', 'name': 'M. Hsu'}, {'authorId': '2119049388', 'name': 'Yao-Chin Wang'}, {'authorId': '1414277011', 'name': 'Dorjsuren Khandregzen'}, {'authorId': '4901290', 'name': 'E. Chuluunbaatar'}, {'authorId': '145690858', 'name': 'P. Nguyen'}, {'authorId': '144049029', 'name': 'Der-Ming Liou'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2013\n",
            "Abstract Introduction The amount of information being uploaded onto social video platforms, such as YouTube, Vimeo, and Veoh, continues to spiral, making it increasingly difficult to discern reliable health information from misleading content. There are thousands of YouTube videos promoting misleading information about anorexia (eg, anorexia as a healthy lifestyle). Objective The aim of this study was to investigate anorexia-related misinformation disseminated through YouTube videos. Methods We retrieved YouTube videos related to anorexia using the keywords anorexia, anorexia nervosa, proana, and thinspo on October 10, 2011.Three doctors reviewed 140 videos with approximately 11 hours of video content, classifying them as informative, pro-anorexia, or others. By informative we mean content describing the health consequences of anorexia and advice on how to recover from it; by pro-anorexia we mean videos promoting anorexia as a fashion, a source of beauty, and that share tips and methods for becoming and remaining anorexic. The 40 most-viewed videos (20 informative and 20 pro-anorexia videos) were assessed to gauge viewer behavior. Results The interrater agreement of classification was moderate (Fleiss’ kappa=0.5), with 29.3% (n=41) being rated as pro-anorexia, 55.7% (n=78) as informative, and 15.0% (n=21) as others. Pro-anorexia videos were favored 3 times more than informative videos (odds ratio [OR] 3.3, 95% CI 3.3-3.4, P<.001). Conclusions Pro-anorexia information was identified in 29.3% of anorexia-related videos. Pro-anorexia videos are less common than informative videos; however, in proportional terms, pro-anorexia content is more highly favored and rated by its viewers. Efforts should focus on raising awareness, particularly among teenagers, about the trustworthiness of online information about beauty and healthy lifestyles. Health authorities producing videos to combat anorexia should consider involving celebrities and models to reach a wider audience. More research is needed to study the characteristics of pro-anorexia videos in order to develop algorithms that will automatically detect and filter those videos before they become popular.\n",
            "------------------------------------\n",
            "Title Hidden factors and hidden topics: understanding rating dimensions with review text\n",
            "Author [{'authorId': '35660011', 'name': 'Julian McAuley'}, {'authorId': '1702139', 'name': 'J. Leskovec'}]\n",
            "Venue ACM Conference on Recommender Systems\n",
            "year 2013\n",
            "Abstract In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.\n",
            "------------------------------------\n",
            "Title Knowledge Graph Convolutional Networks for Recommender Systems\n",
            "Author [{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2152527702', 'name': 'Miao Zhao'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '1697293', 'name': 'M. Guo'}]\n",
            "Venue The Web Conference\n",
            "year 2019\n",
            "Abstract To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.\n",
            "------------------------------------\n",
            "Title Accessibility of Cities in the Digital Economy\n",
            "Author [{'authorId': '3212218', 'name': 'E. Tranos'}, {'authorId': '2870796', 'name': 'A. Reggiani'}, {'authorId': '2965486', 'name': 'P. Nijkamp'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract This paper introduces a new measure to approach the accessibility of places in the frame of the digital economy. Information and Communication Technologies (ICTs) and the Internet are not equally spread around places and this heterogeneity affects spatial configuration. Despite the wide societal changes due to ICTs and the extensive interest in accessibility studies, these two themes have not yet come together in order to study the digital accessibility (DA) of places. Adopting an infrastructural perspective and a potential accessibility framework, a DA measure – embedding different types of impedance distance functions – is calculated for cities in Europe. Spatial Interaction Model and Complex Network Analysis are employed to calibrate and validate the DA results. The outcome of this approach is a new urban hierarchy which reveals a core-periphery pattern in Europe owing to digital accessibility.\n",
            "------------------------------------\n",
            "Title Service innovation in the digital age: key contributions and future directions\n",
            "Author [{'authorId': '2005307530', 'name': 'M. Barrett'}, {'authorId': '144875930', 'name': 'E. Davidson'}, {'authorId': '40191710', 'name': 'Jaideep Prabhu'}, {'authorId': '3321721', 'name': 'Stephen L. Vargo'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Over the last decade, there has been an increasing focus on service across socioeconomic sectors coupled with transformational developments in information and communication technologies (ICTs). Together these developments are engendering dramatic new opportunities for service innovation, the study of which is both timely and important. Fully understanding these opportunities challenges us to question conventional approaches that construe service as a distinctive form of socioeconomic exchange (i.e., as services) and to reconsider what service means and thus how service innovation may develop. The aim of this special issue, therefore, is to bring together some of the latest scholarship from the Marketing and Information Systems disciplines to advance theoretical developments on service innovation in a digital age.\n",
            "------------------------------------\n",
            "Title An Enhanced Fear Appeal Rhetorical Framework: Leveraging Threats to the Human Asset Through Sanctioning Rhetoric\n",
            "Author [{'authorId': '1831186', 'name': 'Allen C. Johnston'}, {'authorId': '2179829', 'name': 'Merrill Warkentin'}, {'authorId': '1796920', 'name': 'M. Siponen'}]\n",
            "Venue MIS Q.\n",
            "year 2015\n",
            "Abstract Fear appeals, which are used widely in information security campaigns, have become common tools in motivating individual compliance with information security policies and procedures. However, empirical assessments of the effectiveness of fear appeals have yielded mixed results, leading IS security scholars and practitioners to question the validity of the conventional fear appeal framework and the manner in which fear appeal behavioral modeling theories, such as protection motivation theory (PMT), have been applied to the study of information security phenomena. We contend that the conventional fear appeal rhetorical framework is inadequate when used in the context of information security threat warnings and that its primary behavioral modeling theory, PMT, has been misspecified in the extant information security research. Based on these arguments, we propose an enhanced fear appeal rhetorical framework that leverages sanctioning rhetoric as a secondary vector of threats to the human asset, thereby adding the dimension of personal relevance, which is critically absent from previous fear appeal frameworks and PMT-grounded security studies. Following a hypothetical scenario research approach involving the employees of a Finnish city government, we validate the efficacy of the enhanced fear appeal framework and determine that informal sanction rhetoric effectively enhances conventional fear appeals, thus providing a significant positive influence on compliance intentions.\n",
            "------------------------------------\n",
            "Title Flooding Facebook - the use of social media during the Queensland and Victorian floods\n",
            "Author [{'authorId': '113336707', 'name': 'Deanne Bird'}, {'authorId': '2072364564', 'name': 'Megan Ling'}, {'authorId': '144275962', 'name': 'K. Haynes'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Community-initiated Facebook groups emerged during the 2010/11 Queensland and Victorian floods, gaining a near instant following from local residents within, and family and friends beyond, the impacted areas. Administrators of the groups sourced their data from agencies such as the Bureau of Meteorology, State Emergency Service, Queensland and Victorian Police Departments, local councils and news media. Even more importantly, administrators published near-real time information from the general public: Facebook members posted information and questions; local residents asked for and received help and advice; and, travellers driving through the area posted and received up-to-date information on road closures and flooding. During the floods in Queensland and Victoria, Risk Frontiers used Facebook to distribute a survey to members of community groups such as CQ Flood Update-version 2 and Victorian Floods. The results indicate that most respondents began using the community groups on the floods to get information about their community and almost all found the medium useful and an effective means of communicating with family or friends. In this paper, we discuss the results of this survey and consider the value of social media to the emergency services, not only as a tool to disseminate information but also as an important resource to tap into and review informal communications, something that was previously inaccessible.\n",
            "------------------------------------\n",
            "Title Susceptibility to misinformation about COVID-19 around the world\n",
            "Author [{'authorId': '24028886', 'name': 'J. Roozenbeek'}, {'authorId': '30039996', 'name': 'C. Schneider'}, {'authorId': '103744236', 'name': 'S. Dryhurst'}, {'authorId': '2067765044', 'name': 'J. Kerr'}, {'authorId': '50456077', 'name': 'A. Freeman'}, {'authorId': '153511872', 'name': 'G. Recchia'}, {'authorId': '4118482', 'name': 'A. M. van der Bles'}, {'authorId': '35958880', 'name': 'S. van der Linden'}]\n",
            "Venue Royal Society Open Science\n",
            "year 2020\n",
            "Abstract Misinformation about COVID-19 is a major threat to public health. Using five national samples from the UK (n = 1050 and n = 1150), Ireland (n = 700), the USA (n = 700), Spain (n = 700) and Mexico (n = 700), we examine predictors of belief in the most common statements about the virus that contain misinformation. We also investigate the prevalence of belief in COVID-19 misinformation across different countries and the role of belief in such misinformation in predicting relevant health behaviours. We find that while public belief in misinformation about COVID-19 is not particularly common, a substantial proportion views this type of misinformation as highly reliable in each country surveyed. In addition, a small group of participants find common factual information about the virus highly unreliable. We also find that increased susceptibility to misinformation negatively affects people's self-reported compliance with public health guidance about COVID-19, as well as people's willingness to get vaccinated against the virus and to recommend the vaccine to vulnerable friends and family. Across all countries surveyed, we find that higher trust in scientists and having higher numeracy skills were associated with lower susceptibility to coronavirus-related misinformation. Taken together, these results demonstrate a clear link between susceptibility to misinformation and both vaccine hesitancy and a reduced likelihood to comply with health guidance measures, and suggest that interventions which aim to improve critical thinking and trust in science may be a promising avenue for future research.\n",
            "------------------------------------\n",
            "Title Mobile Health (mHealth) Approaches and Lessons for Increased Performance and Retention of Community Health Workers in Low- and Middle-Income Countries: A Review\n",
            "Author [{'authorId': '5085097', 'name': 'Karin Källander'}, {'authorId': '4670906', 'name': 'J. Tibenderana'}, {'authorId': '49136235', 'name': 'O. Akpogheneta'}, {'authorId': '49451580', 'name': 'D. Strachan'}, {'authorId': '6680020', 'name': 'Z. Hill'}, {'authorId': '116700742', 'name': 'A. T. ten Asbroek'}, {'authorId': '5049383', 'name': 'L. Conteh'}, {'authorId': '4691518', 'name': 'B. Kirkwood'}, {'authorId': '2809192', 'name': 'S. Meek'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2013\n",
            "Abstract Background Mobile health (mHealth) describes the use of portable electronic devices with software applications to provide health services and manage patient information. With approximately 5 billion mobile phone users globally, opportunities for mobile technologies to play a formal role in health services, particularly in low- and middle-income countries, are increasingly being recognized. mHealth can also support the performance of health care workers by the dissemination of clinical updates, learning materials, and reminders, particularly in underserved rural locations in low- and middle-income countries where community health workers deliver integrated community case management to children sick with diarrhea, pneumonia, and malaria. Objective Our aim was to conduct a thematic review of how mHealth projects have approached the intersection of cellular technology and public health in low- and middle-income countries and identify the promising practices and experiences learned, as well as novel and innovative approaches of how mHealth can support community health workers. Methods In this review, 6 themes of mHealth initiatives were examined using information from peer-reviewed journals, websites, and key reports. Primary mHealth technologies reviewed included mobile phones, personal digital assistants (PDAs) and smartphones, patient monitoring devices, and mobile telemedicine devices. We examined how these tools could be used for education and awareness, data access, and for strengthening health information systems. We also considered how mHealth may support patient monitoring, clinical decision making, and tracking of drugs and supplies. Lessons from mHealth trials and studies were summarized, focusing on low- and middle-income countries and community health workers. Results The review revealed that there are very few formal outcome evaluations of mHealth in low-income countries. Although there is vast documentation of project process evaluations, there are few studies demonstrating an impact on clinical outcomes. There is also a lack of mHealth applications and services operating at scale in low- and middle-income countries. The most commonly documented use of mHealth was 1-way text-message and phone reminders to encourage follow-up appointments, healthy behaviors, and data gathering. Innovative mHealth applications for community health workers include the use of mobile phones as job aides, clinical decision support tools, and for data submission and instant feedback on performance. Conclusions With partnerships forming between governments, technologists, non-governmental organizations, academia, and industry, there is great potential to improve health services delivery by using mHealth in low- and middle-income countries. As with many other health improvement projects, a key challenge is moving mHealth approaches from pilot projects to national scalable programs while properly engaging health workers and communities in the process. By harnessing the increasing presence of mobile phones among diverse populations, there is promising evidence to suggest that mHealth can be used to deliver increased and enhanced health care services to individuals and communities, while helping to strengthen health systems.\n",
            "------------------------------------\n",
            "Title The Impact of Electronic Patient Portals on Patient Care: A Systematic Review of Controlled Trials\n",
            "Author [{'authorId': '2756660', 'name': 'E. Ammenwerth'}, {'authorId': '1398028045', 'name': 'P. Schnell-Inderst'}, {'authorId': '1899309796', 'name': 'A. Hoerbst'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2012\n",
            "Abstract Background Modern information technology is changing and provides new challenges to health care. The emergence of the Internet and the electronic health record (EHR) has brought new opportunities for patients to play a more active role in his/her care. Although in many countries patients have the right to access their clinical information, access to clinical records electronically is not common. Patient portals consist of provider-tethered applications that allow patients to electronically access health information that are documented and managed by a health care institution. Although patient portals are already being implemented, it is still unclear in which ways these technologies can influence patient care. Objective To systematically review the available evidence on the impact of electronic patient portals on patient care. Methods A systematic search was conducted using PubMed and other sources to identify controlled experimental or quasi-experimental studies on the impact of patient portals that were published between 1990 and 2011. A total of 1,306 references from all the publication hits were screened, and 13 papers were retrieved for full text analysis. Results We identified 5 papers presenting 4 distinct studies. There were no statistically significant changes between intervention and control group in the 2 randomized controlled trials investigating the effect of patient portals on health outcomes. Significant changes in the patient portal group, compared to a control group, could be observed for the following parameters: quicker decrease in office visit rates and slower increase in telephone contacts; increase in number of messages sent; changes of the medication regimen; and better adherence to treatment. Conclusions The number of available controlled studies with regard to patient portals is low. Even when patient portals are often discussed as a way to empower patients and improve quality of care, there is insufficient evidence to support this assumption.\n",
            "------------------------------------\n",
            "Title Deep High-Resolution Representation Learning for Human Pose Estimation\n",
            "Author [{'authorId': '143819050', 'name': 'Ke Sun'}, {'authorId': '144025674', 'name': 'Bin Xiao'}, {'authorId': '1718355', 'name': 'Dong Liu'}, {'authorId': '1688516', 'name': 'Jingdong Wang'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2019\n",
            "Abstract In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.\n",
            "------------------------------------\n",
            "Title A comparative analysis of international frameworks for 21st century competences: Implications for national curriculum policies\n",
            "Author [{'authorId': '144737149', 'name': 'J. Voogt'}, {'authorId': '1922607', 'name': 'N. P. Roblin'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract National curricula need to change drastically to comply with the competences needed for the 21st century. In this paper eight frameworks describing 21st century competences were analysed. A comprehensive search for information about 21st century competences was conducted across the official websites of the selected frameworks, resulting in 32 documents that were analysed in detail. Travers and Westbury’s framework of curriculum representations was used to determine horizontal and vertical consistency between the frameworks. The frameworks were compared on their underlying rationales and goals, their definition of 21st century competences, and the recommended strategies for the implementation and assessment of these skills in educational practice. In addition three international studies were examined to analyse how various countries (EU member states, OECD countries) and schools (SITES studies) deal (or not) with 21st century competences. The findings indicate a large extent of alignment between the frameworks about what 21st century competences are and why they are important (horizontal consistency), but intentions and practice seemed still far apart, indicating lack of vertical consistency. The implications of the implementation of 21st century competences in national curriculum policies are discussed and recommendations are provided.\n",
            "------------------------------------\n",
            "Title The Impact of Relative Standards on the Propensity to Disclose\n",
            "Author [{'authorId': '1683053', 'name': 'A. Acquisti'}, {'authorId': '39350003', 'name': 'L. John'}, {'authorId': '3070352', 'name': 'G. Loewenstein'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Two sets of studies illustrate the comparative nature of disclosure behavior. The first set investigates how divulgence is affected by signals about others' readiness to divulge and shows a “herding” effect: Survey respondents are more willing to divulge sensitive information when told that previous respondents have made sensitive disclosures (Study 1a). The authors provide evidence of the process underlying this effect and rule out alternative explanations by showing that information on others' propensity to disclose affects respondents' discomfort associated with divulgence (Study 1b) but not their interpretation of the questions (Study 1c). The second set of studies investigates how divulgence is affected by the order in which inquiries of varying intrusiveness are made and suggests that divulgence is anchored by the initial questions in a survey. People are particularly likely to divulge when questions are presented in decreasing order of intrusiveness and less likely when questions are presented in increasing order (Study 2a). The authors show that the effect arises by affecting people's judgments of the intrusiveness of the inquiries (Study 2b). The effect is altered when, at the outset of the study, privacy concerns are primed (Study 2c) and when respondents are made to consider the relative intrusiveness of a different set of questions (Study 2d). This research helps illuminate how consumers' propensity to disclose is affected by continual streams of requests for personal information and by the equally unavoidable barrage of personal information about others.\n",
            "------------------------------------\n",
            "Title Systematic Review of Factors Influencing the Adoption of Information and Communication Technologies by Healthcare Professionals\n",
            "Author [{'authorId': '49978166', 'name': 'M. Gagnon'}, {'authorId': '1897320', 'name': 'M. Desmartis'}, {'authorId': '52190951', 'name': 'M. Labrecque'}, {'authorId': '3007050', 'name': 'J. Car'}, {'authorId': '2938133', 'name': 'C. Pagliari'}, {'authorId': '1871259', 'name': 'P. Pluye'}, {'authorId': '2614188', 'name': 'P. Frémont'}, {'authorId': '36415502', 'name': 'J. Gagnon'}, {'authorId': '2065701140', 'name': 'Nadine Tremblay'}, {'authorId': '4361330', 'name': 'F. Légaré'}]\n",
            "Venue Journal of medical systems\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Promoting transparency and accountability through ICTs, social media, and collaborative e‐government\n",
            "Author [{'authorId': '3005122', 'name': 'J. Bertot'}, {'authorId': '143762896', 'name': 'P. Jaeger'}, {'authorId': '25943188', 'name': 'J. Grimes'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Purpose – The purpose of this paper is to examine the ways in which governments build social media and information and communication technologies (ICTs) into e‐government transparency initiatives, to promote collaboration with members of the public and the ways in members of the public are able to employ the same social media to monitor government activities.Design/methodology/approach – This study used an iterative strategy that involved conducting a literature review, content analysis, and web site analysis, offering multiple perspectives on government transparency efforts, the role of ICTs and social media in these efforts, and the ability of e‐government initiatives to foster collaborative transparency through embedded ICTs and social media.Findings – The paper identifies key initiatives, potential impacts, and future challenges for collaborative e‐government as a means of transparency.Originality/value – The paper is one of the first to examine the interrelationships between ICTs, social media, and c...\n",
            "------------------------------------\n",
            "Title Nonprice incentives and energy conservation\n",
            "Author [{'authorId': '12928935', 'name': 'O. Asensio'}, {'authorId': '48015350', 'name': 'M. Delmas'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2015\n",
            "Abstract Significance We investigate the effectiveness of nonprice incentives to motivate conservation behavior. We test whether tailored information about environmental and health damages produces behavior change in the residential electricity sector. In a randomized controlled trial with real-time appliance-level energy metering over 8 mo, we find that environment and health-based information strategies outperform monetary savings information to drive energy conservation. Environment and health-based messages, which communicate the environmental and public health externalities of electricity production—such as pounds of pollutants, childhood asthma, and cancer—motivated 8% energy savings versus control. This strategy was particularly effective on families with children, who achieved 19% energy savings. However, we do not study the persistence of these behavioral changes after the conclusion of the study. In the electricity sector, energy conservation through technological and behavioral change is estimated to have a savings potential of 123 million metric tons of carbon per year, which represents 20% of US household direct emissions in the United States. In this article, we investigate the effectiveness of nonprice information strategies to motivate conservation behavior. We introduce environment and health-based messaging as a behavioral strategy to reduce energy use in the home and promote energy conservation. In a randomized controlled trial with real-time appliance-level energy metering, we find that environment and health-based information strategies, which communicate the environmental and public health externalities of electricity production, such as pounds of pollutants, childhood asthma, and cancer, outperform monetary savings information to drive behavioral change in the home. Environment and health-based information treatments motivated 8% energy savings versus control and were particularly effective on families with children, who achieved up to 19% energy savings. Our results are based on a panel of 3.4 million hourly appliance-level kilowatt–hour observations for 118 residences over 8 mo. We discuss the relative impacts of both cost-savings information and environmental health messaging strategies with residential consumers.\n",
            "------------------------------------\n",
            "Title Correlates of Health-Related Social Media Use Among Adults\n",
            "Author [{'authorId': '2006675', 'name': 'R. Thackeray'}, {'authorId': '6585390', 'name': 'B. Crookston'}, {'authorId': '3864835', 'name': 'J. West'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2013\n",
            "Abstract Background Sixty percent of Internet users report using the Internet to look for health information. Social media sites are emerging as a potential source for online health information. However, little is known about how people use social media for such purposes. Objectives The purpose of this study was two-fold: (1) to establish the frequency of various types of online health-seeking behaviors, and (2) to identify correlates of 2 health-related online activities, social networking sites (SNS) for health-related activities and consulting online user-generated content for answers about health care providers, health facilities, or medical treatment. Methods The study consisted of a telephone survey of 1745 adults who reported going online to look for health-related information. Four subscales were created to measure use of online resources for (1) using SNS for health-related activities; (2) consulting online rankings and reviews of doctors, hospitals or medical facilities, and drugs or medical treatments; (3) posting a review online of doctors, hospitals or medical facilities, and drugs or medical treatments, and (4) posting a comment or question about health or medical issues on various social media. Univariate and multivariate logistic regression analyses were performed. Results Respondents consulted online rankings or reviews (41.15%), used SNS for health (31.58%), posted reviews (9.91%), and posted a comment, question, or information (15.19%). Respondents with a chronic disease were nearly twice as likely to consult online rankings (odds ratio [OR] 2.09, 95% CI 1.66-2.63, P<.001). Lower odds of consulting online reviews were associated with less formal education (OR 0.49, 95% CI 0.37-0.65, P<.001) and being male (OR 0.71, 95% CI 0.57-0.87, P<.001). Respondents with higher incomes were 1.5 times as likely to consult online rankings or reviews (OR 1.49, 95% CI 0.10-2.24, P=.05), than respondents with a regular provider (OR 2.05, 95% CI 1.52-2.78, P<.001), or living in an urban/suburban location (OR 1.61, 95% CI 1.17-2.22, P<.001). Older respondents were less likely to use SNS for health-related activities (OR 0.96, 95% CI 0.95-0.97, P<.001), as were males (OR 0.70, 95% CI 0.56-0.87, P<.001), whereas respondents with a regular provider had nearly twice the likelihood of using SNS for health-related activities (OR 1.89, 95% CI 1.43-2.52, P<.001). Conclusions People are using social media for seeking health information. However, individuals are more likely to consume information than they are to contribute to the dialog. The inherent value of “social” in social media is not being captured with online health information seeking. People with a regular health care provider, chronic disease, and those in younger age groups are more likely to consult online rankings and reviews and use SNS for health-related activities.\n",
            "------------------------------------\n",
            "Title End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures\n",
            "Author [{'authorId': '1731657', 'name': 'Makoto Miwa'}, {'authorId': '143977268', 'name': 'Mohit Bansal'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2016\n",
            "Abstract We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components.\n",
            "------------------------------------\n",
            "Title Use of the Internet as a Health Information Resource Among French Young Adults: Results From a Nationally Representative Survey\n",
            "Author [{'authorId': '143826172', 'name': 'F. Beck'}, {'authorId': '37376572', 'name': 'J. Richard'}, {'authorId': '1403560051', 'name': 'V. Nguyen-Thanh'}, {'authorId': '3415034', 'name': 'I. Montagni'}, {'authorId': '2071310828', 'name': 'I. Parizot'}, {'authorId': '3936412', 'name': 'E. Renahy'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2014\n",
            "Abstract Background The Internet is one of the main resources of health information especially for young adults, but website content is not always trustworthy or validated. Little is known about this specific population and the importance of online health searches for use and impact. It is fundamental to assess behaviors and attitudes of young people looking for online health-related information and their level of trust in such information. Objective The objective is to describe the characteristics of Internet users aged 15-30 years who use the Web as a health information resource and their trust in it, and to define the context and the effect of such use on French young adults’ behavior in relation to their medical consultations. Methods We used the French Health Barometer 2010, a nationally representative survey of 27,653 individuals that investigates population health behaviors and concerns. Multivariate logistic regressions were performed using a subsample of 1052 young adults aged 15-30 years to estimate associations between demographics, socioeconomic, and health status and (1) the use of the Internet to search for health information, and (2) its impact on health behaviors and the physician-patient relationship. Results In 2010, 48.5% (474/977) of Web users aged 15-30 years used the Internet for health purposes. Those who did not use the Internet for health purposes reported being informed enough by other sources (75.0%, 377/503), stated they preferred seeing a doctor (74.1%, 373/503) or did not trust the information on the Internet (67.2%, 338/503). However, approximately 80% (371/474) of young online health seekers considered the information found online reliable. Women (P<.001) and people with higher sociocultural positions (OR 0.5, 95% CI 0.3-0.9 and OR 0.4, 95% CI 0.2-0.7 for employees and manual workers, respectively, vs individuals with executive or manager positions) were more likely to use the Internet for health purposes. For a subsample of women only, online health seeking was more likely among those having a child (OR 1.8, 95% CI 1.1-2.7) and experiencing psychological distress (OR 2.0, 95% CI 1.0-4.0). Finally, for online health seekers aged 15-30 years, one-third (33.3%, 157/474) reported they changed their health behaviors (eg, frequency of medical consultations, way of taking care of one’s own health) because of their online searches. Different factors were associated with different outcomes of change, but psychological distress, poor quality of life, and low income were the most common. Conclusions The Internet is a useful tool to spread health information and prevention campaigns, especially to target young adults. Young adults trust online information and consider the Internet as a valid source of health advice. Health agencies should ensure the improvement of online health information quality and the creation of health-related websites and programs dedicated to young adults.\n",
            "------------------------------------\n",
            "Title DKN: Deep Knowledge-Aware Network for News Recommendation\n",
            "Author [{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2642200', 'name': 'Fuzheng Zhang'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '1697293', 'name': 'M. Guo'}]\n",
            "Venue The Web Conference\n",
            "year 2018\n",
            "Abstract Online news recommender systems aim to address the information explosion of news and make personalized recommendation for users. In general, news language is highly condensed, full of knowledge entities and common sense. However, existing methods are unaware of such external knowledge and cannot fully discover latent knowledge-level connections among news. The recommended results for a user are consequently limited to simple patterns and cannot be extended reasonably. To solve the above problem, in this paper, we propose a deep knowledge-aware network (DKN) that incorporates knowledge graph representation into news recommendation. DKN is a content-based deep recommendation framework for click-through rate prediction. The key component of DKN is a multi-channel and word-entity-aligned knowledge-aware convolutional neural network (KCNN) that fuses semantic-level and knowledge-level representations of news. KCNN treats words and entities as multiple channels, and explicitly keeps their alignment relationship during convolution. In addition, to address users» diverse interests, we also design an attention module in DKN to dynamically aggregate a user»s history with respect to current candidate news. Through extensive experiments on a real online news platform, we demonstrate that DKN achieves substantial gains over state-of-the-art deep recommendation models. We also validate the efficacy of the usage of knowledge in DKN.\n",
            "------------------------------------\n",
            "Title Understanding the Factors That Influence the Adoption and Meaningful Use of Social Media by Physicians to Share Medical Information\n",
            "Author [{'authorId': '2060622571', 'name': 'B. Mcgowan'}, {'authorId': '38938099', 'name': 'M. Wasko'}, {'authorId': '6035263', 'name': 'B. Vartabedian'}, {'authorId': '1400120490', 'name': 'Robert S. Miller'}, {'authorId': '6166874', 'name': 'Desirae D Freiherr'}, {'authorId': '4916149', 'name': 'M. Abdolrasulnia'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2012\n",
            "Abstract Background Within the medical community there is persistent debate as to whether the information available through social media is trustworthy and valid, and whether physicians are ready to adopt these technologies and ultimately embrace them as a format for professional development and lifelong learning. Objective To identify how physicians are using social media to share and exchange medical information with other physicians, and to identify the factors that influence physicians’ use of social media as a component of their lifelong learning and continuing professional development. Methods We developed a survey instrument based on the Technology Acceptance Model, hypothesizing that technology usage is best predicted by a physician’s attitudes toward the technology, perceptions about the technology’s usefulness and ease of use, and individual factors such as personal innovativeness. The survey was distributed via email to a random sample of 1695 practicing oncologists and primary care physicians in the United States in March 2011. Responses from 485 physicians were analyzed (response rate 28.61%). Results Overall, 117 of 485 (24.1%) of respondents used social media daily or many times daily to scan or explore medical information, whereas 69 of 485 (14.2%) contributed new information via social media on a daily basis. On a weekly basis or more, 296 of 485 (61.0%) scanned and 223 of 485 (46.0%) contributed. In terms of attitudes toward the use of social media, 279 of 485 respondents (57.5%) perceived social media to be beneficial, engaging, and a good way to get current, high-quality information. In terms of usefulness, 281 of 485 (57.9%) of respondents stated that social media enabled them to care for patients more effectively, and 291 of 485 (60.0%) stated it improved the quality of patient care they delivered. The main factors influencing a physician’s usage of social media to share medical knowledge with other physicians were perceived ease of use and usefulness. Respondents who had positive attitudes toward the use of social media were more likely to use social media and to share medical information with other physicians through social media. Neither age nor gender had a significant impact on adoption or usage of social media. Conclusions Based on the results of this study, the use of social media applications may be seen as an efficient and effective method for physicians to keep up-to-date and to share newly acquired medical knowledge with other physicians within the medical community and to improve the quality of patient care. Future studies are needed to examine the impact of the meaningful use of social media on physicians’ knowledge, attitudes, skills, and behaviors in practice.\n",
            "------------------------------------\n",
            "Title The role of data privacy in marketing\n",
            "Author [{'authorId': '46662068', 'name': 'Kelly D. Martin'}, {'authorId': '145215321', 'name': 'P. Murphy'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Information-theoretic analysis of generalization capability of learning algorithms\n",
            "Author [{'authorId': '2173432', 'name': 'Aolin Xu'}, {'authorId': '1693598', 'name': 'M. Raginsky'}]\n",
            "Venue NIPS\n",
            "year 2017\n",
            "Abstract We derive upper bounds on the generalization error of a learning algorithm in terms of the mutual information between its input and output. The bounds provide an information-theoretic understanding of generalization in learning problems, and give theoretical guidelines for striking the right balance between data fit and generalization by controlling the input-output mutual information. We propose a number of methods for this purpose, among which are algorithms that regularize the ERM algorithm with relative entropy or with random noise. Our work extends and leads to nontrivial improvements on the recent results of Russo and Zou.\n",
            "------------------------------------\n",
            "Title Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author [{'authorId': '19284184', 'name': 'Lei Shi'}, {'authorId': '40382978', 'name': 'Yifan Zhang'}, {'authorId': '143949499', 'name': 'Jian Cheng'}, {'authorId': '1694235', 'name': 'Hanqing Lu'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2018\n",
            "Abstract In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeleton-based action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.\n",
            "------------------------------------\n",
            "Title Quantum Fisher information matrix and multiparameter estimation\n",
            "Author [{'authorId': '2153465660', 'name': 'Jing Liu'}, {'authorId': '2151334140', 'name': 'Haidong Yuan'}, {'authorId': '48574681', 'name': 'Xiao-Ming Lu'}, {'authorId': '1524728320', 'name': 'Xiaoguang Wang'}]\n",
            "Venue Journal of Physics A: Mathematical and Theoretical\n",
            "year 2019\n",
            "Abstract Quantum Fisher information matrix (QFIM) is a core concept in theoretical quantum metrology due to the significant importance of quantum Cramér–Rao bound in quantum parameter estimation. However, studies in recent years have revealed wide connections between QFIM and other aspects of quantum mechanics, including quantum thermodynamics, quantum phase transition, entanglement witness, quantum speed limit and non-Markovianity. These connections indicate that QFIM is more than a concept in quantum metrology, but rather a fundamental quantity in quantum mechanics. In this paper, we summarize the properties and existing calculation techniques of QFIM for various cases, and review the development of QFIM in some aspects of quantum mechanics apart from quantum metrology. On the other hand, as the main application of QFIM, the second part of this paper reviews the quantum multiparameter Cramér–Rao bound, its attainability condition and the associated optimal measurements. Moreover, recent developments in a few typical scenarios of quantum multiparameter estimation and the quantum advantages are also thoroughly discussed in this part.\n",
            "------------------------------------\n",
            "Title Adoption and use of social media among public health departments\n",
            "Author [{'authorId': '2006675', 'name': 'R. Thackeray'}, {'authorId': '3773147', 'name': 'B. Neiger'}, {'authorId': '153087794', 'name': 'Amanda Smith'}, {'authorId': '50364070', 'name': 'Sarah B Van Wagenen'}]\n",
            "Venue BMC Public Health\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Geodesic Information Flows: Spatially-Variant Graphs and Their Application to Segmentation and Fusion\n",
            "Author [{'authorId': '145244249', 'name': 'M. Cardoso'}, {'authorId': '1711439', 'name': 'M. Modat'}, {'authorId': '1696539', 'name': 'R. Wolz'}, {'authorId': '1730022', 'name': 'A. Melbourne'}, {'authorId': '2032710721', 'name': 'D. Cash'}, {'authorId': '1717710', 'name': 'D. Rueckert'}, {'authorId': '143951081', 'name': 'S. Ourselin'}]\n",
            "Venue IEEE Transactions on Medical Imaging\n",
            "year 2015\n",
            "Abstract Clinical annotations, such as voxel-wise binary or probabilistic tissue segmentations, structural parcellations, pathological regions-of-interest and anatomical landmarks are key to many clinical studies. However, due to the time consuming nature of manually generating these annotations, they tend to be scarce and limited to small subsets of data. This work explores a novel framework to propagate voxel-wise annotations between morphologically dissimilar images by diffusing and mapping the available examples through intermediate steps. A spatially-variant graph structure connecting morphologically similar subjects is introduced over a database of images, enabling the gradual diffusion of information to all the subjects, even in the presence of large-scale morphological variability. We illustrate the utility of the proposed framework on two example applications: brain parcellation using categorical labels and tissue segmentation using probabilistic features. The application of the proposed method to categorical label fusion showed highly statistically significant improvements when compared to state-of-the-art methodologies. Significant improvements were also observed when applying the proposed framework to probabilistic tissue segmentation of both synthetic and real data, mainly in the presence of large morphological variability.\n",
            "------------------------------------\n",
            "Title Nucleation, stability and current-induced motion of isolated magnetic skyrmions in nanostructures.\n",
            "Author [{'authorId': '143977032', 'name': 'J. Sampaio'}, {'authorId': '2325567', 'name': 'V. Cros'}, {'authorId': '8317370', 'name': 'S. Rohart'}, {'authorId': '152945222', 'name': 'A. Thiaville'}, {'authorId': '3083436', 'name': 'A. Fert'}]\n",
            "Venue Nature Nanotechnology\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title New media landscapes and the science information consumer\n",
            "Author [{'authorId': '3030164', 'name': 'D. Brossard'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2013\n",
            "Abstract Individuals are increasingly turning to online environments to find information about science and to follow scientific developments. It is therefore crucial for scientists and scientific institutions to consider empirical findings from research in online science communication when thinking about science in the public sphere. After providing a snapshot of the current media landscape, this paper reviews recent major research findings related to science communication in the online environment and their implications for science in the 21st century. Particular emphasis is given to the bias introduced by search engines, the nature of scientific content encountered online, and the potential impact of the Internet on audiences’ knowledge and attitudes toward science.\n",
            "------------------------------------\n",
            "Title Advances in fingerprint analysis.\n",
            "Author [{'authorId': '3681712', 'name': 'Pompi Hazarika'}, {'authorId': '10747613', 'name': 'D. Russell'}]\n",
            "Venue Angewandte Chemie\n",
            "year 2012\n",
            "Abstract Fingerprints have been used in forensic investigations for the identification of individuals since the late 19th century. However, it is now clear that fingerprints can provide significantly more information about an individual. Here, we highlight the considerable advances in fingerprinting technology that can simultaneously provide chemical information regarding the drugs ingested and the explosives and drugs handled by a person as well as the identity of that individual.\n",
            "------------------------------------\n",
            "Title An Introduction to Information Retrieval\n",
            "Author [{'authorId': '144161686', 'name': 'S. Ceri'}, {'authorId': '1710630', 'name': 'A. Bozzon'}, {'authorId': '40350773', 'name': 'Marco Brambilla'}, {'authorId': '2539248', 'name': 'Emanuele Della Valle'}, {'authorId': '1704595', 'name': 'P. Fraternali'}, {'authorId': '1794305', 'name': 'S. Quarteroni'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Nucleation, stability and current-induced motion of isolated magnetic skyrmions in nanostructures.\n",
            "Author [{'authorId': '143977032', 'name': 'J. Sampaio'}, {'authorId': '2325567', 'name': 'V. Cros'}, {'authorId': '8317370', 'name': 'S. Rohart'}, {'authorId': '152945222', 'name': 'A. Thiaville'}, {'authorId': '3083436', 'name': 'A. Fert'}]\n",
            "Venue Nature Nanotechnology\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information\n",
            "Author [{'authorId': '6426643', 'name': 'Yunan Luo'}, {'authorId': '1848401', 'name': 'Xinbin Zhao'}, {'authorId': '3462984', 'name': 'Jingtian Zhou'}, {'authorId': '2109818202', 'name': 'Jinling Yang'}, {'authorId': '2108082363', 'name': 'Yanqing Zhang'}, {'authorId': '1396897128', 'name': 'Wenhua Kuang'}, {'authorId': '144439558', 'name': 'Jian Peng'}, {'authorId': '2145163696', 'name': 'Ligong Chen'}, {'authorId': '38347129', 'name': 'Jianyang Zeng'}]\n",
            "Venue bioRxiv\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title From Use to Effective Use: A Representation Theory Perspective\n",
            "Author [{'authorId': '1400115225', 'name': 'A. Burton-Jones'}, {'authorId': '2823704', 'name': 'Camille Grange'}]\n",
            "Venue Information systems research\n",
            "year 2013\n",
            "Abstract Information systems must be used effectively to obtain maximum benefits from them. However, despite a great deal of research on when and why systems are used, very little research has examined what effective system use involves and what drives it. To move from use to effective use requires understanding an information system's nature and purpose, which in turn requires a theory of information systems. We draw on representation theory, which states that an information system is made up of several structures that serve to represent some part of the world that a user and other stakeholders must understand. From this theory, we derive a high-level framework of how effective use and performance evolve, as well as specific models of the nature and drivers of effective use. The models are designed to explain the effective use of any information system and offer unique insights that would not be offered by traditional views, which tend to consider information systems to be just another tool. We explain how our theory extends existing research, provides a rich platform for research on effective use, and how it contributes back to the theory of information systems from which it was derived.\n",
            "------------------------------------\n",
            "Title Learning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-Temporal Path Proposals\n",
            "Author [{'authorId': '2371221', 'name': 'Yantao Shen'}, {'authorId': '2014849645', 'name': 'Tong Xiao'}, {'authorId': '47893312', 'name': 'Hongsheng Li'}, {'authorId': '2447593', 'name': 'Shuai Yi'}, {'authorId': '31843833', 'name': 'Xiaogang Wang'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2017\n",
            "Abstract Vehicle re-identification is an important problem and has many applications in video surveillance and intelligent transportation. It gains increasing attention because of the recent advances of person re-identification techniques. However, unlike person re-identification, the visual differences between pairs of vehicle images are usually subtle and even challenging for humans to distinguish. Incorporating additional spatio-temporal information is vital for solving the challenging re-identification task. Existing vehicle re-identification methods ignored or used oversimplified models for the spatio-temporal relations between vehicle images. In this paper, we propose a two-stage framework that incorporates complex spatio-temporal information for effectively regularizing the re-identification results. Given a pair of vehicle images with their spatiotemporal information, a candidate visual-spatio-temporal path is first generated by a chain MRF model with a deeply learned potential function, where each visual-spatiotemporal state corresponds to an actual vehicle image with its spatio-temporal information. A Siamese-CNN+Path- LSTM model takes the candidate path as well as the pairwise queries to generate their similarity score. Extensive experiments and analysis show the effectiveness of our proposed method and individual components.\n",
            "------------------------------------\n",
            "Title Learning Character-level Representations for Part-of-Speech Tagging\n",
            "Author [{'authorId': '1790831', 'name': 'C. D. Santos'}, {'authorId': '1735228', 'name': 'B. Zadrozny'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2014\n",
            "Abstract Distributed word representations have recently been proven to be an invaluable resource for NLP. These representations are normally learned using neural networks and capture syntactic and semantic information about words. Information about word morphology and shape is normally ignored when learning word representations. However, for tasks like part-of-speech tagging, intra-word information is extremely useful, specially when dealing with morphologically rich languages. In this paper, we propose a deep neural network that learns character-level representation of words and associate them with usual word representations to perform POS tagging. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for two languages: English, with 97.32% accuracy on the Penn Treebank WSJ corpus; and Portuguese, with 97.47% accuracy on the Mac-Morpho corpus, where the latter represents an error reduction of 12.2% on the best previous known result.\n",
            "------------------------------------\n",
            "Title On the joys of missing data.\n",
            "Author [{'authorId': '2462877', 'name': 'T. Little'}, {'authorId': '39273203', 'name': 'T. Jorgensen'}, {'authorId': '31846263', 'name': 'Kyle M Lang'}, {'authorId': '33074531', 'name': 'E. Moore'}]\n",
            "Venue Journal of Pediatric Psychology\n",
            "year 2014\n",
            "Abstract We provide conceptual introductions to missingness mechanisms--missing completely at random, missing at random, and missing not at random--and state-of-the-art methods of handling missing data--full-information maximum likelihood and multiple imputation--followed by a discussion of planned missing designs: Multiform questionnaire protocols, 2-method measurement models, and wave-missing longitudinal designs. We reviewed 80 articles of empirical studies published in the 2012 issues of the Journal of Pediatric Psychology to present a picture of how adequately missing data are currently handled in this field. To illustrate the benefits of using multiple imputation or full-information maximum likelihood and incorporating planned missingness into study designs, we provide example analyses of empirical data gathered using a 3-form planned missing design.\n",
            "------------------------------------\n",
            "Title Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author [{'authorId': '19284184', 'name': 'Lei Shi'}, {'authorId': '40382978', 'name': 'Yifan Zhang'}, {'authorId': '143949499', 'name': 'Jian Cheng'}, {'authorId': '1694235', 'name': 'Hanqing Lu'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2018\n",
            "Abstract In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeleton-based action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.\n",
            "------------------------------------\n",
            "Title Measuring Information-Transfer Delays\n",
            "Author [{'authorId': '1775434', 'name': 'M. Wibral'}, {'authorId': '5570691', 'name': 'Nicolae Pampu'}, {'authorId': '2964400', 'name': 'V. Priesemann'}, {'authorId': '2692662', 'name': 'F. Siebenhühner'}, {'authorId': '4773547', 'name': 'Hannes Seiwert'}, {'authorId': '2061254650', 'name': 'Michael Lindner'}, {'authorId': '1783110', 'name': 'J. Lizier'}, {'authorId': '144846212', 'name': 'Raul Vicente'}]\n",
            "Venue PLoS ONE\n",
            "year 2013\n",
            "Abstract In complex networks such as gene networks, traffic systems or brain circuits it is important to understand how long it takes for the different parts of the network to effectively influence one another. In the brain, for example, axonal delays between brain areas can amount to several tens of milliseconds, adding an intrinsic component to any timing-based processing of information. Inferring neural interaction delays is thus needed to interpret the information transfer revealed by any analysis of directed interactions across brain structures. However, a robust estimation of interaction delays from neural activity faces several challenges if modeling assumptions on interaction mechanisms are wrong or cannot be made. Here, we propose a robust estimator for neuronal interaction delays rooted in an information-theoretic framework, which allows a model-free exploration of interactions. In particular, we extend transfer entropy to account for delayed source-target interactions, while crucially retaining the conditioning on the embedded target state at the immediately previous time step. We prove that this particular extension is indeed guaranteed to identify interaction delays between two coupled systems and is the only relevant option in keeping with Wiener’s principle of causality. We demonstrate the performance of our approach in detecting interaction delays on finite data by numerical simulations of stochastic and deterministic processes, as well as on local field potential recordings. We also show the ability of the extended transfer entropy to detect the presence of multiple delays, as well as feedback loops. While evaluated on neuroscience data, we expect the estimator to be useful in other fields dealing with network dynamics.\n",
            "------------------------------------\n",
            "Title ClinVar: public archive of interpretations of clinically relevant variants\n",
            "Author [{'authorId': '3218124', 'name': 'M. Landrum'}, {'authorId': '2108441407', 'name': 'Jennifer M. Lee'}, {'authorId': '2057961586', 'name': 'M. Benson'}, {'authorId': '2148612924', 'name': 'Garth R. Brown'}, {'authorId': '41170163', 'name': 'Chen Chao'}, {'authorId': '2238195', 'name': 'S. Chitipiralla'}, {'authorId': '2052182323', 'name': 'Baoshan Gu'}, {'authorId': '144951362', 'name': 'Jennifer Hart'}, {'authorId': '146499947', 'name': 'Douglas Hoffman'}, {'authorId': '2065316669', 'name': 'Jeffrey Hoover'}, {'authorId': '50027016', 'name': 'W. Jang'}, {'authorId': '1997190', 'name': 'K. Katz'}, {'authorId': '3333288', 'name': 'M. Ovetsky'}, {'authorId': '35625261', 'name': 'George R. Riley'}, {'authorId': '153626744', 'name': 'Amanjeev Sethi'}, {'authorId': '36967624', 'name': 'R. E. Tully'}, {'authorId': '1405373084', 'name': 'Ricardo Villamarín-Salomón'}, {'authorId': '2862785', 'name': 'W. Rubinstein'}, {'authorId': '1758049', 'name': 'D. Maglott'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2015\n",
            "Abstract ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) at the National Center for Biotechnology Information (NCBI) is a freely available archive for interpretations of clinical significance of variants for reported conditions. The database includes germline and somatic variants of any size, type or genomic location. Interpretations are submitted by clinical testing laboratories, research laboratories, locus-specific databases, OMIM®, GeneReviews™, UniProt, expert panels and practice guidelines. In NCBI's Variation submission portal, submitters upload batch submissions or use the Submission Wizard for single submissions. Each submitted interpretation is assigned an accession number prefixed with SCV. ClinVar staff review validation reports with data types such as HGVS (Human Genome Variation Society) expressions; however, clinical significance is reported directly from submitters. Interpretations are aggregated by variant-condition combination and assigned an accession number prefixed with RCV. Clinical significance is calculated for the aggregate record, indicating consensus or conflict in the submitted interpretations. ClinVar uses data standards, such as HGVS nomenclature for variants and MedGen identifiers for conditions. The data are available on the web as variant-specific views; the entire data set can be downloaded via ftp. Programmatic access for ClinVar records is available through NCBI's E-utilities. Future development includes providing a variant-centric XML archive and a web page for details of SCV submissions.\n",
            "------------------------------------\n",
            "Title An Enhanced Fear Appeal Rhetorical Framework: Leveraging Threats to the Human Asset Through Sanctioning Rhetoric\n",
            "Author [{'authorId': '1831186', 'name': 'Allen C. Johnston'}, {'authorId': '2179829', 'name': 'Merrill Warkentin'}, {'authorId': '1796920', 'name': 'M. Siponen'}]\n",
            "Venue MIS Q.\n",
            "year 2015\n",
            "Abstract Fear appeals, which are used widely in information security campaigns, have become common tools in motivating individual compliance with information security policies and procedures. However, empirical assessments of the effectiveness of fear appeals have yielded mixed results, leading IS security scholars and practitioners to question the validity of the conventional fear appeal framework and the manner in which fear appeal behavioral modeling theories, such as protection motivation theory (PMT), have been applied to the study of information security phenomena. We contend that the conventional fear appeal rhetorical framework is inadequate when used in the context of information security threat warnings and that its primary behavioral modeling theory, PMT, has been misspecified in the extant information security research. Based on these arguments, we propose an enhanced fear appeal rhetorical framework that leverages sanctioning rhetoric as a secondary vector of threats to the human asset, thereby adding the dimension of personal relevance, which is critically absent from previous fear appeal frameworks and PMT-grounded security studies. Following a hypothetical scenario research approach involving the employees of a Finnish city government, we validate the efficacy of the enhanced fear appeal framework and determine that informal sanction rhetoric effectively enhances conventional fear appeals, thus providing a significant positive influence on compliance intentions.\n",
            "------------------------------------\n",
            "Title Ubiquitous Data Accessing Method in IoT-Based Information System for Emergency Medical Services\n",
            "Author [{'authorId': '102630053', 'name': 'Boyi Xu'}, {'authorId': '39466716', 'name': 'Lida Xu'}, {'authorId': '1720869', 'name': 'Hongming Cai'}, {'authorId': '144801997', 'name': 'Cheng Xie'}, {'authorId': '2118517096', 'name': 'Jingyuan Hu'}, {'authorId': '1732336', 'name': 'Fenglin Bu'}]\n",
            "Venue IEEE Transactions on Industrial Informatics\n",
            "year 2014\n",
            "Abstract The rapid development of Internet of things (IoT) technology makes it possible for connecting various smart objects together through the Internet and providing more data interoperability methods for application purpose. Recent research shows more potential applications of IoT in information intensive industrial sectors such as healthcare services. However, the diversity of the objects in IoT causes the heterogeneity problem of the data format in IoT platform. Meanwhile, the use of IoT technology in applications has spurred the increase of real-time data, which makes the information storage and accessing more difficult and challenging. In this research, first a semantic data model is proposed to store and interpret IoT data. Then a resource-based data accessing method (UDA-IoT) is designed to acquire and process IoT data ubiquitously to improve the accessibility to IoT data resources. Finally, we present an IoT-based system for emergency medical services to demonstrate how to collect, integrate, and interoperate IoT data flexibly in order to provide support to emergency medical services. The result shows that the resource-based IoT data accessing method is effective in a distributed heterogeneous data environment for supporting data accessing timely and ubiquitously in a cloud and mobile computing platform.\n",
            "------------------------------------\n",
            "Title Blockchain Disruption and Smart Contracts\n",
            "Author [{'authorId': '38396645', 'name': 'L. Cong'}, {'authorId': '2351678', 'name': 'Zhiguo He'}]\n",
            "Venue The Review of financial studies\n",
            "year 2018\n",
            "Abstract Blockchain technology provides decentralized consensus and potentially enlarges the contracting space using smart contracts with tamper-proofness and algorithmic executions. Meanwhile, generating decentralized consensus entails distributing information which necessarily alters the informational environment. We analyze how decentralization affects consensus effectiveness, and how the quintessential features of blockchain reshape industrial organization and the landscape of competition. Smart contracts can mitigate informational asymmetry and improve welfare and consumer surplus through enhanced entry and competition, yet the irreducible distribution of information during consensus generation may encourage greater collusion. In general, blockchains can sustain market equilibria with a wider range of economic outcomes. We further discuss anti-trust policy implications targeted to blockchain applications, such as separating consensus record-keepers from users.\n",
            "------------------------------------\n",
            "Title The Effect of Economic Policy Uncertainty on Investor Information Asymmetry and Management Disclosures\n",
            "Author [{'authorId': '2713514', 'name': 'Venky Nagar'}, {'authorId': '48365688', 'name': 'Jordan Schoenfeld'}, {'authorId': '118839445', 'name': 'Laura A. Wellman'}]\n",
            "Venue Journal of Accounting & Economics\n",
            "year 2018\n",
            "Abstract Abstract Investor uncertainty about firm value drives investors’ information collection and trading activities, as well as managers’ disclosure choices. This study examines an important source of uncertainty that likely cannot be influenced by most managers and investors: uncertainty about government economic policy. We find that this uncertainty is associated with increased bid-ask spreads and decreased stock price reactions to earnings surprises. Managers respond to this uncertainty by increasing their voluntary disclosures, but these disclosures only partly mitigate the bid-ask spread increase. We conclude that government economic policy uncertainty is an important component of firms’ information environments and managers’ voluntary disclosure decisions.\n",
            "------------------------------------\n",
            "Title Inference Attacks on Property-Preserving Encrypted Databases\n",
            "Author [{'authorId': '145116440', 'name': 'Muhammad Naveed'}, {'authorId': '144032384', 'name': 'S. Kamara'}, {'authorId': '39457373', 'name': 'C. V. Wright'}]\n",
            "Venue Conference on Computer and Communications Security\n",
            "year 2015\n",
            "Abstract Many encrypted database (EDB) systems have been proposed in the last few years as cloud computing has grown in popularity and data breaches have increased. The state-of-the-art EDB systems for relational databases can handle SQL queries over encrypted data and are competitive with commercial database systems. These systems, most of which are based on the design of CryptDB (SOSP 2011), achieve these properties by making use of property-preserving encryption schemes such as deterministic (DTE) and order- preserving encryption (OPE). In this paper, we study the concrete security provided by such systems. We present a series of attacks that recover the plaintext from DTE- and OPE-encrypted database columns using only the encrypted column and publicly-available auxiliary information. We consider well-known attacks, including frequency analysis and sorting, as well as new attacks based on combinatorial optimization. We evaluate these attacks empirically in an electronic medical records (EMR) scenario using real patient data from 200 U.S. hospitals. When the encrypted database is operating in a steady-state where enough encryption layers have been peeled to permit the application to run its queries, our experimental results show that an alarming amount of sensitive information can be recovered. In particular, our attacks correctly recovered certain OPE-encrypted attributes (e.g., age and disease severity) for more than 80% of the patient records from 95% of the hospitals; and certain DTE- encrypted attributes (e.g., sex, race, and mortality risk) for more than 60% of the patient records from more than 60% of the hospitals.\n",
            "------------------------------------\n",
            "Title Mandatory IFRS Adoption and Financial Statement Comparability\n",
            "Author [{'authorId': '6377328', 'name': 'François Brochet'}, {'authorId': '3118272', 'name': 'Alan D. Jagolinzer'}, {'authorId': '50075584', 'name': 'Edward J. Riedl'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This study examines whether mandatory adoption of International Financial Reporting Standards (IFRS) leads to capital market benefits through enhanced financial statement comparability. UK domestic standards are considered very similar to IFRS (Bae et al. 2008), suggesting any capital market benefits observed for UK-domiciled firms are more likely attributable to improvements in comparability (i.e., better precision of across-firm information) than to changes in information quality specific to the firm (i.e., core information quality). If IFRS adoption improves financial statement comparability, we predict this should reduce insiders’ ability to benefit from private information. Consistent with these expectations, we find that abnormal returns to insider purchases ― used to proxy for private information ― are reduced following IFRS adoption. Similar results obtain across numerous subsamples and proxies used to isolate IFRS effects attributable to comparability. Together, the findings are consistent with mandatory IFRS adoption improving comparability and thus leading to capital market benefits by reducing insiders’ ability to exploit private information.\n",
            "------------------------------------\n",
            "Title Directional Message Passing for Molecular Graphs\n",
            "Author [{'authorId': '51516539', 'name': 'Johannes Klicpera'}, {'authorId': '1557081085', 'name': 'Janek Groß'}, {'authorId': '3075189', 'name': 'Stephan Günnemann'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2020\n",
            "Abstract Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes) and not the spatial direction from one atom to another. However, directional information plays a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions to construct a theoretically well-founded, orthogonal radial basis that achieves better performance than the currently prevalent Gaussian radial basis functions while using more than 4x fewer parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 77% on MD17 and by 41% on QM9.\n",
            "------------------------------------\n",
            "Title When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author [{'authorId': '2375942', 'name': 'L. Thygesen'}, {'authorId': '1390048098', 'name': 'A. Ersbøll'}]\n",
            "Venue European Journal of Epidemiology\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks\n",
            "Author [{'authorId': '2727584', 'name': 'Yossi Adi'}, {'authorId': '2098460', 'name': 'Einat Kermany'}, {'authorId': '2083259', 'name': 'Yonatan Belinkov'}, {'authorId': '3120346', 'name': 'Ofer Lavi'}, {'authorId': '2089067', 'name': 'Yoav Goldberg'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2016\n",
            "Abstract There is a lot of research interest in encoding variable length sentences into fixed length vectors, in a way that preserves the sentence meanings. Two common methods include representations based on averaging word vectors, and representations based on the hidden states of recurrent neural networks such as LSTMs. The sentence vectors are used as features for subsequent machine learning tasks or for pre-training in the context of deep learning. However, not much is known about the properties that are encoded in these sentence representations and about the language information they capture. We propose a framework that facilitates better understanding of the encoded representations. We define prediction tasks around isolated aspects of sentence structure (namely sentence length, word content, and word order), and score representations by the ability to train a classifier to solve each prediction task when using the representation as input. We demonstrate the potential contribution of the approach by analyzing different sentence representation mechanisms. The analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks, and on the effect of the encoded vector's dimensionality on the resulting representations.\n",
            "------------------------------------\n",
            "Title Quantifying unique information\n",
            "Author [{'authorId': '1750120', 'name': 'Nils Bertschinger'}, {'authorId': '34538722', 'name': 'J. Rauh'}, {'authorId': '2439079', 'name': 'E. Olbrich'}, {'authorId': '39990953', 'name': 'J. Jost'}, {'authorId': '2850091', 'name': 'N. Ay'}]\n",
            "Venue Entropy\n",
            "year 2013\n",
            "Abstract We propose new measures of shared information, unique information and synergistic information that can be used to decompose the mutual information of a pair of random variables (Y, Z) with a third random variable X. Our measures are motivated by an operational idea of unique information, which suggests that shared information and unique information should depend only on the marginal distributions of the pairs (X, Y) and (X,Z). Although this invariance property has not been studied before, it is satisfied by other proposed measures of shared information. The invariance property does not uniquely determine our new measures, but it implies that the functions that we define are bounds to any other measures satisfying the same invariance property. We study properties of our measures and compare them to other candidate measures.\n",
            "------------------------------------\n",
            "Title The orbitofrontal cortex.\n",
            "Author [{'authorId': '144663088', 'name': 'E. Rolls'}]\n",
            "Venue Philosophical transactions of the Royal Society of London. Series B, Biological sciences\n",
            "year 2019\n",
            "Abstract The orbitofrontal cortex contains the secondary taste cortex, in which the reward value of taste is represented. It also contains the secondary and tertiary olfactory cortical areas, in which information about the identity and also about the reward value of odours is represented. The orbitofrontal cortex also receives information about the sight of objects from the temporal lobe cortical visual areas, and is involved in learning and in reversing stimulus-reinforcement associations. The stimulus might be a visual or olfactory stimulus, and the primary (unlearned) reinforcer a taste or touch. Damage to the orbitofrontal cortex impairs the learning and reversal of stimulus-reinforcement associations, and thus the correction of behavioural responses when these are no longer appropriate because previous reinforcement contingencies change. The information which reaches the orbitofrontal cortex for these functions includes information about faces, and damage to the orbitofrontal cortex can impair face expression identification. This evidence thus shows that the orbitofrontal cortex is involved in decoding some primary reinforcers such as taste; in learning and reversing associations of visual and other stimuli to these primary reinforcers; and plays an executive function in controlling and correcting reward-related and punishment-related behaviour, and thus in emotion.\n",
            "------------------------------------\n",
            "Title Oscillatory multiplexing of population codes for selective communication in the mammalian brain\n",
            "Author [{'authorId': '2711511', 'name': 'T. Akam'}, {'authorId': '3026613', 'name': 'D. Kullmann'}]\n",
            "Venue Nature Reviews Neuroscience\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Scaling the Ion Trap Quantum Processor\n",
            "Author [{'authorId': '50856718', 'name': 'C. Monroe'}, {'authorId': '1924091', 'name': 'J. Kim'}]\n",
            "Venue Science\n",
            "year 2013\n",
            "Abstract Trapped atomic ions are standards for quantum information processing, serving as quantum memories, hosts of quantum gates in quantum computers and simulators, and nodes of quantum communication networks. Quantum bits based on trapped ions enjoy a rare combination of attributes: They have exquisite coherence properties, they can be prepared and measured with nearly 100% efficiency, and they are readily entangled with each other through the Coulomb interaction or remote photonic interconnects. The outstanding challenge is the scaling of trapped ions to hundreds or thousands of qubits and beyond, at which scale quantum processors can outperform their classical counterparts in certain applications. We review the latest progress and prospects in that effort, with the promise of advanced architectures and new technologies, such as microfabricated ion traps and integrated photonics.\n",
            "------------------------------------\n",
            "Title Developing and Testing a Theoretical Framework for Computer‐Mediated Transparency of Local Governments\n",
            "Author [{'authorId': '1931965', 'name': 'S. Grimmelikhuijsen'}, {'authorId': '8753317', 'name': 'E. Welch'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This article contributes to the emerging literature on transparency by developing and empirically testing a theoretical framework that explains the determinants of local government Web site transparency. It aims to answer the following central question: What institutional factors determine the different dimensions of government transparency? The framework distinguishes three dimensions of transparency—decision making transparency, policy information transparency, and policy outcome transparency—and hypothesizes three explanations for each: organizational capacity, political influence, and group influence on government. Results indicate that each dimension of transparency is associated with different factors. Decision-making transparency is associated with political influence; when left-wing parties are strong in the local council, local government tends to be more transparent. Policy information transparency is associated with media attention and external group pressure, and policy outcome transparency is associated with both external group pressure and the organizational capacity. The authors discuss the implications for policy and administration\n",
            "------------------------------------\n",
            "Title Accounting information systems\n",
            "Author [{'authorId': '3220663', 'name': 'S. Altschuller'}, {'authorId': '2168984276', 'name': 'Shaya Altschuller'}]\n",
            "Venue The Routledge Companion to Risk, Crisis and Security in Business\n",
            "year 2018\n",
            "Abstract Accounting Information Systems Introduction The development of information technology impacts significantly on various fields and activities. The biggest impact can be seen in accounting practice. The changes are becoming more and more complex as there are shifts in business activities, such as in organization management, the concept of change management, and integration activities making closer ties among suppliers, customers and even competitors (Computing Curricula 2005, Information System).\n",
            "------------------------------------\n",
            "Title Connecting with new information landscapes: information literacy practices of refugees\n",
            "Author [{'authorId': '39181224', 'name': 'A. Lloyd'}, {'authorId': '1717766', 'name': 'M. Kennan'}, {'authorId': '49269524', 'name': 'K. Thompson'}, {'authorId': '2102889', 'name': 'M. Qayyum'}]\n",
            "Venue J. Documentation\n",
            "year 2013\n",
            "Abstract Purpose – The purpose of the research reported in this article is to understand how refugees learn to engage with a complex, multimodal information landscape and how their information literacy practice may be constructed to enable them to connect and be included in their new information landscape. Design/methodology/approach – The study is framed through practice and socio‐cultural theories. A qualitative research design is employed including semi‐structured face‐to‐face interviews and focus groups which are thematically analysed through an information practice lens. Findings – Refugees encounter complex and challenging information landscapes that present barriers to their full participation in their new communities. Social inclusion becomes possible where information is provided via sharing through trusted mediators who assist with navigating the information landscape and information mapping, and through visual and social sources. Research limitations/implications – The study is local and situated and therefore not empirically generalizable. It does however provide rich, deep description and explanation that is instructive beyond the specific research site and contributes to theory building. Practical implications – The study highlights the role, and importance, of social and visual information sources and the key role of service providers as mediators and navigators. Governments, funders and service providers can use these findings to inform their service provision. Originality/value – This is an original research paper in which the results provide practical advice for those working with refugees and which also extends theories of information literacy practice as an information practice.\n",
            "------------------------------------\n",
            "Title Predicting information credibility in time-sensitive social media\n",
            "Author [{'authorId': '153191671', 'name': 'Carlos Castillo'}, {'authorId': '145893609', 'name': 'Marcelo Mendoza'}, {'authorId': '2272762', 'name': 'Bárbara Poblete'}]\n",
            "Venue Internet Research\n",
            "year 2013\n",
            "Abstract Purpose – Twitter is a popular microblogging service which has proven, in recent years, its potential for propagating news and information about developing events. The purpose of this paper is to focus on the analysis of information credibility on Twitter. The purpose of our research is to establish if an automatic discovery process of relevant and credible news events can be achieved. Design/methodology/approach – The paper follows a supervised learning approach for the task of automatic classification of credible news events. A first classifier decides if an information cascade corresponds to a newsworthy event. Then a second classifier decides if this cascade can be considered credible or not. The paper undertakes this effort training over a significant amount of labeled data, obtained using crowdsourcing tools. The paper validates these classifiers under two settings: the first, a sample of automatically detected Twitter “trends” in English, and second, the paper tests how well this model transfers to...\n",
            "------------------------------------\n",
            "Title Neural Sentiment Classification with User and Product Attention\n",
            "Author [{'authorId': '47666582', 'name': 'Huimin Chen'}, {'authorId': '1753344', 'name': 'Maosong Sun'}, {'authorId': '2652217', 'name': 'Cunchao Tu'}, {'authorId': '2427350', 'name': 'Yankai Lin'}, {'authorId': '49293587', 'name': 'Zhiyuan Liu'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2016\n",
            "Abstract Document-level sentiment classification aims to predict user’s overall sentiment in a document about a product. However, most of existing methods only focus on local text information and ignore the global user preference and product characteristics. Even though some works take such information into account, they usually suffer from high model complexity and only consider wordlevel preference rather than semantic levels. To address this issue, we propose a hierarchical neural network to incorporate global user and product information into sentiment classification. Our model first builds a hierarchical LSTM model to generate sentence and document representations. Afterwards, user and product information is considered via attentions over different semantic levels due to its ability of capturing crucial semantic components. The experimental results show that our model achieves significant and consistent improvements compared to all state-of-theart methods. The source code of this paper can be obtained from https://github. com/thunlp/NSC.\n",
            "------------------------------------\n",
            "Title Revealing the hidden networks of interaction in mobile animal groups allows prediction of complex behavioral contagion\n",
            "Author [{'authorId': '47755959', 'name': 'S. Rosenthal'}, {'authorId': '39431767', 'name': 'Colin R. Twomey'}, {'authorId': '2626843', 'name': 'Andrew T. Hartnett'}, {'authorId': '49498925', 'name': 'H. Wu'}, {'authorId': '3191663', 'name': 'I. Couzin'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2015\n",
            "Abstract Significance We know little about the nature of the evolved interaction networks that give rise to the rapid coordinated collective response exhibited by many group-living organisms. Here, we study collective evasion in schooling fish using computational techniques to reconstruct the scene from the perspective of the organisms themselves. This method allows us to establish how the complex social scene is translated into behavioral response at the level of individuals and to visualize, and analyze, the resulting complex communication network as behavioral change spreads rapidly through groups. Thus, we can map, for any moment in time, the extent to which each individual is socially influential during collective evasion and predict the magnitude of such behavioral epidemics before they actually occur. Coordination among social animals requires rapid and efficient transfer of information among individuals, which may depend crucially on the underlying structure of the communication network. Establishing the decision-making circuits and networks that give rise to individual behavior has been a central goal of neuroscience. However, the analogous problem of determining the structure of the communication network among organisms that gives rise to coordinated collective behavior, such as is exhibited by schooling fish and flocking birds, has remained almost entirely neglected. Here, we study collective evasion maneuvers, manifested through rapid waves, or cascades, of behavioral change (a ubiquitous behavior among taxa) in schooling fish (Notemigonus crysoleucas). We automatically track the positions and body postures, calculate visual fields of all individuals in schools of ∼150 fish, and determine the functional mapping between socially generated sensory input and motor response during collective evasion. We find that individuals use simple, robust measures to assess behavioral changes in neighbors, and that the resulting networks by which behavior propagates throughout groups are complex, being weighted, directed, and heterogeneous. By studying these interaction networks, we reveal the (complex, fractional) nature of social contagion and establish that individuals with relatively few, but strongly connected, neighbors are both most socially influential and most susceptible to social influence. Furthermore, we demonstrate that we can predict complex cascades of behavioral change at their moment of initiation, before they actually occur. Consequently, despite the intrinsic stochasticity of individual behavior, establishing the hidden communication networks in large self-organized groups facilitates a quantitative understanding of behavioral contagion.\n",
            "------------------------------------\n",
            "Title Coronavirus disease 2019: The harms of exaggerated information and non‐evidence‐based measures\n",
            "Author [{'authorId': '145441750', 'name': 'J. Ioannidis'}]\n",
            "Venue European Journal of Clinical Investigation\n",
            "year 2020\n",
            "Abstract The evolving coronavirus disease 2019 (COVID-19) epidemic1 is certainly cause for concern. Proper communication and optimal decision-making is an ongoing challenge, as data evolve. The challenge is compounded, however, by exaggerated information. This can lead to inappropriate actions. It is important to differentiate promptly the true epidemic from an epidemic of false claims and potentially harmful actions.\n",
            "------------------------------------\n",
            "Title IEA International Computer and Information Literacy Study 2018 Assessment Framework\n",
            "Author [{'authorId': '47946182', 'name': 'J. Fraillon'}, {'authorId': '40007442', 'name': 'Wolfram Schulz'}, {'authorId': '80863696', 'name': 'J. Ainley'}]\n",
            "Venue \n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title EGNet: Edge Guidance Network for Salient Object Detection\n",
            "Author [{'authorId': '2109784468', 'name': 'Jiaxing Zhao'}, {'authorId': '2119612440', 'name': 'Jiangjiang Liu'}, {'authorId': '23999143', 'name': 'Deng-Ping Fan'}, {'authorId': '2108097465', 'name': 'Yang Cao'}, {'authorId': '1755872', 'name': 'Jufeng Yang'}, {'authorId': '37535930', 'name': 'Ming-Ming Cheng'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2019\n",
            "Abstract Fully convolutional neural networks (FCNs) have shown their advantages in the salient object detection task. However, most existing FCNs-based methods still suffer from coarse object boundaries. In this paper, to solve this problem, we focus on the complementarity between salient edge information and salient object information. Accordingly, we present an edge guidance network (EGNet) for salient object detection with three steps to simultaneously model these two kinds of complementary information in a single network. In the ﬁrst step, we extract the salient object features by a progressive fusion way. In the second step, we integrate the local edge information and global location information to obtain the salient edge features. Finally, to sufﬁciently leverage these complementary features, we couple the same salient edge features with salient object features at various resolutions. Beneﬁting from the rich edge information and location information in salient edge features, the fused features can help locate salient objects, especially their boundaries more accurately. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art methods on six widely used datasets without any pre-processing and post-processing. The source code is available at http: //mmcheng.net/egnet/.\n",
            "------------------------------------\n",
            "Title Suspense and Surprise\n",
            "Author [{'authorId': '2281491', 'name': 'Jeffrey C. Ely'}, {'authorId': '144047191', 'name': 'A. Frankel'}, {'authorId': '2968902', 'name': 'Emir Kamenica'}]\n",
            "Venue Journal of Political Economy\n",
            "year 2015\n",
            "Abstract We model demand for noninstrumental information, drawing on the idea that people derive entertainment utility from suspense and surprise. A period has more suspense if the variance of the next period’s beliefs is greater. A period has more surprise if the current belief is further from the last period’s belief. Under these definitions, we analyze the optimal way to reveal information over time so as to maximize expected suspense or surprise experienced by a Bayesian audience. We apply our results to the design of mystery novels, political primaries, casinos, game shows, auctions, and sports.\n",
            "------------------------------------\n",
            "Title Identifying Participants in the Personal Genome Project by Name\n",
            "Author [{'authorId': '144851214', 'name': 'L. Sweeney'}, {'authorId': '46578953', 'name': 'A. Abu'}, {'authorId': '34060063', 'name': 'Julia Winn'}]\n",
            "Venue ArXiv\n",
            "year 2013\n",
            "Abstract We linked names and contact information to publicly available profiles in the Personal Genome Project. These profiles contain medical and genomic information, including details about medications, procedures and diseases, and demographic information, such as date of birth, gender, and postal code. By linking demographics to public records such as voter lists, and mining for names hidden in attached documents, we correctly identified 84 to 97 percent of the profiles for which we provided names. Our ability to learn their names is based on their demographics, not their DNA, thereby revisiting an old vulnerability that could be easily thwarted with minimal loss of research value. So, we propose technical remedies for people to learn about their demographics to make better decisions.\n",
            "------------------------------------\n",
            "Title The Past, Present, and Future of \"IS Success\"\n",
            "Author [{'authorId': '2103322', 'name': 'S. Petter'}, {'authorId': '3035043', 'name': 'William H. DeLone'}, {'authorId': '2400363', 'name': 'E. McLean'}]\n",
            "Venue Journal of the AIS\n",
            "year 2012\n",
            "Abstract Since the introduction of information systems more than 60 years ago, organizations want to ensure that their systems are effective or “successful”. Much has changed in the evaluation of information systems success during this period. The role of information systems in organizations has changed dramatically, as have the key stakeholders and the expected benefits of the investments in IS. During this period, IS research has evolved to keep pace with the changing expectations regarding the success of information systems, yet practice tends to lag behind. In this commentary, we discuss five eras of information systems evolution and explain how the perceptions and measures of successful information systems have changed across these eras. By looking at the past and present, we are able to comment on how our understanding of success has evolved over time in research and practice. We discuss the inadequacy of IS success evaluation in practice. Finally, we offer four themes as calls for future action related to the research of information systems success.\n",
            "------------------------------------\n",
            "Title Jerusalem Lectures on Black Holes and Quantum Information\n",
            "Author [{'authorId': '102579897', 'name': 'D. Harlow'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract In these lectures I give an introduction to the quantum physics of black holes, including recent developments based on quantum information theory such as the rewall paradox and its various cousins. I also give an introduction to holography and the AdS/CFT correspondence, focusing on those aspects which are relevant for the black hole information problem.\n",
            "------------------------------------\n",
            "Title Graph Convolution over Pruned Dependency Trees Improves Relation Extraction\n",
            "Author [{'authorId': '49889487', 'name': 'Yuhao Zhang'}, {'authorId': '50531624', 'name': 'Peng Qi'}, {'authorId': '144783904', 'name': 'Christopher D. Manning'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2018\n",
            "Abstract Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.\n",
            "------------------------------------\n",
            "Title Verified quantum information scrambling\n",
            "Author [{'authorId': '143852035', 'name': 'K. Landsman'}, {'authorId': '3928432', 'name': 'C. Figgatt'}, {'authorId': '46869204', 'name': 'T. Schuster'}, {'authorId': '8609946', 'name': 'N. Linke'}, {'authorId': '2727848', 'name': 'B. Yoshida'}, {'authorId': '4138853', 'name': 'N. Yao'}, {'authorId': '50856718', 'name': 'C. Monroe'}]\n",
            "Venue Nature\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A Survey of Text Similarity Approaches\n",
            "Author [{'authorId': '1986886', 'name': 'W. H. Gomaa'}, {'authorId': '33838038', 'name': 'A. Fahmy'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract ABSTRACT Measuring the similarity between words, sentences, paragraphs and documents is an important component in various tasks such as information retrieval, document clustering, word-sense disambiguation, automatic essay scoring, short answer grading, machine translation and text summarization. This survey discusses the existing works on text similarity through partitioning them into three approaches; String-based, Corpus-based and Knowledge-based similarities. Furthermore, samples of combination between these similarities are presented. General Terms Text Mining, Natural Language Processing. Keywords BasedText Similarity, Semantic Similarity, String-Based Similarity, Corpus-Based Similarity, Knowledge-Based Similarity. NeedlemanWunsch 1. INTRODUCTION Text similarity measures play an increasingly important role in text related research and applications in tasks Nsuch as information retrieval, text classification, document clustering, topic detection, topic tracking, questions generation, question answering, essay scoring, short answer scoring, machine translation, text summarization and others. Finding similarity between words is a fundamental part of text similarity which is then used as a primary stage for sentence, paragraph and document similarities. Words can be similar in two ways lexically and semantically. Words are similar lexically if they have a similar character sequence. Words are similar semantically if they have the same thing, are opposite of each other, used in the same way, used in the same context and one is a type of another. DistanceLexical similarity is introduced in this survey though different String-Based algorithms, Semantic similarity is introduced through Corpus-Based and Knowledge-Based algorithms. String-Based measures operate on string sequences and character composition. A string metric is a metric that measures similarity or dissimilarity (distance) between two text strings for approximate string matching or comparison. Corpus-Based similarity is a semantic similarity measure that determines the similarity between words according to information gained from large corpora. Knowledge-Based similarity is a semantic similarity measure that determines the degree of similarity between words using information derived from semantic networks. The most popular for each type will be presented briefly. This paper is organized as follows: Section two presents String-Based algorithms by partitioning them into two types character-based and term-based measures. Sections three and four introduce Corpus-Based and knowledge-Based algorithms respectively. Samples of combinations between similarity algorithms are introduced in section five and finally section six presents conclusion of the survey.\n",
            "------------------------------------\n",
            "Title Psychological and Health Outcomes of Perceived Information Overload\n",
            "Author [{'authorId': '5381289', 'name': 'Shalini Misra'}, {'authorId': '1720057', 'name': 'D. Stokols'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract The rapid growth and transmission of information in the digital age poses new challenges for individuals coping with the onslaught of communications from multiple sources. This research (a) conceptualizes and measures perceived information overload from cyber-based and place-based sources, (b) tests the reliability and validity of a newly developed Perceived Information Overload Scale, and (c) tests hypotheses concerning the psychological and health outcomes of information overload. A repeated-measures panel study design was used to test the proposed hypotheses. Confirmatory factor analyses provided support for the hypothesized two-factor model of perceived information overload, encompassing cyber-based and place-based sources of stimulation. Hierarchical regression analyses indicated that higher levels of perceived cyber-based overload significantly predicted self-reports of greater stress, poorer health, and less time devoted to contemplative activities, controlling for age, gender, ethnicity, and baseline measures of stress and health status. Participants’ sensation-seeking levels were found to significantly moderate the relationships between cyber-based, place-based, and composite perceived information overload and stress. Directions for further study are discussed.\n",
            "------------------------------------\n",
            "Title Structural and Functional Brain Networks: From Connections to Cognition\n",
            "Author [{'authorId': '2963077', 'name': 'Hae-Jeong Park'}, {'authorId': '1737497', 'name': 'Karl J. Friston'}]\n",
            "Venue Science\n",
            "year 2013\n",
            "Abstract Background The human brain presents a puzzling and challenging paradox: Despite a fixed anatomy, characterized by its connectivity, its functional repertoire is vast, enabling action, perception, and cognition. This contrasts with organs like the heart that have a dynamic anatomy but just one function. The resolution of this paradox may reside in the brain's network architecture, which organizes local interactions to cope with diverse environmental demands—ensuring adaptability, robustness, resilience to damage, efficient message passing, and diverse functionality from a fixed structure. This review asks how recent advances in understanding brain networks elucidate the brain’s many-to-one (degenerate) function-structure relationships. In other words, how does diverse function arise from an apparently static neuronal architecture? We conclude that the emergence of dynamic functional connectivity, from static structural connections, calls for formal (computational) approaches to neuronal information processing that may resolve the dialectic between structure and function. Schematic of the multiscale hierarchical organization of brain networks. Brain function or cognition can be described as the global integration of local (segregated) neuronal operations that underlies hierarchical message passing among cortical areas, and which is facilitated by hierarchical modular network architectures. Advances Much of our understanding of brain connectivity rests on the way that it is measured and modeled. We consider two complementary approaches: the first has its basis in graph theory that aims to describe the network topology of (undirected) connections of the sort measured by noninvasive brain imaging of anatomical connections and functional connectivity (correlations) between remote sites. This is compared with model-based definitions of context-sensitive (directed) effective connectivity that are grounded in the biophysics of neuronal interactions. Recent topological network analyses of brain circuits suggest that modular and hierarchical structural networks are particularly suited for the functional integration of local (functionally specialized) neuronal operations that underlie cognition. Measurements of spontaneous activity reveal functional connectivity patterns that are similar to structural connectivity, suggesting that structural networks constrain functional networks. However, task-related responses that require context-sensitive integration disclose a divergence between function and structure that appears to rest mainly on long-range connections. In contrast to methods that describe network topology phenomenologically, model-based theoretical and computational approaches focus on the mechanisms of neuronal interactions that accommodate the dynamic reconfiguration of effective connectivity. We highlight the consilience between hierarchical topologies (based on structural and functional connectivity) and the effective connectivity that would be required for hierarchical message passing of the sort suggested by computational neuroscience. Outlook In summary, neuronal interactions represent dynamics on a fixed structural connectivity that underlie cognition and behavior. Such divergence of function from structure is, perhaps, the most intriguing property of the brain and invites intensive future research. By studying the dynamics and self-organization of functional networks, we may gain insight into the true nature of the brain as the embodiment of the mind. The repertoire of functional networks rests upon the (hidden) structural architecture of connections that enables hierarchical functional integration. Understanding these networks will require theoretical models of neuronal processing that underlies cognition. How rich functionality emerges from the invariant structural architecture of the brain remains a major mystery in neuroscience. Recent applications of network theory and theoretical neuroscience to large-scale brain networks have started to dissolve this mystery. Network analyses suggest that hierarchical modular brain networks are particularly suited to facilitate local (segregated) neuronal operations and the global integration of segregated functions. Although functional networks are constrained by structural connections, context-sensitive integration during cognition tasks necessarily entails a divergence between structural and functional networks. This degenerate (many-to-one) function-structure mapping is crucial for understanding the nature of brain networks. The emergence of dynamic functional networks from static structural connections calls for a formal (computational) approach to neuronal information processing that may resolve this dialectic between structure and function.\n",
            "------------------------------------\n",
            "Title Accounting Conservatism and Stock Price Crash Risk: Firm-Level Evidence\n",
            "Author [{'authorId': '2109160866', 'name': 'Jeong‐Bon Kim'}, {'authorId': '121860290', 'name': 'Liandong Zhang'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Using a large sample of U.S. firms over the period 1964–2007, we find that conditional conservatism is associated with the lower likelihood of a firm’s future stock price crashes. This finding holds for multiple measures of conditional conservatism and crash risk and it is robust to controlling for other known determinants of crash risk and firm fixed effects. Moreover, we find that the relation between conservatism and crash risk is more pronounced for firms with higher information asymmetries. Overall, our results are consistent with the notion that conditional conservatism limits managers’ incentive and ability to overstate performance and hide bad news from investors, which, in turn, reduces stock price crash risk.\n",
            "------------------------------------\n",
            "Title Missing Information Reconstruction of Remote Sensing Data: A Technical Review\n",
            "Author [{'authorId': '32309758', 'name': 'Huanfeng Shen'}, {'authorId': '50079922', 'name': 'Xinghua Li'}, {'authorId': '2055428402', 'name': 'Qing Cheng'}, {'authorId': '2055608950', 'name': 'Chao Zeng'}, {'authorId': '2109701270', 'name': 'Gang Yang'}, {'authorId': '26157918', 'name': 'Huifang Li'}, {'authorId': '9802604', 'name': 'Liangpei Zhang'}]\n",
            "Venue IEEE Geoscience and Remote Sensing Magazine\n",
            "year 2015\n",
            "Abstract Because of sensor malfunction and poor atmospheric conditions, there is usually a great deal of missing information in optical remote sensing data, which reduces the usage rate and hinders the follow-up interpretation. In the past decades, missing information reconstruction of remote sensing data has become an active research field, and a large number of algorithms have been developed. However, to the best of our knowledge, there has not, to date, been a study that has been aimed at expatiating and summarizing the current situation. This is therefore our motivation in this review. This paper provides an introduction to the principles and theories of missing information reconstruction of remote sensing data. We classify the established and emerging algorithms into four main categories, followed by a comprehensive comparison of them from both experimental and theoretical perspectives. This paper also predicts the promising future research directions.\n",
            "------------------------------------\n",
            "Title Smart Refugees: How Syrian Asylum Migrants Use Social Media Information in Migration Decision-Making\n",
            "Author [{'authorId': '39689636', 'name': 'R. Dekker'}, {'authorId': '107860383', 'name': 'G. Engbersen'}, {'authorId': '2086551257', 'name': 'Jeanine Klaver'}, {'authorId': '2085478269', 'name': 'Hanna Vonk'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Social media are increasingly popular channels of information on which migrants base their decisions on whether to migrate and the destinations where to settle. While social media offer a relatively cheap, easily accessible, and media-rich means of communication, their use is not without challenges for asylum migrants. Various studies describe issues with access and evaluation of the truthfulness of available information for this specific group of migrants. This article discusses social media use by asylum migrants prior to and during migration. This study is based on in-depth interviews with 54 Syrian asylum migrants who recently obtained refugee status in the Netherlands. Syrians were the largest group of migrants applying for asylum in European Union (EU) member states in 2015 and 2016. The findings show that the majority of Syrian asylum migrants have access to social media information before and during migration, often through the use of smartphones. Besides uneven access to technologies, fear of government surveillance restricts the smartphone use of asylum migrants. The results of this study indicate that Syrian asylum migrants prefer social media information that originates from existing social ties and information that is based on personal experiences. Generally, this information is considered more trustworthy. Asylum migrants use various strategies to validate rumors that are present on social media and come from unknown sources. These strategies include checking the source of information, validating information with trusted social ties, triangulation of online sources, and comparing information with their own experience.\n",
            "------------------------------------\n",
            "Title The End of Framing as we Know it … and the Future of Media Effects\n",
            "Author [{'authorId': '32998833', 'name': 'M. Cacciatore'}, {'authorId': '2994143', 'name': 'D. Scheufele'}, {'authorId': '39120083', 'name': 'S. Iyengar'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Framing has become one of the most popular areas of research for scholars in communication and a wide variety of other disciplines, such as psychology, behavioral economics, political science, and sociology. Particularly in the communication discipline, however, ambiguities surrounding how we conceptualize and therefore operationalize framing have begun to overlap with other media effects models to a point that is dysfunctional. This article provides an in-depth examination of framing and positions the theory in the context of recent evolutions in media effects research. We begin by arguing for changes in how communication scholars approach framing as a theoretical construct. We urge scholars to abandon the general term “framing” altogether and instead distinguish between different types of framing. We also propose that, as a field, we refocus attention on the concept's original theoretical foundations and, more important, the potential empirical contributions that the concept can make to our field and our understanding of media effects. Finally, we discuss framing as a bridge between paradigms as we shift from an era of mass communication to one of echo chambers, tailored information and microtargeting in the new media environment.\n",
            "------------------------------------\n",
            "Title A Review of “Doing Case Study Research: A Practical Guide for Beginning Researchers”\n",
            "Author [{'authorId': '1456396436', 'name': 'L. Vernon-Dotson'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract I n Doing Case Study Research: A Practical Guide for Beginning Researchers, Hancock and Algozzine provide a concrete, step-by-step process for beginning researchers who are conducting case study research. The authors claim that Doing Case Study Research is not a “case study research for dummies” (p. xii) manual, and I absolutely concur. They are successful in stripping away the theories and attacking case study research in a very rudimentary manner, hence providing readers a prescriptive approach. It is a practical look at doing case study research—a solid companion for those teaching, facilitating, or conducting introductory qualitative research. Doing Case Study Research is divided into three sections: “Foundations” (Chapters 1–2), “Stages of Doing Case Study Research” (Chapters 3–11), and “Putting It All Together” (Chapters 12–13). In the first part, Hancock and Algozzine provide insights into the purposes and processes of research, in general, and offer their readers an overview of basic types of qualitative and quantitative research. The authors fittingly provide the reader with guidance in selecting the appropriate research within the two broad traditions. Comprising 59 of the book’s 114 pages, the second section is truly the “nuts and bolts” of conducting case study research. In this section, the authors outline their prescriptive, step-by-step process, which spans from literature review and research design through data collection and interpretation and then ending with reporting and confirming the findings. Each chapter in this section is thorough, with just enough information as to not overwhelm novice researchers. For example, Chapter 4 (“Determining What We Know”) beautifully illustrates and iterates the rationale for the conceptual framework and outlines a seminal and well-documented process for writing a literature review. For instance, the authors suggest following Galvan’s (1999, 2009) key directions for writing literature reviews by first selecting a topic and identifying the literature to review followed by analyzing, criticizing, synthesizing, and documenting the literature. The final section focuses on preparing proposals and disseminating research. These last two chapters bring the book full circle by providing the reader with steps for the typical outlets of their completed work. This book is an easy, quick read and is very user friendly. Hancock and Algozzine offer a variety of cross-disciplinary examples from published works to support their basic process for doing case study research. For example, in Chapter 3 (“Setting the Stage”) the authors provide the readers with examples of published studies from researchers who utilized case study research through 18 brief descriptions of events, situations, programs, and activities across several disciplines including, but not limited to education, social work, counseling, technology, adult education, criminal justice, and psychology. At the conclusion of each chapter, the authors deliver questions (Content Review) and activities to facilitate understanding (Activities and Applications for Prospective Researchers). I greatly appreciated the attention to research design (Chapter 5: “Selecting a Design”); in many qualitative texts, this seems to be overlooked or lacking specificity within the context of case study research. I have reviewed several manuscripts submitted for publication where “case study research” was indicated as the “design.” It seems that beginning researchers (and some veterans) fail to realize that, as Hancock and Algozzine indicated, “[d]oing case study research means selecting a design that matches the disciplinary perspective of the investigation” (p. 37). Not only did the authors distinguish between the classifications, types, and orientations of case study research designs, they also provided 12 different examples that clearly illustrated these different designs. Although this is a practical guide for implementing case study research, a few weaknesses should be noted. First, Hancock and Algozzine make it sound easy. They do mention that qualitative research is a time-consuming task in the first section of the book; however, the time factor is not otherwise stressed. Further, the data analysis section just scratches the surface of what needs to be done to effectively interpret mass amounts of data typically gathered over a long period of time. With that said, the authors appropriately emphasize the need to remain focused on the research questions when sifting through the data—something both beginning and seasoned qualitative researchers tend to forget. Finally, a chapter on the uses, pros, and cons of qualitative data management systems versus just mentioning them in passing (Chapter 9: “Summarizing and Interpreting the Information”) may be helpful to novice researchers who may mistakenly believe that the software (e.g., NVivo, NUDIST, Atlis-ti) actually analyze the data with the click of a button. The lack of context and theory in Doing Case Study Research is both purposeful and effective. Hancock and Algozzine fill a gap in the literature with regard to case study research and their book makes a very useful accompaniment to qualitative research courses. It may not teach some old research dogs new tricks, but Doing Case Study Research is definitely a useful resource to pass along to more novice researchers.\n",
            "------------------------------------\n",
            "Title SpotFi: Decimeter Level Localization Using WiFi\n",
            "Author [{'authorId': '40657287', 'name': 'Manikanta Kotaru'}, {'authorId': '3256955', 'name': 'K. Joshi'}, {'authorId': '2061177', 'name': 'Dinesh Bharadia'}, {'authorId': '2546322', 'name': 'S. Katti'}]\n",
            "Venue Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication\n",
            "year 2015\n",
            "Abstract This paper presents the design and implementation of SpotFi, an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes, yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First, SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second, it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath.\n",
            "------------------------------------\n",
            "Title Pyramid Stereo Matching Network\n",
            "Author [{'authorId': '2936466', 'name': 'Jia-Ren Chang'}, {'authorId': '2143438143', 'name': 'Yonghao Chen'}]\n",
            "Venue 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year 2018\n",
            "Abstract Recent work has shown that depth estimation from a stereo pair of images can be formulated as a supervised learning task to be resolved with convolutional neural networks (CNNs). However, current architectures rely on patch-based Siamese networks, lacking the means to exploit context information for finding correspondence in ill-posed regions. To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision. The proposed approach was evaluated on several benchmark datasets. Our method ranked first in the KITTI 2012 and 2015 leaderboards before March 18, 2018. The codes of PSMNet are available at: https://github.com/JiaRenChang/PSMNet.\n",
            "------------------------------------\n",
            "Title Editorial - Big Data, Data Science, and Analytics: The Opportunity and Challenge for IS Research\n",
            "Author [{'authorId': '1700216', 'name': 'Ritu Agarwal'}, {'authorId': '144730302', 'name': 'V. Dhar'}]\n",
            "Venue Information systems research\n",
            "year 2014\n",
            "Abstract We address key questions related to the explosion of interest in the emerging fields of big data, analytics, and data science. We discuss the novelty of the fields and whether the underlying questions are fundamentally different, the strengths that the information systems IS community brings to this discourse, interesting research questions for IS scholars, the role of predictive and explanatory modeling, and how research in this emerging area should be evaluated for contribution and significance.\n",
            "------------------------------------\n",
            "Title The development of student feedback literacy: enabling uptake of feedback\n",
            "Author [{'authorId': '51458791', 'name': 'D. Carless'}, {'authorId': '3753458', 'name': 'D. Boud'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Abstract Student feedback literacy denotes the understandings, capacities and dispositions needed to make sense of information and use it to enhance work or learning strategies. In this conceptual paper, student responses to feedback are reviewed and a number of barriers to student uptake of feedback are discussed. Four inter-related features are proposed as a framework underpinning students’ feedback literacy: appreciating feedback; making judgments; managing affect; and taking action. Two well-established learning activities, peer feedback and analysing exemplars, are discussed to illustrate how this framework can be operationalized. Some ways in which these two enabling activities can be re-focused more explicitly towards developing students’ feedback literacy are elaborated. Teachers are identified as playing important facilitating roles in promoting student feedback literacy through curriculum design, guidance and coaching. The implications and conclusion summarise recommendations for teaching and set out an agenda for further research.\n",
            "------------------------------------\n",
            "Title Deep High-Resolution Representation Learning for Human Pose Estimation\n",
            "Author [{'authorId': '143819050', 'name': 'Ke Sun'}, {'authorId': '144025674', 'name': 'Bin Xiao'}, {'authorId': '1718355', 'name': 'Dong Liu'}, {'authorId': '1688516', 'name': 'Jingdong Wang'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2019\n",
            "Abstract In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.\n",
            "------------------------------------\n",
            "Title Characterizing nonclassical correlations via local quantum uncertainty.\n",
            "Author [{'authorId': '9830344', 'name': 'D. Girolami'}, {'authorId': '9875396', 'name': 'T. Tufarelli'}, {'authorId': '2922587', 'name': 'G. Adesso'}]\n",
            "Venue Physical Review Letters\n",
            "year 2012\n",
            "Abstract Quantum mechanics predicts that measurements of incompatible observables carry a minimum uncertainty which is independent of technical deficiencies of the measurement apparatus or incomplete knowledge of the state of the system. Nothing yet seems to prevent a single physical quantity, such as one spin component, from being measured with arbitrary precision. Here, we show that an intrinsic quantum uncertainty on a single observable is ineludible in a number of physical situations. When revealed on local observables of a bipartite system, such uncertainty defines an entire class of bona fide measures of nonclassical correlations. For the case of 2 × d systems, we find that a unique measure is defined, which we evaluate in closed form. We then discuss the role that these correlations, which are of the \"discord\" type, can play in the context of quantum metrology. We show in particular that the amount of discord present in a bipartite mixed probe state guarantees a minimum precision, as quantified by the quantum Fisher information, in the optimal phase estimation protocol.\n",
            "------------------------------------\n",
            "Title How to win in an Omnichannel world\n",
            "Author [{'authorId': '152466760', 'name': 'David R. Bell'}, {'authorId': '2192628', 'name': 'Santiago Gallino'}, {'authorId': '152142558', 'name': 'Antonio Moreno'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract The omnichannel environment presents new challenges and opportunities for both information and product fulfillment. While all retailers need to effectively and efficiently manage fulfillment and information provision, there are important nuances to how this happens, depending on where and how the retailer got started and what kinds of improvement create the most leverage. This article delivers a customer-focused framework showing how to win in the omni-channel environment through critical innovations in information delivery and product fulfillment. The framework emerged from our research with both traditional and nontraditional retailers. To thrive in the new environment, retailers of all stripes and origins need to deploy information and fulfillment strategies that reduce friction in every phase of the buying process. This means simultaneously providing, in a cost-effective and narrative-enhancing way\n",
            "------------------------------------\n",
            "Title RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems\n",
            "Author [{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2642200', 'name': 'Fuzheng Zhang'}, {'authorId': '2109656553', 'name': 'Jialin Wang'}, {'authorId': '2152527702', 'name': 'Miao Zhao'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '1697293', 'name': 'M. Guo'}]\n",
            "Venue International Conference on Information and Knowledge Management\n",
            "year 2018\n",
            "Abstract To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple \"ripples\" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.\n",
            "------------------------------------\n",
            "Title End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures\n",
            "Author [{'authorId': '1731657', 'name': 'Makoto Miwa'}, {'authorId': '143977268', 'name': 'Mohit Bansal'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2016\n",
            "Abstract We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components.\n",
            "------------------------------------\n",
            "Title A comparative analysis of international frameworks for 21st century competences: Implications for national curriculum policies\n",
            "Author [{'authorId': '144737149', 'name': 'J. Voogt'}, {'authorId': '1922607', 'name': 'N. P. Roblin'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract National curricula need to change drastically to comply with the competences needed for the 21st century. In this paper eight frameworks describing 21st century competences were analysed. A comprehensive search for information about 21st century competences was conducted across the official websites of the selected frameworks, resulting in 32 documents that were analysed in detail. Travers and Westbury’s framework of curriculum representations was used to determine horizontal and vertical consistency between the frameworks. The frameworks were compared on their underlying rationales and goals, their definition of 21st century competences, and the recommended strategies for the implementation and assessment of these skills in educational practice. In addition three international studies were examined to analyse how various countries (EU member states, OECD countries) and schools (SITES studies) deal (or not) with 21st century competences. The findings indicate a large extent of alignment between the frameworks about what 21st century competences are and why they are important (horizontal consistency), but intentions and practice seemed still far apart, indicating lack of vertical consistency. The implications of the implementation of 21st century competences in national curriculum policies are discussed and recommendations are provided.\n",
            "------------------------------------\n",
            "Title Therapeutic target database 2020: enriched resource for facilitating research and early development of targeted therapeutics\n",
            "Author [{'authorId': '2121402780', 'name': 'Yunxia Wang'}, {'authorId': '7671120', 'name': 'Song-zhao Zhang'}, {'authorId': '153196338', 'name': 'Fengcheng Li'}, {'authorId': '2118861134', 'name': 'Ying Zhou'}, {'authorId': '48378879', 'name': 'Ying Zhang'}, {'authorId': '1421836928', 'name': 'Zhengwen Wang'}, {'authorId': '152692066', 'name': 'Runyuan Zhang'}, {'authorId': '2146281359', 'name': 'Jiang Zhu'}, {'authorId': '1500526954', 'name': 'Yuxiang Ren'}, {'authorId': '2110747084', 'name': 'Ying Tan'}, {'authorId': '40300011', 'name': 'C. Qin'}, {'authorId': '2201629248', 'name': 'Yinghong Li'}, {'authorId': '2144456223', 'name': 'Xiaoxu Li'}, {'authorId': '2109199880', 'name': 'Yuzong Chen'}, {'authorId': '144571173', 'name': 'Feng Zhu'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2019\n",
            "Abstract Abstract Knowledge of therapeutic targets and early drug candidates is useful for improved drug discovery. In particular, information about target regulators and the patented therapeutic agents facilitates research regarding druggability, systems pharmacology, new trends, molecular landscapes, and the development of drug discovery tools. To complement other databases, we constructed the Therapeutic Target Database (TTD) with expanded information about (i) target-regulating microRNAs and transcription factors, (ii) target-interacting proteins, and (iii) patented agents and their targets (structures and experimental activity values if available), which can be conveniently retrieved and is further enriched with regulatory mechanisms or biochemical classes. We also updated the TTD with the recently released International Classification of Diseases ICD-11 codes and additional sets of successful, clinical trial, and literature-reported targets that emerged since the last update. TTD is accessible at http://bidd.nus.edu.sg/group/ttd/ttd.asp. In case of possible web connectivity issues, two mirror sites of TTD are also constructed (http://db.idrblab.org/ttd/ and http://db.idrblab.net/ttd/).\n",
            "------------------------------------\n",
            "Title Fairness for Non-Orthogonal Multiple Access in 5G Systems\n",
            "Author [{'authorId': '2193568', 'name': 'S. Timotheou'}, {'authorId': '1694913', 'name': 'I. Krikidis'}]\n",
            "Venue IEEE Signal Processing Letters\n",
            "year 2015\n",
            "Abstract In non-orthogonal multiple access (NOMA) downlink, multiple data flows are superimposed in the power domain and user decoding is based on successive interference cancellation. NOMA's performance highly depends on the power split among the data flows and the associated power allocation (PA) problem. In this letter, we study NOMA from a fairness standpoint and we investigate PA techniques that ensure fairness for the downlink users under i) instantaneous channel state information (CSI) at the transmitter, and ii) average CSI. Although the formulated problems are non-convex, we have developed low-complexity polynomial algorithms that yield the optimal solution in both cases considered.\n",
            "------------------------------------\n",
            "Title Comparison of co-expression measures: mutual information, correlation, and model based indices\n",
            "Author [{'authorId': '2150598496', 'name': 'Lin Song'}, {'authorId': '2566204', 'name': 'P. Langfelder'}, {'authorId': '144712285', 'name': 'S. Horvath'}]\n",
            "Venue BMC Bioinformatics\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
            "Author [{'authorId': '2111431444', 'name': 'Sijie Yan'}, {'authorId': '3331521', 'name': 'Yuanjun Xiong'}, {'authorId': '1807606', 'name': 'Dahua Lin'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2018\n",
            "Abstract \n",
            " \n",
            " Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title Granular Computing Approach to Two-Way Learning Based on Formal Concept Analysis in Fuzzy Datasets\n",
            "Author [{'authorId': '145738402', 'name': 'Weihua Xu'}, {'authorId': '2108743403', 'name': 'Wentao Li'}]\n",
            "Venue IEEE Transactions on Cybernetics\n",
            "year 2016\n",
            "Abstract The main task of granular computing (GrC) is about representing, constructing, and processing information granules. Information granules are formalized in many different approaches. Different formal approaches emphasize the same fundamental facet in different ways. In this paper, we propose a novel GrC method of machine learning by using formal concept description of information granules. Based on information granules, the model and mechanism of two-way learning system is constructed in fuzzy datasets. It is addressed about how to train arbitrary fuzzy information granules to become necessary, sufficient, and necessary and sufficient fuzzy information granules. Moreover, an algorithm of the presented approach is established, and the complexity of the algorithm is analyzed carefully. Finally, to interpret and help understand the theories and algorithm, a real-life case study is considered and experimental evaluation is performed by five datasets from the University of California-Irvine, which is valuable for applying these theories to deal with practical issues.\n",
            "------------------------------------\n",
            "Title Nonprice incentives and energy conservation\n",
            "Author [{'authorId': '12928935', 'name': 'O. Asensio'}, {'authorId': '48015350', 'name': 'M. Delmas'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2015\n",
            "Abstract Significance We investigate the effectiveness of nonprice incentives to motivate conservation behavior. We test whether tailored information about environmental and health damages produces behavior change in the residential electricity sector. In a randomized controlled trial with real-time appliance-level energy metering over 8 mo, we find that environment and health-based information strategies outperform monetary savings information to drive energy conservation. Environment and health-based messages, which communicate the environmental and public health externalities of electricity production—such as pounds of pollutants, childhood asthma, and cancer—motivated 8% energy savings versus control. This strategy was particularly effective on families with children, who achieved 19% energy savings. However, we do not study the persistence of these behavioral changes after the conclusion of the study. In the electricity sector, energy conservation through technological and behavioral change is estimated to have a savings potential of 123 million metric tons of carbon per year, which represents 20% of US household direct emissions in the United States. In this article, we investigate the effectiveness of nonprice information strategies to motivate conservation behavior. We introduce environment and health-based messaging as a behavioral strategy to reduce energy use in the home and promote energy conservation. In a randomized controlled trial with real-time appliance-level energy metering, we find that environment and health-based information strategies, which communicate the environmental and public health externalities of electricity production, such as pounds of pollutants, childhood asthma, and cancer, outperform monetary savings information to drive behavioral change in the home. Environment and health-based information treatments motivated 8% energy savings versus control and were particularly effective on families with children, who achieved up to 19% energy savings. Our results are based on a panel of 3.4 million hourly appliance-level kilowatt–hour observations for 118 residences over 8 mo. We discuss the relative impacts of both cost-savings information and environmental health messaging strategies with residential consumers.\n",
            "------------------------------------\n",
            "Title Communication dynamics in complex brain networks\n",
            "Author [{'authorId': '1387946952', 'name': 'Andrea Avena-Koenigsberger'}, {'authorId': '2440937', 'name': 'B. Mišić'}, {'authorId': '1694232', 'name': 'O. Sporns'}]\n",
            "Venue Nature Reviews Neuroscience\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Millimeter-Wave Vehicular Communication to Support Massive Automotive Sensing\n",
            "Author [{'authorId': '1790994', 'name': 'Junil Choi'}, {'authorId': '1800694', 'name': 'Vutha Va'}, {'authorId': '2998505', 'name': 'N. G. Prelcic'}, {'authorId': '38297861', 'name': 'R. Daniels'}, {'authorId': '2364974', 'name': 'C. Bhat'}, {'authorId': '1797630', 'name': 'R. Heath'}]\n",
            "Venue IEEE Communications Magazine\n",
            "year 2016\n",
            "Abstract As driving becomes more automated, vehicles are being equipped with more sensors generating even higher data rates. Radars are used for object detection, visual cameras as virtual mirrors, and LIDARs for generating high resolution depth associated range maps, all to enhance the safety and efficiency of driving. Connected vehicles can use wireless communication to exchange sensor data, allowing them to enlarge their sensing range and improve automated driving functions. Unfortunately, conventional technologies, such as DSRC and 4G cellular communication, do not support the gigabit-per-second data rates that would be required for raw sensor data exchange between vehicles. This article makes the case that mmWave communication is the only viable approach for high bandwidth connected vehicles. The motivations and challenges associated with using mmWave for vehicle-to-vehicle and vehicle-to-infrastructure applications are highlighted. A high-level solution to one key challenge - the overhead of mmWave beam training - is proposed. The critical feature of this solution is to leverage information derived from the sensors or DSRC as side information for the mmWave communication link configuration. Examples and simulation results show that the beam alignment overhead can be reduced by using position information obtained from DSRC.\n",
            "------------------------------------\n",
            "Title Revisiting Natural Gradient for Deep Networks\n",
            "Author [{'authorId': '1996134', 'name': 'Razvan Pascanu'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2013\n",
            "Abstract We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for training deep models: Hessian-Free (Martens, 2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et al., 2008). We describe how one can use unlabeled data to improve the generalization error obtained by natural gradient and empirically evaluate the robustness of the algorithm to the ordering of the training set compared to stochastic gradient descent. Finally we extend natural gradient to incorporate second order information alongside the manifold information and provide a benchmark of the new algorithm using a truncated Newton approach for inverting the metric matrix instead of using a diagonal approximation of it.\n",
            "------------------------------------\n",
            "Title Research on information systems failures and successes: Status update and future directions\n",
            "Author [{'authorId': '1724490', 'name': 'Yogesh Kumar Dwivedi'}, {'authorId': '1760915', 'name': 'D. Wastell'}, {'authorId': '1734224', 'name': 'Sven Laumer'}, {'authorId': '1804146', 'name': 'H. Henriksen'}, {'authorId': '144305675', 'name': 'M. Myers'}, {'authorId': '1698631', 'name': 'D. Bunker'}, {'authorId': '8518510', 'name': 'Amany R. Elbanna'}, {'authorId': '144092255', 'name': 'M. Ravishankar'}, {'authorId': '2948637', 'name': 'S. Srivastava'}]\n",
            "Venue Inf. Syst. Frontiers\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title ClinVar: improving access to variant interpretations and supporting evidence\n",
            "Author [{'authorId': '3218124', 'name': 'M. Landrum'}, {'authorId': '2108441407', 'name': 'Jennifer M. Lee'}, {'authorId': '2057961586', 'name': 'M. Benson'}, {'authorId': '2148612924', 'name': 'Garth R. Brown'}, {'authorId': '41170163', 'name': 'Chen Chao'}, {'authorId': '2238195', 'name': 'S. Chitipiralla'}, {'authorId': '2052182323', 'name': 'Baoshan Gu'}, {'authorId': '144951362', 'name': 'Jennifer Hart'}, {'authorId': '146499947', 'name': 'Douglas Hoffman'}, {'authorId': '50027016', 'name': 'W. Jang'}, {'authorId': '144755312', 'name': 'Karen Karapetyan'}, {'authorId': '1997190', 'name': 'K. Katz'}, {'authorId': '2107964129', 'name': 'Chunlei Liu'}, {'authorId': '35701310', 'name': 'Zenith Maddipatla'}, {'authorId': '50742796', 'name': 'A. Malheiro'}, {'authorId': '35421611', 'name': 'Kurt McDaniel'}, {'authorId': '3333288', 'name': 'M. Ovetsky'}, {'authorId': '35625261', 'name': 'George R. Riley'}, {'authorId': '2110530042', 'name': 'George Zhou'}, {'authorId': '145140882', 'name': 'J. B. Holmes'}, {'authorId': '8619885', 'name': 'B. Kattman'}, {'authorId': '1758049', 'name': 'D. Maglott'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2017\n",
            "Abstract Abstract ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) is a freely available, public archive of human genetic variants and interpretations of their significance to disease, maintained at the National Institutes of Health. Interpretations of the clinical significance of variants are submitted by clinical testing laboratories, research laboratories, expert panels and other groups. ClinVar aggregates data by variant-disease pairs, and by variant (or set of variants). Data aggregated by variant are accessible on the website, in an improved set of variant call format files and as a new comprehensive XML report. ClinVar recently started accepting submissions that are focused primarily on providing phenotypic information for individuals who have had genetic testing. Submissions may come from clinical providers providing their own interpretation of the variant (‘provider interpretation’) or from groups such as patient registries that primarily provide phenotypic information from patients (‘phenotyping only’). ClinVar continues to make improvements to its search and retrieval functions. Several new fields are now indexed for more precise searching, and filters allow the user to narrow down a large set of search results.\n",
            "------------------------------------\n",
            "Title Fused Matrix Factorization with Geographical and Social Influence in Location-Based Social Networks\n",
            "Author [{'authorId': '1801613', 'name': 'Chen-Kuang Cheng'}, {'authorId': '1702456', 'name': 'Haiqin Yang'}, {'authorId': '145310663', 'name': 'Irwin King'}, {'authorId': '1785083', 'name': 'Michael R. Lyu'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2012\n",
            "Abstract \n",
            " \n",
            " Recently, location-based social networks (LBSNs), such as Gowalla, Foursquare, Facebook, and Brightkite, etc., have attracted millions of users to share their social friendship and their locations via check-ins. The available check-in information makes it possible to mine users’ preference on locations and to provide favorite recommendations. Personalized Point-of-interest (POI) recommendation is a significant task in LBSNs since it can help targeted users explore their surroundings as well as help third-party developers to provide personalized services. To solve this task, matrix factorization is a promising tool due to its success in recommender systems. However, previously proposed matrix factorization (MF) methods do not explore geographical influence, e.g., multi-center check-in property, which yields suboptimal solutions for the recommendation. In this paper, to the best of our knowledge, we are the first to fuse MF with geographical and social influence for POI recommendation in LBSNs. We first capture the geographical influence via modeling the probability of a user’s check-in on a location as a Multi-center Gaussian Model (MGM). Next, we include social information and fuse the geographical influence into a generalized matrix factorization framework. Our solution to POI recommendation is efficient and scales linearly with the number of observations. Finally, we conduct thorough experiments on a large-scale real-world LBSNs dataset and demonstrate that the fused matrix factorization framework with MGM utilizes the distance information sufficiently and outperforms other state-of-the-art methods significantly.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title Evidence from internet search data shows information-seeking responses to news of local COVID-19 cases\n",
            "Author [{'authorId': '3715992', 'name': 'A. Bento'}, {'authorId': '2137957574', 'name': 'Thuy Nguyen'}, {'authorId': '117485281', 'name': 'Coady Wing'}, {'authorId': '1413140544', 'name': 'Felipe Lozano-Rojas'}, {'authorId': '36663090', 'name': 'Yong-Yeol Ahn'}, {'authorId': '4763866', 'name': 'K. Simon'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2020\n",
            "Abstract The COVID-19 outbreak is a global pandemic with community circulation in many countries, including the United States, with confirmed cases in all states. The course of this pandemic will be shaped by how governments enact timely policies and disseminate information and by how the public reacts to policies and information. Here, we examine information-seeking responses to the first COVID-19 case public announcement in a state. Using an event study framework for all US states, we show that such news increases collective attention to the crisis right away. However, the elevated level of attention is short-lived, even though the initial announcements are followed by increasingly strong policy measures. Specifically, searches for “coronavirus” increased by about 36% (95% CI: 27 to 44%) on the day immediately after the first case announcement but decreased back to the baseline level in less than a week or two. We find that people respond to the first report of COVID-19 in their state by immediately seeking information about COVID-19, as measured by searches for coronavirus, coronavirus symptoms, and hand sanitizer. On the other hand, searches for information regarding community-level policies (e.g., quarantine, school closures, testing) or personal health strategies (e.g., masks, grocery delivery, over-the-counter medications) do not appear to be immediately triggered by first reports. These results are representative of the study period being relatively early in the epidemic, and more-elaborate policy responses were not yet part of the public discourse. Further analysis should track evolving patterns of responses to subsequent flows of public information.\n",
            "------------------------------------\n",
            "Title Energy-Efficient Information and Communication Infrastructures in the Smart Grid: A Survey on Interactions and Open Issues\n",
            "Author [{'authorId': '1398876404', 'name': 'M. Erol-Kantarci'}, {'authorId': '144769367', 'name': 'H. Mouftah'}]\n",
            "Venue IEEE Communications Surveys and Tutorials\n",
            "year 2015\n",
            "Abstract Smart grid has modernized the way electricity is generated, transported, distributed, and consumed by integrating advanced sensing, communications, and control in the day-to-day operation of the grid. Electricity is a core utility for the functioning of society and for the services provided by information and communication technologies (ICTs). Several concepts of the smart grid, such as dynamic pricing, distributed generation, and demand management, have significantly impacted the operation of ICT services, in particular, communication networks and data centers. Ongoing energy-efficiency and operational expenditures reduction efforts in communication networks and data centers have gained another dimension with those smart grid concepts. In this paper, we provide a comprehensive survey on the smart grid-driven approaches in energy-efficient communications and data centers, and the interaction between smart grid and information and communication infrastructures. Although the studies on smart grid, energy-efficient communications, and green data centers have been separately surveyed in previous studies, to this end, research that falls in the intersection of those fields has not been properly classified and surveyed yet. We start our survey by providing background information on the smart grid and continue with surveying smart grid-driven approaches in energy-efficient communication systems, followed by energy, cost and emission minimizing approaches in data centers, and the corresponding cloud network infrastructure. We discuss the open issues in smart grid-driven approaches in ICTs and point some important research directions such as the distributed renewable energy generation capability-coupled communication infrastructures, optimum energy-efficient network design for the smart grid environment, the impact of green communication techniques on the reliability and latency requirements of smart grid data, workload consolidation with smart grid-awareness, and many more.\n",
            "------------------------------------\n",
            "Title PubChem in 2021: new data content and improved web interfaces\n",
            "Author [{'authorId': '49899890', 'name': 'Sunghwan Kim'}, {'authorId': '2155099762', 'name': 'Jie Chen'}, {'authorId': '1797121', 'name': 'Tiejun Cheng'}, {'authorId': '3349472', 'name': 'A. Gindulyte'}, {'authorId': '2153098586', 'name': 'Jia He'}, {'authorId': '2805841', 'name': 'Siqian He'}, {'authorId': '2108047195', 'name': 'Qingliang Li'}, {'authorId': '3340459', 'name': 'B. Shoemaker'}, {'authorId': '39689316', 'name': 'P. Thiessen'}, {'authorId': '2110705813', 'name': 'Bo Yu'}, {'authorId': '1765354', 'name': 'L. Zaslavsky'}, {'authorId': '2151809519', 'name': 'Jian Zhang'}, {'authorId': '145600821', 'name': 'Evan E. Bolton'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2020\n",
            "Abstract Abstract PubChem (https://pubchem.ncbi.nlm.nih.gov) is a popular chemical information resource that serves the scientific community as well as the general public, with millions of unique users per month. In the past two years, PubChem made substantial improvements. Data from more than 100 new data sources were added to PubChem, including chemical-literature links from Thieme Chemistry, chemical and physical property links from SpringerMaterials, and patent links from the World Intellectual Properties Organization (WIPO). PubChem's homepage and individual record pages were updated to help users find desired information faster. This update involved a data model change for the data objects used by these pages as well as by programmatic users. Several new services were introduced, including the PubChem Periodic Table and Element pages, Pathway pages, and Knowledge panels. Additionally, in response to the coronavirus disease 2019 (COVID-19) outbreak, PubChem created a special data collection that contains PubChem data related to COVID-19 and the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).\n",
            "------------------------------------\n",
            "Title Advances in cognitive theory and therapy: the generic cognitive model.\n",
            "Author [{'authorId': '145373715', 'name': 'A. Beck'}, {'authorId': '4828265', 'name': 'Emily A P Haigh'}]\n",
            "Venue Annual Review of Clinical Psychology\n",
            "year 2014\n",
            "Abstract For over 50 years, Beck's cognitive model has provided an evidence-based way to conceptualize and treat psychological disorders. The generic cognitive model represents a set of common principles that can be applied across the spectrum of psychological disorders. The updated theoretical model provides a framework for addressing significant questions regarding the phenomenology of disorders not explained in previous iterations of the original model. New additions to the theory include continuity of adaptive and maladaptive function, dual information processing, energizing of schemas, and attentional focus. The model includes a theory of modes, an organization of schemas relevant to expectancies, self-evaluations, rules, and memories. A description of the new theoretical model is followed by a presentation of the corresponding applied model, which provides a template for conceptualizing a specific disorder and formulating a case. The focus on beliefs differentiates disorders and provides a target for treatment. A variety of interventions are described.\n",
            "------------------------------------\n",
            "Title Cognitive Mechanisms of Treatment in Depression\n",
            "Author [{'authorId': '34895627', 'name': 'J. Roiser'}, {'authorId': '49691586', 'name': 'R. Elliott'}, {'authorId': '144766323', 'name': 'B. Sahakian'}]\n",
            "Venue Neuropsychopharmacology\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Pengaruh Investasi Dan Ekspor Terhadap Pertumbuhan Ekonomi Serta Penyerapan Tenaga Kerja Provinsi Kalimantan Timur\n",
            "Author [{'authorId': '2139880606', 'name': 'M. Taufik'}, {'authorId': '104257459', 'name': 'Eny Rochaida'}, {'authorId': '81786523', 'name': 'Fitriadi Fitriadi'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This research was aims to know the influence of investment and exports on economic growth and Labor recruitment of East Kalimantan Province. The research was analyzed by using model of analysis two lanes performed with SPSS software version 11.5 with data retrival based on primary data of investment, exports, economic growth and labor from BPS of East Kalimantan from 2003 until 2011. Based on analysis way substructure 1 model through F test, showed that the independent variables (investment and exports) have a significant influence on economic growth because the value of the probability of the F-statistic less than standard real (0,008 < 0,08). So it can be said that both free variables used in the model has a real influence on economic growth at 5% level of trust (a=0,05). On the sub structure 2 model, indicates that the three of independent variables (investment, exports, economic growth) has significant effects on the labor recruitment  because probability F statistic’s value is less than real standard used by (0,000 < 0,05). So it can be said which this third free variable has a significant influence to labor reqruitment at 5% level of trust (a=0,05).\n",
            "------------------------------------\n",
            "Title Institutions and Information Environment of Chinese Listed Firms\n",
            "Author [{'authorId': '2217909', 'name': 'Joseph D. Piotroski'}, {'authorId': '143907911', 'name': 'T. Wong'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This paper describes the financial reporting practices and information environment of Chinese listed firms and documents the influence that local and country-level institutions have on reporting incentives and the resultant information environment. We identify four key institutional arrangements that influence the supply and demand for information about Chinese listed firms: the State’s controlling ownership of listed firms, the government’s control of capital markets, the limited protection of property rights and weak market institutions, a lack of independence of local auditors, and the importance of social networks and political connections. The paper concludes by discussing how actual and potential changes in these institutional arrangements would likely influence China’s information environment.\n",
            "------------------------------------\n",
            "Title The longitudinal integrated database for health insurance and labour market studies (LISA) and its use in medical research\n",
            "Author [{'authorId': '144310215', 'name': 'J. Ludvigsson'}, {'authorId': '4255670', 'name': 'P. Svedberg'}, {'authorId': '3852176', 'name': 'O. Olén'}, {'authorId': '10442672', 'name': 'G. Bruze'}, {'authorId': '2918935', 'name': 'M. Neovius'}]\n",
            "Venue European Journal of Epidemiology\n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models\n",
            "Author [{'authorId': '39055225', 'name': 'Jun Wang'}, {'authorId': '3469209', 'name': 'Lantao Yu'}, {'authorId': '2108309275', 'name': 'Weinan Zhang'}, {'authorId': '2087062414', 'name': 'Yu Gong'}, {'authorId': '50125871', 'name': 'Yinghui Xu'}, {'authorId': '2894465', 'name': 'Benyou Wang'}, {'authorId': '47243067', 'name': 'P. Zhang'}, {'authorId': '37510526', 'name': 'Dell Zhang'}]\n",
            "Venue Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year 2017\n",
            "Abstract This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96% on Precision@5 and 15.50% on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering.\n",
            "------------------------------------\n",
            "Title The Functional Art: An introduction to information graphics and visualization\n",
            "Author [{'authorId': '32902815', 'name': 'A. Cairo'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Unlike any time before in our lives, we have access to vast amounts of free information. With the right tools, we can start to make sense of all this data to see patterns and trends that would otherwise be invisible to us. By transforming numbers into graphical shapes, we allow readers to understand the stories those numbers hide. In this practical introduction to understanding and using information graphics, youll learn how to use data visualizations as tools to see beyond lists of numbers and variables and achieve new insights into the complex world around us. Regardless of the kind of data youre working withbusiness, science, politics, sports, or even your own personal financesthis book will show you how to use statistical charts, maps, and explanation diagrams to spot the stories in the data and learn new things from it. Youll also get to peek into the creative process of some of the worlds most talented designers and visual journalists, including Cond Nast Travelers John Grimwade, National Geographic Magazines Fernando Baptista, The New York Times Steve Duenes, The Washington Posts Hannah Fairfield, Hans Rosling of the Gapminder Foundation, Stanfords Geoff McGhee, and European superstars Moritz Stefaner, Jan Willem Tulp, Stefanie Posavec, and Gregor Aisch. The book also includes a DVD-ROM containing over 90 minutes of video lessons that expand on core concepts explained within the book and includes even more inspirational information graphics from the worlds leading designers. The first book to offer a broad, hands-on introduction to information graphics and visualization, The Functional Art reveals: Why data visualization should be thought of as functional art rather than fine art How to use color, type, and other graphic tools to make your information graphics more effective, not just better looking The science of how our brains perceive and remember information Best practices for creating interactive information graphics A comprehensive look at the creative process behind successful information graphics An extensive gallery of inspirational work from the worlds top designers and visual artists On the DVD-ROM: In this introductory video course on information graphics, Alberto Cairo goes into greater detail with even more visual examples of how to create effective information graphics that function as practical tools for aiding perception. Youll learn how to: incorporate basic design principles in your visualizations, create simple interfaces for interactive graphics, and choose the appropriate type of graphic forms for your data. Cairo also deconstructs successful information graphics from The New York Times and National Geographic magazine with sketches and images not shown in the book.\n",
            "------------------------------------\n",
            "Title Nudging Energy Efficiency Behavior: The Role of Information Labels\n",
            "Author [{'authorId': '49251385', 'name': 'R. Newell'}, {'authorId': '4894037', 'name': 'J. Siikamäki'}]\n",
            "Venue Journal of the Association of Environmental and Resource Economists\n",
            "year 2013\n",
            "Abstract We use choice experiments and randomized information treatments to study the effectiveness of alternative energy efficiency labels in guiding households’ energy efficiency decisions. We disentangle the relative importance of different types of information and distinguish it from intertemporal behavior. We find that insufficient information can lead to considerable undervaluation of energy efficiency. Simple information on the monetary value of energy savings was the most important element guiding cost-efficient energy efficiency investments, with information on physical energy use and carbon dioxide emissions having additional but lesser importance. The degree to which the current US EnergyGuide label guided cost-efficient decisions depends on the discount rate. Using elicited individual discount rates, the current EnergyGuide label came very close to guiding cost-efficient decisions. Using a uniform 5% discount rate, the current label led to one-third undervaluation of energy efficiency. Our results reinforce the centrality of discounting in understanding individual behavior and guiding policy.\n",
            "------------------------------------\n",
            "Title Rating Agencies in the Face of Regulation\n",
            "Author [{'authorId': '34362888', 'name': 'C. Opp'}, {'authorId': '35002483', 'name': 'Marcus M. Opp'}, {'authorId': '145705520', 'name': 'M. Harris'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This paper develops a theoretical framework to shed light on variation in credit rating standards over time and across asset classes. Ratings issued by credit rating agencies serve a dual role: they provide information to investors and are used to regulate institutional investors. We show that introducing rating-contingent regulation that favors highly rated securities may increase or decrease rating informativeness, but unambiguously increases the volume of highly rated securities. If the regulatory advantage of highly rated securities is sufficiently large, delegated information acquisition is unsustainable, since the rating agency prefers to facilitate regulatory arbitrage by inflating ratings. Our model relates rating informativeness to the quality distribution of issuers, the complexity of assets, and issuers' outside options. We reconcile our results with the existing empirical literature and highlight new, testable implications, such as repercussions of the Dodd-Frank Act.\n",
            "------------------------------------\n",
            "Title Deep Collaborative Filtering via Marginalized Denoising Auto-encoder\n",
            "Author [{'authorId': '39541577', 'name': 'Sheng Li'}, {'authorId': '2605045', 'name': 'Jaya Kawale'}, {'authorId': '46956675', 'name': 'Y. Fu'}]\n",
            "Venue International Conference on Information and Knowledge Management\n",
            "year 2015\n",
            "Abstract Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.\n",
            "------------------------------------\n",
            "Title Correlates of Health-Related Social Media Use Among Adults\n",
            "Author [{'authorId': '2006675', 'name': 'R. Thackeray'}, {'authorId': '6585390', 'name': 'B. Crookston'}, {'authorId': '3864835', 'name': 'J. West'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2013\n",
            "Abstract Background Sixty percent of Internet users report using the Internet to look for health information. Social media sites are emerging as a potential source for online health information. However, little is known about how people use social media for such purposes. Objectives The purpose of this study was two-fold: (1) to establish the frequency of various types of online health-seeking behaviors, and (2) to identify correlates of 2 health-related online activities, social networking sites (SNS) for health-related activities and consulting online user-generated content for answers about health care providers, health facilities, or medical treatment. Methods The study consisted of a telephone survey of 1745 adults who reported going online to look for health-related information. Four subscales were created to measure use of online resources for (1) using SNS for health-related activities; (2) consulting online rankings and reviews of doctors, hospitals or medical facilities, and drugs or medical treatments; (3) posting a review online of doctors, hospitals or medical facilities, and drugs or medical treatments, and (4) posting a comment or question about health or medical issues on various social media. Univariate and multivariate logistic regression analyses were performed. Results Respondents consulted online rankings or reviews (41.15%), used SNS for health (31.58%), posted reviews (9.91%), and posted a comment, question, or information (15.19%). Respondents with a chronic disease were nearly twice as likely to consult online rankings (odds ratio [OR] 2.09, 95% CI 1.66-2.63, P<.001). Lower odds of consulting online reviews were associated with less formal education (OR 0.49, 95% CI 0.37-0.65, P<.001) and being male (OR 0.71, 95% CI 0.57-0.87, P<.001). Respondents with higher incomes were 1.5 times as likely to consult online rankings or reviews (OR 1.49, 95% CI 0.10-2.24, P=.05), than respondents with a regular provider (OR 2.05, 95% CI 1.52-2.78, P<.001), or living in an urban/suburban location (OR 1.61, 95% CI 1.17-2.22, P<.001). Older respondents were less likely to use SNS for health-related activities (OR 0.96, 95% CI 0.95-0.97, P<.001), as were males (OR 0.70, 95% CI 0.56-0.87, P<.001), whereas respondents with a regular provider had nearly twice the likelihood of using SNS for health-related activities (OR 1.89, 95% CI 1.43-2.52, P<.001). Conclusions People are using social media for seeking health information. However, individuals are more likely to consume information than they are to contribute to the dialog. The inherent value of “social” in social media is not being captured with online health information seeking. People with a regular health care provider, chronic disease, and those in younger age groups are more likely to consult online rankings and reviews and use SNS for health-related activities.\n",
            "------------------------------------\n",
            "Title The eICU Collaborative Research Database, a freely available multi-center database for critical care research\n",
            "Author [{'authorId': '40541154', 'name': 'T. Pollard'}, {'authorId': '28972636', 'name': 'A. Johnson'}, {'authorId': '5719984', 'name': 'J. Raffa'}, {'authorId': '143605744', 'name': 'L. Celi'}, {'authorId': '1978710', 'name': 'R. Mark'}, {'authorId': '4337300', 'name': 'O. Badawi'}]\n",
            "Venue Scientific Data\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Social Media and Clinical Care: Ethical, Professional, and Social Implications\n",
            "Author [{'authorId': '4347924', 'name': 'Katherine C. Chretien'}, {'authorId': '2493644', 'name': 'T. Kind'}]\n",
            "Venue Circulation\n",
            "year 2013\n",
            "Abstract It is an exciting time to practice medicine during our digital “coming of age.” Social media, the freely available Web-based platforms that facilitate information sharing of user-generated content, such as social networking sites, media-sharing sites, blogs, microblogs, and wikis, have transformed the way we communicate as a society. Through community building, message amplification, rapid dissemination, and engagement, social media has changed our interactions with others and, by direct consequence, our relationships. For health care, this represents a veritable social revolution. 1\n",
            "\n",
            "Indeed, medicine is constantly evolving to adapt to new technologies. These advances have led to new therapies, diagnostic tools, and ways of communicating. As physicians and lifelong learners, it has been imperative to embrace the new when it has meant better and more efficient patient care while holding on to the stable tenets of medicine that root our profession: humanism, integrity, ethics, professionalism, and trust.\n",
            "\n",
            "Patients have been active on social media to find health information, find support through discussion groups and forums, and chronicle their illness journeys.2 Naturally, they are also interested in using social media to facilitate communication between themselves and their providers. In a survey of patients of an outpatient family practice clinic, 56% wanted their providers to use social media for appointment setting and reminders, diagnostic test results reporting, health information sharing, prescription notifications, and answering general questions.3 For those patients who do not use social media, many would start if they knew that they could connect with their providers there.3\n",
            "\n",
            "Physicians are also exploring ways to use social media, both personally and professionally, although personal use is more common.4–6 Some physicians use social media professionally to find and share health information, communicate/network with colleagues and trainees, disseminate their research, market their practice, or engage in health advocacy. In …\n",
            "------------------------------------\n",
            "Title Learning Semantic Representations of Users and Products for Document Level Sentiment Classification\n",
            "Author [{'authorId': '39483833', 'name': 'Duyu Tang'}, {'authorId': '152277111', 'name': 'Bing Qin'}, {'authorId': '40282288', 'name': 'Ting Liu'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2015\n",
            "Abstract Neural network methods have achieved promising results for sentiment classification of text. However, these models only use semantics of texts, while ignoring users who express the sentiment and products which are evaluated, both of which have great influences on interpreting the sentiment of text. In this paper, we address this issue by incorporating userand productlevel information into a neural network approach for document level sentiment classification. Users and products are modeled using vector space models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, productand documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1.\n",
            "------------------------------------\n",
            "Title An Empirical Examination of the Antecedents and Consequences of Contribution Patterns in Crowd-Funded Markets\n",
            "Author [{'authorId': '2556694', 'name': 'Gordon Burtch'}, {'authorId': '143888439', 'name': 'A. Ghose'}, {'authorId': '2628487', 'name': 'S. Wattal'}]\n",
            "Venue Information systems research\n",
            "year 2013\n",
            "Abstract Crowd-funded markets have recently emerged as a novel source of capital for entrepreneurs. As the economic potential of these markets is now being realized, they are beginning to go mainstream, a trend reflected by the explicit attention crowdfunding has received in the American Jobs Act as a potential avenue for economic growth, as well as the recent focus that regulators such as the U.S. Securities and Exchange Commission have placed upon it. Although the formulation of regulation and policy surrounding crowd-funded markets is becoming increasingly important, the behavior of crowdfunders, an important aspect that must be considered in this formulation effort, is not yet well understood. A key factor that can influence the behavior of crowd funders is information on prior contribution behavior, including the amount and timing of others’ contributions, which is published for general consumption. With that in mind, in this study, we empirically examine social influence in a crowd-funded marketplace for online journalism projects, employing a unique data set that incorporates contribution events and Web traffic statistics for approximately 100 story pitches. This data set allows us to examine both the antecedents and consequences of the contribution process. First, noting that digital journalism is a form of public good, we evaluate the applicability of two competing classes of economic models that explain private contribution toward public goods in the presence of social information: substitution models and reinforcement models. We also propose a new measure that captures both the amount and the timing of others’ contribution behavior: contribution frequency (dollars per unit time). We find evidence in support of a substitution model, which suggests a partial crowding-out effect, where contributors may experience a decrease in their marginal utility from making a contribution as it becomes less important to the recipient. Further, we find that the duration of funding and, more importantly, the degree of exposure that a pitch receives over the course of the funding process, are positively associated with readership upon the story’s publication. This appears to validate the widely held belief that a key benefit of the crowdfunding model is the potential it offers for awareness and attention-building around causes and ventures. This last aspect is a major contribution of the study, as it demonstrates a clear linkage between marketing effort and the success of crowd-funded projects.\n",
            "------------------------------------\n",
            "Title The Impact of Electronic Patient Portals on Patient Care: A Systematic Review of Controlled Trials\n",
            "Author [{'authorId': '2756660', 'name': 'E. Ammenwerth'}, {'authorId': '1398028045', 'name': 'P. Schnell-Inderst'}, {'authorId': '1899309796', 'name': 'A. Hoerbst'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2012\n",
            "Abstract Background Modern information technology is changing and provides new challenges to health care. The emergence of the Internet and the electronic health record (EHR) has brought new opportunities for patients to play a more active role in his/her care. Although in many countries patients have the right to access their clinical information, access to clinical records electronically is not common. Patient portals consist of provider-tethered applications that allow patients to electronically access health information that are documented and managed by a health care institution. Although patient portals are already being implemented, it is still unclear in which ways these technologies can influence patient care. Objective To systematically review the available evidence on the impact of electronic patient portals on patient care. Methods A systematic search was conducted using PubMed and other sources to identify controlled experimental or quasi-experimental studies on the impact of patient portals that were published between 1990 and 2011. A total of 1,306 references from all the publication hits were screened, and 13 papers were retrieved for full text analysis. Results We identified 5 papers presenting 4 distinct studies. There were no statistically significant changes between intervention and control group in the 2 randomized controlled trials investigating the effect of patient portals on health outcomes. Significant changes in the patient portal group, compared to a control group, could be observed for the following parameters: quicker decrease in office visit rates and slower increase in telephone contacts; increase in number of messages sent; changes of the medication regimen; and better adherence to treatment. Conclusions The number of available controlled studies with regard to patient portals is low. Even when patient portals are often discussed as a way to empower patients and improve quality of care, there is insufficient evidence to support this assumption.\n",
            "------------------------------------\n",
            "Title Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks\n",
            "Author [{'authorId': '2032788', 'name': 'Massimo Quadrana'}, {'authorId': '1713164', 'name': 'Alexandros Karatzoglou'}, {'authorId': '2507883', 'name': 'Balázs Hidasi'}, {'authorId': '1709519', 'name': 'P. Cremonesi'}]\n",
            "Venue ACM Conference on Recommender Systems\n",
            "year 2017\n",
            "Abstract Session-based recommendations are highly relevant in many modern on-line services (e.g. e-commerce, video streaming) and recommendation settings. Recently, Recurrent Neural Networks have been shown to perform very well in session-based settings. While in many session-based recommendation domains user identifiers are hard to come by, there are also domains in which user profiles are readily available. We propose a seamless way to personalize RNN models with cross-session information transfer and devise a Hierarchical RNN model that relays end evolves latent hidden states of the RNNs across user sessions. Results on two industry datasets show large improvements over the session-only RNNs.\n",
            "------------------------------------\n",
            "Title ‘It's on my iPhone’: attitudes to the use of mobile computing devices in medical education, a mixed-methods study\n",
            "Author [{'authorId': '2055946593', 'name': 'Sean Wallace'}, {'authorId': '2093410730', 'name': 'Marcia L Clark'}, {'authorId': '48374314', 'name': 'J. White'}]\n",
            "Venue BMJ Open\n",
            "year 2012\n",
            "Abstract Objective The last decade has seen the introduction of new technology which has transformed many aspects of our culture, commerce, communication and education. This study examined how medical teachers and learners are using mobile computing devices such as the iPhone in medical education and practice, and how they envision them being used in the future. Design Semistructured interviews were conducted with medical students, residents and faculty to examine participants’ attitudes about the current and future use of mobile computing devices in medical education and practice. A thematic approach was used to summarise ideas and concepts expressed, and to develop an online survey. A mixed methods approach was used to integrate qualitative and quantitative findings. Setting and participants Medical students, residents and faculty at a large Canadian medical school in 2011. Results Interviews were conducted with 18 participants (10 students, 7 residents and 1 faculty member). Only 213 participants responded to the online survey (76 students, 65 residents and 41 faculty members). Over 85% of participants reported using a mobile-computing device. The main uses described for mobile devices related to information management, communication and time management. Advantages identified were portability, flexibility, access to multimedia and the ability to look up information quickly. Challenges identified included: superficial learning, not understanding how to find good learning resources, distraction, inappropriate use and concerns about access and privacy. Both medical students and physicians expressed the view that the use of these devices in medical education and practice will increase in the future. Conclusions This new technology offers the potential to enhance learning and patient care, but also has potential problems associated with its use. It is important for leadership in medical schools and healthcare organisations to set the agenda in this rapidly developing area to maximise the benefits of this powerful new technology while avoiding unintended consequences.\n",
            "------------------------------------\n",
            "Title New approach for understanding genome variations in KEGG\n",
            "Author [{'authorId': '87339519', 'name': 'M. Kanehisa'}, {'authorId': '46657535', 'name': 'Yoko Sato'}, {'authorId': '3222501', 'name': 'Miho Furumichi'}, {'authorId': '16058014', 'name': 'Kanae Morishima'}, {'authorId': '2199255', 'name': 'M. Tanabe'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2018\n",
            "Abstract Abstract KEGG (Kyoto Encyclopedia of Genes and Genomes; https://www.kegg.jp/ or https://www.genome.jp/kegg/) is a reference knowledge base for biological interpretation of genome sequences and other high-throughput data. It is an integrated database consisting of three generic categories of systems information, genomic information and chemical information, and an additional human-specific category of health information. KEGG pathway maps, BRITE hierarchies and KEGG modules have been developed as generic molecular networks with KEGG Orthology nodes of functional orthologs so that KEGG pathway mapping and other procedures can be applied to any cellular organism. Unfortunately, however, this generic approach was inadequate for knowledge representation in the health information category, where variations of human genomes, especially disease-related variations, had to be considered. Thus, we have introduced a new approach where human gene variants are explicitly incorporated into what we call ‘network variants’ in the recently released KEGG NETWORK database. This allows accumulation of knowledge about disease-related perturbed molecular networks caused not only by gene variants, but also by viruses and other pathogens, environmental factors and drugs. We expect that KEGG NETWORK will become another reference knowledge base for the basic understanding of disease mechanisms and practical use in clinical sequencing and drug development.\n",
            "------------------------------------\n",
            "Title Prefrontal–hippocampal interactions in episodic memory\n",
            "Author [{'authorId': '1823860', 'name': 'H. Eichenbaum'}]\n",
            "Venue Nature Reviews Neuroscience\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Does Mandatory IFRS Adoption Improve Information Comparability?\n",
            "Author [{'authorId': '122754022', 'name': 'Rita W. Y. Yip'}, {'authorId': '49419153', 'name': 'Danqing Young'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract ABSTRACT: This study examines whether the mandatory adoption of International Financial Reporting Standards (IFRS) in the European Union significantly improves information comparability in 17 European countries. We employ three proxies—the similarity of accounting functions that translate economic events into accounting data, the degree of information transfer, and the similarity of the information content of earnings and of the book value of equity—to measure information comparability. Our results suggest that mandatory IFRS adoption improves cross-country information comparability by making similar things look more alike without making different things look less different. Our results also suggest that both accounting convergence and higher quality information under IFRS are the likely drivers of the comparability improvement. In addition, we find some evidence that cross-country comparability improvement is affected by firms' institutional environment. Data Availability: Data are available from commerc...\n",
            "------------------------------------\n",
            "Title Feeling Blue? Go Online: An Empirical Study of Social Support among Patients\n",
            "Author [{'authorId': '46518162', 'name': 'L. Yan'}, {'authorId': '144176421', 'name': 'Yong Tan'}]\n",
            "Venue Information systems research\n",
            "year 2014\n",
            "Abstract In this paper, we investigate whether social support exchanged in an online healthcare community benefits patients' mental health. We propose a nonhomogeneous Partially Observed Markov Decision Process POMDP model to examine the latent health outcomes for online health community members. The transition between different health states is modeled as a probability function that incorporates different forms of social support that patients exchange via discussion board posts. We find that patients benefit from learning from others and that their participation in the online community helps them to improve their health and to better engage in their disease self-management process. Our results also reveal differences in the influence of various forms of social support exchanged on the evolution of patients' health conditions. We find evidence that informational support is the most prevalent type in the online healthcare community. Nevertheless, emotional support plays the most significant role in helping patients move to a healthier state. Overall, the influence of social support is found to vary depending on patients' health conditions. Finally, we demonstrate that our proposed POMDP model can provide accurate predictions for patients' health states and can be used to recover missing or unavailable information on patients' health conditions.\n",
            "------------------------------------\n",
            "Title Exposure to opposing views on social media can increase political polarization\n",
            "Author [{'authorId': '11583899', 'name': 'C. Bail'}, {'authorId': '51291213', 'name': 'Lisa P. Argyle'}, {'authorId': '16434274', 'name': 'Taylor W. Brown'}, {'authorId': '51313884', 'name': 'John P. Bumpus'}, {'authorId': '31091886', 'name': 'Haohan Chen'}, {'authorId': '51310396', 'name': 'M. F. Hunzaker'}, {'authorId': '2118350570', 'name': 'Jaemin Lee'}, {'authorId': '34551639', 'name': 'M. Mann'}, {'authorId': '46173646', 'name': 'Friedolin Merhout'}, {'authorId': '6974508', 'name': 'A. Volfovsky'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2018\n",
            "Abstract Significance Social media sites are often blamed for exacerbating political polarization by creating “echo chambers” that prevent people from being exposed to information that contradicts their preexisting beliefs. We conducted a field experiment that offered a large group of Democrats and Republicans financial compensation to follow bots that retweeted messages by elected officials and opinion leaders with opposing political views. Republican participants expressed substantially more conservative views after following a liberal Twitter bot, whereas Democrats’ attitudes became slightly more liberal after following a conservative Twitter bot—although this effect was not statistically significant. Despite several limitations, this study has important implications for the emerging field of computational social science and ongoing efforts to reduce political polarization online. There is mounting concern that social media sites contribute to political polarization by creating “echo chambers” that insulate people from opposing views about current events. We surveyed a large sample of Democrats and Republicans who visit Twitter at least three times each week about a range of social policy issues. One week later, we randomly assigned respondents to a treatment condition in which they were offered financial incentives to follow a Twitter bot for 1 month that exposed them to messages from those with opposing political ideologies (e.g., elected officials, opinion leaders, media organizations, and nonprofit groups). Respondents were resurveyed at the end of the month to measure the effect of this treatment, and at regular intervals throughout the study period to monitor treatment compliance. We find that Republicans who followed a liberal Twitter bot became substantially more conservative posttreatment. Democrats exhibited slight increases in liberal attitudes after following a conservative Twitter bot, although these effects are not statistically significant. Notwithstanding important limitations of our study, these findings have significant implications for the interdisciplinary literature on political polarization and the emerging field of computational social science.\n",
            "------------------------------------\n",
            "Title Attributed Social Network Embedding\n",
            "Author [{'authorId': '32781973', 'name': 'Lizi Liao'}, {'authorId': '7792071', 'name': 'Xiangnan He'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2017\n",
            "Abstract Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Attributed Social Network Embedding framework (ASNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, ASNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, ASNE significantly outperforms  node2vec with an 8.2 percent relative improvement on the link prediction task, and a 12.7 percent gain on the node classification task.\n",
            "------------------------------------\n",
            "Title A General Self-Organized Tree-Based Energy-Balance Routing Protocol for Wireless Sensor Network\n",
            "Author [{'authorId': '2113962875', 'name': 'Zhao Han'}, {'authorId': '2118432165', 'name': 'Jie Wu'}, {'authorId': '2159190175', 'name': 'Jie Zhang'}, {'authorId': '2602078', 'name': 'Liefeng Liu'}, {'authorId': '2408984', 'name': 'Kaiyun Tian'}]\n",
            "Venue IEEE Transactions on Nuclear Science\n",
            "year 2012\n",
            "Abstract Wireless sensor network (WSN) is a system composed of a large number of low-cost micro-sensors. This network is used to collect and send various kinds of messages to a base station (BS). WSN consists of low-cost nodes with limited battery power, and the battery replacement is not easy for WSN with thousands of physically embedded nodes, which means energy efficient routing protocol should be employed to offer a long-life work time. To achieve the aim, we need not only to minimize total energy consumption but also to balance WSN load. Researchers have proposed many protocols such as LEACH, HEED, PEGASIS, TBC and PEDAP. In this paper, we propose a General Self-Organized Tree-Based Energy-Balance routing protocol (GSTEB) which builds a routing tree using a process where, for each round, BS assigns a root node and broadcasts this selection to all sensor nodes. Subsequently, each node selects its parent by considering only itself and its neighbors' information, thus making GSTEB a dynamic protocol. Simulation results show that GSTEB has a better performance than other protocols in balancing energy consumption, thus prolonging the lifetime of WSN.\n",
            "------------------------------------\n",
            "Title The Ethics of Information\n",
            "Author [{'authorId': '1982425', 'name': 'L. Floridi'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract PREFACE 1. ETHICS AFTER THE INFORMATION REVOLUTION 2. WHAT IS INFORMATION ETHICS? 3. THE METHOD OF ABSTRACTION 4. INFORMATION ETHICS AS E-NVIRONMENTAL ETHICS 5. INFORMATION ETHICS AND THE FOUNDATIONALIST DEBATE 6. THE INTRINSIC VALUE OF THE INFOSPHERE 7. THE MORALITY OF ARTIFICIAL AGENTS 8. THE CONSTRUCTIONIST VALUES OF HOMO POIETICUS 9. ARTIFICIAL EVIL 10. THE TRAGEDY OF THE GOOD WILL 11. THE INFORMATIONAL NATURE OF SELVES 12. THE ONTOLOGICAL INTERPRETATION OF INFORMATIONAL PRIVACY 13. DISTRIBUTED MORALITY 14. INFORMATION BUSINESS ETHICS 15. GLOBAL INFORMATION ETHICS 16. A DEFENCE OF INFORMATION ETHICS EPILOGUE REFERENCES INDEX\n",
            "------------------------------------\n",
            "Title Natural Language Processing in Radiology: A Systematic Review.\n",
            "Author [{'authorId': '2848716', 'name': 'E. Pons'}, {'authorId': '144530097', 'name': 'Loes M M Braun'}, {'authorId': '143872849', 'name': 'M. Hunink'}, {'authorId': '1904671', 'name': 'J. Kors'}]\n",
            "Venue Radiology\n",
            "year 2016\n",
            "Abstract Radiological reporting has generated large quantities of digital content within the electronic health record, which is potentially a valuable source of information for improving clinical care and supporting research. Although radiology reports are stored for communication and documentation of diagnostic imaging, harnessing their potential requires efficient and automated information extraction: they exist mainly as free-text clinical narrative, from which it is a major challenge to obtain structured data. Natural language processing (NLP) provides techniques that aid the conversion of text into a structured representation, and thus enables computers to derive meaning from human (ie, natural language) input. Used on radiology reports, NLP techniques enable automatic identification and extraction of information. By exploring the various purposes for their use, this review examines how radiology benefits from NLP. A systematic literature search identified 67 relevant publications describing NLP methods that support practical applications in radiology. This review takes a close look at the individual studies in terms of tasks (ie, the extracted information), the NLP methodology and tools used, and their application purpose and performance results. Additionally, limitations, future challenges, and requirements for advancing NLP in radiology will be discussed.\n",
            "------------------------------------\n",
            "Title Spectral–Spatial Classification of Hyperspectral Data Based on Deep Belief Network\n",
            "Author [{'authorId': '2597809', 'name': 'Yushi Chen'}, {'authorId': '2143711163', 'name': 'Xing Zhao'}, {'authorId': '144787387', 'name': 'X. Jia'}]\n",
            "Venue IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "year 2015\n",
            "Abstract Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.\n",
            "------------------------------------\n",
            "Title BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\n",
            "Author [{'authorId': '145408381', 'name': 'Andreas Kirsch'}, {'authorId': '3038326', 'name': 'Joost R. van Amersfoort'}, {'authorId': '2681954', 'name': 'Y. Gal'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2019\n",
            "Abstract We develop BatchBALD, a tractable approximation to the mutual information between a batch of points and model parameters, which we use as an acquisition function to select multiple informative points jointly for the task of deep Bayesian active learning. BatchBALD is a greedy linear-time $1 - \\frac{1}{e}$-approximate algorithm amenable to dynamic programming and efficient caching. We compare BatchBALD to the commonly used approach for batch data acquisition and find that the current approach acquires similar and redundant points, sometimes performing worse than randomly acquiring data. We finish by showing that, using BatchBALD to consider dependencies within an acquisition batch, we achieve new state of the art performance on standard benchmarks, providing substantial data efficiency improvements in batch acquisition.\n",
            "------------------------------------\n",
            "Title Rating Agencies in the Face of Regulation\n",
            "Author [{'authorId': '34362888', 'name': 'C. Opp'}, {'authorId': '35002483', 'name': 'Marcus M. Opp'}, {'authorId': '145705520', 'name': 'M. Harris'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This paper develops a theoretical framework to shed light on variation in credit rating standards over time and across asset classes. Ratings issued by credit rating agencies serve a dual role: they provide information to investors and are used to regulate institutional investors. We show that introducing rating-contingent regulation that favors highly rated securities may increase or decrease rating informativeness, but unambiguously increases the volume of highly rated securities. If the regulatory advantage of highly rated securities is sufficiently large, delegated information acquisition is unsustainable, since the rating agency prefers to facilitate regulatory arbitrage by inflating ratings. Our model relates rating informativeness to the quality distribution of issuers, the complexity of assets, and issuers' outside options. We reconcile our results with the existing empirical literature and highlight new, testable implications, such as repercussions of the Dodd-Frank Act.\n",
            "------------------------------------\n",
            "Title Local E‐Government in the United States: Transformation or Incremental Change?\n",
            "Author [{'authorId': '8650480', 'name': 'D. Norris'}, {'authorId': '1761721', 'name': 'C. Reddick'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract In this article, the authors address the recent trajectory of local e-government in the United States and compare it with the predictions of early e-government writings, using empirical data from two nationwide surveys of e-government among American local governments. The authors find that local e-government has not produced the results that those writings predicted. Instead, its development has largely been incremental, and local e-government is mainly about delivering information and services online, followed by a few transactions and limited interactivity. Local e-government is also mainly one way, from government to citizens, and there is little or no evidence that it is transformative in any way. This disparity between early predictions and actual results is partly attributable to the incremental nature of American public administration. Other reasons include a lack of attention by early writers to the history of information technology in government and the influence of technological determinism on those writings.\n",
            "------------------------------------\n",
            "Title Comparing Online and Offline Self-Disclosure: A Systematic Review\n",
            "Author [{'authorId': '39668610', 'name': 'M. Nguyen'}, {'authorId': '2054618333', 'name': 'Y. Bin'}, {'authorId': '35410804', 'name': 'A. Campbell'}]\n",
            "Venue Cyberpsychology, Behavior, and Social Networking\n",
            "year 2012\n",
            "Abstract Disclosure of personal information is believed to be more frequent in online compared to offline communication. However, this assumption is both theoretically and empirically contested. This systematic review examined existing research comparing online and offline self-disclosure to ascertain the evidence for current theories of online communication. Studies that compared online and offline disclosures in dyadic interactions were included for review. Contrary to expectations, disclosure was not consistently found to be greater in online contexts. Factors such as the relationship between the communicators, the specific mode of communication, and the context of the interaction appear to moderate the degree of disclosure. In relation to the theories of online communication, there is support for each theory. It is argued that the overlapping predictions of each theory and the current state of empirical research highlights a need for an overarching theory of communication that can account for disclosure in both online and offline interactions.\n",
            "------------------------------------\n",
            "Title Predictive information in a sensory population\n",
            "Author [{'authorId': '5058643', 'name': 'S. Palmer'}, {'authorId': '2797469', 'name': 'O. Marre'}, {'authorId': '48647163', 'name': 'Michael J. Berry'}, {'authorId': '1762240', 'name': 'W. Bialek'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2013\n",
            "Abstract Significance Prediction is an essential part of life. However, are we really “good” at making predictions? More specifically, are pieces of our brain close to being optimal predictors? To assess the efficiency of prediction, we need to measure the information that neurons carry about the future of our sensory experiences. We show how to do this, at least in simplified contexts, and find that groups of neurons in the retina indeed are close to maximally efficient at separating predictive information from the nonpredictive background. Efficient coding of predictive information is a principle that can be applied at every stage of neural computation. Guiding behavior requires the brain to make predictions about the future values of sensory inputs. Here, we show that efficient predictive computation starts at the earliest stages of the visual system. We compute how much information groups of retinal ganglion cells carry about the future state of their visual inputs and show that nearly every cell in the retina participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons that exhibit feature selectivity that would support predictive computations. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.\n",
            "------------------------------------\n",
            "Title Local active information storage as a tool to understand distributed neural information processing\n",
            "Author [{'authorId': '1775434', 'name': 'M. Wibral'}, {'authorId': '1783110', 'name': 'J. Lizier'}, {'authorId': '2334510', 'name': 'Sebastian Vögler'}, {'authorId': '2964400', 'name': 'V. Priesemann'}, {'authorId': '1732587', 'name': 'R. Galuske'}]\n",
            "Venue Front. Neuroinform.\n",
            "year 2013\n",
            "Abstract Every act of information processing can in principle be decomposed into the component operations of information storage, transfer, and modification. Yet, while this is easily done for today's digital computers, the application of these concepts to neural information processing was hampered by the lack of proper mathematical definitions of these operations on information. Recently, definitions were given for the dynamics of these information processing operations on a local scale in space and time in a distributed system, and the specific concept of local active information storage was successfully applied to the analysis and optimization of artificial neural systems. However, no attempt to measure the space-time dynamics of local active information storage in neural data has been made to date. Here we measure local active information storage on a local scale in time and space in voltage sensitive dye imaging data from area 18 of the cat. We show that storage reflects neural properties such as stimulus preferences and surprise upon unexpected stimulus change, and in area 18 reflects the abstract concept of an ongoing stimulus despite the locally random nature of this stimulus. We suggest that LAIS will be a useful quantity to test theories of cortical function, such as predictive coding.\n",
            "------------------------------------\n",
            "Title Wireless powered communication networks: an overview\n",
            "Author [{'authorId': '2745067', 'name': 'S. Bi'}, {'authorId': '144498185', 'name': 'Yong Zeng'}, {'authorId': '144142357', 'name': 'Rui Zhang'}]\n",
            "Venue IEEE wireless communications\n",
            "year 2015\n",
            "Abstract Wireless powered communication networking (WPCN) is a new networking paradigm where the battery of wireless communication devices can be remotely replenished by means of microwave wireless power transfer (WPT) technology. WPCN eliminates the need for frequent manual battery replacement/recharging, and thus significantly improves the performance over conventional battery-powered communication networks in many aspects, such as higher throughput, longer device lifetime, and lower network operating cost. However, the design and future application of WPCN is essentially challenged by the low WPT efficiency over long distance, and the complex nature of joint wireless information and power transfer within the same network. In this article, we provide an overview of the key networking structures and performance enhancing techniques to build an efficient WPCN. In addition, we point out new and challenging future research directions for WPCN.\n",
            "------------------------------------\n",
            "Title T-CNN: Tubelets With Convolutional Neural Networks for Object Detection From Videos\n",
            "Author [{'authorId': '2114072675', 'name': 'Kai Kang'}, {'authorId': '49404547', 'name': 'Hongsheng Li'}, {'authorId': '1721677', 'name': 'Junjie Yan'}, {'authorId': '2550719', 'name': 'Xingyu Zeng'}, {'authorId': '49188662', 'name': 'Binh Yang'}, {'authorId': '2014849645', 'name': 'Tong Xiao'}, {'authorId': '2116343425', 'name': 'Cong Zhang'}, {'authorId': '40072288', 'name': 'Zhe Wang'}, {'authorId': '2108694893', 'name': 'Ruohui Wang'}, {'authorId': '31843833', 'name': 'Xiaogang Wang'}, {'authorId': '3001348', 'name': 'Wanli Ouyang'}]\n",
            "Venue IEEE transactions on circuits and systems for video technology (Print)\n",
            "year 2016\n",
            "Abstract The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks, such as GoogleNet and VGG, novel object detection frameworks, such as R-CNN and its successors, Fast R-CNN, and Faster R-CNN, play an essential role in improving the state of the art. Despite their effectiveness on still images, those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this paper, we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN, i.e., tubelets with convolutional neueral networks. The proposed framework won newly introduced an object-detection-from-video task with provided data in the ImageNet Large-Scale Visual Recognition Challenge 2015. Code is publicly available at https://github.com/myfavouritekk/T-CNN.\n",
            "------------------------------------\n",
            "Title Everything you wanted to know about smart cities: The Internet of things is the backbone\n",
            "Author [{'authorId': '1710189', 'name': 'S. Mohanty'}]\n",
            "Venue IEEE Consumer Electronics Magazine\n",
            "year 2016\n",
            "Abstract This article is a single-source introduction to the emerging concept of smart cities. It can be used for familiarizing researchers with the vast scope of research possible in this application domain. The smart city is primarily a concept, and there is still not a clear and consistent definition among practitioners and academia. As a simplistic explanation, a smart city is a place where traditional networks and services are made more flexible, efficient, and sustainable with the use of information, digital, and telecommunication technologies to improve the city's operations for the benefit of its inhabitants. Smart cities are greener, safer, faster, and friendlier. The different components of a smart city include smart infrastructure, smart transportation, smart energy, smart health care, and smart technology. These components are what make the cities smart and efficient. Information and communication technology (ICT) are enabling keys for transforming traditional cities into smart cities. Two closely related emerging technology frameworks, the Internet of Things (IoT) and big data (BD), make smart cities efficient and responsive. The technology has matured enough to allow smart cities to emerge. However, there is much needed in terms of physical infrastructure, a smart city, the digital technologies translate into better public services for inhabitants and better use of resources while reducing environmental impacts. One of the formal definitions of the smart city is the following: a city \"connecting the physical infrastructure, the information-technology infrastructure, the social infrastructure, and the business infrastructure to leverage the collective intelligence of the city\". Another formal and comprehensive definition is \"a smart sustainable city is an innovative city that uses information and communication technologies (ICTs) and other means to improve quality of life, efficiency of urban operations and services, and competitiveness, while ensuring that it meets the needs of present and future generations with respect to economic, social and environmental aspects\". Any combination of various smart components can make cities smart. A city need not have all the components to be labeled as smart. The number of smart components depends on the cost and available technology.\n",
            "------------------------------------\n",
            "Title Jerusalem Lectures on Black Holes and Quantum Information\n",
            "Author [{'authorId': '102579897', 'name': 'D. Harlow'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract In these lectures I give an introduction to the quantum physics of black holes, including recent developments based on quantum information theory such as the rewall paradox and its various cousins. I also give an introduction to holography and the AdS/CFT correspondence, focusing on those aspects which are relevant for the black hole information problem.\n",
            "------------------------------------\n",
            "Title The Goldilocks Effect: Human Infants Allocate Attention to Visual Sequences That Are Neither Too Simple Nor Too Complex\n",
            "Author [{'authorId': '144584048', 'name': 'Celeste Kidd'}, {'authorId': '6766605', 'name': 'S. Piantadosi'}, {'authorId': '3065843', 'name': 'R. Aslin'}]\n",
            "Venue PLoS ONE\n",
            "year 2012\n",
            "Abstract Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants’ visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants’ probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.\n",
            "------------------------------------\n",
            "Title Directional Message Passing for Molecular Graphs\n",
            "Author [{'authorId': '51516539', 'name': 'Johannes Klicpera'}, {'authorId': '1557081085', 'name': 'Janek Groß'}, {'authorId': '3075189', 'name': 'Stephan Günnemann'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2020\n",
            "Abstract Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes) and not the spatial direction from one atom to another. However, directional information plays a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions to construct a theoretically well-founded, orthogonal radial basis that achieves better performance than the currently prevalent Gaussian radial basis functions while using more than 4x fewer parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 77% on MD17 and by 41% on QM9.\n",
            "------------------------------------\n",
            "Title When the entire population is the sample: strengths and limitations in register-based epidemiology\n",
            "Author [{'authorId': '2375942', 'name': 'L. Thygesen'}, {'authorId': '1390048098', 'name': 'A. Ersbøll'}]\n",
            "Venue European Journal of Epidemiology\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title How Long to Wait? Predicting Bus Arrival Time With Mobile Phone Based Participatory Sensing\n",
            "Author [{'authorId': '46842554', 'name': 'Pengfei Zhou'}, {'authorId': '1694986', 'name': 'Yuanqing Zheng'}, {'authorId': '143641798', 'name': 'Mo Li'}]\n",
            "Venue IEEE Transactions on Mobile Computing\n",
            "year 2012\n",
            "Abstract The bus arrival time is primary information to most city transport travelers. Excessively long waiting time at bus stops often discourages the travelers and makes them reluctant to take buses. In this paper, we present a bus arrival time prediction system based on bus passengers' participatory sensing. With commodity mobile phones, the bus passengers' surrounding environmental context is effectively collected and utilized to estimate the bus traveling routes and predict bus arrival time at various bus stops. The proposed system solely relies on the collaborative effort of the participating users and is independent from the bus operating companies, so it can be easily adopted to support universal bus service systems without requesting support from particular bus operating companies. Instead of referring to GPS-enabled location information, we resort to more generally available and energy efficient sensing resources, including cell tower signals, movement statuses, audio recordings, etc., which bring less burden to the participatory party and encourage their participation. We develop a prototype system with different types of Android-based mobile phones and comprehensively experiment with the NTU campus shuttle buses as well as Singapore public buses over a 7-week period. The evaluation results suggest that the proposed system achieves outstanding prediction accuracy compared with those bus operator initiated and GPS supported solutions. We further adopt our system and conduct quick trial experiments with London bus system for 4 days, which suggests the easy deployment of our system and promising system performance across cities. At the same time, the proposed solution is more generally available and energy friendly.\n",
            "------------------------------------\n",
            "Title A national action plan to support consumer engagement via e-health.\n",
            "Author [{'authorId': '33425984', 'name': 'L. Ricciardi'}, {'authorId': '2615710', 'name': 'F. Mostashari'}, {'authorId': '145905204', 'name': 'Judy Murphy'}, {'authorId': '145672901', 'name': 'Jodi G. Daniel'}, {'authorId': '12159778', 'name': 'Erin P Siminerio'}]\n",
            "Venue Health Affairs\n",
            "year 2013\n",
            "Abstract Patient-centered care is considered one pillar of a high-performing, high-quality health care system. It is a key component of many efforts to transform care and achieve better population health. Expansion of health information technology and consumer e-health tools--electronic tools and services such as secure e-mail messaging between patients and providers, or mobile health apps--have created new opportunities for individuals to participate actively in monitoring and directing their health and health care. The Office of the National Coordinator for Health Information Technology in the Department of Health and Human Services leads the strategy to increase electronic access to health information, support the development of tools that enable people to take action with that information, and shift attitudes related to the traditional roles of patients and providers. In this article we review recent evidence in support of consumer e-health and present the federal strategy to promote advances in consumer e-health to increase patient engagement, improve individual health, and achieve broader health care system improvements.\n",
            "------------------------------------\n",
            "Title Selecting optimal partitioning schemes for phylogenomic datasets\n",
            "Author [{'authorId': '5325261', 'name': 'R. Lanfear'}, {'authorId': '5705699', 'name': 'B. Calcott'}, {'authorId': '4104973', 'name': 'D. Kainer'}, {'authorId': '50565651', 'name': 'C. Mayer'}, {'authorId': '143958048', 'name': 'A. Stamatakis'}]\n",
            "Venue BMC Evolutionary Biology\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Decentralized Stochastic Control with Partial History Sharing: A Common Information Approach\n",
            "Author [{'authorId': '1990526', 'name': 'A. Nayyar'}, {'authorId': '1811910', 'name': 'Aditya Mahajan'}, {'authorId': '2918181', 'name': 'D. Teneketzis'}]\n",
            "Venue IEEE Transactions on Automatic Control\n",
            "year 2012\n",
            "Abstract A general model of decentralized stochastic control called partial history sharing information structure is presented. In this model, at each step the controllers share part of their observation and control history with each other. This general model subsumes several existing models of information sharing as special cases. Based on the information commonly known to all the controllers, the decentralized problem is reformulated as an equivalent centralized problem from the perspective of a coordinator. The coordinator knows the common information and selects prescriptions that map each controller's local information to its control actions. The optimal control problem at the coordinator is shown to be a partially observable Markov decision process (POMDP) which is solved using techniques from Markov decision theory. This approach provides 1) structural results for optimal strategies and 2) a dynamic program for obtaining optimal strategies for all controllers in the original decentralized problem. Thus, this approach unifies the various ad-hoc approaches taken in the literature. In addition, the structural results on optimal control strategies obtained by the proposed approach cannot be obtained by the existing generic approach (the person-by-person approach) for obtaining structural results in decentralized problems; and the dynamic program obtained by the proposed approach is simpler than that obtained by the existing generic approach (the designer's approach) for obtaining dynamic programs in decentralized problems.\n",
            "------------------------------------\n",
            "Title Pyramid Stereo Matching Network\n",
            "Author [{'authorId': '2936466', 'name': 'Jia-Ren Chang'}, {'authorId': '2143438143', 'name': 'Yonghao Chen'}]\n",
            "Venue 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year 2018\n",
            "Abstract Recent work has shown that depth estimation from a stereo pair of images can be formulated as a supervised learning task to be resolved with convolutional neural networks (CNNs). However, current architectures rely on patch-based Siamese networks, lacking the means to exploit context information for finding correspondence in ill-posed regions. To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision. The proposed approach was evaluated on several benchmark datasets. Our method ranked first in the KITTI 2012 and 2015 leaderboards before March 18, 2018. The codes of PSMNet are available at: https://github.com/JiaRenChang/PSMNet.\n",
            "------------------------------------\n",
            "Title Advances in communications using optical vortices\n",
            "Author [{'authorId': '49605770', 'name': 'Jian Wang'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract An optical vortex having an isolated point singularity is associated with the spatial structure of light waves. A polarization vortex (vector beam) with a polarization singularity has spatially variant polarizations. A phase vortex with phase singularity or screw dislocation has a spiral phase front. The optical vortex has recently gained increasing interest in optical trapping, optical tweezers, laser machining, microscopy, quantum information processing, and optical communications. In this paper, we review recent advances in optical communications using optical vortices. First, basic concepts of polarization/phase vortex modulation and multiplexing in communications and key techniques of polarization/phase vortex generation and (de)multiplexing are introduced. Second, free-space and fiber optical communications using optical vortex modulation and optical vortex multiplexing are presented. Finally, key challenges and perspectives of optical communications using optical vortices are discussed. It is expected that optical vortices exploiting the space physical dimension of light waves might find more interesting applications in optical communications and interconnects.\n",
            "------------------------------------\n",
            "Title Rumor Cascades\n",
            "Author [{'authorId': '34760887', 'name': 'A. Friggeri'}, {'authorId': '1778398', 'name': 'Lada A. Adamic'}, {'authorId': '1996878', 'name': 'Dean Eckles'}, {'authorId': '144500753', 'name': 'Justin Cheng'}]\n",
            "Venue International Conference on Web and Social Media\n",
            "year 2014\n",
            "Abstract \n",
            " \n",
            " Online social networks provide a rich substrate for rumor propagation. Information received via friends tends to be trusted, and online social networks allow individuals to transmit information to many friends at once. By referencing known rumors from Snopes.com, a popular website documenting memes and urban legends, we track the propagation of thousands of rumors appearing on Facebook. From this sample we infer the rates at which rumors from different categories and of varying truth value are uploaded and reshared. We find that rumor cascades run deeper in the social network than reshare cascades in general. We then examine the effect of individual reshares receiving a comment containing a link to a Snopes article on the evolution of the cascade. We find that receiving such a comment increases the likelihood that a reshare of a rumor will be deleted. Furthermore, large cascades are able to accumulate hundreds of Snopes comments while continuing to propagate. Finally, using a dataset of rumors copied and pasted from one status update to another, we show that rumors change over time and that different variants tend to dominate different bursts in popularity.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title Helpfulness of Online Consumer Reviews: Readers' Objectives and Review Cues\n",
            "Author [{'authorId': '2925271', 'name': 'Hyunmi Baek'}, {'authorId': '33809893', 'name': 'Joongho Ahn'}, {'authorId': '2167591475', 'name': 'Youngseok Choi'}]\n",
            "Venue International Journal of Electronic Commerce\n",
            "year 2012\n",
            "Abstract With the growth of e-commerce, online consumer reviews have increasingly become important sources of information that help consumers in their purchase decisions. However, the influx of online consumer reviews has caused information overload, making it difficult for consumers to choose reliable reviews. For an online retail market to succeed, it is important to lead product reviewers to write more helpful reviews, and for consumers to get helpful reviews more easily by figuring out the factors determining the helpfulness of online reviews. For this research, 75,226 online consumer reviews were collected from Amazon.com using a Web data crawler. Additional information on review content was also gathered by carrying out a sentiment analysis for mining review text. Our results show that both peripheral cues, including review rating and reviewer's credibility, and central cues, such as the content of reviews, influence the helpfulness of reviews. Based on dual process theories, we find that consumers focus on different information sources of reviews, depending on their purposes for reading reviews: online reviews can be used for information search or for evaluating alternatives. Our findings provide new perspectives to online market owners on how to manage online reviews on their Web sites.\n",
            "------------------------------------\n",
            "Title Leveraging media and health communication strategies to overcome the COVID-19 infodemic\n",
            "Author [{'authorId': '1573276243', 'name': 'Nour Mheidly'}, {'authorId': '48328305', 'name': 'Jawad Fares'}]\n",
            "Venue Journal of Public Health Policy\n",
            "year 2020\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title The Filter Bubble\n",
            "Author [{'authorId': '96905757', 'name': 'Eli Pariser'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract : Introduced by tech entrepreneur and activist Eli Pariser in 2011, the ‘filter bubble’ is a persistent concept which suggests that search engines and social media, together with their recommendation and personalisation algorithms, are centrally culpable for the societal and ideological polarisation experienced in many countries: we no longer encounter a balanced and healthy information diet, but only see information that targets our established interests and reinforces our existing worldviews. Filter bubbles are seen as critical enablers of Brexit, Trump, Bolsonaro, and other populist political phenomena, and search and social media companies have been criticised for failing to prevent their development. Yet, there is scant empirical evidence for their existence, or for the related concept of ‘echo chambers’: indeed, search and social media users generally appear to encounter a highly centrist media diet that is, if anything, more diverse than that of non-users. However, the persistent use of these concepts in mainstream media and political debates has now created its own discursive reality that continues to impact materially on societal institutions, media and communication platforms, and ordinary users themselves. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to redirect scholarly attention from far more critical areas of enquiry.\n",
            "------------------------------------\n",
            "Title From Use to Effective Use: A Representation Theory Perspective\n",
            "Author [{'authorId': '1400115225', 'name': 'A. Burton-Jones'}, {'authorId': '2823704', 'name': 'Camille Grange'}]\n",
            "Venue Information systems research\n",
            "year 2013\n",
            "Abstract Information systems must be used effectively to obtain maximum benefits from them. However, despite a great deal of research on when and why systems are used, very little research has examined what effective system use involves and what drives it. To move from use to effective use requires understanding an information system's nature and purpose, which in turn requires a theory of information systems. We draw on representation theory, which states that an information system is made up of several structures that serve to represent some part of the world that a user and other stakeholders must understand. From this theory, we derive a high-level framework of how effective use and performance evolve, as well as specific models of the nature and drivers of effective use. The models are designed to explain the effective use of any information system and offer unique insights that would not be offered by traditional views, which tend to consider information systems to be just another tool. We explain how our theory extends existing research, provides a rich platform for research on effective use, and how it contributes back to the theory of information systems from which it was derived.\n",
            "------------------------------------\n",
            "Title A review on supply chain contracting with information considerations: information updating and information asymmetry\n",
            "Author [{'authorId': '145098670', 'name': 'Bin Shen'}, {'authorId': '144728286', 'name': 'T. Choi'}, {'authorId': '34939858', 'name': 'S. Minner'}]\n",
            "Venue International Journal of Production Research\n",
            "year 2019\n",
            "Abstract Supply chain contracting and the use of information are undoubtedly two critical and influential areas in modern supply chain management. However, relatively little is known about supply chain contracting mechanisms with different information settings. To fill this gap, we review and classify the related supply chain contracting literature into three categories with respect to different kinds of information considerations, namely (i) demand information updating, (ii) supply information updating and (iii) information asymmetry. We report the publication trend and classify the commonly studied supply chain contracts with the use of information such as pricing contracts, commitment contracts and menu of contracts. We discuss how contracting and the use of information influence each other in the supply chain. Moreover, we review the major application areas of information usage and report the historical development of major related topics. Finally, we propose several important future research directions.\n",
            "------------------------------------\n",
            "Title HL7 FHIR: An Agile and RESTful approach to healthcare information exchange\n",
            "Author [{'authorId': '38444385', 'name': 'D. Bender'}, {'authorId': '1711438', 'name': 'K. Sartipi'}]\n",
            "Venue Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems\n",
            "year 2013\n",
            "Abstract This research examines the potential for new Health Level 7 (HL7) standard Fast Healthcare Interoperability Resources (FHIR, pronounced “fire”) standard to help achieve healthcare systems interoperability. HL7 messaging standards are widely implemented by the healthcare industry and have been deployed internationally for decades. HL7 Version 2 (“v2”) health information exchange standards are a popular choice of local hospital communities for the exchange of healthcare information, including electronic medical record information. In development for 15 years, HL7 Version 3 (“v3”) was designed to be the successor to Version 2, addressing Version 2's shortcomings. HL7 v3 has been heavily criticized by the industry for being internally inconsistent even in it's own documentation, too complex and expensive to implement in real world systems and has been accused of contributing towards many failed and stalled systems implementations. HL7 is now experimenting with a new approach to the development of standards with FHIR. This research provides a chronicle of the evolution of the HL7 messaging standards, an introduction to HL7 FHIR and a comparative analysis between HL7 FHIR and previous HL7 messaging standards.\n",
            "------------------------------------\n",
            "Title Background and Data Configuration Process of a Nationwide Population-Based Study Using the Korean National Health Insurance System\n",
            "Author [{'authorId': '145487760', 'name': 'Sun-Ok Song'}, {'authorId': '2629687', 'name': 'C. Jung'}, {'authorId': '1863186', 'name': 'Y. Song'}, {'authorId': '145782218', 'name': 'Cheol-Young Park'}, {'authorId': '153182485', 'name': 'H. Kwon'}, {'authorId': '66275028', 'name': 'B. Cha'}, {'authorId': '48490894', 'name': 'J. Park'}, {'authorId': '82277999', 'name': 'Ki-Up Lee'}, {'authorId': '118396660', 'name': 'K. Ko'}, {'authorId': '79043784', 'name': 'Byung-wan Lee'}]\n",
            "Venue Diabetes & Metabolism Journal\n",
            "year 2014\n",
            "Abstract Background The National Health Insurance Service (NHIS) recently signed an agreement to provide limited open access to the databases within the Korean Diabetes Association for the benefit of Korean subjects with diabetes. Here, we present the history, structure, contents, and way to use data procurement in the Korean National Health Insurance (NHI) system for the benefit of Korean researchers. Methods The NHIS in Korea is a single-payer program and is mandatory for all residents in Korea. The three main healthcare programs of the NHI, Medical Aid, and long-term care insurance (LTCI) provide 100% coverage for the Korean population. The NHIS in Korea has adopted a fee-for-service system to pay health providers. Researchers can obtain health information from the four databases of the insured that contain data on health insurance claims, health check-ups and LTCI. Results Metabolic disease as chronic disease is increasing with aging society. NHIS data is based on mandatory, serial population data, so, this might show the time course of disease and predict some disease progress, and also be used in primary and secondary prevention of disease after data mining. Conclusion The NHIS database represents the entire Korean population and can be used as a population-based database. The integrated information technology of the NHIS database makes it a world-leading population-based epidemiology and disease research platform.\n",
            "------------------------------------\n",
            "Title Measuring Information-Transfer Delays\n",
            "Author [{'authorId': '1775434', 'name': 'M. Wibral'}, {'authorId': '5570691', 'name': 'Nicolae Pampu'}, {'authorId': '2964400', 'name': 'V. Priesemann'}, {'authorId': '2692662', 'name': 'F. Siebenhühner'}, {'authorId': '4773547', 'name': 'Hannes Seiwert'}, {'authorId': '2061254650', 'name': 'Michael Lindner'}, {'authorId': '1783110', 'name': 'J. Lizier'}, {'authorId': '144846212', 'name': 'Raul Vicente'}]\n",
            "Venue PLoS ONE\n",
            "year 2013\n",
            "Abstract In complex networks such as gene networks, traffic systems or brain circuits it is important to understand how long it takes for the different parts of the network to effectively influence one another. In the brain, for example, axonal delays between brain areas can amount to several tens of milliseconds, adding an intrinsic component to any timing-based processing of information. Inferring neural interaction delays is thus needed to interpret the information transfer revealed by any analysis of directed interactions across brain structures. However, a robust estimation of interaction delays from neural activity faces several challenges if modeling assumptions on interaction mechanisms are wrong or cannot be made. Here, we propose a robust estimator for neuronal interaction delays rooted in an information-theoretic framework, which allows a model-free exploration of interactions. In particular, we extend transfer entropy to account for delayed source-target interactions, while crucially retaining the conditioning on the embedded target state at the immediately previous time step. We prove that this particular extension is indeed guaranteed to identify interaction delays between two coupled systems and is the only relevant option in keeping with Wiener’s principle of causality. We demonstrate the performance of our approach in detecting interaction delays on finite data by numerical simulations of stochastic and deterministic processes, as well as on local field potential recordings. We also show the ability of the extended transfer entropy to detect the presence of multiple delays, as well as feedback loops. While evaluated on neuroscience data, we expect the estimator to be useful in other fields dealing with network dynamics.\n",
            "------------------------------------\n",
            "Title Differential Recurrent Neural Networks for Action Recognition\n",
            "Author [{'authorId': '2300921', 'name': 'Vivek Veeriah'}, {'authorId': '2227667', 'name': 'Naifan Zhuang'}, {'authorId': '2272096', 'name': 'Guo-Jun Qi'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2015\n",
            "Abstract The long short-term memory (LSTM) neural network is capable of processing complex sequential information since it utilizes special gating schemes for learning representations from long input sequences. It has the potential to model any time-series or sequential data, where the current hidden state has to be considered in the context of the past hidden states. This property makes LSTM an ideal choice to learn the complex dynamics of various actions. Unfortunately, the conventional LSTMs do not consider the impact of spatio-temporal dynamics corresponding to the given salient motion patterns, when they gate the information that ought to be memorized through time. To address this problem, we propose a differential gating scheme for the LSTM neural network, which emphasizes on the change in information gain caused by the salient motions between the successive frames. This change in information gain is quantified by Derivative of States (DoS), and thus the proposed LSTM model is termed as differential Recurrent Neural Network (dRNN). We demonstrate the effectiveness of the proposed model by automatically recognizing actions from the real-world 2D and 3D human action datasets. Our study is one of the first works towards demonstrating the potential of learning complex time-series representations via high-order derivatives of states.\n",
            "------------------------------------\n",
            "Title Resolving human object recognition in space and time\n",
            "Author [{'authorId': '2492727', 'name': 'Radoslaw Martin Cichy'}, {'authorId': '8152383', 'name': 'D. Pantazis'}, {'authorId': '143868587', 'name': 'A. Oliva'}]\n",
            "Venue Nature Neuroscience\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title IEA International Computer and Information Literacy Study 2018 Assessment Framework\n",
            "Author [{'authorId': '47946182', 'name': 'J. Fraillon'}, {'authorId': '40007442', 'name': 'Wolfram Schulz'}, {'authorId': '80863696', 'name': 'J. Ainley'}]\n",
            "Venue \n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Supervised Contrastive Learning\n",
            "Author [{'authorId': '8980423', 'name': 'Prannay Khosla'}, {'authorId': '1388407541', 'name': 'Piotr Teterwak'}, {'authorId': '2146562893', 'name': 'Chen Wang'}, {'authorId': '8707513', 'name': 'Aaron Sarna'}, {'authorId': '2476765', 'name': 'Yonglong Tian'}, {'authorId': '2094770', 'name': 'Phillip Isola'}, {'authorId': '2064102741', 'name': 'Aaron Maschinot'}, {'authorId': '1681442', 'name': 'Ce Liu'}, {'authorId': '1707347', 'name': 'Dilip Krishnan'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2020\n",
            "Abstract Cross entropy is the most widely used loss function for supervised training of image classification models. In this paper, we propose a novel training methodology that consistently outperforms cross entropy on supervised learning tasks across different architectures and data augmentations. We modify the batch contrastive loss, which has recently been shown to be very effective at learning powerful representations in the self-supervised setting. We are thus able to leverage label information more effectively than cross entropy. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. In addition to this, we leverage key ingredients such as large batch sizes and normalized embeddings, which have been shown to benefit self-supervised learning. On both ResNet-50 and ResNet-200, we outperform cross entropy by over 1%, setting a new state of the art number of 78.8% among methods that use AutoAugment data augmentation. The loss also shows clear benefits for robustness to natural corruptions on standard benchmarks on both calibration and accuracy. Compared to cross entropy, our supervised contrastive loss is more stable to hyperparameter settings such as optimizers or data augmentations.\n",
            "------------------------------------\n",
            "Title Towards a definition of the Internet of Things ( IoT )\n",
            "Author []\n",
            "Venue \n",
            "year 2015\n",
            "Abstract ion Yes No Partly Availability / Mobility No No No Fault tolerance Partly No Partly Flexibility/Event based Yes Partly Partly Uncertainty of Information No No No\n",
            "------------------------------------\n",
            "Title Technology Acceptance Model: A Survey of Literature\n",
            "Author [{'authorId': '2105355817', 'name': 'Priyanka Surendran'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract The technology acceptance model has been a theory that is most widely used to explain an individualâ€™s acceptance of an information system. This study has reviewed numerous literatures available in this area. The different studies in this area were evaluated to understand the modifications that were done on this model. The paper then tries to provide an insight on future trends in the technology acceptance model.\n",
            "------------------------------------\n",
            "Title Why People Use Chatbots\n",
            "Author [{'authorId': '2535812', 'name': 'P. Brandtzæg'}, {'authorId': '1399101050', 'name': 'A. Følstad'}]\n",
            "Venue International Conference on Internet Science\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Improving Diagnosis in Health Care\n",
            "Author [{'authorId': '38718360', 'name': 'E. Balogh'}, {'authorId': '50135996', 'name': 'B. Miller'}, {'authorId': '144066224', 'name': 'J. Ball'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Getting the right diagnosis is a key aspect of health care - it provides an explanation of a patient's health problem and informs subsequent health care decisions. The diagnostic process is a complex, collaborative activity that involves clinical reasoning and information gathering to determine a patient's health problem. According to Improving Diagnosis in Health Care, diagnostic errors-inaccurate or delayed diagnoses-persist throughout all settings of care and continue to harm an unacceptable number of patients. It is likely that most people will experience at least one diagnostic error in their lifetime, sometimes with devastating consequences. Diagnostic errors may cause harm to patients by preventing or delaying appropriate treatment, providing unnecessary or harmful treatment, or resulting in psychological or financial repercussions. The committee concluded that improving the diagnostic process is not only possible, but also represents a moral, professional, and public health imperative. Improving Diagnosis in Health Care a continuation of the landmark Institute of Medicine reports To Err Is Human (2000) and Crossing the Quality Chasm (2001) finds that diagnosis–and, in particular, the occurrence of diagnostic errors–has been largely unappreciated in efforts to improve the quality and safety of health care. Without a dedicated focus on improving diagnosis, diagnostic errors will likely worsen as the delivery of health care and the diagnostic process continue to increase in complexity. Just as the diagnostic process is a collaborative activity, improving diagnosis will require collaboration and a widespread commitment to change among health care professionals, health care organizations, patients and their families, researchers, and policy makers. The recommendations of Improving Diagnosis in Health Care contribute to the growing momentum for change in this crucial area of health care quality and safety.\n",
            "------------------------------------\n",
            "Title Internet of Things-IOT : Definition , Characteristics , Architecture , Enabling Technologies , Application & Future Challenges\n",
            "Author [{'authorId': '50985444', 'name': 'Keyur K. Patel'}, {'authorId': '2109461279', 'name': 'Sunil M Patel'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract The Internet of things refers to a type of network to connect anything with the Internet based on stipulated protocols through information sensing equipments to conduct information exchange and communications in order to achieve smart recognitions, positioning, tracing, monitoring, and administration. In this paper we briefly discussed about what IOT is, how IOT enables different technologies, about its architecture, characteristics & applications, IOT functional view & what are the future challenges for IOT. Key Terms: IOT (Internet of Things), IOT definitions, IOT functional view, architecture, characteristics, future challenges.\n",
            "------------------------------------\n",
            "Title Feeling Blue? Go Online: An Empirical Study of Social Support among Patients\n",
            "Author [{'authorId': '46518162', 'name': 'L. Yan'}, {'authorId': '144176421', 'name': 'Yong Tan'}]\n",
            "Venue Information systems research\n",
            "year 2014\n",
            "Abstract In this paper, we investigate whether social support exchanged in an online healthcare community benefits patients' mental health. We propose a nonhomogeneous Partially Observed Markov Decision Process POMDP model to examine the latent health outcomes for online health community members. The transition between different health states is modeled as a probability function that incorporates different forms of social support that patients exchange via discussion board posts. We find that patients benefit from learning from others and that their participation in the online community helps them to improve their health and to better engage in their disease self-management process. Our results also reveal differences in the influence of various forms of social support exchanged on the evolution of patients' health conditions. We find evidence that informational support is the most prevalent type in the online healthcare community. Nevertheless, emotional support plays the most significant role in helping patients move to a healthier state. Overall, the influence of social support is found to vary depending on patients' health conditions. Finally, we demonstrate that our proposed POMDP model can provide accurate predictions for patients' health states and can be used to recover missing or unavailable information on patients' health conditions.\n",
            "------------------------------------\n",
            "Title What Do Systems Users Have to Fear? Using Fear Appeals to Engender Threats and Fear that Motivate Protective Security Behaviors\n",
            "Author [{'authorId': '1695521', 'name': 'Scott R. Boss'}, {'authorId': '1732200', 'name': 'D. Galletta'}, {'authorId': '1786893', 'name': 'P. Lowry'}, {'authorId': '144155253', 'name': 'Gregory Moody'}, {'authorId': '2129279', 'name': 'P. Polak'}]\n",
            "Venue MIS Q.\n",
            "year 2015\n",
            "Abstract Because violations of information security (ISec) and privacy have become ubiquitous in both personal and work environments, academic attention to ISec and privacy has taken on paramount importance. Consequently, a key focus of ISec research has been discovering ways to motivate individuals to engage in more secure behaviors. Over time, the protection motivation theory (PMT) has become a leading theoretical foundation used in ISec research to help motivate individuals to change their security-related behaviors to protect themselves and their organizations. Our careful review of the foundation for PMT identified four opportunities for improving ISec PMT research. First, extant ISec studies do not use the full nomology of PMT constructs. Second, only one study uses fear-appeal manipulations, even though these are a core element of PMT. Third, virtually no ISec study models or measures fear. Fourth, whereas these studies have made excellent progress in predicting security intentions, none of them have addressed actual security behaviors. \n",
            " \n",
            "This article describes the theoretical foundation of these four opportunities for improvement. We tested the nomology of PMT, including manipulated fear appeals, in two different ISec contexts that model the modern theoretical treatment of PMT more closely than do extant ISec studies. The first data collection was a longitudinal study in the context of data backups. The second study was a short-term cross-sectional study in the context of anti-malware software. Our new model demonstrated better results and stronger fit than the existing models and confirms the efficacy of the four potential improvements we identified.\n",
            "------------------------------------\n",
            "Title Research Note - Privacy Concerns and Privacy-Protective Behavior in Synchronous Online Social Interactions\n",
            "Author [{'authorId': '1699964', 'name': 'Z. Jiang'}, {'authorId': '2502925', 'name': 'C. Heng'}, {'authorId': '3032830', 'name': 'Ben C. F. Choi'}]\n",
            "Venue Information systems research\n",
            "year 2013\n",
            "Abstract Privacy is of prime importance to many individuals when they attempt to develop online social relationships. Nonetheless, it has been observed that individuals' behavior is at times inconsistent with their privacy concerns, e.g., they disclose substantial private information in synchronous online social interactions, even though they are aware of the risks involved. Drawing on the hyperpersonal framework and the privacy calculus perspective, this paper elucidates the interesting roles of privacy concerns and social rewards in synchronous online social interactions by examining the causes and the behavioral strategies that individuals utilize to protect their privacy. An empirical study involving 251 respondents was conducted in online chat rooms. Our results indicate that individuals utilize both self-disclosure and misrepresentation to protect their privacy and that social rewards help explain why individuals may not behave in accordance with their privacy concerns. In addition, we find that perceived anonymity of others and perceived intrusiveness affect both privacy concerns and social rewards. Our findings also suggest that higher perceived anonymity of self decreases individuals' privacy concerns, and higher perceived media richness increases social rewards. Generally, this study contributes to the information systems literature by integrating the hyperpersonal framework and the privacy calculus perspective to identify antecedents of privacy trade-off and predict individuals' behavior in synchronous online social interactions.\n",
            "------------------------------------\n",
            "Title Technology acceptance model (TAM) and social media usage: an empirical study on Facebook\n",
            "Author [{'authorId': '3251885', 'name': 'Rupak Rauniar'}, {'authorId': '2485725', 'name': 'Greg Rawski'}, {'authorId': '2109754771', 'name': 'Jei Yang'}, {'authorId': '2111309754', 'name': 'Ben Johnson'}]\n",
            "Venue Journal of Enterprise Information Management\n",
            "year 2014\n",
            "Abstract Purpose – Given the widespread popularity of social media, such as Twitter, Facebook, Google+, and LinkedIn, theorizing and understanding the user attitude and usage behavior of social media site is fundamental in developing future understandings and deployment of these new technologies. One approach to such studies on drivers of social media usage behavior would be to revisit the technology acceptance model (TAM). The purpose of this paper is to discuss these issues. Design/methodology/approach – Decades of extensive research have focussed on validating the TAM, proposed by Davis (1986), for various types of information systems and communication technologies. TAM forecasts individual adoption and voluntary use of technology. This study examines individual adoption behavior of the most popular social networking site Facebook. The influences on the intention of using social networking based on individual's perceived ease of use (EU), the user's critical mass (CM), social networking site capability (CP), pe...\n",
            "------------------------------------\n",
            "Title Compressed Sensing Signal and Data Acquisition in Wireless Sensor Networks and Internet of Things\n",
            "Author [{'authorId': '1775276', 'name': 'Shancang Li'}, {'authorId': '39466716', 'name': 'Lida Xu'}, {'authorId': '48631815', 'name': 'Xinheng Wang'}]\n",
            "Venue IEEE Transactions on Industrial Informatics\n",
            "year 2013\n",
            "Abstract The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.\n",
            "------------------------------------\n",
            "Title The Real Effects of Financial Shocks: Evidence from Exogenous Changes in Analyst Coverage\n",
            "Author [{'authorId': '46249469', 'name': 'F. Derrien'}, {'authorId': '50548980', 'name': 'Ambrus Kecskés'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract We study the causal effects of analyst coverage on corporate investment and financing policies. We hypothesize that a decrease in analyst coverage increases information asymmetry and thus increases the cost of capital; as a result, firms decrease their investment and financing. We use broker closures and broker mergers to identify changes in analyst coverage that are exogenous to corporate policies. Using a difference-in-differences approach, we find that firms that lose an analyst decrease their investment and financing by 2.4% and 2.6% of total assets, respectively. These results are significantly stronger for firms that are smaller, have less analyst coverage, have a bigger increase in information asymmetry, and are more financially constrained.\n",
            "------------------------------------\n",
            "Title Bridges, brokers and boundary spanners in collaborative networks: a systematic review\n",
            "Author [{'authorId': '145092660', 'name': 'J. Long'}, {'authorId': '32657335', 'name': 'F. Cunningham'}, {'authorId': '145070047', 'name': 'J. Braithwaite'}]\n",
            "Venue BMC Health Services Research\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title LayoutLM: Pre-training of Text and Layout for Document Image Understanding\n",
            "Author [{'authorId': '3032611', 'name': 'Yiheng Xu'}, {'authorId': '123545597', 'name': 'Minghao Li'}, {'authorId': '145500855', 'name': 'Lei Cui'}, {'authorId': '3110003', 'name': 'Shaohan Huang'}, {'authorId': '49807919', 'name': 'Furu Wei'}, {'authorId': '92660691', 'name': 'Ming Zhou'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2019\n",
            "Abstract Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm.\n",
            "------------------------------------\n",
            "Title Big Data-Survey\n",
            "Author [{'authorId': '70661169', 'name': 'P. Sri'}, {'authorId': '144697723', 'name': 'M. Anusha'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Big data is the term for any gathering of information sets, so expensive and complex, that it gets to be hard to process for utilizing customary information handling applications. The difficulties incorporate investigation, catch, duration, inquiry, sharing, stockpiling, Exchange, perception, and protection infringement. To reduce spot business patterns, anticipate diseases, conflict etc., we require bigger data sets when compared with the smaller data sets. Enormous information is hard to work with utilizing most social database administration frameworks and desktop measurements and perception bundles, needing rather enormously parallel programming running on tens, hundreds, or even a large number of servers. In this paper there was an observation on Hadoop architecture, different tools used for big data and its security issues.\n",
            "------------------------------------\n",
            "Title Temporal Contiguity and Negativity Bias in the Impact of Online Word of Mouth\n",
            "Author [{'authorId': '100975264', 'name': 'Zoey Chen'}, {'authorId': '7444382', 'name': 'Nicholas H. Lurie'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Prior research shows that positive online reviews are less valued than negative reviews. The authors argue that this is due to differences in causal attributions for positive versus negative information such that positive reviews tend to be relatively more attributed to the reviewer (vs. product experience) than negative reviews. The presence of temporal contiguity cues, which indicate that review writing closely follows consumption, reduces the relative extent to which positive reviews are attributed to the reviewer and mitigates the negativity bias. An examination of 65,531 Yelp.com restaurant reviews shows that review value is negatively related to review valence but that this negative relationship is absent for reviews that contain temporal contiguity cues. A series of lab studies replicates these findings and suggests that temporal contiguity cues enhance the value of a positive review and increase the likelihood of choosing a product with a positive review by changing reader beliefs about the cause of the review.\n",
            "------------------------------------\n",
            "Title Integrated information theory of consciousness: an updated account.\n",
            "Author [{'authorId': '1726111', 'name': 'G. Tononi'}]\n",
            "Venue Archives Italiennes de Biologie\n",
            "year 2012\n",
            "Abstract This article presents an updated account of integrated information theory of consciousness (liT) and some of its implications. /IT stems from thought experiments that lead to phenomenological axioms (existence, compositionality, information, integration, exclusion) and corresponding ontological postulates. The information axiom asserts that every experience is spec~fic - it is what it is by differing in its particular way from a large repertoire of alternatives. The integration axiom asserts that each experience is unified- it cannot be reduced to independent components. The exclusion axiom asserts that every experience is definite - it is limited to particular things and not others and flows at a particular speed and resolution. /IT formalizes these intuitions with postulates. The information postulate states that only \"differences that make a difference\" from the intrinsic perpective of a system matter: a mechanism generates cause-effect information if its present state has selective past causes and selective future effects within a system. The integration postulate states that only information that is irreducible matters: mechanisms generate integrated information only to the extent that the information they generate cannot be partitioned into that generated within independent components. The exclusion postulate states that only maxima of integrated information matter: a mechanism specifies only one maximally irreducible set of past causes and future effects - a concept. A complex is a set of elements specifying a maximally irreducible constellation of concepts, where the maximum is evaluated over elements and at the optimal spatiatemporal scale. Its concepts specify a maximally integrated conceptual information structure or quale, which is identical with an experience. Finally, changes in information integration upon exposure to the environment reflect a system's ability to match the causal structure of the world. After introducing an updated definition of information integration and related quantities, the article presents some theoretical considerations about the relationship between information and causation and about the relational structure of concepts within a qua/e. It also explores the relationship between the temporal grain size of information integration and the dynamic of metastable states in the corticothalamic complex. Finally, it summarizes how liT accounts for empirical findings about the neural substrate of consciousness, and how various aspects of phenomenology may in principle be addressed in terms of the geometry of information integration.\n",
            "------------------------------------\n",
            "Title Nudging Energy Efficiency Behavior: The Role of Information Labels\n",
            "Author [{'authorId': '49251385', 'name': 'R. Newell'}, {'authorId': '4894037', 'name': 'J. Siikamäki'}]\n",
            "Venue Journal of the Association of Environmental and Resource Economists\n",
            "year 2013\n",
            "Abstract We use choice experiments and randomized information treatments to study the effectiveness of alternative energy efficiency labels in guiding households’ energy efficiency decisions. We disentangle the relative importance of different types of information and distinguish it from intertemporal behavior. We find that insufficient information can lead to considerable undervaluation of energy efficiency. Simple information on the monetary value of energy savings was the most important element guiding cost-efficient energy efficiency investments, with information on physical energy use and carbon dioxide emissions having additional but lesser importance. The degree to which the current US EnergyGuide label guided cost-efficient decisions depends on the discount rate. Using elicited individual discount rates, the current EnergyGuide label came very close to guiding cost-efficient decisions. Using a uniform 5% discount rate, the current label led to one-third undervaluation of energy efficiency. Our results reinforce the centrality of discounting in understanding individual behavior and guiding policy.\n",
            "------------------------------------\n",
            "Title BIM for facility managers\n",
            "Author [{'authorId': '70126316', 'name': 'P. Teicholz'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Building owners and facility managers are discovering that Building Information Modeling (BIM) models of buildings are deep reservoirs of information that can provide valuable spatial and mechanical details on every aspect of a property. When used appropriately, this data can improve performance and save time, effort, and money in running and maintaining the building during its life cycle. It can also provide information for future modifications. For instance, a BIM could reveal everything from the manufacturer of a light fixture to its energy usage to maintenance instructions.\n",
            "------------------------------------\n",
            "Title SHARE, LIKE, RECOMMEND\n",
            "Author [{'authorId': '144545646', 'name': 'A. Hermida'}, {'authorId': '113748384', 'name': 'F. Fletcher'}, {'authorId': '116426555', 'name': 'Darryl Korell'}, {'authorId': '117498746', 'name': 'Donna Logan'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This study examines the impact of social media spaces on news consumption, based on an online survey of 1600 Canadians. News organizations are rushing into social media, viewing services like Facebook and Twitter as opportunities to market and distribute content. There has been limited research outside the United States into the effects of social media on news consumption. Our study found that social networks are becoming a significant source of news for Canadians. Two-fifths of social networking users said they receive news from people they follow on services like Facebook, while a fifth get news from news organizations and individual journalists they follow. Users said they valued social media because it helped them keep up with events and exposed them to a wider range of news and information. While social interaction has always affected the dissemination of news, our study contributes to research that suggests social media are becoming central to the way people experience news. Networked media technologies are extending the ability of users to create and receive personalized news streams. Investigating how networked publics are reframing the news and shaping news flows would contribute to our understanding of the evolving relationship between the journalist and the audience.\n",
            "------------------------------------\n",
            "Title An Evolutionary Upgrade of Cognitive Load Theory: Using the Human Motor System and Collaboration to Support the Learning of Complex Cognitive Tasks\n",
            "Author [{'authorId': '2786756', 'name': 'F. Paas'}, {'authorId': '2479443', 'name': 'J. Sweller'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Crowdsourcing Geographic Knowledge: Volunteered Geographic Information (VGI) in Theory and Practice\n",
            "Author [{'authorId': '2484792', 'name': 'D. Sui'}, {'authorId': '144939902', 'name': 'S. Elwood'}, {'authorId': '2191738', 'name': 'M. Goodchild'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Consensus-Based Linear and Nonlinear Filtering\n",
            "Author [{'authorId': '1764788', 'name': 'G. Battistelli'}, {'authorId': '1799999', 'name': 'L. Chisci'}, {'authorId': '32230240', 'name': 'G. Mugnai'}, {'authorId': '145047816', 'name': 'A. Farina'}, {'authorId': '2505164', 'name': 'A. Graziano'}]\n",
            "Venue IEEE Transactions on Automatic Control\n",
            "year 2015\n",
            "Abstract This note addresses Distributed State Estimation (DSE) over sensor networks. Two existing consensus approaches for DSE, i.e., consensus on information (CI) and consensus on measurements (CM), are combined to provide a novel class of hybrid consensus filters (named Hybrid CMCI) which enjoy the complementary benefits of CM and CI. Novel theoretical results, limitedly to linear systems, on the guaranteed stability of the Hybrid CMCI filters under collective observability and network connectivity are proved. Finally, the effectiveness of the proposed class of consensus filters is evaluated on a target tracking case study with both linear and nonlinear sensors.\n",
            "------------------------------------\n",
            "Title Graph Convolution over Pruned Dependency Trees Improves Relation Extraction\n",
            "Author [{'authorId': '49889487', 'name': 'Yuhao Zhang'}, {'authorId': '50531624', 'name': 'Peng Qi'}, {'authorId': '144783904', 'name': 'Christopher D. Manning'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2018\n",
            "Abstract Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.\n",
            "------------------------------------\n",
            "Title The Simple Rules of Social Contagion\n",
            "Author [{'authorId': '1811944', 'name': 'Nathan Oken Hodas'}, {'authorId': '1782658', 'name': 'Kristina Lerman'}]\n",
            "Venue Scientific Reports\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title ClinVar: improving access to variant interpretations and supporting evidence\n",
            "Author [{'authorId': '3218124', 'name': 'M. Landrum'}, {'authorId': '2108441407', 'name': 'Jennifer M. Lee'}, {'authorId': '2057961586', 'name': 'M. Benson'}, {'authorId': '2148612924', 'name': 'Garth R. Brown'}, {'authorId': '41170163', 'name': 'Chen Chao'}, {'authorId': '2238195', 'name': 'S. Chitipiralla'}, {'authorId': '2052182323', 'name': 'Baoshan Gu'}, {'authorId': '144951362', 'name': 'Jennifer Hart'}, {'authorId': '146499947', 'name': 'Douglas Hoffman'}, {'authorId': '50027016', 'name': 'W. Jang'}, {'authorId': '144755312', 'name': 'Karen Karapetyan'}, {'authorId': '1997190', 'name': 'K. Katz'}, {'authorId': '2107964129', 'name': 'Chunlei Liu'}, {'authorId': '35701310', 'name': 'Zenith Maddipatla'}, {'authorId': '50742796', 'name': 'A. Malheiro'}, {'authorId': '35421611', 'name': 'Kurt McDaniel'}, {'authorId': '3333288', 'name': 'M. Ovetsky'}, {'authorId': '35625261', 'name': 'George R. Riley'}, {'authorId': '2110530042', 'name': 'George Zhou'}, {'authorId': '145140882', 'name': 'J. B. Holmes'}, {'authorId': '8619885', 'name': 'B. Kattman'}, {'authorId': '1758049', 'name': 'D. Maglott'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2017\n",
            "Abstract Abstract ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) is a freely available, public archive of human genetic variants and interpretations of their significance to disease, maintained at the National Institutes of Health. Interpretations of the clinical significance of variants are submitted by clinical testing laboratories, research laboratories, expert panels and other groups. ClinVar aggregates data by variant-disease pairs, and by variant (or set of variants). Data aggregated by variant are accessible on the website, in an improved set of variant call format files and as a new comprehensive XML report. ClinVar recently started accepting submissions that are focused primarily on providing phenotypic information for individuals who have had genetic testing. Submissions may come from clinical providers providing their own interpretation of the variant (‘provider interpretation’) or from groups such as patient registries that primarily provide phenotypic information from patients (‘phenotyping only’). ClinVar continues to make improvements to its search and retrieval functions. Several new fields are now indexed for more precise searching, and filters allow the user to narrow down a large set of search results.\n",
            "------------------------------------\n",
            "Title A Turn Toward Avoidance? Selective Exposure to Online Political Information, 2004–2008\n",
            "Author [{'authorId': '144648517', 'name': 'R. Garrett'}, {'authorId': '115213499', 'name': 'Dustin Carnahan'}, {'authorId': '144915193', 'name': 'Emily K. Lynch'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Minimum information reporting in bio–nano experimental literature\n",
            "Author [{'authorId': '15208247', 'name': 'Matthew Faria'}, {'authorId': '6693931', 'name': 'M. Björnmalm'}, {'authorId': '6509165', 'name': 'K. Thurecht'}, {'authorId': '38588896', 'name': 'S. Kent'}, {'authorId': '3825957', 'name': 'R. Parton'}, {'authorId': '3888545', 'name': 'M. Kavallaris'}, {'authorId': '5857898', 'name': 'A. Johnston'}, {'authorId': '153937048', 'name': 'J. Gooding'}, {'authorId': '3569249', 'name': 'S. Corrie'}, {'authorId': '5712542', 'name': 'B. Boyd'}, {'authorId': '6757331', 'name': 'P. Thordarson'}, {'authorId': '2113938825', 'name': 'A. Whittaker'}, {'authorId': '2931286', 'name': 'M. Stevens'}, {'authorId': '5824537', 'name': 'C. Prestidge'}, {'authorId': '34733441', 'name': 'C. Porter'}, {'authorId': '2947319', 'name': 'W. Parak'}, {'authorId': '145649820', 'name': 'T. P. Davis'}, {'authorId': '2434078', 'name': 'E. Crampin'}, {'authorId': '144534243', 'name': 'F. Caruso'}]\n",
            "Venue Nature Nanotechnology\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Information Transmission in Irrigation Technology Adoption and Diffusion: Social Learning, Extension Services, and Spatial Effects\n",
            "Author [{'authorId': '2112865', 'name': 'Margarita Genius'}, {'authorId': '3985163', 'name': 'P. Koundouri'}, {'authorId': '3230722', 'name': 'V. Tzouvelekas'}, {'authorId': '13092399', 'name': 'Céline Nauges'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract In this article, we investigate the role of information transmission in promoting agricultural technology adoption and diffusion through extension services and social learning. We develop a theoretical model of technology adoption and diffusion, which we then empirically apply, using duration analysis, on a micro-dataset consisting of recall data covering the period 1994-2004 for olive-producing farms from Crete, Greece. Our findings suggest that both extension services and social learning are strong determinants of technology adoption and diffusion, while the effectiveness of each of the two informational channels is enhanced by the presence of the other.\n",
            "------------------------------------\n",
            "Title How the public uses social media wechat to obtain health information in china: a survey study\n",
            "Author [{'authorId': '2153647243', 'name': 'Xingting Zhang'}, {'authorId': '2054328989', 'name': 'Dong Wen'}, {'authorId': '96114397', 'name': 'Jun Liang'}, {'authorId': '2572773', 'name': 'Jianbo Lei'}]\n",
            "Venue BMC Medical Informatics and Decision Making\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Mixed Method Research: Instruments, Validity, Reliability and Reporting Findings\n",
            "Author [{'authorId': '11429840', 'name': 'Mohammad Zohrabi'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The mixed method approaches have recently risen to prominence. The reason that more researchers are opting for these types of research is that both qualitative and quantitative data are simultaneously collected, analyzed and interpreted. In this article the main research instruments (questionnaire, interview and classroom observation) usually used in the mixed method designs are presented and elaborated on. It is believed that using different types of procedures for collecting data and obtaining that information through different sources (learners, teachers, program staff, etc.) can augment the validity and reliability of the data and their interpretation. Therefore, the various ways of boosting the validity and reliability of the data and instruments are delineated at length. Finally, an outline of reporting the findings in the mixed method approaches is sketched out. It is believed that this article can be useful and beneficial to the researchers in general and postgraduate students in particular who want to start or are involved in the process of conducting research.\n",
            "------------------------------------\n",
            "Title Enabling Flexibility in Process-Aware Information Systems: Challenges, Methods, Technologies\n",
            "Author [{'authorId': '145870311', 'name': 'M. Reichert'}, {'authorId': '143811023', 'name': 'B. Weber'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract In todays dynamic business world, the success of a company increasingly depends on its ability to react to changes in its environment in a quick and flexible way. Companies have therefore identified process agility as a competitive advantage to address business trends like increasing product and service variability or faster time to market, and to ensure business IT alignment. Along this trend, a new generation of information systems has emergedso-called process-aware information systems (PAIS), like workflow management systems, case handling tools, and service orchestration engines. With this book, Reichert and Weber address these flexibility needs and provide an overview of PAIS with a strong focus on methods and technologies fostering flexibility for all phases of the process lifecycle (i.e., modeling, configuration, execution and evolution). Their presentation is divided into six parts. Part I starts with an introduction of fundamental PAIS concepts and establishes the context of process flexibility in the light of practical scenarios. Part II focuses on flexibility support for pre-specified processes, the currently predominant paradigm in the field of business process management (BPM). Part III details flexibility support for loosely specified processes, which only partially specify the process model at build-time, while decisions regarding the exact specification of certain model parts are deferred to the run-time. Part IV deals with user- and data-driven processes, which aim at a tight integration of processes and data, and hence enable an increased flexibility compared to traditional PAIS. Part V introduces existing technologies and systems for the realization of a flexible PAIS. Finally, Part VI summarizes the main ideas of this book and gives an outlook on advanced flexibility issues. The bookstarget groups include researchers, PhD students and Master students in the field of information systems. After reading the book, they will better understand PAIS flexibility aspects. To support the easy use as a textbook, a series of exercises is provided at the end of each chapter and slides and further teaching material are available on the books web site www.flexible-processes.com. Professionals specializing in business process management (BPM) who want to obtain a good understanding of flexibility challenges in BPM and state-of-the-art solutions will also benefit from the presentations of open source as well as commercial process management systems and related practical scenarios.\n",
            "------------------------------------\n",
            "Title The evolutionary basis of human social learning\n",
            "Author [{'authorId': '47580769', 'name': 'T. Morgan'}, {'authorId': '143926493', 'name': 'L. Rendell'}, {'authorId': '145289835', 'name': 'M. Ehn'}, {'authorId': '52030466', 'name': 'W. Hoppitt'}, {'authorId': '2866059', 'name': 'K. Laland'}]\n",
            "Venue Proceedings of the Royal Society B: Biological Sciences\n",
            "year 2012\n",
            "Abstract Humans are characterized by an extreme dependence on culturally transmitted information. Such dependence requires the complex integration of social and asocial information to generate effective learning and decision making. Recent formal theory predicts that natural selection should favour adaptive learning strategies, but relevant empirical work is scarce and rarely examines multiple strategies or tasks. We tested nine hypotheses derived from theoretical models, running a series of experiments investigating factors affecting when and how humans use social information, and whether such behaviour is adaptive, across several computer-based tasks. The number of demonstrators, consensus among demonstrators, confidence of subjects, task difficulty, number of sessions, cost of asocial learning, subject performance and demonstrator performance all influenced subjects' use of social information, and did so adaptively. Our analysis provides strong support for the hypothesis that human social learning is regulated by adaptive learning rules.\n",
            "------------------------------------\n",
            "Title End-to-End Flow Correlation Tracking with Spatial-Temporal Attention\n",
            "Author [{'authorId': '2118932732', 'name': 'Zheng Zhu'}, {'authorId': '39533001', 'name': 'Wei Wu'}, {'authorId': '2057328643', 'name': 'Wei Zou'}, {'authorId': '1721677', 'name': 'Junjie Yan'}]\n",
            "Venue 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "year 2017\n",
            "Abstract Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable performance in recent tracking benchmarks. However, most of existing DCF trackers only consider appearance features of current frame, and hardly benefit from motion and inter-frame information. The lack of temporal information degrades the tracking performance during challenges such as partial occlusion and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. The FlowTrack formulates individual components, including optical flow estimation, feature extraction, aggregation and correlation filters tracking as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in deep learning framework. Then the historical feature maps at predefined intervals are warped and aggregated with current ones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VOT2015 and VOT2016.\n",
            "------------------------------------\n",
            "Title A Longitudinal Study of Herd Behavior in the Adoption and Continued Use of Technology\n",
            "Author [{'authorId': '1799935', 'name': 'Heshan Sun'}]\n",
            "Venue MIS Q.\n",
            "year 2013\n",
            "Abstract Herd literature suggests that people tend to discount their own beliefs and imitate others when making adoption decisions and that the resulting adoption decisions are fragile and can be easily reversed during the post-adoptive stage. This helps explain why the adoption of a number of new technologies--from Amazon's Kindle, to Apple's iPod, iPhone, and iPad, to various types of Web 2.0 technologies--appears to have adoption patterns similar to those of new fashion trends (i. e., an initial en masse acquisition followed by subsequent abandonment). It is important to understand these phenomena because they are strongly related to the staying power of technology. From a herd behavior perspective, this study proposes two new concepts, namely discounting one's own information and imitating others, to describe herd behavior in technology adoption. A research model is developed to describe the conditions under which herd behavior in technology adoption occurs, how it impacts technology adoption decision making, and how it influences post-adoptive system use. A longitudinal study is conducted to examine the research model. Findings from this research suggest that the discounting of one's own beliefs and the imitating of others when adopting a new technology are provoked primarily by the observation of prior adoptions and perceptions of uncertainty regarding the adoption of new technology. Herd behavior has a significant influence on user technology adoption; however, it does not necessarily lead to the collapse of the user base, as predicted in the herd literature. Instead, imitation can help reduce post-adoption regret and thus serve as a legitimate strategy for choosing a good enough technology, which may or may not be the best option to enhance job performance. People tend to adjust their beliefs when herding and also to revive their discounted initial beliefs to modify their beliefs about the technology at the post-adoptive stage. Findings from this study have significant research and practical implications.\n",
            "------------------------------------\n",
            "Title Exploring the Security of Information Sharing on Social Networking Sites: The Role of Perceived Control of Information\n",
            "Author [{'authorId': '30583543', 'name': 'Nick Hajli'}, {'authorId': '2251737', 'name': 'Xiaolin Lin'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Epidemiological modeling of news and rumors on Twitter\n",
            "Author [{'authorId': '2068091096', 'name': 'Fang Jin'}, {'authorId': '2056134295', 'name': 'Edward R. Dougherty'}, {'authorId': '1814998', 'name': 'Parang Saraf'}, {'authorId': '2108097082', 'name': 'Yang Cao'}, {'authorId': '1755938', 'name': 'Naren Ramakrishnan'}]\n",
            "Venue Social Network Mining and Analysis\n",
            "year 2013\n",
            "Abstract Characterizing information diffusion on social platforms like Twitter enables us to understand the properties of underlying media and model communication patterns. As Twitter gains in popularity, it has also become a venue to broadcast rumors and misinformation. We use epidemiological models to characterize information cascades in twitter resulting from both news and rumors. Specifically, we use the SEIZ enhanced epidemic model that explicitly recognizes skeptics to characterize eight events across the world and spanning a range of event types. We demonstrate that our approach is accurate at capturing diffusion in these events. Our approach can be fruitfully combined with other strategies that use content modeling and graph theoretic features to detect (and possibly disrupt) rumors.\n",
            "------------------------------------\n",
            "Title Building Information Modeling\n",
            "Author [{'authorId': '70590035', 'name': 'K. Kensek'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Preface Acknowledgements Introduction Fundamentals 1. BIM Overview Parametric Modeling and the Virtual Building Model BIM \"Dimensions\" Level of Development Summary 2. Stakeholders and BIM's Many Roles Architects, Engineers, Consultants Construction Managers, Contractors, Sub-contractors Fabricators Facilities Managers and Owners Summary 3. Data Exchange and Interoperability Interoperability Data Exchange Workflows Single Model and Federated Model Systems Data and Communication Formats Summary 4. BIM Implementation Transforming the Office to BIM Delivery Methods Legal Issues Office Standards BIM Execution Plan (BEP) Metrics for BIM Maturity Summary 5. Beyond Basic BIM BIM Analytics Cloud Computing Computational Design Increased Sophistication of Owners Summary Application: Project Case Studies designLAB: Small BIM Tames Big Brutalism ZGF: BIM in Transition: Making the Leap at a Large Firm CASE: Building Information Coordinators Mortenson Construction: Outstanding Project Success Through Collaboration Conclusion References and Software Mentioned Index\n",
            "------------------------------------\n",
            "Title A strategy for the design of skyrmion racetrack memories\n",
            "Author [{'authorId': '39343867', 'name': 'R. Tomasello'}, {'authorId': '153623095', 'name': 'E. Martínez'}, {'authorId': '3215410', 'name': 'R. Zivieri'}, {'authorId': '144070755', 'name': 'L. Torres'}, {'authorId': '144902853', 'name': 'M. Carpentieri'}, {'authorId': '1988168', 'name': 'G. Finocchio'}]\n",
            "Venue Scientific Reports\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Challenges and opportunities of digital information at the intersection of Big Data Analytics and supply chain management\n",
            "Author [{'authorId': '121041576', 'name': 'Florian Kache'}, {'authorId': '1879480', 'name': 'S. Seuring'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract Purpose \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Despite the variety of supply chain management (SCM) research, little attention has been given to the use of Big Data Analytics for increased information exploitation in a supply chain. The purpose of this paper is to contribute to theory development in SCM by investigating the potential impacts of Big Data Analytics on information usage in a corporate and supply chain context. As it is imperative for companies in the supply chain to have access to up-to-date, accurate, and meaningful information, the exploratory research will provide insights into the opportunities and challenges emerging from the adoption of Big Data Analytics in SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Design/methodology/approach \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Although Big Data Analytics is gaining increasing attention in management, empirical research on the topic is still scarce. Due to the limited availability of comparable material at the intersection of Big Data Analytics and SCM, the authors apply the Delphi research technique. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Findings \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Portraying the emerging transition trend from a digital business environment, the presented Delphi study findings contribute to extant knowledge by identifying 43 opportunities and challenges linked to the emergence of Big Data Analytics from a corporate and supply chain perspective. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Research limitations/implications \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "These constructs equip the research community with a first collection of aspects, which could provide the basis to tailor further research at the nexus of Big Data Analytics and SCM. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Originality/value \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The research adds to the existing knowledge base as no empirical research has been presented so far specifically assessing opportunities and challenges on corporate and supply chain level with a special focus on the implications imposed through Big Data Analytics.\n",
            "------------------------------------\n",
            "Title Predictive Entropy Search for Efficient Global Optimization of Black-box Functions\n",
            "Author [{'authorId': '1388574431', 'name': 'José Miguel Hernández-Lobato'}, {'authorId': '3243579', 'name': 'Matthew W. Hoffman'}, {'authorId': '1744700', 'name': 'Zoubin Ghahramani'}]\n",
            "Venue NIPS\n",
            "year 2014\n",
            "Abstract We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance.\n",
            "------------------------------------\n",
            "Title Information network or social network?: the structure of the twitter follow graph\n",
            "Author [{'authorId': '50362385', 'name': 'Seth A. Myers'}, {'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '46479974', 'name': 'Pankaj Gupta'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]\n",
            "Venue The Web Conference\n",
            "year 2014\n",
            "Abstract In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.\n",
            "------------------------------------\n",
            "Title Information Cascades among Investors in Equity Crowdfunding\n",
            "Author [{'authorId': '2882685', 'name': 'Silvio Vismara'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Finance studies on information cascades, usually in an initial public offering setting, typically differentiate between institutional and retail investors, as this is the only information available to potential backers. Information available through equity crowdfunding platforms includes details on individual investors as they may disclose information about themselves by linking their profile to social networks or websites. Using a sample of 132 equity offerings on Crowdcube in 2014, we show that information cascades among individual investors play a crucial role in crowdfunding campaigns. Investors with a public profile increase the appeal of the offer among early investors, who in turn attract late investors.\n",
            "------------------------------------\n",
            "Title Norm Perception as a Vehicle for Social Change\n",
            "Author [{'authorId': '21703056', 'name': 'Margaret E. Tankard'}, {'authorId': '4659343', 'name': 'E. Paluck'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract How can we change social norms, the standards describing typical or desirable behavior? Because individuals’ perceptions of norms guide their personal behavior, influencing these perceptions is one way to create social change. And yet individuals do not form perceptions of typical or desirable behavior in an unbiased manner. Individuals attend to select sources of normative information, and their resulting perceptions rarely match actual rates of behavior in their environment. Thus, changing social norms requires an understanding of how individuals perceive norms in the first place. We describe three sources of information that people use to understand norms—individual behavior, summary information about a group, and institutional signals. Social change interventions have used each source to influence perceived norms and behaviors, including recycling, intimate-partner violence, and peer harassment. We discuss conditions under which influence over perceived norms is likely to be stronger, based on the source of the normative information and individuals’ relationship to the source. Finally, we point to future research and suggest when it is most appropriate to use a norm change strategy in the interest of behavior and social change.\n",
            "------------------------------------\n",
            "Title Integration of Online and Offline Channels in Retail: The Impact of Sharing Reliable Inventory Availability Information\n",
            "Author [{'authorId': '2192628', 'name': 'Santiago Gallino'}, {'authorId': '152142558', 'name': 'Antonio Moreno'}]\n",
            "Venue Management Sciences\n",
            "year 2014\n",
            "Abstract Using a proprietary data set, we analyze the impact of the implementation of a “buy-online, pick-up-in-store” BOPS project. The implementation of this project is associated with a reduction in online sales and an increase in store sales and traffic. These results can be explained by two simultaneous phenomena: 1 additional store sales from customers who use the BOPS functionality and buy additional products in the stores cross-selling effect and 2 the shift of some customers from the online to the brick-and-mortar channel and the conversion of noncustomers into store customers channel-shift effect. We explain these channel-shift patterns as an increase in “research online, purchase offline” behavior enabled by BOPS implementation, and we validate this explanation with evidence from the change of cart abandonment and conversion rates of the brick-and-mortar and online channels. We interpret these results in light of recent operations management literature that analyzes the impact of sharing inventory availability information. Our analysis illustrates the limitations of drawing conclusions about complex interventions using single-channel data. \n",
            " \n",
            "This paper was accepted by Alok Gupta, special issue on business analytics.\n",
            "------------------------------------\n",
            "Title What's skill got to do with it?: Information literacy skills and self-views of ability among first-year college students\n",
            "Author [{'authorId': '40030853', 'name': 'M. Gross'}, {'authorId': '3227767', 'name': 'D. Latham'}]\n",
            "Venue J. Assoc. Inf. Sci. Technol.\n",
            "year 2012\n",
            "Abstract This study replicates a previous study based on work in psychology, which demonstrates that students who score as below proficient in information literacy (IL) skills have a miscalibrated self-view of their ability. Simply stated, these students tend to believe that they have above-average IL skills, when, in fact, an objective test of their ability indicates that they are below-proficient in terms of their actual skills. This investigation was part of an Institute of Museum and Library Services-funded project and includes demographic data about participants, their scores on an objective test of their information literacy skills, and self-estimates of their ability. Findings support previous research that indicates many students come to college without proficient IL skills, that students with below-proficient IL skills have inflated views of their ability, and that this miscalibration can also be expressed by students who test as proficient. Implications for research and practice are discussed. © 2012 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title Rumors and Health Care Reform: Experiments in Political Misinformation\n",
            "Author [{'authorId': '4859855', 'name': 'A. Berinsky'}]\n",
            "Venue British Journal of Political Science\n",
            "year 2015\n",
            "Abstract This article explores belief in political rumors surrounding the health care reforms enacted by Congress in 2010. Refuting rumors with statements from unlikely sources can, under certain circumstances, increase the willingness of citizens to reject rumors regardless of their own political predilections. Such source credibility effects, while well known in the political persuasion literature, have not been applied to the study of rumor. Though source credibility appears to be an effective tool for debunking political rumors, risks remain. Drawing upon research from psychology on ‘fluency’ – the ease of information recall – this article argues that rumors acquire power through familiarity. Attempting to quash rumors through direct refutation may facilitate their diffusion by increasing fluency. The empirical results find that merely repeating a rumor increases its power.\n",
            "------------------------------------\n",
            "Title Database resources of the National Center for Biotechnology Information.\n",
            "Author [{'authorId': '3011137', 'name': 'E. Sayers'}, {'authorId': '2065113442', 'name': 'J. Beck'}, {'authorId': '145276593', 'name': 'J. R. Brister'}, {'authorId': '145600821', 'name': 'Evan E. Bolton'}, {'authorId': '51025128', 'name': 'Kathi Canese'}, {'authorId': '1753903', 'name': 'Donald C. Comeau'}, {'authorId': '37996742', 'name': 'Kathryn Funk'}, {'authorId': '1404181075', 'name': 'A. Ketter'}, {'authorId': '49899890', 'name': 'Sunghwan Kim'}, {'authorId': '47258944', 'name': 'Avi Kimchi'}, {'authorId': '50617031', 'name': 'P. Kitts'}, {'authorId': '48022505', 'name': 'A. Kuznetsov'}, {'authorId': '46172352', 'name': 'S. Lathrop'}, {'authorId': '144202084', 'name': 'Zhiyong Lu'}, {'authorId': '3309511', 'name': 'Kelly M. McGarvey'}, {'authorId': '34806045', 'name': 'T. Madden'}, {'authorId': '144308320', 'name': 'Terence D. Murphy'}, {'authorId': '1398781025', 'name': \"N. O'Leary\"}, {'authorId': '144205048', 'name': 'Lon Phan'}, {'authorId': '144863127', 'name': 'Valerie A. Schneider'}, {'authorId': '1401199158', 'name': 'F. Thibaud-Nissen'}, {'authorId': '5878244', 'name': 'B. Trawick'}, {'authorId': '1753253', 'name': 'K. Pruitt'}, {'authorId': '1968560', 'name': 'J. Ostell'}]\n",
            "Venue Nucleic Acids Research\n",
            "year 2019\n",
            "Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface, a sequence database search and a gene orthologs page. Additional resources that were updated in the past year include PMC, Bookshelf, My Bibliography, Assembly, RefSeq, viral genomes, the prokaryotic genome annotation pipeline, Genome Workbench, dbSNP, BLAST, Primer-BLAST, IgBLAST and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "------------------------------------\n",
            "Title Unmet care needs of advanced cancer patients and their informal caregivers: a systematic review\n",
            "Author [{'authorId': '1865225869', 'name': 'Tao Wang'}, {'authorId': '4483816', 'name': 'A. Molassiotis'}, {'authorId': '4362687', 'name': 'B. Chung'}, {'authorId': '3536095', 'name': 'J. Tan'}]\n",
            "Venue BMC Palliative Care\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols\n",
            "Author [{'authorId': '144891750', 'name': 'P. Campos'}, {'authorId': '153153441', 'name': 'F. Díez'}, {'authorId': '1737406', 'name': 'Iván Cantador'}]\n",
            "Venue User modeling and user-adapted interaction\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Effective Pattern Discovery for Text Mining\n",
            "Author [{'authorId': '144729286', 'name': 'N. Zhong'}, {'authorId': '152998482', 'name': 'Yuefeng Li'}, {'authorId': '8174997', 'name': 'Sheng-Tang Wu'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2012\n",
            "Abstract Many data mining techniques have been proposed for mining useful patterns in text documents. However, how to effectively use and update discovered patterns is still an open research issue, especially in the domain of text mining. Since most existing text mining methods adopted term-based approaches, they all suffer from the problems of polysemy and synonymy. Over the years, people have often held the hypothesis that pattern (or phrase)-based approaches should perform better than the term-based ones, but many experiments do not support this hypothesis. This paper presents an innovative and effective pattern discovery technique which includes the processes of pattern deploying and pattern evolving, to improve the effectiveness of using and updating discovered patterns for finding relevant and interesting information. Substantial experiments on RCV1 data collection and TREC topics demonstrate that the proposed solution achieves encouraging performance.\n",
            "------------------------------------\n",
            "Title Life With and Without Coding: Two Methods for Early-Stage Data Analysis in Qualitative Research Aiming at Causal Explanations\n",
            "Author [{'authorId': '3263141', 'name': 'J. Gläser'}, {'authorId': '2347985', 'name': 'G. Laudel'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Qualitative research aimed at \"mechanismic\" explanations poses specific challenges to qualitative data analysis because it must integrate existing theory with patterns identified in the data. We explore the utilization of two methods—coding and qualitative content analysis—for the first steps in the data analysis process, namely \"cleaning\" and organizing qualitative data. Both methods produce an information base that is structured by categories and can be used in the subsequent search for patterns in the data and integration of these patterns into a systematic, theoretically embedded explanation. Used as a stand-alone method outside the grounded theory approach, coding leads to an indexed text, i.e. both the original text and the index (the system of codes describing the content of text segments) are subjected to further analysis. Qualitative content analysis extracts the relevant information, i.e. separates it from the original text, and processes only this information. We suggest that qualitative content analysis has advantages compared to coding whenever the research question is embedded in prior theory and can be answered without processing knowledge about the form of statements and their position in the text, which usually is the case in the search for \"mechanismic\" explanations. Coding outperforms qualitative content analysis in research that needs this information in later stages of the analysis, e.g. the exploration of meaning or the study of the construction of narratives.\n",
            "------------------------------------\n",
            "Title Health-protective behaviour, social media usage and conspiracy belief during the COVID-19 public health emergency\n",
            "Author [{'authorId': '3433561', 'name': 'D. Allington'}, {'authorId': '11920413', 'name': 'B. Duffy'}, {'authorId': '6891628', 'name': 'S. Wessely'}, {'authorId': '6609257', 'name': 'N. Dhavan'}, {'authorId': '2004896039', 'name': 'J. Rubin'}]\n",
            "Venue Psychological Medicine\n",
            "year 2020\n",
            "Abstract Abstract Background Social media platforms have long been recognised as major disseminators of health misinformation. Many previous studies have found a negative association between health-protective behaviours and belief in the specific form of misinformation popularly known as ‘conspiracy theory’. Concerns have arisen regarding the spread of COVID-19 conspiracy theories on social media. Methods Three questionnaire surveys of social media use, conspiracy beliefs and health-protective behaviours with regard to COVID-19 among UK residents were carried out online, one using a self-selecting sample (N = 949) and two using stratified random samples from a recruited panel (N = 2250, N = 2254). Results All three studies found a negative relationship between COVID-19 conspiracy beliefs and COVID-19 health-protective behaviours, and a positive relationship between COVID-19 conspiracy beliefs and use of social media as a source of information about COVID-19. Studies 2 and 3 also found a negative relationship between COVID-19 health-protective behaviours and use of social media as a source of information, and Study 3 found a positive relationship between health-protective behaviours and use of broadcast media as a source of information. Conclusions When used as an information source, unregulated social media may present a health risk that is partly but not wholly reducible to their role as disseminators of health-related conspiracy beliefs.\n",
            "------------------------------------\n",
            "Title Privacy as part of the app decision-making process\n",
            "Author [{'authorId': '1920395', 'name': 'Patrick Gage Kelley'}, {'authorId': '1699751', 'name': 'L. Cranor'}, {'authorId': '2464164', 'name': 'N. Sadeh'}]\n",
            "Venue International Conference on Human Factors in Computing Systems\n",
            "year 2013\n",
            "Abstract Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.\n",
            "------------------------------------\n",
            "Title Consumer Evaluation of the Quality of Online Health Information: Systematic Literature Review of Relevant Criteria and Indicators\n",
            "Author [{'authorId': '2225086', 'name': 'Yalin Sun'}, {'authorId': '48379538', 'name': 'Yan Zhang'}, {'authorId': '2082319', 'name': 'J. Gwizdka'}, {'authorId': '1759299', 'name': 'Ciaran B. Trace'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2019\n",
            "Abstract Background As the quality of online health information remains questionable, there is a pressing need to understand how consumers evaluate this information. Past reviews identified content-, source-, and individual-related factors that influence consumer judgment in this area. However, systematic knowledge concerning the evaluation process, that is, why and how these factors influence the evaluation behavior, is lacking. Objective This review aims (1) to identify criteria (rules that reflect notions of value and worth) that consumers use to evaluate the quality of online health information and the indicators (properties of information objects to which criteria are applied to form judgments) they use to support the evaluation in order to achieve a better understanding of the process of information quality evaluation and (2) to explicate the relationship between indicators and criteria to provide clear guidelines for designers of consumer health information systems. Methods A systematic literature search was performed in seven digital reference databases including Medicine, Psychology, Communication, and Library and Information Science to identify empirical studies that report how consumers directly and explicitly describe their evaluation of online health information quality. Thirty-seven articles met the inclusion criteria. A qualitative content analysis was performed to identify quality evaluation criteria, indicators, and their relationships. Results We identified 25 criteria and 165 indicators. The most widely reported criteria used by consumers were trustworthiness, expertise, and objectivity. The indicators were related to source, content, and design. Among them, 114 were positive indicators (entailing positive quality judgments), 35 were negative indicators (entailing negative judgments), and 16 indicators had both positive and negative quality influence, depending on contextual factors (eg, source and individual differences) and criteria applied. The most widely reported indicators were site owners/sponsors; consensus among multiple sources; characteristics of writing and language; advertisements; content authorship; and interface design. Conclusions Consumer evaluation of online health information is a complex cost-benefit analysis process that involves the use of a wide range of criteria and a much wider range of quality indicators. There are commonalities in the use of criteria across user groups and source types, but the differences are hard to ignore. Evidently, consumers’ health information evaluation can be characterized as highly subjective and contextualized, and sometimes, misinformed. These findings invite more research into how different user groups evaluate different types of online sources and a personalized approach to educate users about evaluating online health information quality.\n",
            "------------------------------------\n",
            "Title A brief introduction to weakly supervised learning\n",
            "Author [{'authorId': '145624000', 'name': 'Zhi-Hua Zhou'}]\n",
            "Venue \n",
            "year 2018\n",
            "Abstract Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.\n",
            "------------------------------------\n",
            "Title CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations\n",
            "Author [{'authorId': '2586287', 'name': 'Stefan Seemayer'}, {'authorId': '153595345', 'name': 'M. Gruber'}, {'authorId': '2225852', 'name': 'J. Söding'}]\n",
            "Venue Bioinform.\n",
            "year 2014\n",
            "Abstract Motivation: Recent breakthroughs in protein residue–residue contact prediction have made reliable de novo prediction of protein structures possible. The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e. to separate direct from indirect effects. Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM). Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads. This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein–protein interactions. Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35–113 times faster and with the same precision as the most accurate published methods. For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4–14 times faster. Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15–60 s on a consumer-grade GPU and 1–6 min on a six-core CPU. Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title The lure of rationality: Why does the deficit model persist in science communication?\n",
            "Author [{'authorId': '13284967', 'name': 'Molly Simis'}, {'authorId': '49101932', 'name': 'Haley C. Madden'}, {'authorId': '32998833', 'name': 'M. Cacciatore'}, {'authorId': '3435391', 'name': 'Sara K. Yeo'}]\n",
            "Venue Public Understanding of Science\n",
            "year 2016\n",
            "Abstract Science communication has been historically predicated on the knowledge deficit model. Yet, empirical research has shown that public communication of science is more complex than what the knowledge deficit model suggests. In this essay, we pose four lines of reasoning and present empirical data for why we believe the deficit model still persists in public communication of science. First, we posit that scientists’ training results in the belief that public audiences can and do process information in a rational manner. Second, the persistence of this model may be a product of current institutional structures. Many graduate education programs in science, technology, engineering, and math (STEM) fields generally lack formal training in public communication. We offer empirical evidence that demonstrates that scientists who have less positive attitudes toward the social sciences are more likely to adhere to the knowledge deficit model of science communication. Third, we present empirical evidence of how scientists conceptualize “the public” and link this to attitudes toward the deficit model. We find that perceiving a knowledge deficit in the public is closely tied to scientists’ perceptions of the individuals who comprise the public. Finally, we argue that the knowledge deficit model is perpetuated because it can easily influence public policy for science issues. We propose some ways to uproot the deficit model and move toward more effective science communication efforts, which include training scientists in communication methods grounded in social science research and using approaches that engage community members around scientific issues.\n",
            "------------------------------------\n",
            "Title Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n",
            "Author [{'authorId': '6272499', 'name': 'I. Korstjens'}, {'authorId': '144589165', 'name': 'A. Moser'}]\n",
            "Venue European Journal of General Practice\n",
            "year 2017\n",
            "Abstract Abstract In the course of our supervisory work over the years we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The first article provides an introduction to this series. The second article focused on context, research questions and designs. The third article focused on sampling, data collection and analysis. This fourth article addresses FAQs about trustworthiness and publishing. Quality criteria for all qualitative research are credibility, transferability, dependability, and confirmability. Reflexivity is an integral part of ensuring the transparency and quality of qualitative research. Writing a qualitative research article reflects the iterative nature of the qualitative research process: data analysis continues while writing. A qualitative research article is mostly narrative and tends to be longer than a quantitative paper, and sometimes requires a different structure. Editors essentially use the criteria: is it new, is it true, is it relevant? An effective cover letter enhances confidence in the newness, trueness and relevance, and explains why your study required a qualitative design. It provides information about the way you applied quality criteria or a checklist, and you can attach the checklist to the manuscript.\n",
            "------------------------------------\n",
            "Title Determinants of Sharing Travel Experiences in Social Media\n",
            "Author [{'authorId': '49594651', 'name': 'Myunghwa Kang'}, {'authorId': '11859901', 'name': 'M. Schuett'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract ABSTRACT The advent of Internet-based social media technologies has enabled travelers to quickly and conveniently share their travel experiences. Shared information on social media sites is recognized as an important information source which may influence travel decision making for potential travelers. This study tests a conceptual framework which examines why travelers share their travel experiences on social media based on the social influence theory and its three conceptual foundations—identification, internalization, and compliance. Data were collected using an online survey and the research model was tested with 543 respondents who were social media users. Results showed that identification and internalization are critical determinants that positively increase actual travel-experience sharing on social media as mediated by perceived enjoyment. Our research extends prior literature on social media by identifying specific determinants that can impact travel-experience sharing. Suggestions are provided for academics, the travel industry, and those working with social media.\n",
            "------------------------------------\n",
            "Title Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\n",
            "Author [{'authorId': '8553015', 'name': 'Jiasen Lu'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}, {'authorId': '153432684', 'name': 'Devi Parikh'}, {'authorId': '2166511', 'name': 'R. Socher'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2016\n",
            "Abstract Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.\n",
            "------------------------------------\n",
            "Title The Media and Mispricing: The Role of the Business Press in the Pricing of Accounting Information\n",
            "Author [{'authorId': '40249559', 'name': 'Michael S. Drake'}, {'authorId': '101554632', 'name': 'Nicholas Guest'}, {'authorId': '119461019', 'name': 'Brady J. Twedt'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract ABSTRACT: This study investigates the role of the business press in the pricing of accounting information. Using a comprehensive dataset of more than 111,000 earnings-related business press articles published from 2000 to 2010, we find that press coverage of the annual earnings announcement mitigates cash flow mispricing, but has a negligible effect on accrual mispricing. We provide evidence that this impact is driven primarily by the press disseminating the information more broadly, rather than by the creation of new content that helps investors understand the implications of accounting information. Our results suggest that the business press plays an important role in facilitating the market's ability to efficiently impound accounting information into stock prices and provide new insights into the role of the business press as an information intermediary in capital markets.\n",
            "------------------------------------\n",
            "Title The Pen Is Mightier Than the Keyboard\n",
            "Author [{'authorId': '38502032', 'name': 'Pam Mueller'}, {'authorId': '3361058', 'name': 'Daniel M. Oppenheimer'}]\n",
            "Venue Psychology Science\n",
            "year 2014\n",
            "Abstract Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students’ capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers’ tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning.\n",
            "------------------------------------\n",
            "Title Partisan Paths to Exposure Diversity: Differences in Pro‐ and Counterattitudinal News Consumption\n",
            "Author [{'authorId': '144648517', 'name': 'R. Garrett'}, {'authorId': '40387300', 'name': 'N. Stroud'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This study examines selective exposure to political information, arguing that attraction to proattitudinal information and aversion to counterattitudinal information are distinct phenomena, and that the tendency to engage in these behaviors varies by partisanship. Data collected in a strict online experiment support these predictions. Republicans are significantly more likely to engage in selective avoidance of predominantly counterattitudinal information than those with other partisan affiliations, while non-Republicans are significantly more likely to select a story that includes proattitudinal information, regardless of its counterattitudinal content. Individuals across the political spectrum are receptive to predominantly proattitudinal content and to content that offers a mix of views, but the form these preferences take varies by partisanship. The political significance of these findings is discussed.\n",
            "------------------------------------\n",
            "Title Semi-Supervised Hashing for Large-Scale Search\n",
            "Author [{'authorId': '39811558', 'name': 'Jun Wang'}, {'authorId': '152663162', 'name': 'Sanjiv Kumar'}, {'authorId': '9546964', 'name': 'Shih-Fu Chang'}]\n",
            "Venue IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "year 2012\n",
            "Abstract Hashing-based approximate nearest neighbor (ANN) search in huge databases has become popular due to its computational and memory efficiency. The popular hashing methods, e.g., Locality Sensitive Hashing and Spectral Hashing, construct hash functions based on random or principal projections. The resulting hashes are either not very accurate or are inefficient. Moreover, these methods are designed for a given metric similarity. On the contrary, semantic similarity is usually given in terms of pairwise labels of samples. There exist supervised hashing methods that can handle such semantic similarity, but they are prone to overfitting when labeled data are small or noisy. In this work, we propose a semi-supervised hashing (SSH) framework that minimizes empirical error over the labeled set and an information theoretic regularizer over both labeled and unlabeled sets. Based on this framework, we present three different semi-supervised hashing methods, including orthogonal hashing, nonorthogonal hashing, and sequential hashing. Particularly, the sequential hashing method generates robust codes in which each hash function is designed to correct the errors made by the previous ones. We further show that the sequential learning paradigm can be extended to unsupervised domains where no labeled pairs are available. Extensive experiments on four large datasets (up to 80 million samples) demonstrate the superior performance of the proposed SSH methods over state-of-the-art supervised and unsupervised hashing techniques.\n",
            "------------------------------------\n",
            "Title At Least Bias Is Bipartisan: A Meta-Analytic Comparison of Partisan Bias in Liberals and Conservatives\n",
            "Author [{'authorId': '5757457', 'name': 'P. Ditto'}, {'authorId': '2108662522', 'name': 'Brittany S. Liu'}, {'authorId': '5084997', 'name': 'Cory J. Clark'}, {'authorId': '6009769', 'name': 'S. Wojcik'}, {'authorId': '30630656', 'name': 'Eric Chen'}, {'authorId': '34950559', 'name': 'R. Grady'}, {'authorId': '46181196', 'name': 'Jared B. Celniker'}, {'authorId': '7420921', 'name': 'Joanne F. Zinger'}]\n",
            "Venue Perspectives on Psychological Science\n",
            "year 2017\n",
            "Abstract Both liberals and conservatives accuse their political opponents of partisan bias, but is there empirical evidence that one side of the political aisle is indeed more biased than the other? To address this question, we meta-analyzed the results of 51 experimental studies, involving over 18,000 participants, that examined one form of partisan bias—the tendency to evaluate otherwise identical information more favorably when it supports one’s political beliefs or allegiances than when it challenges those beliefs or allegiances. Two hypotheses based on previous literature were tested: an asymmetry hypothesis (predicting greater partisan bias in conservatives than in liberals) and a symmetry hypothesis (predicting equal levels of partisan bias in liberals and conservatives). Mean overall partisan bias was robust (r = .245), and there was strong support for the symmetry hypothesis: Liberals (r = .235) and conservatives (r = .255) showed no difference in mean levels of bias across studies. Moderator analyses reveal this pattern to be consistent across a number of different methodological variations and political topics. Implications of the current findings for the ongoing ideological symmetry debate and the role of partisan bias in scientific discourse and political conflict are discussed.\n",
            "------------------------------------\n",
            "Title Stability and Scalability of Homogeneous Vehicular Platoon: Study on the Influence of Information Flow Topologies\n",
            "Author [{'authorId': '2111090954', 'name': 'Yang Zheng'}, {'authorId': '2023891', 'name': 'S. Li'}, {'authorId': '46584136', 'name': 'Jianqiang Wang'}, {'authorId': '34133209', 'name': 'D. Cao'}, {'authorId': '1914913', 'name': 'Keqiang Li'}]\n",
            "Venue IEEE transactions on intelligent transportation systems (Print)\n",
            "year 2016\n",
            "Abstract In addition to decentralized controllers, the information flow among vehicles can significantly affect the dynamics of a platoon. This paper studies the influence of information flow topology on the internal stability and scalability of homogeneous vehicular platoons moving in a rigid formation. A linearized vehicle longitudinal dynamic model is derived using the exact feedback linearization technique, which accommodates the inertial delay of powertrain dynamics. Directed graphs are adopted to describe different types of allowable information flow interconnecting vehicles, including both radar-based sensors and vehicle-to-vehicle (V2V) communications. Under linear feedback controllers, a unified internal stability theorem is proved by using the algebraic graph theory and Routh-Hurwitz stability criterion. The theorem explicitly establishes the stabilizing thresholds of linear controller gains for platoons, under a large class of different information flow topologies. Using matrix eigenvalue analysis, the scalability is investigated for platoons under two typical information flow topologies, i.e., 1) the stability margin of platoon decays to zero as 0(1/N2) for bidirectional topology; and 2) the stability margin is always bounded and independent of the platoon size for bidirectional-leader topology. Numerical simulations are used to illustrate the results.\n",
            "------------------------------------\n",
            "Title Roadmap on optical security\n",
            "Author [{'authorId': '2914817', 'name': 'B. Javidi'}, {'authorId': '144253543', 'name': 'A. Carnicer'}, {'authorId': '46547601', 'name': 'Masahiro Yamaguchi'}, {'authorId': '28927573', 'name': 'T. Nomura'}, {'authorId': '1400985188', 'name': 'E. Pérez-Cabré'}, {'authorId': '32456965', 'name': 'M. S. Millán'}, {'authorId': '9095790', 'name': 'N. Nishchal'}, {'authorId': '15496004', 'name': 'R. Torroba'}, {'authorId': '4520071', 'name': 'J. F. Barrera'}, {'authorId': '50101880', 'name': 'W. He'}, {'authorId': '143621876', 'name': 'Xiang Peng'}, {'authorId': '94314653', 'name': 'A. Stern'}, {'authorId': '48156295', 'name': 'Y. Rivenson'}, {'authorId': '2830224', 'name': 'A. Alfalou'}, {'authorId': '93365176', 'name': 'C. Brosseau'}, {'authorId': '24730382', 'name': 'Changliang Guo'}, {'authorId': '2113789298', 'name': 'J. Sheridan'}, {'authorId': '2176076', 'name': 'G. Situ'}, {'authorId': '144196943', 'name': 'M. Naruse'}, {'authorId': '1576299032', 'name': 'Tsutomu Matsumoto'}, {'authorId': '32680819', 'name': 'I. Juvells'}, {'authorId': '4317493', 'name': 'E. Tajahuerce'}, {'authorId': '4132313', 'name': 'J. Lancis'}, {'authorId': '47482587', 'name': 'Wen Chen'}, {'authorId': '2144171290', 'name': 'Xudong Chen'}, {'authorId': '2178441970', 'name': 'P. Pinkse'}, {'authorId': '145612996', 'name': 'A. Mosk'}, {'authorId': '40191861', 'name': 'A. Markman'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Information security and authentication are important challenges facing society. Recent attacks by hackers on the databases of large commercial and financial companies have demonstrated that more research and development of advanced approaches are necessary to deny unauthorized access to critical data. Free space optical technology has been investigated by many researchers in information security, encryption, and authentication. The main motivation for using optics and photonics for information security is that optical waveforms possess many complex degrees of freedom such as amplitude, phase, polarization, large bandwidth, nonlinear transformations, quantum properties of photons, and multiplexing that can be combined in many ways to make information encryption more secure and more difficult to attack. This roadmap article presents an overview of the potential, recent advances, and challenges of optical security and encryption using free space optics. The roadmap on optical security is comprised of six categories that together include 16 short sections written by authors who have made relevant contributions in this field. The first category of this roadmap describes novel encryption approaches, including secure optical sensing which summarizes double random phase encryption applications and flaws [Yamaguchi], the digital holographic encryption in free space optical technique which describes encryption using multidimensional digital holography [Nomura], simultaneous encryption of multiple signals [Pérez-Cabré], asymmetric methods based on information truncation [Nishchal], and dynamic encryption of video sequences [Torroba]. Asymmetric and one-way cryptosystems are analyzed by Peng. The second category is on compression for encryption. In their respective contributions, Alfalou and Stern propose similar goals involving compressed data and compressive sensing encryption. The very important area of cryptanalysis is the topic of the third category with two sections: Sheridan reviews phase retrieval algorithms to perform different attacks, whereas Situ discusses nonlinear optical encryption techniques and the development of a rigorous optical information security theory. The fourth category with two contributions reports how encryption could be implemented at the nano- or micro-scale. Naruse discusses the use of nanostructures in security applications and Carnicer proposes encoding information in a tightly focused beam. In the fifth category, encryption based on ghost imaging using single-pixel detectors is also considered. In particular, the authors [Chen, Tajahuerce] emphasize the need for more specialized hardware and image processing algorithms. Finally, in the sixth category, Mosk and Javidi analyze in their corresponding papers how quantum imaging can benefit optical encryption systems. Sources that use few photons make encryption systems much more difficult to attack, providing a secure method for authentication.\n",
            "------------------------------------\n",
            "Title Relevance Theory\n",
            "Author [{'authorId': '2110633916', 'name': 'Deirdre Wilson'}]\n",
            "Venue Oxford Research Encyclopedia of Linguistics\n",
            "year 2019\n",
            "Abstract Relevance theory is a cognitive approach to pragmatics which starts from two broadly Gricean assumptions: (a) that much human communication, both verbal and non-verbal, involves the overt expression and inferential recognition of intentions, and (b) that in inferring these intentions, the addressee presumes that the communicator’s behavior will meet certain standards, which for Grice are based on a Cooperative Principle and maxims, and for relevance theory are derived from the assumption that, as a result of constant selection pressures in the course of human evolution, both cognition and communication are relevance-oriented. Relevance is defined in terms of cognitive (or contextual) effects and processing effort: other things being equal, the greater the cognitive effects and the smaller the processing effort, the greater the relevance.\n",
            " A long-standing aim of relevance theory has been to show that building an adequate theory of communication involves going beyond Grice’s notion of speaker’s meaning. Another is to provide a conceptually unified account of how a much broader variety of communicative acts than Grice was concerned with—including cases of both showing that and telling that—are understood. The resulting pragmatic theory differs from Grice’s in several respects. It sees explicit communication as much richer and more inferential than Grice thought, with encoded sentence meanings providing no more than clues to the speaker’s intentions. It rejects the close link that Grice saw between implicit communication and (real or apparent) maxim violation, showing in particular how figurative utterances might arise naturally and spontaneously in the course of communication. It offers an account of vagueness or indeterminacy in communication, which is often abstracted away from in more formally oriented frameworks. It investigates the role of context in comprehension, and shows how tentative hypotheses about the intended combination of explicit content, contextual assumptions, and implicatures might be refined and mutually adjusted in the course of the comprehension process in order to satisfy expectations of relevance.\n",
            " Relevance theory treats the borderline between semantics and pragmatics as co-extensive with the borderline between (linguistic) decoding and (pragmatic) inference. It sees encoded sentence meanings as typically fragmentary and incomplete, and as having to undergo inferential enrichment or elaboration in order to yield fully propositional forms. It reanalyzes Grice’s conventional implicatures—which he saw as semantic but non-truth-conditional aspects of the meaning of words like but and so—as encoding procedural information with dedicated pragmatic or more broadly cognitive functions, and extends the notion of procedural meaning to a range of further items such as pronouns, discourse particles, mood indicators, and affective intonation.\n",
            "------------------------------------\n",
            "Title User cooperation in wireless powered communication networks\n",
            "Author [{'authorId': '1719623', 'name': 'Hyungsik Ju'}, {'authorId': '144142357', 'name': 'Rui Zhang'}]\n",
            "Venue 2014 IEEE Global Communications Conference\n",
            "year 2014\n",
            "Abstract This paper studies user cooperation in the emerging wireless powered communication network (WPCN) for throughput optimization. For the purpose of exposition, we consider a two-user WPCN, in which one hybrid access point (H-AP) broadcasts wireless energy to two distributed users in the downlink (DL) and the users transmit their independent information using their individually harvested energy to the H-AP in the uplink (UL) through time-division-multiple-access (TDMA). We propose user cooperation in the WPCN where the user that is nearer to the H-AP and in general has a better channel for DL energy harvesting as well as UL information transmission uses part of its allocated UL time and DL harvested energy to help relay the far user's information to the H-AP, in order to achieve more balanced throughput. We maximize the weighted sum-rate (WSR) of the two users by jointly optimizing the time and power allocations in the network for both wireless energy transfer in the DL and wireless information transmission and relaying in the UL. Simulation results show that the proposed user cooperation scheme can effectively improve the achievable throughput in the WPCN with desired user fairness.\n",
            "------------------------------------\n",
            "Title Cognitive Mechanisms of Treatment in Depression\n",
            "Author [{'authorId': '34895627', 'name': 'J. Roiser'}, {'authorId': '49691586', 'name': 'R. Elliott'}, {'authorId': '144766323', 'name': 'B. Sahakian'}]\n",
            "Venue Neuropsychopharmacology\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Stability and Scalability of Homogeneous Vehicular Platoon: Study on the Influence of Information Flow Topologies\n",
            "Author [{'authorId': '2111090954', 'name': 'Yang Zheng'}, {'authorId': '2023891', 'name': 'S. Li'}, {'authorId': '46584136', 'name': 'Jianqiang Wang'}, {'authorId': '34133209', 'name': 'D. Cao'}, {'authorId': '1914913', 'name': 'Keqiang Li'}]\n",
            "Venue IEEE transactions on intelligent transportation systems (Print)\n",
            "year 2016\n",
            "Abstract In addition to decentralized controllers, the information flow among vehicles can significantly affect the dynamics of a platoon. This paper studies the influence of information flow topology on the internal stability and scalability of homogeneous vehicular platoons moving in a rigid formation. A linearized vehicle longitudinal dynamic model is derived using the exact feedback linearization technique, which accommodates the inertial delay of powertrain dynamics. Directed graphs are adopted to describe different types of allowable information flow interconnecting vehicles, including both radar-based sensors and vehicle-to-vehicle (V2V) communications. Under linear feedback controllers, a unified internal stability theorem is proved by using the algebraic graph theory and Routh-Hurwitz stability criterion. The theorem explicitly establishes the stabilizing thresholds of linear controller gains for platoons, under a large class of different information flow topologies. Using matrix eigenvalue analysis, the scalability is investigated for platoons under two typical information flow topologies, i.e., 1) the stability margin of platoon decays to zero as 0(1/N2) for bidirectional topology; and 2) the stability margin is always bounded and independent of the platoon size for bidirectional-leader topology. Numerical simulations are used to illustrate the results.\n",
            "------------------------------------\n",
            "Title Heralded entanglement between solid-state qubits separated by three metres\n",
            "Author [{'authorId': '5597372', 'name': 'H. Bernien'}, {'authorId': '36661306', 'name': 'B. Hensen'}, {'authorId': '50297010', 'name': 'W. Pfaff'}, {'authorId': '7922054', 'name': 'G. Koolstra'}, {'authorId': '34892994', 'name': 'M. Blok'}, {'authorId': '121936396', 'name': 'L. Robledo'}, {'authorId': '6489917', 'name': 'T. Taminiau'}, {'authorId': '3118150', 'name': 'M. Markham'}, {'authorId': '34595505', 'name': 'D. Twitchen'}, {'authorId': '145037459', 'name': 'L. Childress'}, {'authorId': '144131768', 'name': 'R. Hanson'}]\n",
            "Venue Nature\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title \"Best practice\" for patient-centered communication: a narrative review.\n",
            "Author [{'authorId': '46542370', 'name': 'A. King'}, {'authorId': '16743437', 'name': 'R. Hoppe'}]\n",
            "Venue Journal of Graduate Medical Education\n",
            "year 2013\n",
            "Abstract BACKGROUND\n",
            "Communicating with patients has long been identified as an important physician competency. More recently, there is a growing consensus regarding the components that define physician-patient communication. There continues to be emphasis on both the need to teach and to assess the communication skills of physicians.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This narrative review aims to summarize the work that has been conducted in physician-patient communication that supports the efficacy of good communications skills. This work may also help to define the physician-patient communication skills that need to be taught and assessed.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "A review of the literature shows it contains impressive evidence supporting positive associations between physician communication behaviors and positive patient outcomes, such as patient recall, patient understanding, and patient adherence to therapy. There is a consensus about what constitutes \"best practice\" for physician communication in medical encounters: (1) fostering the relationship, (2) gathering information, (3) providing information, (4) making decisions, (5) responding to emotions, and (6) enabling disease- and treatment-related behavior.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Evidence supports the importance of communication skills as a dimension of physician competence. Effort to enhance teaching of communication skills to medical trainees likely will require significant changes in instruction at undergraduate and graduate levels, as well as changes in assessing the developing communication skills of physicians. An added critical dimension is faculty understanding of the importance of communication skills, and their commitment to helping trainees develop those skills.\n",
            "------------------------------------\n",
            "Title Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\n",
            "Author [{'authorId': '8553015', 'name': 'Jiasen Lu'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}, {'authorId': '153432684', 'name': 'Devi Parikh'}, {'authorId': '2166511', 'name': 'R. Socher'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2016\n",
            "Abstract Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.\n",
            "------------------------------------\n",
            "Title Wireless powered communication networks: an overview\n",
            "Author [{'authorId': '2745067', 'name': 'S. Bi'}, {'authorId': '144498185', 'name': 'Yong Zeng'}, {'authorId': '144142357', 'name': 'Rui Zhang'}]\n",
            "Venue IEEE wireless communications\n",
            "year 2015\n",
            "Abstract Wireless powered communication networking (WPCN) is a new networking paradigm where the battery of wireless communication devices can be remotely replenished by means of microwave wireless power transfer (WPT) technology. WPCN eliminates the need for frequent manual battery replacement/recharging, and thus significantly improves the performance over conventional battery-powered communication networks in many aspects, such as higher throughput, longer device lifetime, and lower network operating cost. However, the design and future application of WPCN is essentially challenged by the low WPT efficiency over long distance, and the complex nature of joint wireless information and power transfer within the same network. In this article, we provide an overview of the key networking structures and performance enhancing techniques to build an efficient WPCN. In addition, we point out new and challenging future research directions for WPCN.\n",
            "------------------------------------\n",
            "Title Eight Ways to Promote Generative Learning\n",
            "Author [{'authorId': '2464436', 'name': 'Logan Fiorella'}, {'authorId': '1819200', 'name': 'R. Mayer'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Three Phased Component Retrival Technique (TPCRT) for Best Qualified Component\n",
            "Author [{'authorId': '2112607962', 'name': 'Vishnu Sharma'}, {'authorId': '97658075', 'name': 'V. Shekhawat'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The focus of this paper is to suggest a efficient component retrieval technique. Here a combined architecture of three search techniques from traditional (Keywords based) to latest approach (deductive search) is used to get best qualified component. This approach is useful for the software developers to get the appropriate components to develop efficient software within a short span of time. It also provides an efficient way to retrieve appropriate component from repository. The suggested design effectively supports query specification and component search. It further guides users to exploit component resources for reuse.\n",
            "------------------------------------\n",
            "Title Technology Acceptance Model: A Survey of Literature\n",
            "Author [{'authorId': '2105355817', 'name': 'Priyanka Surendran'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract The technology acceptance model has been a theory that is most widely used to explain an individualâ€™s acceptance of an information system. This study has reviewed numerous literatures available in this area. The different studies in this area were evaluated to understand the modifications that were done on this model. The paper then tries to provide an insight on future trends in the technology acceptance model.\n",
            "------------------------------------\n",
            "Title Optimal network modularity for information diffusion.\n",
            "Author [{'authorId': '2477784', 'name': 'Azadeh Nematzadeh'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}, {'authorId': '1769960', 'name': 'A. Flammini'}, {'authorId': '36663090', 'name': 'Yong-Yeol Ahn'}]\n",
            "Venue Physical Review Letters\n",
            "year 2014\n",
            "Abstract We investigate the impact of community structure on information diffusion with the linear threshold model. Our results demonstrate that modular structure may have counterintuitive effects on information diffusion when social reinforcement is present. We show that strong communities can facilitate global diffusion by enhancing local, intracommunity spreading. Using both analytic approaches and numerical simulations, we demonstrate the existence of an optimal network modularity, where global diffusion requires the minimal number of early adopters.\n",
            "------------------------------------\n",
            "Title A predictive model for the temporal dynamics of information diffusion in online social networks\n",
            "Author [{'authorId': '1700578', 'name': 'Adrien Guille'}, {'authorId': '1726350', 'name': 'Hakim Hacid'}]\n",
            "Venue The Web Conference\n",
            "year 2012\n",
            "Abstract Today, online social networks have become powerful tools for the spread of information. They facilitate the rapid and large-scale propagation of content and the consequences of an information -- whether it is favorable or not to someone, false or true -- can then take considerable proportions. Therefore it is essential to provide means to analyze the phenomenon of information dissemination in such networks. Many recent studies have addressed the modeling of the process of information diffusion, from a topological point of view and in a theoretical perspective, but we still know little about the factors involved in it. With the assumption that the dynamics of the spreading process at the macroscopic level is explained by interactions at microscopic level between pairs of users and the topology of their interconnections, we propose a practical solution which aims to predict the temporal dynamics of diffusion in social networks. Our approach is based on machine learning techniques and the inference of time-dependent diffusion probabilities from a multidimensional analysis of individual behaviors. Experimental results on a real dataset extracted from Twitter show the interest and effectiveness of the proposed approach as well as interesting recommendations for future investigation.\n",
            "------------------------------------\n",
            "Title A survey of transfer learning\n",
            "Author [{'authorId': '35541327', 'name': 'Karl R. Weiss'}, {'authorId': '1725285', 'name': 'T. Khoshgoftaar'}, {'authorId': '39472430', 'name': 'Dingding Wang'}]\n",
            "Venue Journal of Big Data\n",
            "year 2016\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Sociality Through Social Network Sites\n",
            "Author [{'authorId': '1791021', 'name': 'N. Ellison'}, {'authorId': '38818867', 'name': 'D. Boyd'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract This chapter reports authoritative insights into one of the most significant developments related to social interaction – social network sites – and offers an analytic framework for exploring these new sites, while underscoring the centrality of social interaction since the Internet's earliest days, such as through email. Social network sites (SNSs) presented several characteristics that made it possible for individuals to easily update their profiles. The implicit role of communication and information sharing has become the driving motivator for participation. The concept of ‘Web 2.0’ was an industry-driven phenomenon, hyped by the news media and by business analysts alike. Social network sites emerged out of the Web 2.0 and social media phenomena, mixing new technologies and older computer-mediated communication practices infused by tech industry ideals. Server-level data offer a unique opportunity to access elaborated behavioural data about what people are doing on SNSs.\n",
            "------------------------------------\n",
            "Title Attributed Social Network Embedding\n",
            "Author [{'authorId': '32781973', 'name': 'Lizi Liao'}, {'authorId': '7792071', 'name': 'Xiangnan He'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]\n",
            "Venue IEEE Transactions on Knowledge and Data Engineering\n",
            "year 2017\n",
            "Abstract Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Attributed Social Network Embedding framework (ASNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, ASNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, ASNE significantly outperforms  node2vec with an 8.2 percent relative improvement on the link prediction task, and a 12.7 percent gain on the node classification task.\n",
            "------------------------------------\n",
            "Title Remote Sensing Technologies for Enhancing Forest Inventories: A Review\n",
            "Author [{'authorId': '3195426', 'name': 'J. White'}, {'authorId': '1878917', 'name': 'N. Coops'}, {'authorId': '145292984', 'name': 'M. Wulder'}, {'authorId': '2315190', 'name': 'M. Vastaranta'}, {'authorId': '3191193', 'name': 'T. Hilker'}, {'authorId': '2298931', 'name': 'P. Tompalski'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Abstract Forest inventory and management requirements are changing rapidly in the context of an increasingly complex set of economic, environmental, and social policy objectives. Advanced remote sensing technologies provide data to assist in addressing these escalating information needs and to support the subsequent development and parameterization of models for an even broader range of information needs. This special issue contains papers that use a variety of remote sensing technologies to derive forest inventory or inventory-related information. Herein, we review the potential of 4 advanced remote sensing technologies, which we posit as having the greatest potential to influence forest inventories designed to characterize forest resource information for strategic, tactical, and operational planning: airborne laser scanning (ALS), terrestrial laser scanning (TLS), digital aerial photogrammetry (DAP), and high spatial resolution (HSR)/very high spatial resolution (VHSR) satellite optical imagery. ALS, in particular, has proven to be a transformative technology, offering forest inventories the required spatial detail and accuracy across large areas and a diverse range of forest types. The coupling of DAP with ALS technologies will likely have the greatest impact on forest inventory practices in the next decade, providing capacity for a broader suite of attributes, as well as for monitoring growth over time.\n",
            "------------------------------------\n",
            "Title Diamond NV centers for quantum computing and quantum networks\n",
            "Author [{'authorId': '145037459', 'name': 'L. Childress'}, {'authorId': '144131768', 'name': 'R. Hanson'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The exotic features of quantum mechanics have the potential to revolutionize information technologies. Using superposition and entanglement, a quantum processor could efficiently tackle problems inaccessible to current-day computers. Nonlocal correlations may be exploited for intrinsically secure communication across the globe. Finding and controlling a physical system suitable for fulfi lling these promises is one of the greatest challenges of our time. The nitrogen-vacancy (NV) center in diamond has recently emerged as one of the leading candidates for such quantum information technologies thanks to its combination of atom-like properties and solid-state host environment. We review the remarkable progress made in the past years in controlling electrons, atomic nuclei, and light at the single-quantum level in diamond. We also discuss prospects and challenges for the use of NV centers in future quantum technologies.\n",
            "------------------------------------\n",
            "Title Revealing the hidden networks of interaction in mobile animal groups allows prediction of complex behavioral contagion\n",
            "Author [{'authorId': '47755959', 'name': 'S. Rosenthal'}, {'authorId': '39431767', 'name': 'Colin R. Twomey'}, {'authorId': '2626843', 'name': 'Andrew T. Hartnett'}, {'authorId': '49498925', 'name': 'H. Wu'}, {'authorId': '3191663', 'name': 'I. Couzin'}]\n",
            "Venue Proceedings of the National Academy of Sciences\n",
            "year 2015\n",
            "Abstract Significance We know little about the nature of the evolved interaction networks that give rise to the rapid coordinated collective response exhibited by many group-living organisms. Here, we study collective evasion in schooling fish using computational techniques to reconstruct the scene from the perspective of the organisms themselves. This method allows us to establish how the complex social scene is translated into behavioral response at the level of individuals and to visualize, and analyze, the resulting complex communication network as behavioral change spreads rapidly through groups. Thus, we can map, for any moment in time, the extent to which each individual is socially influential during collective evasion and predict the magnitude of such behavioral epidemics before they actually occur. Coordination among social animals requires rapid and efficient transfer of information among individuals, which may depend crucially on the underlying structure of the communication network. Establishing the decision-making circuits and networks that give rise to individual behavior has been a central goal of neuroscience. However, the analogous problem of determining the structure of the communication network among organisms that gives rise to coordinated collective behavior, such as is exhibited by schooling fish and flocking birds, has remained almost entirely neglected. Here, we study collective evasion maneuvers, manifested through rapid waves, or cascades, of behavioral change (a ubiquitous behavior among taxa) in schooling fish (Notemigonus crysoleucas). We automatically track the positions and body postures, calculate visual fields of all individuals in schools of ∼150 fish, and determine the functional mapping between socially generated sensory input and motor response during collective evasion. We find that individuals use simple, robust measures to assess behavioral changes in neighbors, and that the resulting networks by which behavior propagates throughout groups are complex, being weighted, directed, and heterogeneous. By studying these interaction networks, we reveal the (complex, fractional) nature of social contagion and establish that individuals with relatively few, but strongly connected, neighbors are both most socially influential and most susceptible to social influence. Furthermore, we demonstrate that we can predict complex cascades of behavioral change at their moment of initiation, before they actually occur. Consequently, despite the intrinsic stochasticity of individual behavior, establishing the hidden communication networks in large self-organized groups facilitates a quantitative understanding of behavioral contagion.\n",
            "------------------------------------\n",
            "Title CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations\n",
            "Author [{'authorId': '2586287', 'name': 'Stefan Seemayer'}, {'authorId': '153595345', 'name': 'M. Gruber'}, {'authorId': '2225852', 'name': 'J. Söding'}]\n",
            "Venue Bioinform.\n",
            "year 2014\n",
            "Abstract Motivation: Recent breakthroughs in protein residue–residue contact prediction have made reliable de novo prediction of protein structures possible. The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e. to separate direct from indirect effects. Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM). Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads. This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein–protein interactions. Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35–113 times faster and with the same precision as the most accurate published methods. For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4–14 times faster. Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15–60 s on a consumer-grade GPU and 1–6 min on a six-core CPU. Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title Patients want granular privacy control over health information in electronic medical records\n",
            "Author [{'authorId': '1786759', 'name': 'Kelly E. Caine'}, {'authorId': '1946629', 'name': 'Rima Hanania'}]\n",
            "Venue J. Am. Medical Informatics Assoc.\n",
            "year 2013\n",
            "Abstract OBJECTIVE\n",
            "To assess patients' desire for granular level privacy control over which personal health information should be shared, with whom, and for what purpose; and whether these preferences vary based on sensitivity of health information.\n",
            "\n",
            "\n",
            "MATERIALS AND METHODS\n",
            "A card task for matching health information with providers, questionnaire, and interview with 30 patients whose health information is stored in an electronic medical record system. Most patients' records contained sensitive health information.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "No patients reported that they would prefer to share all information stored in an electronic medical record (EMR) with all potential recipients. Sharing preferences varied by type of information (EMR data element) and recipient (eg, primary care provider), and overall sharing preferences varied by participant. Patients with and without sensitive records preferred less sharing of sensitive versus less-sensitive information.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "Patients expressed sharing preferences consistent with a desire for granular privacy control over which health information should be shared with whom and expressed differences in sharing preferences for sensitive versus less-sensitive EMR data. The pattern of results may be used by designers to generate privacy-preserving EMR systems including interfaces for patients to express privacy and sharing preferences.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "To maintain the level of privacy afforded by medical records and to achieve alignment with patients' preferences, patients should have granular privacy control over information contained in their EMR.\n",
            "------------------------------------\n",
            "Title Pragmatism vs interpretivism in qualitative information systems research\n",
            "Author [{'authorId': '2118927', 'name': 'G. Goldkuhl'}]\n",
            "Venue European Journal of Information Systems\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title ISO/IEC 27000, 27001 and 27002 for Information Security Management\n",
            "Author [{'authorId': '2084139433', 'name': 'Georg Disterer'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract With the increasing significance of information technology, there is \n",
            "an urgent need for adequate measures of information security. \n",
            "Systematic information security management is one of most important initiatives \n",
            "for IT management. At least since reports about privacy and security breaches, \n",
            "fraudulent accounting practices, and attacks on IT systems appeared \n",
            "in public, organizations have recognized their responsibilities to safeguard \n",
            "physical and information assets. Security standards can be used as guideline or \n",
            "framework to develop and maintain an adequate information security management \n",
            "system (ISMS). The standards ISO/IEC 27000, 27001 and 27002 are international \n",
            "standards that are receiving growing recognition and adoption. They are \n",
            "referred to as “common language of organizations around the world” for \n",
            "information security [1]. With ISO/IEC 27001 companies can have their ISMS \n",
            "certified by a third-party organization and thus show their customers evidence \n",
            "of their security measures.\n",
            "------------------------------------\n",
            "Title The Updated DeLone and McLean Model of Information Systems Success\n",
            "Author [{'authorId': '2986366', 'name': 'Nils Urbach'}, {'authorId': '144662484', 'name': 'B. Müller'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Throughput Optimization for Massive MIMO Systems Powered by Wireless Energy Transfer\n",
            "Author [{'authorId': '2109700299', 'name': 'Gang Yang'}, {'authorId': '1761761', 'name': 'Chin Keong Ho'}, {'authorId': '144142357', 'name': 'Rui Zhang'}, {'authorId': '1737045', 'name': 'Y. Guan'}]\n",
            "Venue IEEE Journal on Selected Areas in Communications\n",
            "year 2014\n",
            "Abstract This paper studies a wireless-energy-transfer (WET) enabled massive multiple-input-multiple-output (MIMO) system (MM) consisting of a hybrid data-and-energy access point (H-AP) and multiple single-antenna users. In the WET-MM system, the H-AP is equipped with a large number M of antennas and functions like a conventional AP in receiving data from users, but additionally supplies wireless power to the users. We consider frame-based transmissions. Each frame is divided into three phases: the uplink channel estimation (CE) phase, the downlink WET phase, as well as the uplink wireless information transmission (WIT) phase. Firstly, users use a fraction of the previously harvested energy to send pilots, while the H-AP estimates the uplink channels and obtains the downlink channels by exploiting channel reciprocity. Next, the H-AP utilizes the channel estimates just obtained to transfer wireless energy to all users in the downlink via energy beamforming. Finally, the users use a portion of the harvested energy to send data to the H-AP simultaneously in the uplink (reserving some harvested energy for sending pilots in the next frame) . To optimize the throughput and ensure rate fairness, we consider the problem of maximizing the minimum rate among all users. In the large-M regime, we obtain the asymptotically optimal solutions and some interesting insights for the optimal design of WET-MM system.\n",
            "------------------------------------\n",
            "Title Faces in Context: A Review and Systematization of Contextual Influences on Affective Face Processing\n",
            "Author [{'authorId': '34439843', 'name': 'M. Wieser'}, {'authorId': '2256291', 'name': 'T. Brosch'}]\n",
            "Venue Front. Psychology\n",
            "year 2012\n",
            "Abstract Facial expressions are of eminent importance for social interaction as they convey information about other individuals’ emotions and social intentions. According to the predominant “basic emotion” approach, the perception of emotion in faces is based on the rapid, automatic categorization of prototypical, universal expressions. Consequently, the perception of facial expressions has typically been investigated using isolated, de-contextualized, static pictures of facial expressions that maximize the distinction between categories. However, in everyday life, an individual’s face is not perceived in isolation, but almost always appears within a situational context, which may arise from other people, the physical environment surrounding the face, as well as multichannel information from the sender. Furthermore, situational context may be provided by the perceiver, including already present social information gained from affective learning and implicit processing biases such as race bias. Thus, the perception of facial expressions is presumably always influenced by contextual variables. In this comprehensive review, we aim at (1) systematizing the contextual variables that may influence the perception of facial expressions and (2) summarizing experimental paradigms and findings that have been used to investigate these influences. The studies reviewed here demonstrate that perception and neural processing of facial expressions are substantially modified by contextual information, including verbal, visual, and auditory information presented together with the face as well as knowledge or processing biases already present in the observer. These findings further challenge the assumption of automatic, hardwired categorical emotion extraction mechanisms predicted by basic emotion theories. Taking into account a recent model on face processing, we discuss where and when these different contextual influences may take place, thus outlining potential avenues in future research.\n",
            "------------------------------------\n",
            "Title Assessing the risks of ‘infodemics’ in response to COVID-19 epidemics\n",
            "Author [{'authorId': '2557324', 'name': 'R. Gallotti'}, {'authorId': '2074353024', 'name': 'F. Valle'}, {'authorId': '31750406', 'name': 'N. Castaldo'}, {'authorId': '3130592', 'name': 'P. Sacco'}, {'authorId': '46617468', 'name': 'M. De Domenico'}]\n",
            "Venue Nature Human Behaviour\n",
            "year 2020\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Top Concerns of Tweeters During the COVID-19 Pandemic: Infoveillance Study\n",
            "Author [{'authorId': '1411490511', 'name': 'Alaa A. Abd-alrazaq'}, {'authorId': '3463573', 'name': 'Dari Alhuwail'}, {'authorId': '31776961', 'name': 'M. Househ'}, {'authorId': '153521546', 'name': 'Mounir Hamdi'}, {'authorId': '2052725797', 'name': 'Zubair Shah'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2020\n",
            "Abstract Background The recent coronavirus disease (COVID-19) pandemic is taking a toll on the world’s health care infrastructure as well as the social, economic, and psychological well-being of humanity. Individuals, organizations, and governments are using social media to communicate with each other on a number of issues relating to the COVID-19 pandemic. Not much is known about the topics being shared on social media platforms relating to COVID-19. Analyzing such information can help policy makers and health care organizations assess the needs of their stakeholders and address them appropriately. Objective This study aims to identify the main topics posted by Twitter users related to the COVID-19 pandemic. Methods Leveraging a set of tools (Twitter’s search application programming interface (API), Tweepy Python library, and PostgreSQL database) and using a set of predefined search terms (“corona,” “2019-nCov,” and “COVID-19”), we extracted the text and metadata (number of likes and retweets, and user profile information including the number of followers) of public English language tweets from February 2, 2020, to March 15, 2020. We analyzed the collected tweets using word frequencies of single (unigrams) and double words (bigrams). We leveraged latent Dirichlet allocation for topic modeling to identify topics discussed in the tweets. We also performed sentiment analysis and extracted the mean number of retweets, likes, and followers for each topic and calculated the interaction rate per topic. Results Out of approximately 2.8 million tweets included, 167,073 unique tweets from 160,829 unique users met the inclusion criteria. Our analysis identified 12 topics, which were grouped into four main themes: origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating the risk of infection. The mean sentiment was positive for 10 topics and negative for 2 topics (deaths caused by COVID-19 and increased racism). The mean for tweet topics of account followers ranged from 2722 (increased racism) to 13,413 (economic losses). The highest mean of likes for the tweets was 15.4 (economic loss), while the lowest was 3.94 (travel bans and warnings). Conclusions Public health crisis response activities on the ground and online are becoming increasingly simultaneous and intertwined. Social media provides an opportunity to directly communicate health information to the public. Health systems should work on building national and international disease detection and surveillance systems through monitoring social media. There is also a need for a more proactive and agile public health presence on social media to combat the spread of fake news.\n",
            "------------------------------------\n",
            "Title Blissfully ignorant: the effects of general privacy concerns, general institutional trust, and affect in the privacy calculus\n",
            "Author [{'authorId': '3035002', 'name': 'F. Kehr'}, {'authorId': '1793743', 'name': 'T. Kowatsch'}, {'authorId': '145775736', 'name': 'D. Wentzel'}, {'authorId': '2801545', 'name': 'E. Fleisch'}]\n",
            "Venue Information Systems Journal\n",
            "year 2015\n",
            "Abstract Existing research on information privacy has mostly relied on the privacy calculus model, which views privacy‐related decision‐making as a rational process where individuals weigh the anticipated risks of disclosing personal data against the potential benefits. In this research, we develop an extension to the privacy calculus model, arguing that the situation‐specific assessment of risks and benefits is bounded by (1) pre‐existing attitudes or dispositions, such as general privacy concerns or general institutional trust, and (2) limited cognitive resources and heuristic thinking. An experimental study, employing two samples from the USA and Switzerland, examined consumer responses to a new smartphone application that collects driving behavior data and provided converging support for these predictions. Specifically, the results revealed that a situation‐specific assessment of risks and benefits fully mediates the effect of dispositional factors on information disclosure. In addition, the results showed that privacy assessment is influenced by momentary affective states, indicating that consumers underestimate the risks of information disclosure when confronted with a user interface that elicits positive affect.\n",
            "------------------------------------\n",
            "Title Analytic projection from plane‐wave and PAW wavefunctions and application to chemical‐bonding analysis in solids\n",
            "Author [{'authorId': '1966702', 'name': 'Stefan Maintz'}, {'authorId': '2432235', 'name': 'Volker L. Deringer'}, {'authorId': '2072688', 'name': 'A. Tchougréeff'}, {'authorId': '2607648', 'name': 'R. Dronskowski'}]\n",
            "Venue Journal of Computational Chemistry\n",
            "year 2013\n",
            "Abstract Quantum‐chemical computations of solids benefit enormously from numerically efficient plane‐wave (PW) basis sets, and together with the projector augmented‐wave (PAW) method, the latter have risen to one of the predominant standards in computational solid‐state sciences. Despite their advantages, plane waves lack local information, which makes the interpretation of local densities‐of‐states (DOS) difficult and precludes the direct use of atom‐resolved chemical bonding indicators such as the crystal orbital overlap population (COOP) and the crystal orbital Hamilton population (COHP) techniques. Recently, a number of methods have been proposed to overcome this fundamental issue, built around the concept of basis‐set projection onto a local auxiliary basis. In this work, we propose a novel computational technique toward this goal by transferring the PW/PAW wavefunctions to a properly chosen local basis using analytically derived expressions. In particular, we describe a general approach to project both PW and PAW eigenstates onto given custom orbitals, which we then exemplify at the hand of contracted multiple‐ζ Slater‐type orbitals. The validity of the method presented here is illustrated by applications to chemical textbook examples—diamond, gallium arsenide, the transition‐metal titanium—as well as nanoscale allotropes of carbon: a nanotube and the C60 fullerene. Remarkably, the analytical approach not only recovers the total and projected electronic DOS with a high degree of confidence, but it also yields a realistic chemical‐bonding picture in the framework of the projected COHP method. © 2013 Wiley Periodicals, Inc.\n",
            "------------------------------------\n",
            "Title A guide for the utilization of Health Insurance Review and Assessment Service National Patient Samples\n",
            "Author [{'authorId': '4783347', 'name': 'L. Kim'}, {'authorId': '4721986', 'name': 'Jee-Ae Kim'}, {'authorId': '2128114854', 'name': 'Sanghyun Kim'}]\n",
            "Venue Epidemiology and Health\n",
            "year 2014\n",
            "Abstract The claims data of the Health Insurance Review and Assessment Service (HIRA) is an important source of information for healthcare service research. The claims data of HIRA is collected when healthcare service providers submit a claim to HIRA to be reimbursed for a service that they provided to patients. To improve the accessibility of healthcare service researchers to claims data of HIRA, HIRA has developed the Patient Samples which are extracted using a stratified randomized sampling method. The Patient Samples of HIRA consist of five tables: a table for general information (Table 20) containing socio-demographic information such as gender, age and medical aid, indicators for inpatient and outpatient services; a table for specific information on healthcare services provided (Table 30); a table for diagnostic information (Table 40); a table for outpatient prescriptions (Table 53) and a table for information on healthcare service providers (Table of providers). Researchers who are interested in using the Patient Sample data for research can apply via HIRA’s website (https://www.hira.or.kr).\n",
            "------------------------------------\n",
            "Title Global priorities for an effective information basis of biodiversity distributions\n",
            "Author [{'authorId': '39326465', 'name': 'Carsten Meyer'}, {'authorId': '2871866', 'name': 'H. Kreft'}, {'authorId': '145634039', 'name': 'R. Guralnick'}, {'authorId': '3799786', 'name': 'W. Jetz'}]\n",
            "Venue Nature Communications\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title DNA Fountain enables a robust and efficient storage architecture\n",
            "Author [{'authorId': '2422788', 'name': 'Yaniv Erlich'}, {'authorId': '1815791', 'name': 'Dina Zielinski'}]\n",
            "Venue Science\n",
            "year 2016\n",
            "Abstract A reliable and efficient DNA storage architecture DNA has the potential to provide large-capacity information storage. However, current methods have only been able to use a fraction of the theoretical maximum. Erlich and Zielinski present a method, DNA Fountain, which approaches the theoretical maximum for information stored per nucleotide. They demonstrated efficient encoding of information—including a full computer operating system—into DNA that could be retrieved at scale after multiple rounds of polymerase chain reaction. Science, this issue p. 950 A resilient DNA storage strategy enables near-maximal information content per nucleotide. DNA is an attractive medium to store digital information. Here we report a storage strategy, called DNA Fountain, that is highly robust and approaches the information capacity per nucleotide. Using our approach, we stored a full computer operating system, movie, and other files with a total of 2.14 × 106 bytes in DNA oligonucleotides and perfectly retrieved the information from a sequencing coverage equivalent to a single tile of Illumina sequencing. We also tested a process that can allow 2.18 × 1015 retrievals using the original DNA sample and were able to perfectly decode the data. Finally, we explored the limit of our architecture in terms of bytes per molecule and obtained a perfect retrieval from a density of 215 petabytes per gram of DNA, orders of magnitude higher than previous reports.\n",
            "------------------------------------\n",
            "Title The Determinants and Consequences of Information Acquisition via EDGAR\n",
            "Author [{'authorId': '40249559', 'name': 'Michael S. Drake'}, {'authorId': '26325758', 'name': 'D. Roulstone'}, {'authorId': '26366285', 'name': 'Jacob R. Thornock'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Using a novel dataset that tracks all web traffic on the SEC’s EDGAR servers from 2008-2011, we examine the determinants and capital market consequences of investor information acquisition of SEC filings. The average user employs the database very few times per quarter and most users target specific filing types such as periodic accounting reports; a small subset of users employ EDGAR almost daily and access many filings. EDGAR activity is positively related with corporate events (particularly restatements, earnings announcements, and acquisition announcements), poor stock performance, and the strength of a firm’s information environment. EDGAR activity is related to, but distinct from, other proxies of investor interest such as trading volume, business press articles, and Google searches. Finally, information acquisition via EDGAR, both to obtain earnings news and to provide context for it, has a positive influence on market efficiency with respect to earnings news. Overall, our results provide a unique, user-based perspective on investor access of mandatory disclosures and its impact on price formation.\n",
            "------------------------------------\n",
            "Title Probabilistic data association for semantic SLAM\n",
            "Author [{'authorId': '21653787', 'name': 'Sean L. Bowman'}, {'authorId': '50365495', 'name': 'Nikolay A. Atanasov'}, {'authorId': '1751586', 'name': 'Kostas Daniilidis'}, {'authorId': '143770945', 'name': 'George J. Pappas'}]\n",
            "Venue IEEE International Conference on Robotics and Automation\n",
            "year 2017\n",
            "Abstract Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.\n",
            "------------------------------------\n",
            "Title Value of Information\n",
            "Author [{'authorId': '3994759', 'name': 'N. Welton'}, {'authorId': '49875598', 'name': 'H. Thom'}]\n",
            "Venue Medical decision making\n",
            "year 2015\n",
            "Abstract Expected value of sample information (EVSI) 1 measures the average net-benefit gain from conducting new research and can be used to inform decisions on which new studies to fund and how best to design those studies. This helps avoid wasting resources researching treatments that were never likely to be cost-effective or conversely by adopting treatments that, if more evidence were collected, may be shown not to be cost-effective. However, the calculations in the general case rely on nested simulations, which can be very computationally demanding and even infeasible to compute in some cases. Since EVSI needs to be repeatedly computed over the potential study design space, this represents a clear barrier to the uptake of EVSI methods in practice. In some special situations, algebraic solutions are available that avoid the inner simulation step. 2–4 More generally, meta-modeling, which attempts to build a model to approximate the relationship between the model inputs (on which a new study can provide information) and model outputs (net benefit), is a promising approach that can lead to substantial computational savings. 5,6 In this issue, 2 novel meta-modeling methods are proposed for the calculation of EVSI, 7,8 both of which require only\n",
            "------------------------------------\n",
            "Title The Evolving Disclosure Landscape: How Changes in Technology, the Media, and Capital Markets Are Affecting Disclosure\n",
            "Author [{'authorId': '144405514', 'name': 'Gregory S. Miller'}, {'authorId': '46187645', 'name': 'Douglas J. Skinner'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Recent changes in technology and the media are causing significant changes in how capital markets assimilate and respond to information. We identify important themes in the disclosure literature and use this as a framework to discuss the conference papers that appear in this volume. These papers examine how managers’ disclosure practices are being affected by changes in technology, the media, and capital markets. While this work makes important progress, we discuss how continuing technological change and the emergence of new forms of media offer further opportunities for research on the role of disclosure in capital markets.\n",
            "------------------------------------\n",
            "Title Feature Selection\n",
            "Author [{'authorId': '2040455', 'name': 'Jundong Li'}, {'authorId': '3161399', 'name': 'Kewei Cheng'}, {'authorId': '2893721', 'name': 'Suhang Wang'}, {'authorId': '2775559', 'name': 'Fred Morstatter'}, {'authorId': '39690948', 'name': 'Robert P. Trevino'}, {'authorId': '1736632', 'name': 'Jiliang Tang'}, {'authorId': '145896397', 'name': 'Huan Liu'}]\n",
            "Venue Encyclopedia of Machine Learning and Data Mining\n",
            "year 2016\n",
            "Abstract Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.\n",
            "------------------------------------\n",
            "Title Overview of the CLEF eHealth Evaluation Lab 2016\n",
            "Author [{'authorId': '47146974', 'name': 'L. Kelly'}, {'authorId': '144354285', 'name': 'L. Goeuriot'}, {'authorId': '1712592', 'name': 'H. Suominen'}, {'authorId': '1692256', 'name': 'Aurélie Névéol'}, {'authorId': '3071228', 'name': 'João Palotti'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]\n",
            "Venue Conference and Labs of the Evaluation Forum\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Digital Imaging and Communications in Medicine (DICOM)\n",
            "Author [{'authorId': '3135569', 'name': 'O. Pianykh'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Supervised hashing with kernels\n",
            "Author [{'authorId': '46641573', 'name': 'W. Liu'}, {'authorId': '39811558', 'name': 'Jun Wang'}, {'authorId': '145592290', 'name': 'R. Ji'}, {'authorId': '1717861', 'name': 'Yu-Gang Jiang'}, {'authorId': '9546964', 'name': 'Shih-Fu Chang'}]\n",
            "Venue 2012 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "year 2012\n",
            "Abstract Recent years have witnessed the growing popularity of hashing in large-scale vision problems. It has been shown that the hashing quality could be boosted by leveraging supervised information into hash function learning. However, the existing supervised methods either lack adequate performance or often incur cumbersome model training. In this paper, we propose a novel kernel-based supervised hashing model which requires a limited amount of supervised information, i.e., similar and dissimilar data pairs, and a feasible training cost in achieving high quality hashing. The idea is to map the data to compact binary codes whose Hamming distances are minimized on similar pairs and simultaneously maximized on dissimilar pairs. Our approach is distinct from prior works by utilizing the equivalence between optimizing the code inner products and the Hamming distances. This enables us to sequentially and efficiently train the hash functions one bit at a time, yielding very short yet discriminative codes. We carry out extensive experiments on two image benchmarks with up to one million samples, demonstrating that our approach significantly outperforms the state-of-the-arts in searching both metric distance neighbors and semantically similar neighbors, with accuracy gains ranging from 13% to 46%.\n",
            "------------------------------------\n",
            "Title Quantum Secure Direct Communication with Quantum Memory.\n",
            "Author [{'authorId': None, 'name': 'Wei Zhang'}, {'authorId': '4636148', 'name': 'D. Ding'}, {'authorId': '2383237', 'name': 'Y. Sheng'}, {'authorId': '145053578', 'name': 'Lan Zhou'}, {'authorId': '145913582', 'name': 'B. Shi'}, {'authorId': '143878299', 'name': 'G. Guo'}]\n",
            "Venue Physical Review Letters\n",
            "year 2016\n",
            "Abstract Quantum communication provides an absolute security advantage, and it has been widely developed over the past 30 years. As an important branch of quantum communication, quantum secure direct communication (QSDC) promotes high security and instantaneousness in communication through directly transmitting messages over a quantum channel. The full implementation of a quantum protocol always requires the ability to control the transfer of a message effectively in the time domain; thus, it is essential to combine QSDC with quantum memory to accomplish the communication task. In this Letter, we report the experimental demonstration of QSDC with state-of-the-art atomic quantum memory for the first time in principle. We use the polarization degrees of freedom of photons as the information carrier, and the fidelity of entanglement decoding is verified as approximately 90%. Our work completes a fundamental step toward practical QSDC and demonstrates a potential application for long-distance quantum communication in a quantum network.\n",
            "------------------------------------\n",
            "Title Dimensionality Reduction Technique on SIFT Feature Vector for Content Based Image Retrival\n",
            "Author [{'authorId': '2142212124', 'name': 'Mukul Kirti Verma'}, {'authorId': '1491643653', 'name': 'Rajesh Dwivedi'}, {'authorId': '3470601', 'name': 'Ajay Kumar Mallick'}, {'authorId': '9074538', 'name': 'Ebenezer Jangam'}]\n",
            "Venue International Conference on Recent Trends in Image Processing and Pattern Recognition\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title The Hidden Cost of Accommodating Crowdfunder Privacy Preferences: A Randomized Field Experiment\n",
            "Author [{'authorId': '2556694', 'name': 'Gordon Burtch'}, {'authorId': '143888439', 'name': 'A. Ghose'}, {'authorId': '2628487', 'name': 'S. Wattal'}]\n",
            "Venue Management Sciences\n",
            "year 2014\n",
            "Abstract Online crowdfunding has received a great deal of attention as a promising avenue to fostering entrepreneurship and innovation. Because online settings bring increased visibility and traceability of transactions, many crowdfunding platforms provide mechanisms that enable a campaign contributor to conceal his or her identity or contribution amount from peers. We study the impact of these information (privacy) control mechanisms on crowdfunder behavior. Employing a randomized experiment at one of the world’s largest online crowdfunding platforms, we find evidence of both positive (e.g., comfort) and negative (e.g., privacy priming) causal effects. We find that reducing access to information controls induces a net increase in fundraising, yet this outcome results from two competing influences — treatment increases willingness to engage with the platform (a 4.9% increase in the probability of contribution) and simultaneously decreases the average contribution (a U.S.$5.81 decline). This decline derives from a publicity effect, wherein contributors respond to a lack of privacy by tempering extreme contributions. We unravel the causal mechanisms that drive the results and discuss the implications of our findings for the design of online platforms.\n",
            "------------------------------------\n",
            "Title GSDS 2.0: an upgraded gene feature visualization server\n",
            "Author [{'authorId': '2143657223', 'name': 'B. Hu'}, {'authorId': '2436328', 'name': 'Jinpu Jin'}, {'authorId': '36328688', 'name': 'Anyuan Guo'}, {'authorId': '2153526647', 'name': 'He Zhang'}, {'authorId': '8277897', 'name': 'Jingchu Luo'}, {'authorId': '144398798', 'name': 'G. Gao'}]\n",
            "Venue Bioinform.\n",
            "year 2014\n",
            "Abstract Summary: Visualizing genes’ structure and annotated features helps biologists to investigate their function and evolution intuitively. The Gene Structure Display Server (GSDS) has been widely used by more than 60 000 users since its first publication in 2007. Here, we reported the upgraded GSDS 2.0 with a newly designed interface, supports for more types of annotation features and formats, as well as an integrated visual editor for editing the generated figure. Moreover, a user-specified phylogenetic tree can be added to facilitate further evolutionary analysis. The full source code is also available for downloading. Availability and implementation: Web server and source code are freely available at http://gsds.cbi.pku.edu.cn. Contact: gaog@mail.cbi.pku.edu.cn or gsds@mail.cbi.pku.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title China's Strategic Censorship\n",
            "Author [{'authorId': '5774912', 'name': 'Peter Lorentzen'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract While it is often assumed that authoritarian regimes inevitably fear and restrict media independence, permitting watchdog journalism can actually help such regimes maintain power by improving governance. Yet such a strategy risks facilitating a coordinated uprising if discontent is revealed to be widespread. A formal model shows that under some conditions, a regime optimally permits investigative reporting on lower-level officialdom, adjusting how much reporting is allowed depending on the level of underlying social tensions. This strategy yields many of the benefits of free media without risking overthrow. An extension shows why an increase in uncontrollable information, such as from the Internet, may result in a reduction in media freedom. The model sheds light on important aspects of China's media policy and its evolution and on authoritarian media control more broadly.\n",
            "------------------------------------\n",
            "Title Multicriteria decision-making method using the correlation coefficient under single-valued neutrosophic environment\n",
            "Author [{'authorId': '144030861', 'name': 'Jun Ye'}]\n",
            "Venue International Journal of General Systems\n",
            "year 2013\n",
            "Abstract The paper presents the correlation and correlation coefficient of single-valued neutrosophic sets (SVNSs) based on the extension of the correlation of intuitionistic fuzzy sets and demonstrates that the cosine similarity measure is a special case of the correlation coefficient in SVNS. Then a decision-making method is proposed by the use of the weighted correlation coefficient or the weighted cosine similarity measure of SVNSs, in which the evaluation information for alternatives with respect to criteria is carried out by truth-membership degree, indeterminacy-membership degree, and falsity-membership degree under single-valued neutrosophic environment. We utilize the weighted correlation coefficient or the weighted cosine similarity measure between each alternative and the ideal alternative to rank the alternatives and to determine the best one(s). Finally, an illustrative example demonstrates the application of the proposed decision-making method.\n",
            "------------------------------------\n",
            "Title Oruta: privacy-preserving public auditing for shared data in the cloud\n",
            "Author [{'authorId': '2661981', 'name': 'Boyang Wang'}, {'authorId': '91269142', 'name': 'Baochun Li'}, {'authorId': '144462039', 'name': 'Hui Li'}]\n",
            "Venue IEEE Transactions on Cloud Computing\n",
            "year 2012\n",
            "Abstract With cloud data services, it is commonplace for data to be not only stored in the cloud, but also shared across multiple users. Unfortunately, the integrity of cloud data is subject to skepticism due to the existence of hardware/software failures and human errors. Several mechanisms have been designed to allow both data owners and public verifiers to efficiently audit cloud data integrity without retrieving the entire data from the cloud server. However, public auditing on the integrity of shared data with these existing mechanisms will inevitably reveal confidential information-identity privacy-to public verifiers. In this paper, we propose a novel privacy-preserving mechanism that supports public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute verification metadata needed to audit the correctness of shared data. With our mechanism, the identity of the signer on each block in shared data is kept private from public verifiers, who are able to efficiently verify shared data integrity without retrieving the entire file. In addition, our mechanism is able to perform multiple auditing tasks simultaneously instead of verifying them one by one. Our experimental results demonstrate the effectiveness and efficiency of our mechanism when auditing shared data integrity.\n",
            "------------------------------------\n",
            "Title Can Twitter Help Predict Firm-Level Earnings and Stock Returns?\n",
            "Author [{'authorId': '50534165', 'name': 'Eli Bartov'}, {'authorId': '83279718', 'name': 'Lucile Faurel'}, {'authorId': '3428581', 'name': 'Partha Mohanram'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract ABSTRACT: Prior research has examined how companies exploit Twitter in communicating with investors, and whether Twitter activity predicts the stock market as a whole. We test whether opinions of individuals tweeted just prior to a firm's earnings announcement predict its earnings and announcement returns. Using a broad sample from 2009 to 2012, we find that the aggregate opinion from individual tweets successfully predicts a firm's forthcoming quarterly earnings and announcement returns. These results hold for tweets that convey original information, as well as tweets that disseminate existing information, and are stronger for tweets providing information directly related to firm fundamentals and stock trading. Importantly, our results hold even after controlling for concurrent information or opinion from traditional media sources, and are stronger for firms in weaker information environments. Our findings highlight the importance of considering the aggregate opinion from individual tweets when assessing...\n",
            "------------------------------------\n",
            "Title An Integrated System for Regional Environmental Monitoring and Management Based on Internet of Things\n",
            "Author [{'authorId': '2322472', 'name': 'S. Fang'}, {'authorId': '39466716', 'name': 'Lida Xu'}, {'authorId': '3217039', 'name': 'Yunqiang Zhu'}, {'authorId': '1785841', 'name': 'Jiaerheng Ahati'}, {'authorId': '2582442', 'name': 'Huan Pei'}, {'authorId': '2709021', 'name': 'Jianwu Yan'}, {'authorId': '2157183591', 'name': 'Zhihui Liu'}]\n",
            "Venue IEEE Transactions on Industrial Informatics\n",
            "year 2014\n",
            "Abstract Climate change and environmental monitoring and management have received much attention recently, and an integrated information system (IIS) is considered highly valuable. This paper introduces a novel IIS that combines Internet of Things (IoT), Cloud Computing, Geoinformatics [remote sensing (RS), geographical information system (GIS), and global positioning system (GPS)], and e-Science for environmental monitoring and management, with a case study on regional climate change and its ecological effects. Multi-sensors and Web services were used to collect data and other information for the perception layer; both public networks and private networks were used to access and transport mass data and other information in the network layer. The key technologies and tools include real-time operational database (RODB); extraction-transformation-loading (ETL); on-line analytical processing (OLAP) and relational OLAP (ROLAP); naming, addressing, and profile server (NAPS); application gateway (AG); application software for different platforms and tasks (APPs); IoT application infrastructure (IoT-AI); GIS and e-Science platforms; and representational state transfer/Java database connectivity (RESTful/JDBC). Application Program Interfaces (APIs) were implemented in the middleware layer of the IIS. The application layer provides the functions of storing, organizing, processing, and sharing of data and other information, as well as the functions of applications in environmental monitoring and management. The results from the case study show that there is a visible increasing trend of the air temperature in Xinjiang over the last 50 years (1962-2011) and an apparent increasing trend of the precipitation since the early 1980s. Furthermore, from the correlation between ecological indicators [gross primary production (GPP), net primary production (NPP), and leaf area index (LAI)] and meteorological elements (air temperature and precipitation), water resource availability is the decisive factor with regard to the terrestrial ecosystem in the area. The study shows that the research work is greatly benefited from such an IIS, not only in data collection supported by IoT, but also in Web services and applications based on cloud computing and e-Science platforms, and the effectiveness of monitoring processes and decision-making can be obviously improved. This paper provides a prototype IIS for environmental monitoring and management, and it also provides a new paradigm for the future research and practice; especially in the era of big data and IoT.\n",
            "------------------------------------\n",
            "Title A Turn Toward Avoidance? Selective Exposure to Online Political Information, 2004–2008\n",
            "Author [{'authorId': '144648517', 'name': 'R. Garrett'}, {'authorId': '115213499', 'name': 'Dustin Carnahan'}, {'authorId': '144915193', 'name': 'Emily K. Lynch'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Towards a definition of the Internet of Things ( IoT )\n",
            "Author []\n",
            "Venue \n",
            "year 2015\n",
            "Abstract ion Yes No Partly Availability / Mobility No No No Fault tolerance Partly No Partly Flexibility/Event based Yes Partly Partly Uncertainty of Information No No No\n",
            "------------------------------------\n",
            "Title Community Detection in Networks with Node Attributes\n",
            "Author [{'authorId': '32073252', 'name': 'Jaewon Yang'}, {'authorId': '35660011', 'name': 'Julian McAuley'}, {'authorId': '1702139', 'name': 'J. Leskovec'}]\n",
            "Venue 2013 IEEE 13th International Conference on Data Mining\n",
            "year 2013\n",
            "Abstract Community detection algorithms are fundamental tools that allow us to uncover organizational principles in networks. When detecting communities, there are two possible sources of information one can use: the network structure, and the features and attributes of nodes. Even though communities form around nodes that have common edges and common attributes, typically, algorithms have only focused on one of these two data modalities: community detection algorithms traditionally focus only on the network structure, while clustering algorithms mostly consider only node attributes. In this paper, we develop Communities from Edge Structure and Node Attributes (CESNA), an accurate and scalable algorithm for detecting overlapping communities in networks with node attributes. CESNA statistically models the interaction between the network structure and the node attributes, which leads to more accurate community detection as well as improved robustness in the presence of noise in the network structure. CESNA has a linear runtime in the network size and is able to process networks an order of magnitude larger than comparable approaches. Last, CESNA also helps with the interpretation of detected communities by finding relevant node attributes for each community.\n",
            "------------------------------------\n",
            "Title The Economics of Crowdfunding Platforms\n",
            "Author [{'authorId': '3151109', 'name': 'Paul Belleflamme'}, {'authorId': '1941866', 'name': 'N. Omrani'}, {'authorId': '2905541', 'name': 'M. Peitz'}]\n",
            "Venue Information Economics and Policy\n",
            "year 2015\n",
            "Abstract This paper provides a description of the crowdfunding sector, considering investment- based crowdfunding platforms as well as platforms in which funders do not obtain monetary payments. It lays out key features of this quickly developing sector and explores the economic forces at play that can explain the design of these platforms. In particular, it elaborates on cross-group and within-group external effects and asymmetric information on crowdfunding platforms.\n",
            "------------------------------------\n",
            "Title Regularizing Rioting: Permitting Public Protest in an Authoritarian Regime\n",
            "Author [{'authorId': '5774912', 'name': 'Peter Lorentzen'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Lacking the informative feedback provided by competitive elections, an unfettered press and an active civil society, authoritarian regimes can find it difficult to identify which social groups have become dangerously discontented and to monitor lower levels of government. While a rise in public protest is often seen as a harbinger of regime collapse in such states, this paper uses a formal model and a close examination of the Chinese case to show that the informal toleration and even encouragement of small-scale, narrowly economic protests can be an effective information gathering tool, mitigating these informational problems. The analysis demonstrates that protests should be observed most frequently where discontent is neither too high nor too low. This calls into question the common assumption in comparative politics that an increase in protests necessarily reflects an increase in discontent or the weakness of a regime.\n",
            "------------------------------------\n",
            "Title Psychological characteristics associated with COVID-19 vaccine hesitancy and resistance in Ireland and the United Kingdom\n",
            "Author [{'authorId': '2151116194', 'name': 'Jamie Murphy'}, {'authorId': '6328131', 'name': 'F. Vallières'}, {'authorId': '3656616', 'name': 'R. Bentall'}, {'authorId': '1921545', 'name': 'M. Shevlin'}, {'authorId': '47303600', 'name': 'O. McBride'}, {'authorId': '103509097', 'name': 'T. Hartman'}, {'authorId': '143685716', 'name': 'R. McKay'}, {'authorId': '2263256', 'name': 'K. Bennett'}, {'authorId': '39541275', 'name': 'L. Mason'}, {'authorId': '2008348597', 'name': 'J. Gibson-Miller'}, {'authorId': '1954722', 'name': 'L. Levita'}, {'authorId': '1701199354', 'name': 'Antón P. Martínez'}, {'authorId': '2124052113', 'name': 'T. Stocks'}, {'authorId': '4590859', 'name': 'T. Karatzias'}, {'authorId': '2027273', 'name': 'P. Hyland'}]\n",
            "Venue Nature Communications\n",
            "year 2021\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Crowdsourcing Geographic Knowledge: Volunteered Geographic Information (VGI) in Theory and Practice\n",
            "Author [{'authorId': '2484792', 'name': 'D. Sui'}, {'authorId': '144939902', 'name': 'S. Elwood'}, {'authorId': '2191738', 'name': 'M. Goodchild'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title On the Rise of FinTechs – Credit Scoring Using Digital Footprints\n",
            "Author [{'authorId': '152544373', 'name': 'M. Puri'}, {'authorId': '49061799', 'name': 'Tobias Berg'}, {'authorId': '9253464', 'name': 'Valentin Burg'}, {'authorId': '121143167', 'name': 'Ana Gombović'}]\n",
            "Venue The Review of financial studies\n",
            "year 2018\n",
            "Abstract \n",
            " We analyze the information content of a digital footprint—that is, information that users leave online simply by accessing or registering on a Web site—for predicting consumer default. We show that even simple, easily accessible variables from a digital footprint match the information content of credit bureau scores. A digital footprint complements rather than substitutes for credit bureau information and affects access to credit and reduces default rates. We discuss the implications for financial intermediaries’ business models, access to credit for the unbanked, and the behavior of consumers, firms, and regulators in the digital sphere. (JEL G20, G21, G29)\n",
            "------------------------------------\n",
            "Title Bridges, brokers and boundary spanners in collaborative networks: a systematic review\n",
            "Author [{'authorId': '145092660', 'name': 'J. Long'}, {'authorId': '32657335', 'name': 'F. Cunningham'}, {'authorId': '145070047', 'name': 'J. Braithwaite'}]\n",
            "Venue BMC Health Services Research\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title COMPARTMENTS: unification and visualization of protein subcellular localization evidence\n",
            "Author [{'authorId': '3203173', 'name': 'Janos X. Binder'}, {'authorId': '1403256809', 'name': 'Sune Pletscher-Frankild'}, {'authorId': '2720390', 'name': 'K. Tsafou'}, {'authorId': '2512853', 'name': 'C. Stolte'}, {'authorId': '1395618484', 'name': 'S. O’Donoghue'}, {'authorId': '144704594', 'name': 'Reinhard Schneider'}, {'authorId': '2214567', 'name': 'L. Jensen'}]\n",
            "Venue Database J. Biol. Databases Curation\n",
            "year 2014\n",
            "Abstract Information on protein subcellular localization is important to understand the cellular functions of proteins. Currently, such information is manually curated from the literature, obtained from high-throughput microscopy-based screens and predicted from primary sequence. To get a comprehensive view of the localization of a protein, it is thus necessary to consult multiple databases and prediction tools. To address this, we present the COMPARTMENTS resource, which integrates all sources listed above as well as the results of automatic text mining. The resource is automatically kept up to date with source databases, and all localization evidence is mapped onto common protein identifiers and Gene Ontology terms. We further assign confidence scores to the localization evidence to facilitate comparison of different types and sources of evidence. To further improve the comparability, we assign confidence scores based on the type and source of the localization evidence. Finally, we visualize the unified localization evidence for a protein on a schematic cell to provide a simple overview. Database URL: http://compartments.jensenlab.org\n",
            "------------------------------------\n",
            "Title Social media and political communication: a social media analytics framework\n",
            "Author [{'authorId': '2423134', 'name': 'Stefan Stieglitz'}, {'authorId': '1403158479', 'name': 'Linh Dang-Xuan'}]\n",
            "Venue Social Network Analysis and Mining\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n",
            "Author [{'authorId': '6272499', 'name': 'I. Korstjens'}, {'authorId': '144589165', 'name': 'A. Moser'}]\n",
            "Venue European Journal of General Practice\n",
            "year 2017\n",
            "Abstract Abstract In the course of our supervisory work over the years we have noticed that qualitative research tends to evoke a lot of questions and worries, so-called frequently asked questions (FAQs). This series of four articles intends to provide novice researchers with practical guidance for conducting high-quality qualitative research in primary care. By ‘novice’ we mean Master’s students and junior researchers, as well as experienced quantitative researchers who are engaging in qualitative research for the first time. This series addresses their questions and provides researchers, readers, reviewers and editors with references to criteria and tools for judging the quality of qualitative research papers. The first article provides an introduction to this series. The second article focused on context, research questions and designs. The third article focused on sampling, data collection and analysis. This fourth article addresses FAQs about trustworthiness and publishing. Quality criteria for all qualitative research are credibility, transferability, dependability, and confirmability. Reflexivity is an integral part of ensuring the transparency and quality of qualitative research. Writing a qualitative research article reflects the iterative nature of the qualitative research process: data analysis continues while writing. A qualitative research article is mostly narrative and tends to be longer than a quantitative paper, and sometimes requires a different structure. Editors essentially use the criteria: is it new, is it true, is it relevant? An effective cover letter enhances confidence in the newness, trueness and relevance, and explains why your study required a qualitative design. It provides information about the way you applied quality criteria or a checklist, and you can attach the checklist to the manuscript.\n",
            "------------------------------------\n",
            "Title The digital traces of bubbles: feedback cycles between socio-economic signals in the Bitcoin economy\n",
            "Author [{'authorId': '144240725', 'name': 'David García'}, {'authorId': '2146531', 'name': 'C. Tessone'}, {'authorId': '2618549', 'name': 'Pavlin Mavrodiev'}, {'authorId': '2939899', 'name': 'N. Perony'}]\n",
            "Venue Journal of the Royal Society Interface\n",
            "year 2014\n",
            "Abstract What is the role of social interactions in the creation of price bubbles? Answering this question requires obtaining collective behavioural traces generated by the activity of a large number of actors. Digital currencies offer a unique possibility to measure socio-economic signals from such digital traces. Here, we focus on Bitcoin, the most popular cryptocurrency. Bitcoin has experienced periods of rapid increase in exchange rates (price) followed by sharp decline; we hypothesize that these fluctuations are largely driven by the interplay between different social phenomena. We thus quantify four socio-economic signals about Bitcoin from large datasets: price on online exchanges, volume of word-of-mouth communication in online social media, volume of information search and user base growth. By using vector autoregression, we identify two positive feedback loops that lead to price bubbles in the absence of exogenous stimuli: one driven by word of mouth, and the other by new Bitcoin adopters. We also observe that spikes in information search, presumably linked to external events, precede drastic price declines. Understanding the interplay between the socio-economic signals we measured can lead to applications beyond cryptocurrencies to other phenomena that leave digital footprints, such as online social network usage.\n",
            "------------------------------------\n",
            "Title A classification of location privacy attacks and approaches\n",
            "Author [{'authorId': '1926764', 'name': 'Marius Wernke'}, {'authorId': '145454897', 'name': 'P. Skvortsov'}, {'authorId': '145046960', 'name': 'Frank Dürr'}, {'authorId': '1700118', 'name': 'K. Rothermel'}]\n",
            "Venue Personal and Ubiquitous Computing\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Emotions, Partisanship, and Misperceptions: How Anger and Anxiety Moderate the Effect of Partisan Bias on Susceptibility to Political Misinformation\n",
            "Author [{'authorId': '37433997', 'name': 'Brian E. Weeks'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Citizens are frequently misinformed about political issues and candidates but the circumstances under which inaccurate beliefs emerge are not fully understood. This experimental study demonstrates that the independent experience of two emotions, anger and anxiety, in part determines whether citizens consider misinformation in a partisan or open-minded fashion. Anger encourages partisan, motivated evaluation of uncorrected misinformation that results in beliefs consistent with the supported political party, while anxiety at times promotes initial beliefs based less on partisanship and more on the information environment. However, exposure to corrections improves belief accuracy, regardless of emotion or partisanship. The results indicate that the unique experience of anger and anxiety can affect the accuracy of political beliefs by strengthening or attenuating the influence of partisanship\n",
            "------------------------------------\n",
            "Title Improving bug localization using structured information retrieval\n",
            "Author [{'authorId': '2671585', 'name': 'Ripon K. Saha'}, {'authorId': '1747771', 'name': 'Matthew Lease'}, {'authorId': '145802044', 'name': 'S. Khurshid'}, {'authorId': '143977783', 'name': 'D. Perry'}]\n",
            "Venue International Conference on Automated Software Engineering\n",
            "year 2013\n",
            "Abstract Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool.\n",
            "------------------------------------\n",
            "Title Unmet care needs of advanced cancer patients and their informal caregivers: a systematic review\n",
            "Author [{'authorId': '1865225869', 'name': 'Tao Wang'}, {'authorId': '4483816', 'name': 'A. Molassiotis'}, {'authorId': '4362687', 'name': 'B. Chung'}, {'authorId': '3536095', 'name': 'J. Tan'}]\n",
            "Venue BMC Palliative Care\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Information network or social network?: the structure of the twitter follow graph\n",
            "Author [{'authorId': '50362385', 'name': 'Seth A. Myers'}, {'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '46479974', 'name': 'Pankaj Gupta'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]\n",
            "Venue The Web Conference\n",
            "year 2014\n",
            "Abstract In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.\n",
            "------------------------------------\n",
            "Title Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks\n",
            "Author [{'authorId': '3082645', 'name': 'P. Bashivan'}, {'authorId': '2109771', 'name': 'I. Rish'}, {'authorId': '1828610', 'name': 'M. Yeasin'}, {'authorId': '40589056', 'name': 'N. Codella'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2015\n",
            "Abstract One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.\n",
            "------------------------------------\n",
            "Title An Introduction to Neural Information Retrieval\n",
            "Author [{'authorId': '116506812', 'name': 'Bhaskar Mitra'}, {'authorId': '1703980', 'name': 'Nick Craswell'}]\n",
            "Venue Foundations and Trends in Information Retrieval\n",
            "year 2018\n",
            "Abstract Neural models have been employed in many Information Retrieval scenarios, including ad-hoc retrieval, recommender systems, multi-media search, and even conversational systems that generate answers in response to natural language questions. An Introduction to Neural Information Retrieval provides a tutorial introduction to neural methods for ranking documents in response to a query, an important IR task. The monograph provides a complete picture of neural information retrieval techniques that culminate in supervised neural learning to rank models including deep neural network architectures that are trained end-to-end for ranking tasks. In reaching this point, the authors cover all the important topics, including the learning to rank framework and an overview of deep neural networks. This monograph provides an accessible, yet comprehensive, overview of the state-of-the-art of Neural Information Retrieval.\n",
            "------------------------------------\n",
            "Title Implementing genomic medicine in the clinic: the future is here\n",
            "Author [{'authorId': '2937408', 'name': 'T. Manolio'}, {'authorId': '3224574', 'name': 'R. Chisholm'}, {'authorId': '5528087', 'name': 'B. Ozenberger'}, {'authorId': '2308034', 'name': 'D. Roden'}, {'authorId': '1947512845', 'name': 'Marc S. Williams'}, {'authorId': '2111010098', 'name': 'R. Wilson'}, {'authorId': '143837583', 'name': 'D. Bick'}, {'authorId': '2278426', 'name': 'E. Bottinger'}, {'authorId': '2661596', 'name': 'M. Brilliant'}, {'authorId': '144966010', 'name': 'C. Eng'}, {'authorId': '2315409', 'name': 'K. Frazer'}, {'authorId': '6523129', 'name': 'B. Korf'}, {'authorId': '145116828', 'name': 'D. Ledbetter'}, {'authorId': '6860524', 'name': 'J. Lupski'}, {'authorId': '1852153', 'name': 'C. Marsh'}, {'authorId': '7984650', 'name': 'D. Mrazek'}, {'authorId': '2588909', 'name': 'M. Murray'}, {'authorId': '1396079496', 'name': 'P. O’Donnell'}, {'authorId': '2753771', 'name': 'D. Rader'}, {'authorId': '3009230', 'name': 'M. Relling'}, {'authorId': '3463535', 'name': 'A. Shuldiner'}, {'authorId': '104734649', 'name': 'D. Valle'}, {'authorId': '144553753', 'name': 'R. Weinshilboum'}, {'authorId': '47915863', 'name': 'E. Green'}, {'authorId': '3013441', 'name': 'G. Ginsburg'}]\n",
            "Venue Genetics in Medicine\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Bayesian Persuasion and Information Design\n",
            "Author [{'authorId': '2968902', 'name': 'Emir Kamenica'}]\n",
            "Venue Annual Review of Economics\n",
            "year 2019\n",
            "Abstract A school may improve its students’ job outcomes if it issues only coarse grades. Google can reduce congestion on roads by giving drivers noisy information about the state of traffic. A social planner might raise everyone's welfare by providing only partial information about solvency of banks. All of this can happen even when everyone is fully rational and understands the data-generating process. Each of these examples raises questions of what is the (socially or privately) optimal information that should be revealed. In this article, I review the literature that answers such questions.\n",
            "------------------------------------\n",
            "Title Rise and fall patterns of information diffusion: model and implications\n",
            "Author [{'authorId': '1744555', 'name': 'Yasuko Matsubara'}, {'authorId': '1734077', 'name': 'Yasushi Sakurai'}, {'authorId': '144214525', 'name': 'B. Prakash'}, {'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '1702392', 'name': 'C. Faloutsos'}]\n",
            "Venue Knowledge Discovery and Data Mining\n",
            "year 2012\n",
            "Abstract The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated faster propagation of news and rumors. How quickly does a piece of news spread over these media? How does its popularity diminish over time? Does the rising and falling pattern follow a simple universal law?\n",
            " In this paper, we propose SpikeM, a concise yet flexible analytical model for the rise and fall patterns of influence propagation. Our model has the following advantages: (a) unification power: it generalizes and explains earlier theoretical models and empirical observations; (b) practicality: it matches the observed behavior of diverse sets of real data; (c) parsimony: it requires only a handful of parameters; and (d) usefulness: it enables further analytics tasks such as fore- casting, spotting anomalies, and interpretation by reverse- engineering the system parameters of interest (e.g. quality of news, count of interested bloggers, etc.).\n",
            " Using SpikeM, we analyzed 7.2GB of real data, most of which were collected from the public domain. We have shown that our SpikeM model accurately and succinctly describes all the patterns of the rise-and-fall spikes in these real datasets.\n",
            "------------------------------------\n",
            "Title An Optimization of Allocation of Information Granularity in the Interpretation of Data Structures: Toward Granular Fuzzy Clustering\n",
            "Author [{'authorId': '1731634', 'name': 'W. Pedrycz'}, {'authorId': '2804290', 'name': 'A. Bargiela'}]\n",
            "Venue IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)\n",
            "year 2012\n",
            "Abstract Clustering forms one of the most visible conceptual and algorithmic framework of developing information granules. In spite of the algorithm being used, the representation of information granules-clusters is predominantly numeric (coming in the form of prototypes, partition matrices, dendrograms, etc.). In this paper, we consider a concept of granular prototypes that generalizes the numeric representation of the clusters and, in this way, helps capture more details about the data structure. By invoking the granulation-degranulation scheme, we design granular prototypes being reflective of the structure of data to a higher extent than the representation that is provided by their numeric counterparts (prototypes). The design is formulated as an optimization problem, which is guided by the coverage criterion, meaning that we maximize the number of data for which their granular realization includes the original data. The granularity of the prototypes themselves is treated as an important design asset; hence, its allocation to the individual prototypes is optimized so that the coverage criterion becomes maximized. With this regard, several schemes of optimal allocation of information granularity are investigated, where interval-valued prototypes are formed around the already produced numeric representatives. Experimental studies are provided in which the design of granular prototypes of interval format is discussed and characterized.\n",
            "------------------------------------\n",
            "Title A General Self-Organized Tree-Based Energy-Balance Routing Protocol for Wireless Sensor Network\n",
            "Author [{'authorId': '2113962875', 'name': 'Zhao Han'}, {'authorId': '2118432165', 'name': 'Jie Wu'}, {'authorId': '2159190175', 'name': 'Jie Zhang'}, {'authorId': '2602078', 'name': 'Liefeng Liu'}, {'authorId': '2408984', 'name': 'Kaiyun Tian'}]\n",
            "Venue IEEE Transactions on Nuclear Science\n",
            "year 2012\n",
            "Abstract Wireless sensor network (WSN) is a system composed of a large number of low-cost micro-sensors. This network is used to collect and send various kinds of messages to a base station (BS). WSN consists of low-cost nodes with limited battery power, and the battery replacement is not easy for WSN with thousands of physically embedded nodes, which means energy efficient routing protocol should be employed to offer a long-life work time. To achieve the aim, we need not only to minimize total energy consumption but also to balance WSN load. Researchers have proposed many protocols such as LEACH, HEED, PEGASIS, TBC and PEDAP. In this paper, we propose a General Self-Organized Tree-Based Energy-Balance routing protocol (GSTEB) which builds a routing tree using a process where, for each round, BS assigns a root node and broadcasts this selection to all sensor nodes. Subsequently, each node selects its parent by considering only itself and its neighbors' information, thus making GSTEB a dynamic protocol. Simulation results show that GSTEB has a better performance than other protocols in balancing energy consumption, thus prolonging the lifetime of WSN.\n",
            "------------------------------------\n",
            "Title A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula\n",
            "Author [{'authorId': '2054557', 'name': 'Robin A. A. Ince'}, {'authorId': '3248511', 'name': 'Bruno L. Giordano'}, {'authorId': '144679212', 'name': 'C. Kayser'}, {'authorId': '2532970', 'name': 'G. Rousselet'}, {'authorId': '37427902', 'name': 'J. Gross'}, {'authorId': '2287417', 'name': 'P. Schyns'}]\n",
            "Venue bioRxiv\n",
            "year 2016\n",
            "Abstract We begin by reviewing the statistical framework of information theory as applicable to neuroimaging data analysis. A major factor hindering wider adoption of this framework in neuroimaging is the difficulty of estimating information theoretic quantities in practice. We present a novel estimation technique that combines the statistical theory of copulas with the closed form solution for the entropy of Gaussian variables. This results in a general, computationally efficient, flexible, and robust multivariate statistical framework that provides effect sizes on a common meaningful scale, allows for unified treatment of discrete, continuous, uni-and multi-dimensional variables, and enables direct comparisons of representations from behavioral and brain responses across any recording modality. We validate the use of this estimate as a statistical test within a neuroimaging context, considering both discrete stimulus classes and continuous stimulus features. We also present examples of analyses facilitated by these developments, including application of multivariate analyses to MEG planar magnetic field gradients, and pairwise temporal interactions in evoked EEG responses. We show the benefit of considering the instantaneous temporal derivative together with the raw values of M/EEG signals as a multivariate response, how we can separately quantify modulations of amplitude and direction for vector quantities, and how we can measure the emergence of novel information over time in evoked responses. Open-source Matlab and Python code implementing the new methods accompanies this article. Highlights Novel estimator for mutual information and other information theoretic quantities Provides general, efficient, flexible and robust multivariate statistical framework Validated statistical performance on EEG and MEG data Applications to spectral power and phase, 2D magnetic field gradients, temporal derivatives Interaction information relates information content in different responses\n",
            "------------------------------------\n",
            "Title Fuzzy Group Decision Making With Incomplete Information Guided by Social Influence\n",
            "Author [{'authorId': '1705430', 'name': 'N. Capuano'}, {'authorId': '1682727', 'name': 'F. Chiclana'}, {'authorId': '1747316', 'name': 'H. Fujita'}, {'authorId': '1397996912', 'name': 'E. Herrera-Viedma'}, {'authorId': '1689838', 'name': 'V. Loia'}]\n",
            "Venue IEEE transactions on fuzzy systems\n",
            "year 2018\n",
            "Abstract A promising research area in the field of group decision making (GDM) is the study of interpersonal influence and its impact on the evolution of experts’ opinions. In conventional GDM models, a group of experts express their individual preferences on a finite set of alternatives, then preferences are aggregated and the best alternative, satisfying the majority of experts, is selected. Nevertheless, in real situations, experts form their opinions in a complex interpersonal environment where preferences are liable to change due to social influence. In order to take into account the effects of social influence during the GDM process, we propose a new influence-guided GDM model based on the following assumptions: experts influence each other and the more an expert trusts in another expert, the more his opinion is influenced by that expert. The effects of social influence are especially relevant to cases when, due to domain complexity, limited expertise or pressure to make a decision, an expert is unable to express preferences on some alternatives, i.e., in presence of incomplete information. The proposed model adopts fuzzy rankings to collect both experts’ preferences on available alternatives and trust statements on other experts. Starting from collected information, possibly incomplete, the configuration and the strengths of interpersonal influences are evaluated and represented through a social influence network (SIN). The SIN, in its turn, is used to estimate missing preferences and evolve them by simulating the effects of experts’ interpersonal influence before aggregating them for the selection of the best alternative. The proposed model has been experimented with synthetic data to demonstrate the influence driven evolution of opinions and its convergence properties.\n",
            "------------------------------------\n",
            "Title The Epistemic Engine: Sequence Organization and Territories of Knowledge\n",
            "Author [{'authorId': '3983793', 'name': 'J. Heritage'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract This article reviews a range of conversation analytic findings concerning the role of information imbalances in the organization of conversational sequences. Considering sequences launched from knowing and unknowing epistemic stances, it considers the role of relative epistemic stance and status as warrants for the production of talk and as forces in the process of sequence production and decay.\n",
            "------------------------------------\n",
            "Title Social Media Update 2016\n",
            "Author [{'authorId': '120387812', 'name': 'S. Greenwood'}, {'authorId': '47521178', 'name': 'Andrew T. Perrin'}, {'authorId': '79515166', 'name': 'Maeve Duggan'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Over the past decade, Pew Research Center has documented the wide variety of ways in which Americans use social media to seek out information and interact with others. A majority of Americans now say they get news via social media, and half of the public has turned to these sites to learn about the 2016 presidential election. Americans are using social media in the context of work (whether to take a mental break on the job or to seek out employment), while also engaging in an ongoing effort to navigate the complex privacy issues that these sites bring to the forefront. In addition to measuring the broad impact and meaning of social media, since 2012 the Center has also tracked the specific sites and platforms that users turn to in the course of living their social lives online. In that context, a national survey of 1,520 adults conducted March 7-April 4, 2016, finds that Facebook continues to be America’s most popular social networking platform by a substantial margin: Nearly eight-in-ten online Americans (79%) now use Facebook, more than double the share that uses Twitter (24%), Pinterest (31%), Instagram (32%) or LinkedIn (29%). On a total population basis (accounting for Americans who do not use the internet at all), that means that 68% of all U.S. adults are Facebook users, while 28% use Instagram, 26% use Pinterest, 25% use LinkedIn and 21% use Twitter.\n",
            "------------------------------------\n",
            "Title Asymmetrically interacting spreading dynamics on complex layered networks\n",
            "Author [{'authorId': '2158505763', 'name': 'Wei Wang'}, {'authorId': '2087082998', 'name': 'M. Tang'}, {'authorId': '2156107784', 'name': 'Hui Yang'}, {'authorId': '46940082', 'name': 'Y. Do'}, {'authorId': '144769611', 'name': 'Y. Lai'}, {'authorId': '1934289', 'name': 'Gyuwon Lee'}]\n",
            "Venue Scientific Reports\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Increasing Accountability Through User-Interface Design Artifacts: A New Approach to Addressing the Problem of Access-Policy Violations\n",
            "Author [{'authorId': '35925413', 'name': 'Anthony Vance'}, {'authorId': '1786893', 'name': 'P. Lowry'}, {'authorId': '3932418', 'name': 'D. Eggett'}]\n",
            "Venue MIS Q.\n",
            "year 2015\n",
            "Abstract Access-policy violations are a growing problem with substantial costs for organizations. Although training programs and sanctions have been suggested as a means of reducing these violations, evidence shows the problem persists. It is thus imperative to identify additional ways to reduce access-policy violations, especially for systems providing broad access to data. We use accountability theory to develop four user-interface (UI) design artifacts that raise users' accountability perceptions within systems and in turn decrease access-policy violations. To test our model, we uniquely applied the scenario-based factorial survey method to various graphical manipulations of a records system containing sensitive information at a large organization with over 300 end users who use the system daily. We show that the UI design artifacts corresponding to four submanipulations of accountability can raise accountability and reduce access policy violation intentions. Our findings have several theoretical and practical implications for increasing accountability using UI design. Moreover, we are the first to extend the scenario-based factorial survey method to test design artifacts. This method provides the ability to use more design manipulations and to test with fewer users than is required in traditional experimentation and research on human--computer interaction. We also provide bootstrapping tests of mediation and moderation and demonstrate how to analyze fixed and random effects within the factorial survey method optimally.\n",
            "------------------------------------\n",
            "Title Critical Realism and Affordances: Theorizing IT-Associated Organizational Change Processes\n",
            "Author [{'authorId': '2706472', 'name': 'O. Volkoff'}, {'authorId': '144519071', 'name': 'D. Strong'}]\n",
            "Venue MIS Q.\n",
            "year 2013\n",
            "Abstract Convincing arguments for using critical realism as an underpinning for theories of IT-associated organizational change have appeared in the Information Systems literature. A central task in developing such theories is to uncover the generative mechanisms by which IT is implicated in organizational change processes, but to do so, we must explain how critical realism's concept of generative mechanisms applies in an IS context. Similarly, convincing arguments have been made for using Gibson's (1986) affordance theory from ecological psychology for developing theories of IT-associated organizational change, but this effort has been hampered due to insufficient attention to the ontological status of affordances. In this paper, we argue that affordances are the generative mechanisms we need to specify and explain how affordances are a specific type of generative mechanism. We use the core principles of critical realism to argue how affordances arise in the real domain from the relation between the complex assemblages of organizations and of IT artifacts, how affordances are actualized over time by organizational actors, and how these actualizations lead to the various effects we observe in the empirical domain. After presenting these arguments, we reanalyze two published cases in the literature, those of ACRO and Autoworks, to illustrate how affordance-based theories informed by critical realism enhance our ability to explain IT-associated organizational change. These examples show how researchers using this approach should proceed, and how managers can use these ideas to diagnose and address IT implementation problems.\n",
            "------------------------------------\n",
            "Title A Glorious and Not-So-Short History of the Information Systems Field\n",
            "Author [{'authorId': '1719444', 'name': 'R. Hirschheim'}, {'authorId': '1716864', 'name': 'H. Klein'}]\n",
            "Venue Journal of the AIS\n",
            "year 2012\n",
            "Abstract Research Article\n",
            "------------------------------------\n",
            "Title Twitcident: fighting fire with information from social web streams\n",
            "Author [{'authorId': '1714362', 'name': 'F. Abel'}, {'authorId': '2731925', 'name': 'C. Hauff'}, {'authorId': '143779489', 'name': 'G. Houben'}, {'authorId': '70028797', 'name': 'R.J.P. Stronkman'}, {'authorId': '2066201863', 'name': 'Ke Tao'}]\n",
            "Venue The Web Conference\n",
            "year 2012\n",
            "Abstract In this paper, we present Twitcident, a framework and Web-based system for filtering, searching and analyzing information about real-world incidents or crises. Twitcident connects to emergency broadcasting services and automatically starts tracking and filtering information from Social Web streams (Twitter) when a new incident occurs. It enriches the semantics of streamed Twitter messages to profile incidents and to continuously improve and adapt the information filtering to the current temporal context. Faceted search and analytical tools allow users to retrieve particular information fragments and overview and analyze the current situation as reported on the Social Web. Demo: http://wis.ewi.tudelft.nl/twitcident/\n",
            "------------------------------------\n",
            "Title An integrated map of genetic variation from 1,092 human genomes\n",
            "Author [{'authorId': None, 'name': 'Gil A. David M. Richard M. Gonçalo R. David R. Aravind McVean Altshuler (Co-Chair) Durbin (Co-Chair) Abec'}, {'authorId': None, 'name': 'Gil A. McVean'}, {'authorId': None, 'name': 'David M. Richard M. Gonçalo R. David R. Aravinda Andrew  Altshuler (Co-Chair) Durbin (Co-Chair) Abecasis Be'}, {'authorId': '2205196202', 'name': 'David M. Altshuler (Co-Chair)'}, {'authorId': '2205199622', 'name': 'Richard M. Durbin (Co-Chair)'}, {'authorId': '1709121', 'name': 'G. Abecasis'}, {'authorId': '144147128', 'name': 'D. Bentley'}, {'authorId': None, 'name': 'Aravinda Chakravarti'}, {'authorId': None, 'name': 'Andrew G. Clark'}, {'authorId': None, 'name': 'Peter Donnelly'}, {'authorId': None, 'name': 'Evan E. Eichler'}, {'authorId': '1767678', 'name': 'P. Flicek'}, {'authorId': '2059377987', 'name': 'S. Gabriel'}, {'authorId': '145744833', 'name': 'R. Gibbs'}, {'authorId': '47915863', 'name': 'E. Green'}, {'authorId': '8215940', 'name': 'M. Hurles'}, {'authorId': '24969339', 'name': 'B. Knoppers'}, {'authorId': '144226508', 'name': 'J. Korbel'}, {'authorId': None, 'name': 'Eric S. Lander'}, {'authorId': None, 'name': 'Charles Lee'}, {'authorId': '145040173', 'name': 'H. Lehrach'}, {'authorId': '3286001', 'name': 'E. Mardis'}, {'authorId': '2502758', 'name': 'G. Marth'}, {'authorId': None, 'name': 'Gil A. McVean'}, {'authorId': None, 'name': 'Deborah A. Nickerson'}, {'authorId': '2149991674', 'name': 'Jeanette P. Schmidt'}, {'authorId': '47019723', 'name': 'S. Sherry'}, {'authorId': None, 'name': 'Jun Wang'}, {'authorId': None, 'name': 'Richard K. Wilson'}, {'authorId': None, 'name': 'Richard A. Huyen Christie Sandra Lora Donna Jeff Min Jun X Gibbs (Principal Investigator) Dinh Kovar Lee Lewi'}, {'authorId': None, 'name': 'Richard A. Huyen Christie Sandra Lora Donna Jeff Min Gibbs (Principal Investigator) Dinh Kovar Lee Lewi'}, {'authorId': '2205199700', 'name': 'Richard A. Gibbs (Principal Investigator)'}, {'authorId': '2395971', 'name': 'H. Dinh'}, {'authorId': None, 'name': 'Christie Kovar'}, {'authorId': None, 'name': 'Sandra Lee'}, {'authorId': None, 'name': 'Lora Lewis'}, {'authorId': '1849102', 'name': 'D. Muzny'}, {'authorId': '2205201797', 'name': 'Jeff Reid'}, {'authorId': None, 'name': 'Min Wang'}, {'authorId': None, 'name': 'Jun Xiaodong Xiaosen Min Hui Xin Guoqing Jingxiang Yin Wang (Principal Investigator) Fang Guo Jian Jiang '}, {'authorId': '2205199678', 'name': 'Jun Wang (Principal Investigator)'}, {'authorId': None, 'name': 'Xiaodong Fang'}, {'authorId': None, 'name': 'Xiaosen Guo'}, {'authorId': '66453645', 'name': 'Min Jian'}, {'authorId': None, 'name': 'Hui Jiang'}, {'authorId': '145746365', 'name': 'Xin Jin'}, {'authorId': None, 'name': 'Guoqing Li'}, {'authorId': '1897483', 'name': 'Jingxiang Li'}, {'authorId': None, 'name': 'Yingrui Li'}, {'authorId': None, 'name': 'Zhuo Li'}, {'authorId': '48032577', 'name': 'Xinyu Liu'}, {'authorId': None, 'name': 'Yao Lu'}, {'authorId': None, 'name': 'Xuedi Ma'}, {'authorId': '48519930', 'name': 'Zheng Su'}, {'authorId': '33032092', 'name': 'S. Tai'}, {'authorId': None, 'name': 'Meifang Tang'}, {'authorId': None, 'name': 'Bo Wang'}, {'authorId': '50248452', 'name': 'Guangbiao Wang'}, {'authorId': None, 'name': 'Honglong Wu'}, {'authorId': None, 'name': 'Renhua Wu'}, {'authorId': None, 'name': 'Ye Yin'}, {'authorId': '48162804', 'name': 'Wenwei Zhang'}, {'authorId': None, 'name': 'Jiao Zhao'}, {'authorId': None, 'name': 'Meiru Zhao'}, {'authorId': None, 'name': 'Xiaole Zheng'}, {'authorId': '2150920526', 'name': 'Yan Zhou'}, {'authorId': None, 'name': 'Eric S. David M. Stacey B. Namrata Lander (Principal Investigator) Altshuler Gabriel '}, {'authorId': None, 'name': 'Eric S. Lander (Principal Investigator)'}, {'authorId': '145479043', 'name': 'D. Altshuler'}, {'authorId': '2205196158', 'name': 'Stacey B. Gabriel (Co-Chair)'}, {'authorId': '48659226', 'name': 'N. Gupta'}, {'authorId': None, 'name': 'Paul Laura Rasko Richard E. Xiangqun Flicek (Principal Investigator) Clarke Leinonen Sm'}, {'authorId': None, 'name': 'Paul Flicek (Principal Investigator)'}, {'authorId': None, 'name': 'Laura Clarke'}, {'authorId': '3230612', 'name': 'R. Leinonen'}, {'authorId': None, 'name': 'Richard E. Smith'}, {'authorId': '1398194766', 'name': 'Xiangqun Zheng-Bradley'}, {'authorId': None, 'name': 'David R. Russell Sean Terena Zoya Bentley (Principal Investigator) Grocock Humphray '}, {'authorId': '2205191312', 'name': 'David R. Bentley (Principal Investigator)'}, {'authorId': '2110859', 'name': 'R. Grocock'}, {'authorId': '4089015', 'name': 'S. Humphray'}, {'authorId': None, 'name': 'Terena James'}, {'authorId': '4032531', 'name': 'Z. Kingsbury'}, {'authorId': None, 'name': 'Hans Ralf Marcus W. Vyacheslav S. Tatiana A. Matthias F Lehrach (Principal Investigator) Sudbrak (Project '}, {'authorId': '2205198868', 'name': 'Hans Lehrach (Principal Investigator)'}, {'authorId': '2205198866', 'name': 'Ralf Sudbrak (Project Leader)'}, {'authorId': '2056191051', 'name': 'Marcus W. Albrecht'}, {'authorId': '3301399', 'name': 'V. Amstislavskiy'}, {'authorId': '2496076', 'name': 'T. Borodina'}, {'authorId': '2698542', 'name': 'M. Lienhard'}, {'authorId': '5854727', 'name': 'F. Mertes'}, {'authorId': '3660279', 'name': 'M. Sultan'}, {'authorId': '2959433', 'name': 'B. Timmermann'}, {'authorId': '21586421', 'name': 'M. Yaspo'}, {'authorId': '2205191282', 'name': 'Stephen T. Sherry (Principal Investigator)'}, {'authorId': '2205198854', 'name': 'Gil A. McVean (Principal Investigator)'}, {'authorId': None, 'name': 'Elaine R. Richard K. Lucinda Robert George M. Mardis (Co-Principal Investigator) (Co-Chair) Wils'}, {'authorId': '2205198852', 'name': 'Elaine R. Mardis (Co-Principal Investigator) (Co-Chair)'}, {'authorId': '2205191278', 'name': 'Richard K. Wilson (Co-Principal Investigator)'}, {'authorId': '35669500', 'name': 'L. Fulton'}, {'authorId': '144374511', 'name': 'R. Fulton'}, {'authorId': '46367152', 'name': 'G. Weinstock'}, {'authorId': None, 'name': 'Richard M. Senduran John Petr Thomas M. Anja Shane James M Durbin (Principal Investigator) Balasubramaniam Bu'}, {'authorId': '2205200963', 'name': 'Richard M. Durbin (Principal Investigator)'}, {'authorId': '2183898333', 'name': 'Senduran Balasubramaniam'}, {'authorId': '118971483', 'name': 'J. Burton'}, {'authorId': None, 'name': 'Petr Danecek'}, {'authorId': None, 'name': 'Thomas M. Keane'}, {'authorId': None, 'name': 'Anja Kolb-Kokocinski'}, {'authorId': '143770502', 'name': 'Shane A. McCarthy'}, {'authorId': '152979766', 'name': 'J. Stalker'}, {'authorId': '2137124383', 'name': 'Michael A. Quail'}, {'authorId': None, 'name': 'Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Adam  Schmidt (Principal Investigator) Davies Gollub Web'}, {'authorId': None, 'name': 'Jeanette P. Christopher J. Jeremy Teresa Brant Yiping Schmidt (Principal Investigator) Davies Gollub Web'}, {'authorId': '2205198712', 'name': 'Jeanette P. Schmidt (Principal Investigator)'}, {'authorId': '31508925', 'name': 'C. J. Davies'}, {'authorId': '37773217', 'name': 'J. Gollub'}, {'authorId': '2701279', 'name': 'Teresa A. Webster'}, {'authorId': '144459507', 'name': 'Brant Wong'}, {'authorId': '47826788', 'name': 'Yiping Zhan'}, {'authorId': '2205196239', 'name': 'Adam Auton (Principal Investigator)'}, {'authorId': None, 'name': 'Richard A. Fuli Matthew Danny Uday S. James Donna Uma Jeff Gibbs (Principal Investigator) Yu (Project Leader)'}, {'authorId': '2205201066', 'name': 'Fuli Yu (Project Leader)'}, {'authorId': '1682585', 'name': 'M. Bainbridge'}, {'authorId': '39700710', 'name': 'Danny Challis'}, {'authorId': None, 'name': 'Uday S. Evani'}, {'authorId': None, 'name': 'James Lu'}, {'authorId': '2317448', 'name': 'U. Nagaswamy'}, {'authorId': '29983679', 'name': 'A. Sabo'}, {'authorId': None, 'name': 'Yi Wang'}, {'authorId': None, 'name': 'Jin Yu'}, {'authorId': None, 'name': 'Jun Lachlan J. M. Lin Xiaosen Xin Guoqing Qibin Yingru Wang (Principal Investigator) Coin Fang Guo Jin Li'}, {'authorId': '1850377', 'name': 'L. Coin'}, {'authorId': '2048748104', 'name': 'L. Fang'}, {'authorId': None, 'name': 'Qibin Li'}, {'authorId': None, 'name': 'Zhenyu Li'}, {'authorId': '48444760', 'name': 'Haoxiang Lin'}, {'authorId': '1612993347', 'name': 'Binghang Liu'}, {'authorId': '1789382', 'name': 'Ruibang Luo'}, {'authorId': None, 'name': 'Nan Qin'}, {'authorId': None, 'name': 'Haojing Shao'}, {'authorId': None, 'name': 'Bingqiang Wang'}, {'authorId': None, 'name': 'Yinlong Xie'}, {'authorId': '2064448617', 'name': 'C. Ye'}, {'authorId': '2117922778', 'name': 'Chang Yu'}, {'authorId': None, 'name': 'Fan Zhang'}, {'authorId': None, 'name': 'Hancheng Zheng'}, {'authorId': None, 'name': 'Hongmei Zhu'}, {'authorId': None, 'name': 'Gabor T. Erik P. Deniz Wan-Ping Wen Alistair N. Jiantao  Marth (Principal Investigator) Garrison Kural Lee '}, {'authorId': None, 'name': 'Gabor T. Marth (Principal Investigator)'}, {'authorId': '2069875395', 'name': 'Erik P Garrison'}, {'authorId': '4578577', 'name': 'Deniz Kural'}, {'authorId': None, 'name': 'Wan-Ping Lee'}, {'authorId': '2205190984', 'name': 'Wen Fung Leong'}, {'authorId': None, 'name': 'Alistair N. Ward'}, {'authorId': None, 'name': 'Jiantao Wu'}, {'authorId': '2153207955', 'name': 'Mengyao Zhang'}, {'authorId': None, 'name': 'Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) Griffin Hsieh Mills S'}, {'authorId': '2205199080', 'name': 'Charles Lee (Principal Investigator)'}, {'authorId': None, 'name': 'Lauren Griffin'}, {'authorId': '4691357', 'name': 'Chih-heng Hsieh'}, {'authorId': '31664912', 'name': 'R. Mills'}, {'authorId': '2148376035', 'name': 'Xinghua Shi'}, {'authorId': '7286202', 'name': 'Marcin von Grotthuss'}, {'authorId': None, 'name': 'Chengsheng Zhang'}, {'authorId': None, 'name': 'Mark J. Mark A. David M. Eric Gaurav Mauricio O. Guille Daly (Principal Investigator) DePristo (Project Le'}, {'authorId': '2205199078', 'name': 'Mark J. Daly (Principal Investigator)'}, {'authorId': None, 'name': 'Mark A. DePristo (Project Leader)'}, {'authorId': '145139019', 'name': 'E. Banks'}, {'authorId': '145131069', 'name': 'G. Bhatia'}, {'authorId': '4361741', 'name': 'Mauricio O. Carneiro'}, {'authorId': None, 'name': 'Guillermo del Angel'}, {'authorId': '2070205', 'name': 'G. Genovese'}, {'authorId': '3177317', 'name': 'R. Handsaker'}, {'authorId': '46573761', 'name': 'C. Hartl'}, {'authorId': '2085660', 'name': 'S. Mccarroll'}, {'authorId': '4345727', 'name': 'J. Nemesh'}, {'authorId': '48663822', 'name': 'R. Poplin'}, {'authorId': None, 'name': 'Stephen F. Schaffner'}, {'authorId': None, 'name': 'Khalid Shakir'}, {'authorId': '2205199072', 'name': 'Seungtai C. Jayon Vladimir Yoon (Principal Investigator) Lihm Makarov'}, {'authorId': '2205199880', 'name': 'Seungtai C. Yoon (Principal Investigator)'}, {'authorId': '1999419', 'name': 'J. Lihm'}, {'authorId': '144252066', 'name': 'Vladimir Makarov'}, {'authorId': '2205199061', 'name': 'Hanjun Wook Ki Jin (Principal Investigator) Kim Cheol Kim'}, {'authorId': '2205199059', 'name': 'Hanjun Jin (Principal Investigator)'}, {'authorId': None, 'name': 'Wook Kim'}, {'authorId': None, 'name': 'Ki Cheol Kim'}, {'authorId': None, 'name': 'Jan O. Tobias Korbel (Principal Investigator) Rausch'}, {'authorId': None, 'name': 'Jan O. Korbel (Principal Investigator)'}, {'authorId': '46934906', 'name': 'T. Rausch'}, {'authorId': None, 'name': 'Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin'}, {'authorId': '145879529', 'name': 'Kathryn Beal'}, {'authorId': None, 'name': 'Fiona Cunningham'}, {'authorId': '145048374', 'name': 'Javier Herrero'}, {'authorId': '1752081', 'name': 'W. McLaren'}, {'authorId': '34976568', 'name': 'G. Ritchie'}, {'authorId': None, 'name': 'Andrew G. Srikanth Alon Juan L. Clark (Principal Investigator) Gottipati Keinan Ro'}, {'authorId': '2205196258', 'name': 'Andrew G. Clark (Principal Investigator)'}, {'authorId': '1953399', 'name': 'S. Gottipati'}, {'authorId': None, 'name': 'Alon Keinan'}, {'authorId': '1398574730', 'name': 'J. Rodriguez-Flores'}, {'authorId': None, 'name': 'Pardis C. Sharon R. Shervin Ridhi Sabeti (Principal Investigator) Grossman Tabrizi T'}, {'authorId': '2205190981', 'name': 'Pardis C. Sabeti (Principal Investigator)'}, {'authorId': '47240378', 'name': 'Sharon R. Grossman'}, {'authorId': '113204465', 'name': 'S. Tabrizi'}, {'authorId': '5605072', 'name': 'Ridhi Tariyal'}, {'authorId': None, 'name': 'David N. Edward V. Peter D. Cooper (Principal Investigator) Ball Stenson'}, {'authorId': '2205199125', 'name': 'David N. Cooper (Principal Investigator)'}, {'authorId': '2497845', 'name': 'E. Ball'}, {'authorId': '2690175', 'name': 'P. Stenson'}, {'authorId': None, 'name': 'David R. Bret Markus R. Tony Michael Sean Scott Lisa Joh Bentley (Principal Investigator) Barnes Bauer Keir'}, {'authorId': None, 'name': 'Bret Barnes'}, {'authorId': '2072883903', 'name': 'Markus Bauer'}, {'authorId': '2205196234', 'name': 'R. Keira Cheetham'}, {'authorId': '49398233', 'name': 'Tony Cox'}, {'authorId': None, 'name': 'Michael Eberle'}, {'authorId': '48267098', 'name': 'Scott D. Kahn'}, {'authorId': '38449392', 'name': 'Lisa J. Murray'}, {'authorId': None, 'name': 'John Peden'}, {'authorId': '2060343781', 'name': 'Richard Shaw'}, {'authorId': None, 'name': 'Kai Ye (Principal Investigator)'}, {'authorId': '2205191038', 'name': 'Mark A. Miriam K. Jerilyn A. Batzer (Principal Investigator) Konkel Walker'}, {'authorId': None, 'name': 'Mark A. Batzer (Principal Investigator)'}, {'authorId': '144879687', 'name': 'Miriam K. Konkel'}, {'authorId': '2110582187', 'name': 'Jerilyn A. Walker'}, {'authorId': None, 'name': 'Daniel G. Monkol MacArthur (Principal Investigator) Lek'}, {'authorId': None, 'name': 'Daniel G. MacArthur (Principal Investigator)'}, {'authorId': '3015823', 'name': 'M. Lek'}, {'authorId': None, 'name': 'Vyacheslav S. Ralf Sudbrak (Project Leader) Amstislavskiy Herwig'}, {'authorId': '2205201225', 'name': 'Sudbrak (Project Leader)'}, {'authorId': None, 'name': 'Ralf Herwig'}, {'authorId': '2205201221', 'name': 'Mark D. Shriver (Principal Investigator)'}, {'authorId': None, 'name': 'Carlos D. Jake K. Francisco M. Simon Eimear E. Jeffrey M. Bustamante (Principal Investigator) Byrnes De La V'}, {'authorId': '2205199119', 'name': 'Carlos D. Bustamante (Principal Investigator)'}, {'authorId': '3263767', 'name': 'J. Byrnes'}, {'authorId': '2222416', 'name': 'F. M. De La Vega'}, {'authorId': '2588593', 'name': 'S. Gravel'}, {'authorId': '2146139', 'name': 'E. Kenny'}, {'authorId': '36063428', 'name': 'J. Kidd'}, {'authorId': '153623898', 'name': 'P. Lacroute'}, {'authorId': None, 'name': 'Brian K. Maples'}, {'authorId': '1398672485', 'name': 'A. Moreno-Estrada'}, {'authorId': '5260119', 'name': 'Fouad Zakharia'}, {'authorId': '2205199089', 'name': 'Eran Yael Halperin (Principal Investigator) Baran'}, {'authorId': '2205201120', 'name': 'Eran Halperin (Principal Investigator)'}, {'authorId': None, 'name': 'Yael Baran'}, {'authorId': None, 'name': 'David W. Alexis Nils Tyler Ahmet A. Shripad A. Kevin Craig (Principal Investigator) Christoforides Home'}, {'authorId': None, 'name': 'David W. Craig (Principal Investigator)'}, {'authorId': '3473683', 'name': 'Alexis Christoforides'}, {'authorId': '2410134', 'name': 'Nils Homer'}, {'authorId': '3487553', 'name': 'Tyler Izatt'}, {'authorId': None, 'name': 'Ahmet A. Kurdoglu'}, {'authorId': '4596658', 'name': 'Shripad A. Sinari'}, {'authorId': None, 'name': 'Kevin Squire'}, {'authorId': '2205191035', 'name': 'Stephen T. Chunlin Sherry (Principal Investigator) Xiao'}, {'authorId': None, 'name': 'Chunlin Xiao'}, {'authorId': None, 'name': 'Jonathan Vineet Kenny Sebat (Principal Investigator) Bafna Ye'}, {'authorId': '2205201294', 'name': 'Jonathan Sebat (Principal Investigator)'}, {'authorId': '7553330', 'name': 'V. Bafna'}, {'authorId': '36851747', 'name': 'Kenny Q. Ye'}, {'authorId': None, 'name': 'Esteban G. Ryan D. Christopher R. Burchard (Principal Investigator) Hernandez (Princ'}, {'authorId': None, 'name': 'Esteban G. Burchard (Principal Investigator)'}, {'authorId': '2205201293', 'name': 'Ryan D. Hernandez (Principal Investigator)'}, {'authorId': '5797364', 'name': 'C. Gignoux'}, {'authorId': None, 'name': 'David Sol J. W. Haussler (Principal Investigator) Katzman James Ke'}, {'authorId': '2205199442', 'name': 'David Haussler (Principal Investigator)'}, {'authorId': '2519970', 'name': 'Sol Katzman'}, {'authorId': None, 'name': 'W. James Kent'}, {'authorId': '5896475', 'name': 'B. Howie'}, {'authorId': '2205196119', 'name': 'Andres Ruiz-Linares (Principal Investigator)'}, {'authorId': '2205199865', 'name': 'Emmanouil T. Tuuli Dermitzakis (Principal Investigator) Lappalainen'}, {'authorId': '2205191027', 'name': 'Emmanouil T. Dermitzakis (Principal Investigator)'}, {'authorId': None, 'name': 'Tuuli Lappalainen'}, {'authorId': '2205201289', 'name': 'Scott E. Xinyue Ankit Luke J. Devine (Principal Investigator) Liu Maroo Tallon'}, {'authorId': '2205196115', 'name': 'Scott E. Devine (Principal Investigator)'}, {'authorId': '49544165', 'name': 'Xinyue Liu'}, {'authorId': '38931992', 'name': 'A. Maroo'}, {'authorId': None, 'name': 'Luke J. Tallon'}, {'authorId': '2205199440', 'name': 'Jeffrey A. Leslie P. Rosenfeld (Principal Investigator) Michelson'}, {'authorId': None, 'name': 'Jeffrey A. Rosenfeld (Principal Investigator)'}, {'authorId': '38782802', 'name': 'L. P. Michelson'}, {'authorId': None, 'name': 'Gonçalo R. Hyun Paul Andrea Abigail Tom Fabio Francesco Ch Abecasis (Principal Investigator) (Co-Chair) Min K'}, {'authorId': None, 'name': 'Gonçalo R. Abecasis (Principal Investigator) (Co-Chair)'}, {'authorId': '2205199437', 'name': 'Hyun Min Kang (Project Leader)'}, {'authorId': '2067834498', 'name': 'Paul Anderson'}, {'authorId': '35459950', 'name': 'A. Angius'}, {'authorId': '2064821', 'name': 'A. Bigham'}, {'authorId': '31707654', 'name': 'T. Blackwell'}, {'authorId': '4754791', 'name': 'F. Busonero'}, {'authorId': '3549167', 'name': 'F. Cucca'}, {'authorId': '1869077', 'name': 'C. Fuchsberger'}, {'authorId': '2115599469', 'name': 'Chris Jones'}, {'authorId': '2326227', 'name': 'G. Jun'}, {'authorId': None, 'name': 'Yun Li'}, {'authorId': '145792217', 'name': 'R. Lyons'}, {'authorId': None, 'name': 'Andrea Maschio'}, {'authorId': '1902338', 'name': 'E. Porcu'}, {'authorId': '2571002', 'name': 'F. Reinier'}, {'authorId': None, 'name': 'Serena Sanna'}, {'authorId': '2189130274', 'name': 'David Schlessinger'}, {'authorId': '2487849', 'name': 'C. Sidore'}, {'authorId': '31912604', 'name': 'Adrian Tan'}, {'authorId': '2205199848', 'name': 'Mary Kate Trost'}, {'authorId': '2205199187', 'name': 'Philip Alan Awadalla (Principal Investigator) Hodgkinson'}, {'authorId': '2205200060', 'name': 'Philip Awadalla (Principal Investigator)'}, {'authorId': '144168976', 'name': 'A. Hodgkinson'}, {'authorId': None, 'name': 'Gerton Gil A. Jonathan L. Simon Claire Olivier Anjali Zam Lunter (Principal Investigator) McVean (Principal '}, {'authorId': '2205201281', 'name': 'Gerton Lunter (Principal Investigator)'}, {'authorId': '2205199185', 'name': 'Gil A. McVean (Principal Investigator) (Co-Chair)'}, {'authorId': '2205200048', 'name': 'Jonathan L. Marchini (Principal Investigator)'}, {'authorId': None, 'name': 'Simon Myers (Principal Investigator)'}, {'authorId': '6430378', 'name': 'C. Churchhouse'}, {'authorId': None, 'name': 'Olivier Delaneau'}, {'authorId': None, 'name': 'Anjali Gupta-Hinch'}, {'authorId': '33168930', 'name': 'Z. Iqbal'}, {'authorId': '48165784', 'name': 'I. Mathieson'}, {'authorId': '38911835', 'name': 'A. Rimmer'}, {'authorId': None, 'name': 'Dionysia K. Xifara'}, {'authorId': '2205191025', 'name': 'Taras K. Oleksyk (Principal Investigator)'}, {'authorId': None, 'name': 'Yunxin Xiaoming Momiao Fu (Principal Investigator) Liu Xiong'}, {'authorId': '2205199176', 'name': 'Yunxin Fu (Principal Investigator)'}, {'authorId': '2108959907', 'name': 'Xiaoming Liu'}, {'authorId': '2060255559', 'name': 'Momiao Xiong'}, {'authorId': '2205200033', 'name': 'Lynn David Jinchuan Jorde (Principal Investigator) Witherspoon Xing'}, {'authorId': '2205201270', 'name': 'Lynn Jorde (Principal Investigator)'}, {'authorId': '2459283', 'name': 'D. Witherspoon'}, {'authorId': '121553658', 'name': 'Jinchuan Xing'}, {'authorId': None, 'name': 'Evan E. Brian L. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) Browning (Princip'}, {'authorId': None, 'name': 'Evan E. Eichler (Principal Investigator)'}, {'authorId': None, 'name': 'Brian L. Browning (Principal Investigator)'}, {'authorId': None, 'name': 'Can Alkan'}, {'authorId': '2201928563', 'name': 'Iman Hajirasouliha'}, {'authorId': '32442918', 'name': 'F. Hormozdiari'}, {'authorId': '2063965594', 'name': 'Arthur Ko'}, {'authorId': '1827825', 'name': 'P. Sudmant'}, {'authorId': None, 'name': 'Elaine R. Ken Asif Li David Daniel C. Michael D. John W.  Mardis (Co-Principal Investigator) Chen Chinwalla '}, {'authorId': None, 'name': 'Elaine R. Mardis (Co-Principal Investigator)'}, {'authorId': None, 'name': 'Ken Chen'}, {'authorId': '3220161', 'name': 'A. Chinwalla'}, {'authorId': '49594724', 'name': 'L. Ding'}, {'authorId': '145091581', 'name': 'D. Dooling'}, {'authorId': '2661241', 'name': 'D. Koboldt'}, {'authorId': '3283893', 'name': 'M. McLellan'}, {'authorId': '144092929', 'name': 'J. Wallis'}, {'authorId': '1707033', 'name': 'M. Wendl'}, {'authorId': None, 'name': 'Qunyuan Zhang'}, {'authorId': None, 'name': 'Richard M. Matthew E. Chris Cornelis A. Qasim Senduran Yua Durbin (Principal Investigator) Hurles (Principal '}, {'authorId': None, 'name': 'Matthew E. Hurles (Principal Investigator)'}, {'authorId': '2205199616', 'name': 'Chris Tyler-Smith (Principal Investigator)'}, {'authorId': '34590088', 'name': 'C. A. Albers'}, {'authorId': '2295051', 'name': 'Q. Ayub'}, {'authorId': None, 'name': 'Yuan Chen'}, {'authorId': '34699852', 'name': 'A. Coffey'}, {'authorId': '49281244', 'name': 'V. Colonna'}, {'authorId': '47873871', 'name': 'N. Huang'}, {'authorId': '2699282', 'name': 'L. Jostins'}, {'authorId': None, 'name': 'Heng Li'}, {'authorId': '48107993', 'name': 'A. Scally'}, {'authorId': '35376885', 'name': 'Klaudia Walter'}, {'authorId': None, 'name': 'Yali Xue'}, {'authorId': None, 'name': 'Yujun Zhang'}, {'authorId': None, 'name': 'Mark B. Alexej Suganthi Jieming Declan Yao Lukas Arif O Gerstein (Principal Investigator) Abyzov Balasubra'}, {'authorId': '2205201722', 'name': 'Mark B. Gerstein (Principal Investigator)'}, {'authorId': None, 'name': 'Alexej Abyzov'}, {'authorId': '2668301', 'name': 'S. Balasubramanian'}, {'authorId': None, 'name': 'Jieming Chen'}, {'authorId': '143848051', 'name': 'Declan Clarke'}, {'authorId': None, 'name': 'Yao Fu'}, {'authorId': '2595445', 'name': 'L. Habegger'}, {'authorId': '32768477', 'name': 'A. Harmanci'}, {'authorId': None, 'name': 'Mike Jin'}, {'authorId': '50166471', 'name': 'Ekta Khurana'}, {'authorId': '1601328348', 'name': 'Xinmeng Jasmine Mu'}, {'authorId': '3034296', 'name': 'Cristina Sisu'}, {'authorId': None, 'name': 'Yingrui Ruibang Hongmei Charles Lauren Chih-Heng Ryan E. X Li Luo Zhu Lee (Principal Investigator) (Co-Chair)'}, {'authorId': '2205191078', 'name': 'Yingrui Ruibang Hongmei Li Luo Zhu'}, {'authorId': None, 'name': 'Charles Lauren Chih-Heng Ryan E. Xinghua Marcin Chengsheng Lee (Principal Investigator) (Co-Chair) Griffin Hs'}, {'authorId': None, 'name': 'Charles Lee (Principal Investigator) (Co-Chair)'}, {'authorId': None, 'name': 'Gabor T. Erik P. Deniz Wan-Ping Alistair N. Jiantao Meng Marth (Principal Investigator) Garrison Kural Lee '}, {'authorId': None, 'name': 'Steven A. David M. Eric Guillermo Giulio Robert E. Chris  McCarroll (Project Leader) Altshuler Banks del Ang'}, {'authorId': '2205196110', 'name': 'Steven A. McCarroll (Project Leader)'}, {'authorId': '48099824', 'name': 'Jeremiah D. Degenhardt'}, {'authorId': None, 'name': 'Paul Laura Richard E. Xiangqun Flicek (Principal Investigator) Clarke Smith Zheng'}, {'authorId': None, 'name': 'Jan O. Tobias Adrian M. Korbel (Principal Investigator) (Co-Chair) Rausch '}, {'authorId': '2205191076', 'name': 'Jan O. Korbel (Principal Investigator) (Co-Chair)'}, {'authorId': '38384569', 'name': 'A. Stütz'}, {'authorId': None, 'name': 'David R. Bret R. Michael Sean Scott Lisa Richard Bentley (Principal Investigator) Barnes Keira Chee'}, {'authorId': '2205200161', 'name': 'David W. Nils Craig (Principal Investigator) Homer'}, {'authorId': '2205201514', 'name': 'Deanna Chunlin Church Xiao'}, {'authorId': '73529582', 'name': 'D. Church'}, {'authorId': '2205200157', 'name': 'Jonathan Vineet Jacob J. Kenny Sebat (Principal Investigator) Bafna Michaelson Ye'}, {'authorId': '2070421199', 'name': 'J. Michaelson'}, {'authorId': None, 'name': 'Gerton Gil A. Zamin Lunter (Principal Investigator) McVean (Principal '}, {'authorId': '2205191074', 'name': 'David Jinchuan Witherspoon Xing'}, {'authorId': None, 'name': 'Evan E. Can Iman Fereydoun Arthur Peter H. Eichler (Principal Investigator) (Co-Chair) Alkan '}, {'authorId': '2205200153', 'name': 'Evan E. Eichler (Principal Investigator) (Co-Chair)'}, {'authorId': None, 'name': 'Ken Asif Li Michael D. John W. Chen Chinwalla Ding McLellan Wallis'}, {'authorId': None, 'name': 'Matthew E. Ben Heng Sarah J. Zemin Aylwyn Klaudia Yujun Hurles (Principal Investigator) (Co-Chair) Blackbu'}, {'authorId': None, 'name': 'Matthew E. Hurles (Principal Investigator) (Co-Chair)'}, {'authorId': '3006362', 'name': 'B. Blackburne'}, {'authorId': '5607377', 'name': 'S. Lindsay'}, {'authorId': '40138891', 'name': 'Z. Ning'}, {'authorId': None, 'name': 'Mark B. Alexej Jieming Declan Ekta Xinmeng Cristina Gerstein (Principal Investigator) Abyzov Chen Clar'}, {'authorId': '2205201722', 'name': 'Mark B. Gerstein (Principal Investigator)'}, {'authorId': None, 'name': 'Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj'}, {'authorId': None, 'name': 'Richard A. Fuli Matthew Danny Uday S. Christie Lora James  Gibbs (Principal Investigator) (Co-Chair) Yu (Proj'}, {'authorId': '2205199540', 'name': 'Richard A. Gibbs (Principal Investigator) (Co-Chair)'}, {'authorId': '2205191072', 'name': 'Xiaosen Yingrui Renhua Guo Li Wu'}, {'authorId': None, 'name': 'Gabor T. Erik P. Wen Alistair N. Marth (Principal Investigator) (Co-Chair) Garrison'}, {'authorId': None, 'name': 'Gabor T. Marth (Principal Investigator) (Co-Chair)'}, {'authorId': '2205196270', 'name': 'Guillermo Mark A. Stacey B. Namrata Chris Ryan E. del Angel DePristo Gabriel Gupta Hartl Poplin'}, {'authorId': '2446263', 'name': 'M. DePristo'}, {'authorId': '2205200149', 'name': 'Andrew G. Juan L. Clark (Principal Investigator) Rodriguez-Flores'}, {'authorId': '2205191070', 'name': 'Carlos D. Simon Bustamante (Principal Investigator) Gravel'}, {'authorId': None, 'name': 'David W. Alexis Nils Tyler Craig (Principal Investigator) Christoforides Home'}, {'authorId': '2205196266', 'name': 'Gonçalo R. Hyun Abecasis (Principal Investigator) Min Kang'}, {'authorId': '2205200147', 'name': 'Gonçalo R. Abecasis (Principal Investigator)'}, {'authorId': '123320893', 'name': 'Hyun Min Kang'}, {'authorId': None, 'name': 'Elaine R. David Lucinda Robert Daniel C. Mardis (Principal Investigator) Dooling Fulton Ful'}, {'authorId': None, 'name': 'Elaine R. Mardis (Principal Investigator)'}, {'authorId': None, 'name': 'Richard M. Senduran Thomas M. Shane James Durbin (Principal Investigator) Balasubramaniam Ke'}, {'authorId': None, 'name': 'Mark B. Suganthi Lukas Gerstein (Principal Investigator) Balasubramanian '}, {'authorId': None, 'name': 'Erik P. Richard A. Matthew Donna Fuli Jin Guillermo Rob Garrison Gibbs (Principal Investigator) Bainbridge'}, {'authorId': None, 'name': 'Richard A. Matthew Donna Fuli Jin Gibbs (Principal Investigator) Bainbridge Muzny Yu'}, {'authorId': None, 'name': 'Fuli Yu'}, {'authorId': '2205191068', 'name': 'Guillermo Robert E. del Angel Handsaker'}, {'authorId': None, 'name': 'Paul Kathryn Laura Fiona Javier William M. Graham R. S. Flicek (Principal Investigator) Beal Clarke Cunnin'}, {'authorId': '2205199536', 'name': 'Carlos D. Francisco M. Bustamante (Principal Investigator) De La Vega'}, {'authorId': None, 'name': 'David W. Ahmet A. Craig (Principal Investigator) Kurdoglu'}, {'authorId': None, 'name': 'Chris Yuan Vincenza Adam Jennifer Yali Tyler-Smith (Principal Investigator) (Co-Chair) Ch'}, {'authorId': '2205201833', 'name': 'Chris Tyler-Smith (Principal Investigator) (Co-Chair)'}, {'authorId': None, 'name': 'Adam Frankish'}, {'authorId': None, 'name': 'Jennifer Harrow'}, {'authorId': None, 'name': 'Mark B. Alexej Suganthi Jieming Declan Yao Arif O. Mike Gerstein (Principal Investigator) (Co-Chair) Abyzo'}, {'authorId': None, 'name': 'Mark B. Gerstein (Principal Investigator) (Co-Chair)'}, {'authorId': None, 'name': 'Richard A. Gerald Walker Divya Christie Donna Jeff Jun Xia Gibbs (Principal Investigator) Fowler Hale Kalra K'}, {'authorId': None, 'name': 'Richard A. Gerald Walker Divya Christie Donna Jeff Gibbs (Principal Investigator) Fowler Hale Kalra K'}, {'authorId': None, 'name': 'Gerald Fowler'}, {'authorId': None, 'name': 'Walker Hale'}, {'authorId': '49698831', 'name': 'D. Kalra'}, {'authorId': '2205196222', 'name': 'Jun Xiaosen Guoqing Yingrui Xiaole Wang (Principal Investigator) Guo Li Li Zheng'}, {'authorId': None, 'name': 'Paul Laura Jonathan Gavin Eugene Rasko William M. Rajes Flicek (Principal Investigator) (Co-Chair) Clarke '}, {'authorId': '2205201831', 'name': 'Paul Flicek (Principal Investigator) (Co-Chair)'}, {'authorId': '2205201826', 'name': 'Laura Clarke (Project Leader)'}, {'authorId': '40395720', 'name': 'Jonathan A. Barker'}, {'authorId': '39373947', 'name': 'G. Kelman'}, {'authorId': None, 'name': 'Eugene Kulesha'}, {'authorId': None, 'name': 'Rajesh Radhakrishnan'}, {'authorId': '2205201907', 'name': 'Asier Roa'}, {'authorId': '38824400', 'name': 'Dmitriy Smirnov'}, {'authorId': '2085927962', 'name': 'Ian Streeter'}, {'authorId': '2895058', 'name': 'I. Toneva'}, {'authorId': None, 'name': 'Brendan Vaughan'}, {'authorId': '2205196211', 'name': 'David R. Tony Sean Scott Bentley (Principal Investigator) Cox Humphray Kahn'}, {'authorId': None, 'name': 'Ralf Marcus W. Matthias Sudbrak (Project Leader) Albrecht Lienhard'}, {'authorId': '2205199403', 'name': 'David W. Tyler Ahmet A. Craig (Principal Investigator) Izatt Kurdoglu'}, {'authorId': None, 'name': 'Stephen T. Victor Zinaida Dimitriy Nathan Chao Deanna Robe Sherry (Principal Investigator) (Co-Chair) Ananiev'}, {'authorId': '2205199803', 'name': 'Stephen T. Sherry (Principal Investigator) (Co-Chair)'}, {'authorId': None, 'name': 'Victor Ananiev'}, {'authorId': '2205199801', 'name': 'Zinaida Belaia'}, {'authorId': '2205201822', 'name': 'Dimitriy Beloslyudtsev'}, {'authorId': '2398610', 'name': 'Nathan Bouk'}, {'authorId': None, 'name': 'Chao Chen'}, {'authorId': None, 'name': 'Robert Cohen'}, {'authorId': '2205197481', 'name': 'Charles Cook'}, {'authorId': None, 'name': 'John Garner'}, {'authorId': '2112788', 'name': 'T. Hefferon'}, {'authorId': '80485928', 'name': 'M. Kimelman'}, {'authorId': None, 'name': 'Chunlei Liu'}, {'authorId': None, 'name': 'John Lopez'}, {'authorId': None, 'name': 'Peter Meric'}, {'authorId': None, 'name': 'Chris O’Sullivan'}, {'authorId': None, 'name': 'Yuri Ostapchuk'}, {'authorId': '144205048', 'name': 'Lon Phan'}, {'authorId': None, 'name': 'Sergiy Ponomarov'}, {'authorId': None, 'name': 'Valerie Schneider'}, {'authorId': None, 'name': 'Eugene Shekhtman'}, {'authorId': None, 'name': 'Karl Sirotkin'}, {'authorId': '2570958', 'name': 'D. Slotta'}, {'authorId': '2108906577', 'name': 'Hua Zhang'}, {'authorId': '2205200189', 'name': 'Can Arthur Alkan Ko'}, {'authorId': None, 'name': 'Aravinda Bartha M. Gonçalo R. Kathleen C. Christine Esteban Chakravarti (Co-Chair) Knoppers (Co-Chair) Abecasi'}, {'authorId': None, 'name': 'Aravinda Chakravarti (Co-Chair)'}, {'authorId': '2205168645', 'name': 'Bartha M. Knoppers (Co-Chair)'}, {'authorId': '1709121', 'name': 'G. Abecasis'}, {'authorId': '5106274', 'name': 'K. Barnes'}, {'authorId': None, 'name': 'Christine Beiswanger'}, {'authorId': None, 'name': 'Esteban G. Burchard'}, {'authorId': '2090993446', 'name': 'C. Bustamante'}, {'authorId': None, 'name': 'Hongyu Cai'}, {'authorId': '3557876', 'name': 'H. Cao'}, {'authorId': '144187514', 'name': 'R. Durbin'}, {'authorId': None, 'name': 'Neda Gharani'}, {'authorId': '145744833', 'name': 'R. Gibbs'}, {'authorId': '4297801', 'name': 'B. Henn'}, {'authorId': None, 'name': 'Danielle Jones'}, {'authorId': '2332524', 'name': 'L. Jorde'}, {'authorId': '50322146', 'name': 'J. Kaye'}, {'authorId': '144239005', 'name': 'A. Kent'}]\n",
            "Venue Nature\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Empowering patients through social media: The benefits and challenges\n",
            "Author [{'authorId': '31776961', 'name': 'M. Househ'}, {'authorId': '2197544', 'name': 'E. Borycki'}, {'authorId': '145027929', 'name': 'A. Kushniruk'}]\n",
            "Venue Health Informatics Journal\n",
            "year 2014\n",
            "Abstract This article explores the range of social media platforms used by patients and examines the benefits and challenges of using these tools from a patient perspective. A literature review was performed to investigate the use of social media technology by patients. The MEDLINE database was searched using the terms “social media” and “patient.” The search was conducted in September 2012 and yielded 765 abstracts. Initially, 63 abstracts were selected. All articles dating from 2004 through 2012 were included. Only 12 articles were found to be relevant for the purposes of the review. The results of this research found that there appears to be an increase in the use of social media by patients across the healthcare spectrum. The research indicates a promising future for the use of social media by patients; however, evidence related to the efficacy and effectiveness of social media is currently limited. Various challenges have also been identified relating to privacy and security concerns, usability, the manipulation of identity, and misinformation. The use of social media technology is an emerging trend for patients who are seeking health information. Conclusions are that such technology holds promise for improving patient engagement and empowerment and community building. Social media has a future in healthcare, especially with regard to patient engagement and empowerment; however, there are several challenges to overcome before the technology can achieve its potential.\n",
            "------------------------------------\n",
            "Title Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation\n",
            "Author [{'authorId': '2604251', 'name': 'Guosheng Lin'}, {'authorId': '12459603', 'name': 'Chunhua Shen'}, {'authorId': '1388378062', 'name': 'Anton van dan Hengel'}, {'authorId': '145950884', 'name': 'I. Reid'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2015\n",
            "Abstract Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information, specifically, we explore 'patch-patch' context between image regions, and 'patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-overunion score of 78:0 on the challenging PASCAL VOC 2012 dataset.\n",
            "------------------------------------\n",
            "Title Research Note - Effects of Individual Self-Protection, Industry Self-Regulation, and Government Regulation on Privacy Concerns: A Study of Location-Based Services\n",
            "Author [{'authorId': '46485370', 'name': 'Heng Xu'}, {'authorId': '144686722', 'name': 'H. Teo'}, {'authorId': '144054451', 'name': 'B. Tan'}, {'authorId': '1700216', 'name': 'Ritu Agarwal'}]\n",
            "Venue Information systems research\n",
            "year 2012\n",
            "Abstract This study seeks to clarify the nature of control in the context of information privacy to generate insights into the effects of different privacy assurance approaches on context-specific concerns for information privacy. We theorize that such effects are exhibited through mediation by perceived control over personal information and develop arguments in support of the interaction effects involving different privacy assurance approaches (individual self-protection, industry self-regulation, and government legislation). We test the research model in the context of location-based services using data obtained from 178 individuals in Singapore. In general, the results support our core assertion that perceived control over personal information is a key factor affecting context-specific concerns for information privacy. In addition to enhancing our theoretical understanding of the link between control and privacy concerns, these findings have important implications for service providers and consumers as well as for regulatory bodies and technology developers.\n",
            "------------------------------------\n",
            "Title Monocular 3D Object Detection for Autonomous Driving\n",
            "Author [{'authorId': '1847684', 'name': 'Xiaozhi Chen'}, {'authorId': '2204339', 'name': 'Kaustav Kundu'}, {'authorId': '3095572', 'name': 'Ziyu Zhang'}, {'authorId': '46389698', 'name': 'Huimin Ma'}, {'authorId': '37895334', 'name': 'S. Fidler'}, {'authorId': '2422559', 'name': 'R. Urtasun'}]\n",
            "Venue Computer Vision and Pattern Recognition\n",
            "year 2016\n",
            "Abstract The goal of this paper is to perform 3D object detection from a single monocular image in the domain of autonomous driving. Our method first aims to generate a set of candidate class-specific object proposals, which are then run through a standard CNN pipeline to obtain high-quality object detections. The focus of this paper is on proposal generation. In particular, we propose an energy minimization approach that places object candidates in 3D using the fact that objects should be on the ground-plane. We then score each candidate box projected to the image plane via several intuitive potentials encoding semantic segmentation, contextual information, size and location priors and typical object shape. Our experimental evaluation demonstrates that our object proposal generation approach significantly outperforms all monocular approaches, and achieves the best detection performance on the challenging KITTI benchmark, among published monocular competitors.\n",
            "------------------------------------\n",
            "Title Distributed robotic sensor networks: An information-theoretic approach\n",
            "Author [{'authorId': '2847166', 'name': 'Brian J. Julian'}, {'authorId': '3115880', 'name': 'M. Angermann'}, {'authorId': '3179069', 'name': 'M. Schwager'}, {'authorId': '145944286', 'name': 'D. Rus'}]\n",
            "Venue Int. J. Robotics Res.\n",
            "year 2012\n",
            "Abstract In this paper we present an information-theoretic approach to distributively control multiple robots equipped with sensors to infer the state of an environment. The robots iteratively estimate the environment state using a sequential Bayesian filter, while continuously moving along the gradient of mutual information to maximize the informativeness of the observations provided by their sensors. The gradient-based controller is proven to be convergent between observations and, in its most general form, locally optimal. However, the computational complexity of the general form is shown to be intractable, and thus non-parametric methods are incorporated to allow the controller to scale with respect to the number of robots. For decentralized operation, both the sequential Bayesian filter and the gradient-based controller use a novel consensus-based algorithm to approximate the robots’ joint measurement probabilities, even when the network diameter, the maximum in/out degree, and the number of robots are unknown. The approach is validated in two separate hardware experiments each using five quadrotor flying robots, and scalability is emphasized in simulations using 100 robots.\n",
            "------------------------------------\n",
            "Title Total Variation Spatial Regularization for Sparse Hyperspectral Unmixing\n",
            "Author [{'authorId': '10760820', 'name': 'Marian-Daniel Iordache'}, {'authorId': '1399086996', 'name': 'J. Bioucas-Dias'}, {'authorId': '143767945', 'name': 'A. Plaza'}]\n",
            "Venue IEEE Transactions on Geoscience and Remote Sensing\n",
            "year 2012\n",
            "Abstract Spectral unmixing aims at estimating the fractional abundances of pure spectral signatures (also called endmembers) in each mixed pixel collected by a remote sensing hyperspectral imaging instrument. In recent work, the linear spectral unmixing problem has been approached in semisupervised fashion as a sparse regression one, under the assumption that the observed image signatures can be expressed as linear combinations of pure spectra, known a priori and available in a library. It happens, however, that sparse unmixing focuses on analyzing the hyperspectral data without incorporating spatial information. In this paper, we include the total variation (TV) regularization to the classical sparse regression formulation, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Our experimental results, conducted with both simulated and real hyperspectral data sets, indicate the potential of including spatial information (through the TV term) on sparse unmixing formulations for improved characterization of mixed pixels in hyperspectral imagery.\n",
            "------------------------------------\n",
            "Title Experimentally induced innovations lead to persistent culture via conformity in wild birds\n",
            "Author [{'authorId': '4679421', 'name': 'L. Aplin'}, {'authorId': '3384335', 'name': 'D. Farine'}, {'authorId': '1399052434', 'name': 'J. Morand‐Ferron'}, {'authorId': '34471793', 'name': 'A. Cockburn'}, {'authorId': '144216799', 'name': 'A. Thornton'}, {'authorId': '6799312', 'name': 'B. Sheldon'}]\n",
            "Venue Nature\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Visual simultaneous localization and mapping: a survey\n",
            "Author [{'authorId': '1400333449', 'name': 'J. Fuentes-Pacheco'}, {'authorId': '2111762', 'name': 'José Ruíz Ascencio'}, {'authorId': '1400333452', 'name': 'J. M. Rendon-Mancha'}]\n",
            "Venue Artificial Intelligence Review\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Building Member Attachment in Online Communities: Applying Theories of Group Identity and Interpersonal Bonds\n",
            "Author [{'authorId': '145217085', 'name': 'Yuqing Ren'}, {'authorId': '145192090', 'name': 'F. M. Harper'}, {'authorId': '2074129839', 'name': 'Sara Drenner'}, {'authorId': '1739628', 'name': 'L. Terveen'}, {'authorId': '47198673', 'name': 'S. Kiesler'}, {'authorId': '2579342', 'name': 'J. Riedl'}, {'authorId': '1702853', 'name': 'R. Kraut'}]\n",
            "Venue MIS Q.\n",
            "year 2012\n",
            "Abstract Online communities are increasingly important to organizations and the general public, but there is little theoretically based research on what makes some online communities more successful than others. In this article, we apply theory from the field of social psychology to understand how online communities develop member attachment, an important dimension of community success. We implemented and empirically tested two sets of community features for building member attachment by strengthening either group identity or interpersonal bonds. To increase identity-based attachment, we gave members information about group activities and intergroup competition, and tools for group-level communication. To increase bond-based attachment, we gave members information about the activities of individual members and interpersonal similarity, and tools for interpersonal communication. Results from a six-month field experiment show that participants' visit frequency and self-reported attachment increased in both conditions. Community features intended to foster identity-based attachment had stronger effects than features intended to foster bond-based attachment. Participants in the identity condition with access to group profiles and repeated exposure to their group's activities visited their community twice as frequently as participants in other conditions. The new features also had stronger effects on newcomers than on old-timers. This research illustrates how theory from the social science literature can be applied to gain a more systematic understanding of online communities and how theory-inspired features can improve their success.\n",
            "------------------------------------\n",
            "Title Key-Value Memory Networks for Directly Reading Documents\n",
            "Author [{'authorId': '143622869', 'name': 'Alexander H. Miller'}, {'authorId': '2064150446', 'name': 'Adam Fisch'}, {'authorId': '34176020', 'name': 'Jesse Dodge'}, {'authorId': '145926563', 'name': 'Amir-Hossein Karimi'}, {'authorId': '1713934', 'name': 'Antoine Bordes'}, {'authorId': '145183709', 'name': 'J. Weston'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2016\n",
            "Abstract Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WikiMovies, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WikiQA benchmark.\n",
            "------------------------------------\n",
            "Title A State-of-the-Art Review on the Integration of Building Information Modeling (BIM) and Geographic Information System (GIS)\n",
            "Author [{'authorId': '2120101375', 'name': 'Xin Liu'}, {'authorId': '2144797317', 'name': 'Xiangyu Wang'}, {'authorId': '8676174', 'name': 'G. Wright'}, {'authorId': '26370859', 'name': 'Jack C. P. Cheng'}, {'authorId': '2108789472', 'name': 'Xiao Li'}, {'authorId': '144207288', 'name': 'R. Liu'}]\n",
            "Venue ISPRS Int. J. Geo Inf.\n",
            "year 2017\n",
            "Abstract The integration of Building Information Modeling (BIM) and Geographic Information System (GIS) has been identified as a promising but challenging topic to transform information towards the generation of knowledge and intelligence. Achievement of integrating these two concepts and enabling technologies will have a significant impact on solving problems in the civil, building and infrastructure sectors. However, since GIS and BIM were originally developed for different purposes, numerous challenges are being encountered for the integration. To better understand these two different domains, this paper reviews the development and dissimilarities of GIS and BIM, the existing integration methods, and investigates their potential in various applications. This study shows that the integration methods are developed for various reasons and aim to solve different problems. The parameters influencing the choice can be summarized and named as “EEEF” criteria: effectiveness, extensibility, effort, and flexibility. Compared with other methods, semantic web technologies provide a promising and generalized integration solution. However, the biggest challenges of this method are the large efforts required at early stage and the isolated development of ontologies within one particular domain. The isolation problem also applies to other methods. Therefore, openness is the key of the success of BIM and GIS integration.\n",
            "------------------------------------\n",
            "Title Virtual memory palaces: immersion aids recall\n",
            "Author [{'authorId': '11150474', 'name': 'Eric Krokos'}, {'authorId': '1764846', 'name': 'C. Plaisant'}, {'authorId': '143735748', 'name': 'A. Varshney'}]\n",
            "Venue Virtual Reality\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Verified quantum information scrambling\n",
            "Author [{'authorId': '143852035', 'name': 'K. Landsman'}, {'authorId': '3928432', 'name': 'C. Figgatt'}, {'authorId': '46869204', 'name': 'T. Schuster'}, {'authorId': '8609946', 'name': 'N. Linke'}, {'authorId': '2727848', 'name': 'B. Yoshida'}, {'authorId': '4138853', 'name': 'N. Yao'}, {'authorId': '50856718', 'name': 'C. Monroe'}]\n",
            "Venue Nature\n",
            "year 2018\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title FILA: Fine-grained indoor localization\n",
            "Author [{'authorId': '8584850', 'name': 'Kaishun Wu'}, {'authorId': '145974115', 'name': 'Jiang Xiao'}, {'authorId': '2398386', 'name': 'Youwen Yi'}, {'authorId': '2147415016', 'name': 'Min Gao'}, {'authorId': '1726587', 'name': 'L. Ni'}]\n",
            "Venue 2012 Proceedings IEEE INFOCOM\n",
            "year 2012\n",
            "Abstract Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. How to eliminate such effect so as to enhance the indoor localization performance is a big challenge. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in OFDM systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to alleviate multipath effect at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.\n",
            "------------------------------------\n",
            "Title The development of software to support multiple systematic review types: the Joanna Briggs Institute System for the Unified Management, Assessment and Review of Information (JBI SUMARI)\n",
            "Author [{'authorId': '3506051', 'name': 'Z. Munn'}, {'authorId': '5874783', 'name': 'E. Aromataris'}, {'authorId': '3690285', 'name': 'C. Tufanaru'}, {'authorId': '145505734', 'name': 'Cindy Stern'}, {'authorId': '4633473', 'name': 'K. Porritt'}, {'authorId': '2075003366', 'name': 'James R. Farrow'}, {'authorId': '144877069', 'name': 'C. Lockwood'}, {'authorId': '50853726', 'name': 'M. Stephenson'}, {'authorId': '78386671', 'name': 'Sandeep Moola'}, {'authorId': '4600321', 'name': 'L. Lizarondo'}, {'authorId': '2656349', 'name': 'A. McArthur'}, {'authorId': '144546884', 'name': 'M. Peters'}, {'authorId': '145368528', 'name': 'A. Pearson'}, {'authorId': '78103581', 'name': 'Z. Jordan'}]\n",
            "Venue International Journal of Evidence-Based Healthcare\n",
            "year 2019\n",
            "Abstract Aim: Systematic reviews play an important role in ensuring trustworthy recommendations in healthcare. However, systematic reviews can be laborious to undertake and as such software has been developed to assist in the conduct and reporting of systematic reviews. The Joanna Briggs Institute and its collaborating centres consist of thousands of researchers, academics and clinicians across the globe conducting systematic reviews of various types. To support them in their work, modern software and online tools are required. Our aim was to develop a software program to support systematic reviewers across the globe. Methods: A working party was formed with extensive consultation with members of the Joanna Briggs Collaboration focusing on ideal features of a software program to support systematic reviews. The new systematic review software was built using an agile methodology and designed to be a modern web application. Results: The new systematic review software, the Joanna Briggs Institute System for the Unified Management, Assessment and Review of Information (JBI SUMARI), was successfully developed through an iterative process of development, feedback, testing and review. The software is now available (https://www.jbisumari.org/) and supports the entire systematic review process for different types of systematic reviews. Conclusions: An agile software development approach combined with wide consultation and user testing can facilitate systematic review software design and development. This new software can support systematic reviews and guideline developers to create systematic reviews for a diverse range of questions.\n",
            "------------------------------------\n",
            "Title Depth Map Prediction from a Single Image using a Multi-Scale Deep Network\n",
            "Author [{'authorId': '2060028', 'name': 'D. Eigen'}, {'authorId': '1940183', 'name': 'Christian Puhrsch'}, {'authorId': '2276554', 'name': 'R. Fergus'}]\n",
            "Venue NIPS\n",
            "year 2014\n",
            "Abstract Predicting depth is an essential component in understanding the 3D geometry of a scene. While for stereo images local correspondence suffices for estimation, finding depth relations from a single image is less straightforward, requiring integration of both global and local information from various cues. Moreover, the task is inherently ambiguous, with a large source of uncertainty coming from the overall scale. In this paper, we present a new method that addresses this task by employing two deep network stacks: one that makes a coarse global prediction based on the entire image, and another that refines this prediction locally. We also apply a scale-invariant error to help measure depth relations rather than scale. By leveraging the raw datasets as large sources of training data, our method achieves state-of-the-art results on both NYU Depth and KITTI, and matches detailed depth boundaries without the need for superpixelation.\n",
            "------------------------------------\n",
            "Title Software-Defined Industrial Internet of Things in the Context of Industry 4.0\n",
            "Author [{'authorId': '70985296', 'name': 'J. Wan'}, {'authorId': '3427818', 'name': 'Shenglong Tang'}, {'authorId': '2646197', 'name': 'Zhaogang Shu'}, {'authorId': '46599370', 'name': 'Di Li'}, {'authorId': '2679504', 'name': 'Shiyong Wang'}, {'authorId': '2113544439', 'name': 'Muhammad Imran'}, {'authorId': '1747034', 'name': 'A. Vasilakos'}]\n",
            "Venue IEEE Sensors Journal\n",
            "year 2016\n",
            "Abstract In recent years, there have been great advances in industrial Internet of Things (IIoT) and its related domains, such as industrial wireless networks (IWNs), big data, and cloud computing. These emerging technologies will bring great opportunities for promoting industrial upgrades and even allow the introduction of the fourth industrial revolution, namely, Industry 4.0. In the context of Industry 4.0, all kinds of intelligent equipment (e.g., industrial robots) supported by wired or wireless networks are widely adopted, and both real-time and delayed signals coexist. Therefore, based on the advancement of software-defined networks technology, we propose a new concept for industrial environments by introducing software-defined IIoT in order to make the network more flexible. In this paper, we analyze the IIoT architecture, including physical layer, IWNs, industrial cloud, and smart terminals, and describe the information interaction among different devices. Then, we propose a software-defined IIoT architecture to manage physical devices and provide an interface for information exchange. Subsequently, we discuss the prominent problems and possible solutions for software-defined IIoT. Finally, we select an intelligent manufacturing environment as an assessment test bed, and implement the basic experimental analysis. This paper will open a new research direction of IIoT and accelerate the implementation of Industry 4.0.\n",
            "------------------------------------\n",
            "Title Smart Cities: Big Data, Civic Hackers, and the Quest for a New Utopia\n",
            "Author [{'authorId': '16851847', 'name': 'A. Townsend'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract We live in a world defined by urbanization and digital ubiquity, where mobile broadband connections outnumber fixed ones, machines dominate a new \"internet of things,\" and more people live in cities than in the countryside. In Smart Cities, urbanist and technology expert Anthony Townsend takes a broad historical look at the forces that have shaped the planning and design of cities and information technologies from the rise of the great industrial cities of the nineteenth century to the present. A century ago, the telegraph and the mechanical tabulator were used to tame cities of millions. Today, cellular networks and cloud computing tie together the complex choreography of mega-regions of tens of millions of people. In response, cities worldwide are deploying technology to address both the timeless challenges of government and the mounting problems posed by human settlements of previously unimaginable size and complexity. In Chicago, GPS sensors on snow plows feed a real-time \"plow tracker\" map that everyone can access. In Zaragoza, Spain, a \"citizen card\" can get you on the free city-wide Wi-Fi network, unlock a bike share, check a book out of the library, and pay for your bus ride home. In New York, a guerrilla group of citizen-scientists installed sensors in local sewers to alert you when stormwater runoff overwhelms the system, dumping waste into local waterways. As technology barons, entrepreneurs, mayors, and an emerging vanguard of civic hackers are trying to shape this new frontier, Smart Cities considers the motivations, aspirations, and shortcomings of them all while offering a new civics to guide our efforts as we build the future together, one click at a time.\n",
            "------------------------------------\n",
            "Title ConceptNet 5.5: An Open Multilingual Graph of General Knowledge\n",
            "Author [{'authorId': '145696762', 'name': 'R. Speer'}, {'authorId': '2060230787', 'name': 'Joshua Chin'}, {'authorId': '2232845', 'name': 'Catherine Havasi'}]\n",
            "Venue AAAI Conference on Artificial Intelligence\n",
            "year 2016\n",
            "Abstract \n",
            " \n",
            " Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.\n",
            " \n",
            "\n",
            "------------------------------------\n",
            "Title \"Best practice\" for patient-centered communication: a narrative review.\n",
            "Author [{'authorId': '46542370', 'name': 'A. King'}, {'authorId': '16743437', 'name': 'R. Hoppe'}]\n",
            "Venue Journal of Graduate Medical Education\n",
            "year 2013\n",
            "Abstract BACKGROUND\n",
            "Communicating with patients has long been identified as an important physician competency. More recently, there is a growing consensus regarding the components that define physician-patient communication. There continues to be emphasis on both the need to teach and to assess the communication skills of physicians.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This narrative review aims to summarize the work that has been conducted in physician-patient communication that supports the efficacy of good communications skills. This work may also help to define the physician-patient communication skills that need to be taught and assessed.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "A review of the literature shows it contains impressive evidence supporting positive associations between physician communication behaviors and positive patient outcomes, such as patient recall, patient understanding, and patient adherence to therapy. There is a consensus about what constitutes \"best practice\" for physician communication in medical encounters: (1) fostering the relationship, (2) gathering information, (3) providing information, (4) making decisions, (5) responding to emotions, and (6) enabling disease- and treatment-related behavior.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Evidence supports the importance of communication skills as a dimension of physician competence. Effort to enhance teaching of communication skills to medical trainees likely will require significant changes in instruction at undergraduate and graduate levels, as well as changes in assessing the developing communication skills of physicians. An added critical dimension is faculty understanding of the importance of communication skills, and their commitment to helping trainees develop those skills.\n",
            "------------------------------------\n",
            "Title RRED Indices: Reduced Reference Entropic Differencing for Image Quality Assessment\n",
            "Author [{'authorId': '2510315', 'name': 'R. Soundararajan'}, {'authorId': '1747569', 'name': 'A. Bovik'}]\n",
            "Venue IEEE Transactions on Image Processing\n",
            "year 2012\n",
            "Abstract We study the problem of automatic “reduced-reference” image quality assessment (QA) algorithms from the point of view of image information change. Such changes are measured between the reference- and natural-image approximations of the distorted image. Algorithms that measure differences between the entropies of wavelet coefficients of reference and distorted images, as perceived by humans, are designed. The algorithms differ in the data on which the entropy difference is calculated and on the amount of information from the reference that is required for quality computation, ranging from almost full information to almost no information from the reference. A special case of these is algorithms that require just a single number from the reference for QA. The algorithms are shown to correlate very well with subjective quality scores, as demonstrated on the Laboratory for Image and Video Engineering Image Quality Assessment Database and the Tampere Image Database. Performance degradation, as the amount of information is reduced, is also studied.\n",
            "------------------------------------\n",
            "Title Detecting Rumors from Microblogs with Recurrent Neural Networks\n",
            "Author [{'authorId': '2157403695', 'name': 'Jing Ma'}, {'authorId': '145816335', 'name': 'Wei Gao'}, {'authorId': '143930195', 'name': 'P. Mitra'}, {'authorId': '2399803', 'name': 'Sejeong Kwon'}, {'authorId': '144715575', 'name': 'B. Jansen'}, {'authorId': '1784988', 'name': 'Kam-Fai Wong'}, {'authorId': '1775511', 'name': 'M. Cha'}]\n",
            "Venue International Joint Conference on Artificial Intelligence\n",
            "year 2016\n",
            "Abstract Microblogging platforms are an ideal place for spreading rumors and automatically debunking rumors is a crucial problem. To detect rumors, existing approaches have relied on hand-crafted features for employing machine learning algorithms that require daunting manual effort. Upon facing a dubious claim, people dispute its truthfulness by posting various cues over time, which generates long-distance dependencies of evidence. This paper presents a novel method that learns continuous representations of microblog events for identifying rumors. The proposed model is based on recurrent neural networks (RNN) for learning the hidden representations that capture the variation of contextual information of relevant posts over time. Experimental results on datasets from two real-world microblog platforms demonstrate that (1) the RNN method outperforms state-of-the-art rumor detection models that use hand-crafted features; (2) performance of the RNN-based algorithm is further improved via sophisticated recurrent units and extra hidden layers; (3) RNN-based method detects rumors more quickly and accurately than existing techniques, including the leading online rumor debunking services.\n",
            "------------------------------------\n",
            "Title Natural Language Processing in Radiology: A Systematic Review.\n",
            "Author [{'authorId': '2848716', 'name': 'E. Pons'}, {'authorId': '144530097', 'name': 'Loes M M Braun'}, {'authorId': '143872849', 'name': 'M. Hunink'}, {'authorId': '1904671', 'name': 'J. Kors'}]\n",
            "Venue Radiology\n",
            "year 2016\n",
            "Abstract Radiological reporting has generated large quantities of digital content within the electronic health record, which is potentially a valuable source of information for improving clinical care and supporting research. Although radiology reports are stored for communication and documentation of diagnostic imaging, harnessing their potential requires efficient and automated information extraction: they exist mainly as free-text clinical narrative, from which it is a major challenge to obtain structured data. Natural language processing (NLP) provides techniques that aid the conversion of text into a structured representation, and thus enables computers to derive meaning from human (ie, natural language) input. Used on radiology reports, NLP techniques enable automatic identification and extraction of information. By exploring the various purposes for their use, this review examines how radiology benefits from NLP. A systematic literature search identified 67 relevant publications describing NLP methods that support practical applications in radiology. This review takes a close look at the individual studies in terms of tasks (ie, the extracted information), the NLP methodology and tools used, and their application purpose and performance results. Additionally, limitations, future challenges, and requirements for advancing NLP in radiology will be discussed.\n",
            "------------------------------------\n",
            "Title An Introduction to Information Retrieval\n",
            "Author [{'authorId': '144161686', 'name': 'S. Ceri'}, {'authorId': '1710630', 'name': 'A. Bozzon'}, {'authorId': '40350773', 'name': 'Marco Brambilla'}, {'authorId': '2539248', 'name': 'Emanuele Della Valle'}, {'authorId': '1704595', 'name': 'P. Fraternali'}, {'authorId': '1794305', 'name': 'S. Quarteroni'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Optimal network modularity for information diffusion.\n",
            "Author [{'authorId': '2477784', 'name': 'Azadeh Nematzadeh'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}, {'authorId': '1769960', 'name': 'A. Flammini'}, {'authorId': '36663090', 'name': 'Yong-Yeol Ahn'}]\n",
            "Venue Physical Review Letters\n",
            "year 2014\n",
            "Abstract We investigate the impact of community structure on information diffusion with the linear threshold model. Our results demonstrate that modular structure may have counterintuitive effects on information diffusion when social reinforcement is present. We show that strong communities can facilitate global diffusion by enhancing local, intracommunity spreading. Using both analytic approaches and numerical simulations, we demonstrate the existence of an optimal network modularity, where global diffusion requires the minimal number of early adopters.\n",
            "------------------------------------\n",
            "Title Online Survival Analysis Software to Assess the Prognostic Value of Biomarkers Using Transcriptomic Data in Non-Small-Cell Lung Cancer\n",
            "Author [{'authorId': '4063224', 'name': 'B. Győrffy'}, {'authorId': '144200591', 'name': 'P. Surowiak'}, {'authorId': '2230124', 'name': 'J. Budczies'}, {'authorId': '4597444', 'name': 'A. Lánczky'}]\n",
            "Venue PLoS ONE\n",
            "year 2013\n",
            "Abstract In the last decade, optimized treatment for non-small cell lung cancer had lead to improved prognosis, but the overall survival is still very short. To further understand the molecular basis of the disease we have to identify biomarkers related to survival. Here we present the development of an online tool suitable for the real-time meta-analysis of published lung cancer microarray datasets to identify biomarkers related to survival. We searched the caBIG, GEO and TCGA repositories to identify samples with published gene expression data and survival information. Univariate and multivariate Cox regression analysis, Kaplan-Meier survival plot with hazard ratio and logrank P value are calculated and plotted in R. The complete analysis tool can be accessed online at: www.kmplot.com/lung. All together 1,715 samples of ten independent datasets were integrated into the system. As a demonstration, we used the tool to validate 21 previously published survival associated biomarkers. Of these, survival was best predicted by CDK1 (p<1E-16), CD24 (p<1E-16) and CADM1 (p = 7E-12) in adenocarcinomas and by CCNE1 (p = 2.3E-09) and VEGF (p = 3.3E-10) in all NSCLC patients. Additional genes significantly correlated to survival include RAD51, CDKN2A, OPN, EZH2, ANXA3, ADAM28 and ERCC1. In summary, we established an integrated database and an online tool capable of uni- and multivariate analysis for in silico validation of new biomarker candidates in non-small cell lung cancer.\n",
            "------------------------------------\n",
            "Title Risk Information Seeking and Processing Model: A Meta‐Analysis\n",
            "Author [{'authorId': '12107336', 'name': 'Z. J. Yang'}, {'authorId': '5284263', 'name': 'Ariel M. Aloe'}, {'authorId': '2090676', 'name': 'T. Feeley'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This study relies on state-of-the-art meta-analytical techniques to assess overall effects of the Risk Information Seeking and Processing (RISP) model. The results support the utility of the RISP model in predicting risk information seeking and systematic processing. However, the model demonstrated limited explanatory power for heuristic processing. A reduced model composed of only 2 variables—current knowledge and informational subjective norms—accounted for a substantial proportion of variance in the outcome variables. This more parsimonious explanation of information seeking and systematic processing might extend the utility of the RISP model to other communication settings not related to risk. Theoretical boundaries of the RISP model and implications for future research are discussed.\n",
            "------------------------------------\n",
            "Title Supplier Encroachment under Asymmetric Information\n",
            "Author [{'authorId': '152985898', 'name': 'Z. Li'}, {'authorId': '48487247', 'name': 'S. Gilbert'}, {'authorId': '35261036', 'name': 'Guoming Lai'}]\n",
            "Venue Management Sciences\n",
            "year 2012\n",
            "Abstract Prior literature has shown that, for a symmetric information setting, supplier encroachment into a reseller's market can mitigate double marginalization and benefit both the supplier and the reseller. This paper extends the investigation of supplier encroachment to the environment where the reseller might be better informed than the supplier. We find that the launch of the supplier's direct channel can result in costly signaling behavior on the part of the reseller, in which he reduces his order quantity when the market size is small. Such a downward order distortion can amplify double marginalization. As a result, in addition to the “win--win” and “win--lose” outcomes for the supplier and the reseller, supplier encroachment can also lead to “lose--lose” and “lose--win” outcomes, particularly when the reseller has a significant efficiency advantage in the selling process and the prior probability of a large market is low. We further explore the implications of those findings for information management in supply chains. Complementing the conventional understanding, we show that with the ability to encroach, the supplier may prefer to sell to either a better informed or an uninformed reseller in different scenarios. On the other hand, as a result of a supplier developing encroachment capability, a reseller either may choose not to develop an advanced informational capability or may become more willing to find a means of credibly sharing his information. \n",
            " \n",
            "This paper was accepted by Yossi Aviv, operations management.\n",
            "------------------------------------\n",
            "Title Explanatory Factors of Integrated Sustainability and Financial Reporting\n",
            "Author [{'authorId': '1405232161', 'name': 'José-Valeriano Frías-Aceituno'}, {'authorId': '1402931366', 'name': 'Lázaro Rodríguez‐Ariza'}, {'authorId': '1403272114', 'name': 'I. García‐Sánchez'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract The complexity of the business world has led to growing demands being made of companies regarding the information provided on their financial performance, corporate governance and contribution to developing sustainability. In response, some leading companies have begun to publish integrated reporting, in the form of a document providing a coherent summary of this information, thus facilitating stakeholder engagement. \n",
            " \n",
            "This paper examines the validity of the hypotheses of the theories of agency and of signalling, and analyses the political costs and those borne by owners in voluntarily developing this new type of business document. More specifically, in order to determine their prevalence among the suggested reasons for these paradigms, we analyse the effect of industry concentration, together with other factors, in the development of integrated reporting. \n",
            " \n",
            "The analysis of a non-balanced sample of 1590 international companies for the years 2008–2010, in which a logistic regression methodology is applied to panel data, reveals the negative impact of industry concentration on the development of a more pluralist report, simultaneously taking into account stakeholders, sustainability and the long-term viewpoint, as well as questions of responsible investment, business ethics and transparency. Copyright © 2012 John Wiley & Sons, Ltd and ERP Environment\n",
            "------------------------------------\n",
            "Title Magnon transistor for all-magnon data processing\n",
            "Author [{'authorId': '144588566', 'name': 'A. Chumak'}, {'authorId': '49946978', 'name': 'A. Serga'}, {'authorId': '144271318', 'name': 'B. Hillebrands'}]\n",
            "Venue Nature Communications\n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Indoor Semantic Segmentation using depth information\n",
            "Author [{'authorId': '2341378', 'name': 'C. Couprie'}, {'authorId': '2256269', 'name': 'C. Farabet'}, {'authorId': '1688714', 'name': 'Laurent Najman'}, {'authorId': '1688882', 'name': 'Yann LeCun'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2013\n",
            "Abstract This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently, most works still rely on hand-crafted features. In contrast, we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-time using appropriate hardware such as an FPGA.\n",
            "------------------------------------\n",
            "Title How Do Firms Form Their Expectations? New Survey Evidence\n",
            "Author [{'authorId': '65732701', 'name': 'Olivier Coibion'}, {'authorId': '15529936', 'name': 'Y. Gorodnichenko'}, {'authorId': '35752233', 'name': 'Saten Kumar'}]\n",
            "Venue The American Economic Review\n",
            "year 2015\n",
            "Abstract We survey New Zealand firms and document novel facts about their macroeconomic beliefs. There is widespread dispersion in beliefs about past and future macroeconomic conditions, especially inflation. This dispersion in beliefs is consistent with firms’ incentives to collect and process information. Using experimental methods, we find that firms update their beliefs in a Bayesian manner when presented with new information about the economy and that changes in their beliefs affect their decisions. Inflation is not generally perceived as being important to business decisions so firms devote few resources to collecting and processing information about inflation. (JEL D22, D83, D84, E31, E52)\n",
            "------------------------------------\n",
            "Title Learning to Explain: An Information-Theoretic Perspective on Model Interpretation\n",
            "Author [{'authorId': '144626708', 'name': 'Jianbo Chen'}, {'authorId': '1779453', 'name': 'Le Song'}, {'authorId': '1721860', 'name': 'M. Wainwright'}, {'authorId': '1694621', 'name': 'Michael I. Jordan'}]\n",
            "Venue International Conference on Machine Learning\n",
            "year 2018\n",
            "Abstract We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.\n",
            "------------------------------------\n",
            "Title Deformable Medical Image Registration: A Survey\n",
            "Author [{'authorId': '2625893', 'name': 'A. Sotiras'}, {'authorId': '1740714', 'name': 'C. Davatzikos'}, {'authorId': '1680727', 'name': 'N. Paragios'}]\n",
            "Venue IEEE Transactions on Medical Imaging\n",
            "year 2013\n",
            "Abstract Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner.\n",
            "------------------------------------\n",
            "Title Critical Realism and Affordances: Theorizing IT-Associated Organizational Change Processes\n",
            "Author [{'authorId': '2706472', 'name': 'O. Volkoff'}, {'authorId': '144519071', 'name': 'D. Strong'}]\n",
            "Venue MIS Q.\n",
            "year 2013\n",
            "Abstract Convincing arguments for using critical realism as an underpinning for theories of IT-associated organizational change have appeared in the Information Systems literature. A central task in developing such theories is to uncover the generative mechanisms by which IT is implicated in organizational change processes, but to do so, we must explain how critical realism's concept of generative mechanisms applies in an IS context. Similarly, convincing arguments have been made for using Gibson's (1986) affordance theory from ecological psychology for developing theories of IT-associated organizational change, but this effort has been hampered due to insufficient attention to the ontological status of affordances. In this paper, we argue that affordances are the generative mechanisms we need to specify and explain how affordances are a specific type of generative mechanism. We use the core principles of critical realism to argue how affordances arise in the real domain from the relation between the complex assemblages of organizations and of IT artifacts, how affordances are actualized over time by organizational actors, and how these actualizations lead to the various effects we observe in the empirical domain. After presenting these arguments, we reanalyze two published cases in the literature, those of ACRO and Autoworks, to illustrate how affordance-based theories informed by critical realism enhance our ability to explain IT-associated organizational change. These examples show how researchers using this approach should proceed, and how managers can use these ideas to diagnose and address IT implementation problems.\n",
            "------------------------------------\n",
            "Title miRBase: from microRNA sequences to function\n",
            "Author [{'authorId': '3066945', 'name': 'Ana Kozomara'}, {'authorId': '51898609', 'name': 'Maria Birgaoanu'}, {'authorId': '1398461217', 'name': 'S. Griffiths-Jones'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2018\n",
            "Abstract Abstract miRBase catalogs, names and distributes microRNA gene sequences. The latest release of miRBase (v22) contains microRNA sequences from 271 organisms: 38 589 hairpin precursors and 48 860 mature microRNAs. We describe improvements to the database and website to provide more information about the quality of microRNA gene annotations, and the cellular functions of their products. We have collected 1493 small RNA deep sequencing datasets and mapped a total of 5.5 billion reads to microRNA sequences. The read mapping patterns provide strong support for the validity of between 20% and 65% of microRNA annotations in different well-studied animal genomes, and evidence for the removal of >200 sequences from the database. To improve the availability of microRNA functional information, we are disseminating Gene Ontology terms annotated against miRBase sequences. We have also used a text-mining approach to search for microRNA gene names in the full-text of open access articles. Over 500 000 sentences from 18 542 papers contain microRNA names. We score these sentences for functional information and link them with 12 519 microRNA entries. The sentences themselves, and word clouds built from them, provide effective summaries of the functional information about specific microRNAs. miRBase is publicly and freely available at http://mirbase.org/.\n",
            "------------------------------------\n",
            "Title Parents' Source of Vaccine Information and Impact on Vaccine Attitudes, Beliefs, and Nonmedical Exemptions\n",
            "Author [{'authorId': '4851294', 'name': 'Abbey M. Jones'}, {'authorId': '3654795', 'name': 'S. Omer'}, {'authorId': '3633019', 'name': 'R. Bednarczyk'}, {'authorId': '5805561', 'name': 'N. Halsey'}, {'authorId': '144578785', 'name': 'L. Moulton'}, {'authorId': '8122591', 'name': 'D. Salmon'}]\n",
            "Venue Advances in Preventive Medicine\n",
            "year 2012\n",
            "Abstract In recent years, use of the Internet to obtain vaccine information has increased. Historical data are necessary to evaluate current vaccine information seeking trends in context. Between 2002 and 2003, surveys were mailed to 1,630 parents of fully vaccinated children and 815 parents of children with at least one vaccine exemption; 56.1% responded. Respondents were asked about their vaccine information sources, perceptions of these sources accuracy, and their beliefs about vaccination. Parents who did not view their child's healthcare provider as a reliable vaccine information source were more likely to obtain vaccine information using the Internet. Parents who were younger, more highly educated, and opposed to school immunization requirements were more likely than their counterparts to use the Internet for vaccine information. Compared to parents who did not use the Internet for vaccine information, those who sought vaccine information on the Internet were more likely to have lower perceptions of vaccine safety (adjusted odds ratio (aOR), 1.66; 95% CI, 1.18–2.35), vaccine effectiveness (aOR, 1.83; 95% CI, 1.32–2.53), and disease susceptibility (aOR, 2.08; 95% CI, 1.49–2.90) and were more likely to have a child with a nonmedical exemption (aOR 3.53, 95% CI, 2.61–4.76). These findings provide context to interpret recent vaccine information seeking research.\n",
            "------------------------------------\n",
            "Title Information Exchange in Policy Networks\n",
            "Author [{'authorId': '9997588', 'name': 'P. Leifeld'}, {'authorId': '145542034', 'name': 'V. Schneider'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Information exchange in policy networks is usually attributed to preference similarity, influence reputation, social trust, and institutional actor roles. We suggest that political opportunity structures and transaction costs play another crucial role and estimate a rich statistical network model on tie formation in the German toxic chemicals policy domain. The results indicate that the effect of preference similarity is absorbed by institutional, relational, and social opportunity structures. Political actors choose contacts who minimize transaction costs while maximizing outreach and information. We also find that different types of information exchange operate in complementary, but not necessarily congruent, ways.\n",
            "------------------------------------\n",
            "Title Generalization in Adaptive Data Analysis and Holdout Reuse\n",
            "Author [{'authorId': '1781565', 'name': 'C. Dwork'}, {'authorId': '145818608', 'name': 'V. Feldman'}, {'authorId': '1775622', 'name': 'Moritz Hardt'}, {'authorId': '1695317', 'name': 'T. Pitassi'}, {'authorId': '1746057', 'name': 'O. Reingold'}, {'authorId': '1682008', 'name': 'Aaron Roth'}]\n",
            "Venue NIPS\n",
            "year 2015\n",
            "Abstract Overfitting is the bane of data analysts, even when data are plentiful. Formal approaches to understanding this problem focus on statistical inference and generalization of individual analysis procedures. Yet the practice of data analysis is an inherently interactive and adaptive process: new analyses and hypotheses are proposed after seeing the results of previous ones, parameters are tuned on the basis of obtained results, and datasets are shared and reused. An investigation of this gap has recently been initiated by the authors in [7], where we focused on the problem of estimating expectations of adaptively chosen functions. \n",
            " \n",
            "In this paper, we give a simple and practical method for reusing a holdout (or testing) set to validate the accuracy of hypotheses produced by a learning algorithm operating on a training set. Reusing a holdout set adaptively multiple times can easily lead to overfitting to the holdout set itself. We give an algorithm that enables the validation of a large number of adaptively chosen hypotheses, while provably avoiding overfitting. We illustrate the advantages of our algorithm over the standard use of the holdout set via a simple synthetic experiment. \n",
            " \n",
            "We also formalize and address the general problem of data reuse in adaptive data analysis. We show how the differential-privacy based approach given in [7] is applicable much more broadly to adaptive data analysis. We then show that a simple approach based on description length can also be used to give guarantees of statistical validity in adaptive settings. Finally, we demonstrate that these incomparable approaches can be unified via the notion of approximate max-information that we introduce. This, in particular, allows the preservation of statistical validity guarantees even when an analyst adaptively composes algorithms which have guarantees based on either of the two approaches.\n",
            "------------------------------------\n",
            "Title Active inference and epistemic value\n",
            "Author [{'authorId': '1737497', 'name': 'Karl J. Friston'}, {'authorId': '3388931', 'name': 'Francesco Rigoli'}, {'authorId': '1685305', 'name': 'D. Ognibene'}, {'authorId': '1859583', 'name': 'C. Mathys'}, {'authorId': '145192124', 'name': 'Thomas H. B. FitzGerald'}, {'authorId': '1746694', 'name': 'G. Pezzulo'}]\n",
            "Venue Cognitive neuroscience\n",
            "year 2015\n",
            "Abstract We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.\n",
            "------------------------------------\n",
            "Title Industry Concentration and Corporate Disclosure Policy\n",
            "Author [{'authorId': '144055851', 'name': 'Ashiq Ali'}, {'authorId': '119236157', 'name': 'Sandy J Klasa'}, {'authorId': '143858647', 'name': 'P. Yeung'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract This study examines the association between U.S. Census industry concentration measures and the informativeness of corporate disclosure policy. We find that in more concentrated industries firms׳ management earnings forecasts are less frequent and have shorter horizons, their disclosure ratings by analysts are lower, and they have more opaque information environments, as measured by the properties of analysts׳ earnings forecasts. Also, when these firms raise funds they prefer private placements, which have minimal SEC-mandated disclosure requirements, over seasoned equity offerings. Overall, our findings suggest that firms in more concentrated industries disclose less and avoid certain financing decisions that have non-trivial disclosure implications, presumably due to proprietary costs of disclosure.\n",
            "------------------------------------\n",
            "Title Mining high utility itemsets without candidate generation\n",
            "Author [{'authorId': '2898327', 'name': 'Mengchi Liu'}, {'authorId': '2745076', 'name': 'Jun-Feng Qu'}]\n",
            "Venue International Conference on Information and Knowledge Management\n",
            "year 2012\n",
            "Abstract High utility itemsets refer to the sets of items with high utility like profit in a database, and efficient mining of high utility itemsets plays a crucial role in many real-life applications and is an important research issue in data mining area. To identify high utility itemsets, most existing algorithms first generate candidate itemsets by overestimating their utilities, and subsequently compute the exact utilities of these candidates. These algorithms incur the problem that a very large number of candidates are generated, but most of the candidates are found out to be not high utility after their exact utilities are computed. In this paper, we propose an algorithm, called HUI-Miner (High Utility Itemset Miner), for high utility itemset mining. HUI-Miner uses a novel structure, called utility-list, to store both the utility information about an itemset and the heuristic information for pruning the search space of HUI-Miner. By avoiding the costly generation and utility computation of numerous candidate itemsets, HUI-Miner can efficiently mine high utility itemsets from the utility-lists constructed from a mined database. We compared HUI-Miner with the state-of-the-art algorithms on various databases, and experimental results show that HUI-Miner outperforms these algorithms in terms of both running time and memory consumption.\n",
            "------------------------------------\n",
            "Title BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\n",
            "Author [{'authorId': '145408381', 'name': 'Andreas Kirsch'}, {'authorId': '3038326', 'name': 'Joost R. van Amersfoort'}, {'authorId': '2681954', 'name': 'Y. Gal'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2019\n",
            "Abstract We develop BatchBALD, a tractable approximation to the mutual information between a batch of points and model parameters, which we use as an acquisition function to select multiple informative points jointly for the task of deep Bayesian active learning. BatchBALD is a greedy linear-time $1 - \\frac{1}{e}$-approximate algorithm amenable to dynamic programming and efficient caching. We compare BatchBALD to the commonly used approach for batch data acquisition and find that the current approach acquires similar and redundant points, sometimes performing worse than randomly acquiring data. We finish by showing that, using BatchBALD to consider dependencies within an acquisition batch, we achieve new state of the art performance on standard benchmarks, providing substantial data efficiency improvements in batch acquisition.\n",
            "------------------------------------\n",
            "Title Humans use directed and random exploration to solve the explore-exploit dilemma.\n",
            "Author [{'authorId': '153160317', 'name': 'Robert C. Wilson'}, {'authorId': '4454861', 'name': 'A. Geana'}, {'authorId': '2111365171', 'name': 'J. M. White'}, {'authorId': '2534715', 'name': 'Elliot A. Ludvig'}, {'authorId': '153564781', 'name': 'J. Cohen'}]\n",
            "Venue Journal of experimental psychology. General\n",
            "year 2014\n",
            "Abstract All adaptive organisms face the fundamental tradeoff between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration). Theory suggests at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. In this work we investigated the extent to which humans use these two strategies. In our \"Horizon task,\" participants made explore-exploit decisions in two contexts that differed in the number of choices that they would make in the future (the time horizon). Participants were allowed to make either a single choice in each game (horizon 1), or 6 sequential choices (horizon 6), giving them more opportunity to explore. By modeling the behavior in these two conditions, we were able to measure exploration-related changes in decision making and quantify the contributions of the two strategies to behavior. We found that participants were more information seeking and had higher decision noise with the longer horizon, suggesting that humans use both strategies to solve the exploration-exploitation dilemma. We thus conclude that both information seeking and choice variability can be controlled and put to use in the service of exploration.\n",
            "------------------------------------\n",
            "Title Inefficient Hiring in Entry-Level Labor Markets\n",
            "Author [{'authorId': '66050438', 'name': 'Amanda Pallais'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract Hiring inexperienced workers generates information about their abilities. If this information is public, workers obtain its benefits. If workers cannot compensate firms for hiring them, firms will hire too few inexperienced workers. I determine the effects of hiring workers and revealing more information about their abilities through a field experiment in an online marketplace. I hired 952 randomly-selected workers, giving them either detailed or coarse public evaluations. Both hiring workers and providing more detailed evaluations substantially improved workers' subsequent employment outcomes. Under plausible assumptions, the experiment's market-level benefits exceeded its cost, suggesting that some experimental workers had been inefficiently unemployed.\n",
            "------------------------------------\n",
            "Title A foundation for the study of behavior change support systems\n",
            "Author [{'authorId': '1400820979', 'name': 'H. Oinas-Kukkonen'}]\n",
            "Venue Personal and Ubiquitous Computing\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Design Guidelines for Spatial Modulation\n",
            "Author [{'authorId': '103718864', 'name': 'Ping Yang'}, {'authorId': '1721870', 'name': 'M. Renzo'}, {'authorId': '1749827', 'name': 'Yue Xiao'}, {'authorId': '1692924', 'name': 'Shaoqian Li'}, {'authorId': '1730180', 'name': 'L. Hanzo'}]\n",
            "Venue IEEE Communications Surveys and Tutorials\n",
            "year 2015\n",
            "Abstract A new class of low-complexity, yet energy-efficient Multiple-Input Multiple-Output (MIMO) transmission techniques, namely, the family of Spatial Modulation (SM) aided MIMOs (SM-MIMO), has emerged. These systems are capable of exploiting the spatial dimensions (i.e., the antenna indices) as an additional dimension invoked for transmitting information, apart from the traditional Amplitude and Phase Modulation (APM). SM is capable of efficiently operating in diverse MIMO configurations in the context of future communication systems. It constitutes a promising transmission candidate for large-scale MIMO design and for the indoor optical wireless communication while relying on a single-Radio Frequency (RF) chain. Moreover, SM may be also viewed as an entirely new hybrid modulation scheme, which is still in its infancy. This paper aims for providing a general survey of the SM design framework as well as of its intrinsic limits. In particular, we focus our attention on the associated transceiver design, on spatial constellation optimization, on link adaptation techniques, on distributed/cooperative protocol design issues, and on their meritorious variants.\n",
            "------------------------------------\n",
            "Title Health-Related Internet Use by Children and Adolescents: Systematic Review\n",
            "Author [{'authorId': '49054789', 'name': 'Eunhee Park'}, {'authorId': '40865623', 'name': 'M. Kwon'}]\n",
            "Venue Journal of Medical Internet Research\n",
            "year 2018\n",
            "Abstract Background The internet is widely used by children and adolescents, who generally have a high level of competency with technology. Thus, the internet has become a great resource for supporting youth self-care and health-related services. However, few studies have explored adolescents’ internet use for health-related matters. Objective The objective of this systematic literature review was to examine the phenomenon of children and adolescents’ health-related internet use and to identify gaps in the research. Methods A total of 19 studies were selected from a search of major electronic databases: PubMed, Cumulative Index of Nursing and Allied Health Literature, and PsycINFO using the following search terms: “health-related internet use,” “eHealth,” “Internet use for health-related purpose,” “Web-based resource,” “health information seeking,” and “online resource,” combined with “child,” “adolescent,” “student,” “youth,” and “teen.” The children’s and adolescents’ ages were limited to 24 years and younger. The search was conducted from September 2015 to October 2017. The studies identified to contain youth (<24 years) health-related internet use were all published in peer-reviewed journals in the past 10 years; these studies examined general internet use seeking health care services, resources, information, or using the internet for health promotion and self-care. Studies were excluded if they explored the role of the internet as a modality for surveys, recruitment, or searching for relevant literature without specifically aiming to study participants’ health-related internet use; focused solely on quality assurance for specific websites; or were designed to test a specific internet-based intervention. Results Interesting patterns in adolescents’ health-related internet use, such as seeking preventative health care and specific information about medical issues, were identified. Quantitative studies reported rates of the internet use and access among youth, and the purpose and patterns of health-related internet use among youth were identified. A major objective of health-related internet use is to gain information, but there are inconsistencies in adolescents’ perceptions of health-related internet use. Conclusions This study’s findings provide important information on how youth seek information and related support systems for their health care on the internet. The conceptual and methodological limitations of the identified studies, such as the lack of a theoretical background and unrepresentative samples, are discussed, and gaps within the studies are identified for future research. This review also suggests important features for potential Web-based health interventions for children and adolescents.\n",
            "------------------------------------\n",
            "Title Best Care at Lower Cost: The Path to Continuously Learning Health Care in America\n",
            "Author [{'authorId': '121758607', 'name': 'M. Smith'}, {'authorId': '49154039', 'name': 'R. Saunders'}, {'authorId': '67249816', 'name': 'Leigh Stuckhardt'}, {'authorId': '145146325', 'name': 'J. McGinnis'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract America's health care system has become too complex and costly to continue business as usual. Best Care at Lower Cost explains that inefficiencies, an overwhelming amount of data, and other economic and quality barriers hinder progress in improving health and threaten the nation's economic stability and global competitiveness. According to this report, the knowledge and tools exist to put the health system on the right course to achieve continuous improvement and better quality care at a lower cost. The costs of the system's current inefficiency underscore the urgent need for a systemwide transformation. About 30 percent of health spending in 2009--roughly $750 billion--was wasted on unnecessary services, excessive administrative costs, fraud, and other problems. Moreover, inefficiencies cause needless suffering. By one estimate, roughly 75,000 deaths might have been averted in 2005 if every state had delivered care at the quality level of the best performing state. This report states that the way health care providers currently train, practice, and learn new information cannot keep pace with the flood of research discoveries and technological advances. About 75 million Americans have more than one chronic condition, requiring coordination among multiple specialists and therapies, which can increase the potential for miscommunication, misdiagnosis, potentially conflicting interventions, and dangerous drug interactions. Best Care at Lower Cost emphasizes that a better use of data is a critical element of a continuously improving health system, such as mobile technologies and electronic health records that offer significant potential to capture and share health data better. In order for this to occur, the National Coordinator for Health Information Technology, IT developers, and standard-setting organizations should ensure that these systems are robust and interoperable. Clinicians and care organizations should fully adopt these technologies, and patients should be encouraged to use tools, such as personal health information portals, to actively engage in their care. This book is a call to action that will guide health care providers; administrators; caregivers; policy makers; health professionals; federal, state, and local government agencies; private and public health organizations; and educational institutions.... Download ebook, read file pdf The Path to Continuously Learning Health Care in America\n",
            "------------------------------------\n",
            "Title PhosphoSitePlus, 2014: mutations, PTMs and recalibrations\n",
            "Author [{'authorId': '46627576', 'name': 'P. Hornbeck'}, {'authorId': '2119454508', 'name': 'Bin Zhang'}, {'authorId': '1993068550', 'name': 'Beth Murray'}, {'authorId': '2269300', 'name': 'J. Kornhauser'}, {'authorId': '39730422', 'name': 'V. Latham'}, {'authorId': '2050463785', 'name': 'E. Skrzypek'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2014\n",
            "Abstract PhosphoSitePlus® (PSP, http://www.phosphosite.org/), a knowledgebase dedicated to mammalian post-translational modifications (PTMs), contains over 330 000 non-redundant PTMs, including phospho, acetyl, ubiquityl and methyl groups. Over 95% of the sites are from mass spectrometry (MS) experiments. In order to improve data reliability, early MS data have been reanalyzed, applying a common standard of analysis across over 1 000 000 spectra. Site assignments with P > 0.05 were filtered out. Two new downloads are available from PSP. The ‘Regulatory sites’ dataset includes curated information about modification sites that regulate downstream cellular processes, molecular functions and protein-protein interactions. The ‘PTMVar’ dataset, an intersect of missense mutations and PTMs from PSP, identifies over 25 000 PTMVars (PTMs Impacted by Variants) that can rewire signaling pathways. The PTMVar data include missense mutations from UniPROTKB, TCGA and other sources that cause over 2000 diseases or syndromes (MIM) and polymorphisms, or are associated with hundreds of cancers. PTMVars include 18 548 phosphorlyation sites, 3412 ubiquitylation sites, 2316 acetylation sites, 685 methylation sites and 245 succinylation sites.\n",
            "------------------------------------\n",
            "Title Practical extraction of disaster-relevant information from social media\n",
            "Author [{'authorId': '151491159', 'name': 'Muhammad Imran'}, {'authorId': '1863248', 'name': 'Shady Elbassuoni'}, {'authorId': '153191671', 'name': 'Carlos Castillo'}, {'authorId': '145472333', 'name': 'Fernando Diaz'}, {'authorId': '49317293', 'name': 'P. Meier'}]\n",
            "Venue The Web Conference\n",
            "year 2013\n",
            "Abstract During times of disasters online users generate a significant amount of data, some of which are extremely valuable for relief efforts. In this paper, we study the nature of social-media content generated during two different natural disasters. We also train a model based on conditional random fields to extract valuable information from such content. We evaluate our techniques over our two datasets through a set of carefully designed experiments. We also test our methods over a non-disaster dataset to show that our extraction model is useful for extracting information from socially-generated content in general.\n",
            "------------------------------------\n",
            "Title Suspense and Surprise\n",
            "Author [{'authorId': '2281491', 'name': 'Jeffrey C. Ely'}, {'authorId': '144047191', 'name': 'A. Frankel'}, {'authorId': '2968902', 'name': 'Emir Kamenica'}]\n",
            "Venue Journal of Political Economy\n",
            "year 2015\n",
            "Abstract We model demand for noninstrumental information, drawing on the idea that people derive entertainment utility from suspense and surprise. A period has more suspense if the variance of the next period’s beliefs is greater. A period has more surprise if the current belief is further from the last period’s belief. Under these definitions, we analyze the optimal way to reveal information over time so as to maximize expected suspense or surprise experienced by a Bayesian audience. We apply our results to the design of mystery novels, political primaries, casinos, game shows, auctions, and sports.\n",
            "------------------------------------\n",
            "Title The entropy of bulk quantum fields and the entanglement wedge of an evaporating black hole\n",
            "Author [{'authorId': '102997334', 'name': 'Ahmed Almheiri'}, {'authorId': '34191870', 'name': 'Netta Engelhardt'}, {'authorId': '10407089', 'name': 'D. Marolf'}, {'authorId': '49072700', 'name': 'Henry Maxfield'}]\n",
            "Venue Journal of High Energy Physics\n",
            "year 2019\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Emotions, Partisanship, and Misperceptions: How Anger and Anxiety Moderate the Effect of Partisan Bias on Susceptibility to Political Misinformation\n",
            "Author [{'authorId': '37433997', 'name': 'Brian E. Weeks'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Citizens are frequently misinformed about political issues and candidates but the circumstances under which inaccurate beliefs emerge are not fully understood. This experimental study demonstrates that the independent experience of two emotions, anger and anxiety, in part determines whether citizens consider misinformation in a partisan or open-minded fashion. Anger encourages partisan, motivated evaluation of uncorrected misinformation that results in beliefs consistent with the supported political party, while anxiety at times promotes initial beliefs based less on partisanship and more on the information environment. However, exposure to corrections improves belief accuracy, regardless of emotion or partisanship. The results indicate that the unique experience of anger and anxiety can affect the accuracy of political beliefs by strengthening or attenuating the influence of partisanship\n",
            "------------------------------------\n",
            "Title The Determinants and Consequences of Information Acquisition via EDGAR\n",
            "Author [{'authorId': '40249559', 'name': 'Michael S. Drake'}, {'authorId': '26325758', 'name': 'D. Roulstone'}, {'authorId': '26366285', 'name': 'Jacob R. Thornock'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Using a novel dataset that tracks all web traffic on the SEC’s EDGAR servers from 2008-2011, we examine the determinants and capital market consequences of investor information acquisition of SEC filings. The average user employs the database very few times per quarter and most users target specific filing types such as periodic accounting reports; a small subset of users employ EDGAR almost daily and access many filings. EDGAR activity is positively related with corporate events (particularly restatements, earnings announcements, and acquisition announcements), poor stock performance, and the strength of a firm’s information environment. EDGAR activity is related to, but distinct from, other proxies of investor interest such as trading volume, business press articles, and Google searches. Finally, information acquisition via EDGAR, both to obtain earnings news and to provide context for it, has a positive influence on market efficiency with respect to earnings news. Overall, our results provide a unique, user-based perspective on investor access of mandatory disclosures and its impact on price formation.\n",
            "------------------------------------\n",
            "Title Model Cards for Model Reporting\n",
            "Author [{'authorId': '49501003', 'name': 'Margaret Mitchell'}, {'authorId': '81120201', 'name': 'Simone Wu'}, {'authorId': '2064225225', 'name': 'Andrew Zaldivar'}, {'authorId': '80940648', 'name': 'Parker Barnes'}, {'authorId': '145177877', 'name': 'Lucy Vasserman'}, {'authorId': '2083807', 'name': 'B. Hutchinson'}, {'authorId': '79542084', 'name': 'Elena Spitzer'}, {'authorId': '81316798', 'name': 'Inioluwa Deborah Raji'}, {'authorId': '2076288', 'name': 'Timnit Gebru'}]\n",
            "Venue FAT\n",
            "year 2018\n",
            "Abstract Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.\n",
            "------------------------------------\n",
            "Title Addressing cold-start in app recommendation: latent user models constructed from twitter followers\n",
            "Author [{'authorId': '1854640', 'name': 'Jovian Lin'}, {'authorId': '3060386', 'name': 'Kazunari Sugiyama'}, {'authorId': '37596605', 'name': 'Min-Yen Kan'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]\n",
            "Venue Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year 2013\n",
            "Abstract As a tremendous number of mobile applications (apps) are readily available, users have difficulty in identifying apps that are relevant to their interests. Recommender systems that depend on previous user ratings (i.e., collaborative filtering, or CF) can address this problem for apps that have sufficient ratings from past users. But for apps that are newly released, CF does not have any user ratings to base recommendations on, which leads to the cold-start problem. In this paper, we describe a method that accounts for nascent information culled from Twitter to provide relevant recommendation in such cold-start situations. We use Twitter handles to access an app's Twitter account and extract the IDs of their Twitter-followers. We create pseudo-documents that contain the IDs of Twitter users interested in an app and then apply latent Dirichlet allocation to generate latent groups. At test time, a target user seeking recommendations is mapped to these latent groups. By using the transitive relationship of latent groups to apps, we estimate the probability of the user liking the app. We show that by incorporating information from Twitter, our approach overcomes the difficulty of cold-start app recommendation and significantly outperforms other state-of-the-art recommendation techniques by up to 33%.\n",
            "------------------------------------\n",
            "Title Health literacy -- a heterogeneous phenomenon: a literature review.\n",
            "Author [{'authorId': '145405355', 'name': 'L. Mårtensson'}, {'authorId': '5468621', 'name': 'G. Hensing'}]\n",
            "Venue Scandinavian Journal of Caring Sciences\n",
            "year 2012\n",
            "Abstract BACKGROUND AND AIM\n",
            "A growing responsibility on the part of individuals to make decisions in health issues implies the need of access to health information and personal skills to comprehend the information. Health literacy comprises skills in obtaining, understanding and acting on information about health issues in ways that promote and maintain health. A lack of health literacy may have effects at both the individual and societal levels. There are thus reasons for health care professionals to gain a comprehensive understanding of health literacy. The aim of this review was to explore how health literacy is described in the scientific literature and to give a synthesis of its different meanings.\n",
            "\n",
            "\n",
            "METHODS\n",
            "The review was based on approximately 200 scientific articles published 2000-2008. The analysis process was inspired by the methods of narrative literature review.\n",
            "\n",
            "\n",
            "FINDINGS AND CONCLUSIONS\n",
            "Two different approaches to health literacy became visible, one in which health literacy is expressed as a polarized phenomenon, focusing on the extremes of low and high health literacy. The definitions of health literacy in this approach are characterized by a functional understanding, pointing out certain basic skills needed to understand health information. The other approach represents a complex understanding of health literacy, acknowledging a broadness of skills in interaction with the social and cultural contexts, which means that an individual's health literacy may fluctuate from one day to another according to the context. The complex approach stresses the interactive and critical skills needed to use information or knowledge as a basis for appropriate health decisions. We conclude that health literacy is a heterogeneous phenomenon that has significance for both the individual and society. Future research will aim at the development of assessments that capture the broadness of skills and agents characteristic for health literacy as a complex phenomenon.\n",
            "------------------------------------\n",
            "Title Neural Evidence for a Distinction between Short-term Memory and the Focus of Attention\n",
            "Author [{'authorId': '1401833932', 'name': 'J. Lewis-Peacock'}, {'authorId': '16165769', 'name': 'A. Drysdale'}, {'authorId': '2128289', 'name': 'K. Oberauer'}, {'authorId': '2884176', 'name': 'B. Postle'}]\n",
            "Venue Journal of Cognitive Neuroscience\n",
            "year 2012\n",
            "Abstract It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.\n",
            "------------------------------------\n",
            "Title Guide to Cyber Threat Information Sharing\n",
            "Author [{'authorId': '50759947', 'name': 'Christopher Johnson'}, {'authorId': '70035063', 'name': 'M. Badger'}, {'authorId': '2916452', 'name': 'David Waltermire'}, {'authorId': '2052437594', 'name': 'Julie Snyder'}, {'authorId': '98182657', 'name': 'C. Skorupka'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract Cyber threat information is any information that can help an organization identify, assess, monitor, and respond to cyber threats. Cyber threat information includes indicators of compromise; tactics, techniques, and procedures used by threat actors; suggested actions to detect, contain, or prevent attacks; and the findings from the analyses of incidents. Organizations that share cyber threat information can improve their own security postures as well as those of other organizations. This publication provides guidelines for establishing and participating in cyber threat information sharing relationships. This guidance helps organizations establish information sharing goals, identify cyber threat information sources, scope information sharing activities, develop rules that control the publication and distribution of threat information, engage with existing sharing communities, and make effective use of threat information in support of the organization’s overall cybersecurity practices.\n",
            "------------------------------------\n",
            "Title Wireless Information and Power Transfer With Full Duplex Relaying\n",
            "Author [{'authorId': '1680643', 'name': 'C. Zhong'}, {'authorId': '1748781', 'name': 'H. Suraweera'}, {'authorId': '145952810', 'name': 'G. Zheng'}, {'authorId': '1694913', 'name': 'I. Krikidis'}, {'authorId': '1732114', 'name': 'Zhaoyang Zhang'}]\n",
            "Venue IEEE Transactions on Communications\n",
            "year 2014\n",
            "Abstract We consider a dual-hop full-duplex relaying system, where the energy constrained relay node is powered by radio frequency signals from the source using the time-switching architecture, both the amplify-and-forward and decode-and-forward relaying protocols are studied. Specifically, we provide an analytical characterization of the achievable throughput of three different communication modes, namely, instantaneous transmission, delay-constrained transmission, and delay tolerant transmission. In addition, the optimal time split is studied for different transmission modes. Our results reveal that, when the time split is optimized, the full-duplex relaying could substantially boost the system throughput compared to the conventional half-duplex relaying architecture for all three transmission modes. In addition, it is shown that the instantaneous transmission mode attains the highest throughput. However, compared to the delay-constrained transmission mode, the throughput gap is rather small. Unlike the instantaneous time split optimization which requires instantaneous channel state information, the optimal time split in the delay-constrained transmission mode depends only on the statistics of the channel, hence, is suitable for practical implementations.\n",
            "------------------------------------\n",
            "Title Structure-based prediction of protein-protein interactions on a genome-wide scale\n",
            "Author [{'authorId': '2628174', 'name': 'Q. Zhang'}, {'authorId': '2031954', 'name': 'D. Petrey'}, {'authorId': '143895325', 'name': 'L. Deng'}, {'authorId': '2066488156', 'name': 'Liao Qiang'}, {'authorId': '74060209', 'name': 'Yu Shi'}, {'authorId': '3858571', 'name': 'Chan Aye Thu'}, {'authorId': '3140816', 'name': 'B. Bisikirska'}, {'authorId': '3245422', 'name': 'C. Lefebvre'}, {'authorId': '4246425', 'name': 'D. Accili'}, {'authorId': '143683912', 'name': 'T. Hunter'}, {'authorId': '2551763', 'name': 'T. Maniatis'}, {'authorId': '144890512', 'name': 'A. Califano'}, {'authorId': '145124695', 'name': 'B. Honig'}]\n",
            "Venue Nature\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms\n",
            "Author [{'authorId': '48024382', 'name': 'K. Crawford'}, {'authorId': '70062314', 'name': 'J. Schultz'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract The rise of “big data” analytics in the private sector poses new challenges for privacy advocates. Unlike previous computational models that exploit personally identifiable information (PII) directly, such as behavioral targeting, big data has exploded the definition of PII to make many more sources of data personally identifiable. By analyzing primarily metadata, such as a set of predictive or aggregated findings without displaying or distributing the originating data, big data approaches often operate outside of current privacy protections (Rubinstein 2013; Tene and Polonetsky 2012), effectively marginalizing regulatory schema. Big data presents substantial privacy concerns – risks of bias or discrimination based on the inappropriate generation of personal data – a risk we call “predictive privacy harm.” Predictive analysis and categorization can pose a genuine threat to individuals, especially when it is performed without their knowledge or consent. While not necessarily a harm that falls within the conventional “invasion of privacy” boundaries, such harms still center on an individual’s relationship with data about her. Big data approaches need not rely on having a person’s PII directly: a combination of techniques from social network analysis, interpreting online behaviors and predictive modeling can create a detailed, intimate picture with a high degree of accuracy. Furthermore, harms can still result when such techniques are done poorly, rendering an inaccurate picture that nonetheless is used to impact on a person’s life and livelihood. In considering how to respond to evolving big data practices, we began by examining the existing rights that individuals have to see and review records pertaining to them in areas such as health and credit information. But it is clear that these existing systems are inadequate to meet current big data challenges. Fair Information Privacy Practices and other notice-and-choice regimes fail to protect against predictive privacy risks in part because individuals are rarely aware of how their individual data is being used to their detriment, what determinations are being made about them, and because at various points in big data processes, the relationship between predictive privacy harms and originating PII may be complicated by multiple technical processes and the involvement of third parties. Thus, past privacy regulations and rights are ill equipped to face current and future big data challenges.We propose a new approach to mitigating predictive privacy harms – that of a right to procedural data due process. In the Anglo-American legal tradition, procedural due process prohibits the government from depriving an individual’s rights to life, liberty, or property without affording her access to certain basic procedural components of the adjudication process – including the rights to review and contest the evidence at issue, the right to appeal any adverse decision, the right to know the allegations presented and be heard on the issues they raise. Procedural due process also serves as an enforcer of separation of powers, prohibiting those who write laws from also adjudicating them.While some current privacy regimes offer nominal due process-like mechanisms in relation to closely defined types of data, these rarely include all of the necessary components to guarantee fair outcomes and arguably do not apply to many kinds of big data systems (Terry 2012). A more rigorous framework is needed, particularly given the inherent analytical assumptions and methodological biases built into many big data systems (boyd and Crawford 2012). Building on previous thinking about due process for public administrative computer systems (Steinbock 2005; Citron 2010), we argue that individuals who are privately and often secretly “judged” by big data should have similar rights to those judged by the courts with respect to how their personal data has been used in such adjudications. Using procedural due process principles, we analogize a system of regulation that would provide such rights against private big data actors.\n",
            "------------------------------------\n",
            "Title News, Politics, and Negativity\n",
            "Author [{'authorId': '143874794', 'name': 'S. Soroka'}, {'authorId': '1785824', 'name': 'S. McAdams'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Work in political communication has discussed the ongoing predominance of negative news, but has offered few convincing accounts for this focus. A growing body of literature shows that humans regularly pay more attention to negative information than to positive information, however. This article argues that we should view the nature of news content in part as a consequence of this asymmetry bias observed in human behavior. A psychophysiological experiment capturing viewers’ reactions to actual news content shows that negative news elicits stronger and more sustained reactions than does positive news. Results are discussed as they pertain to political behavior and communication, and to politics and political institutions more generally.\n",
            "------------------------------------\n",
            "Title The bursty dynamics of the Twitter information network\n",
            "Author [{'authorId': '50362385', 'name': 'Seth A. Myers'}, {'authorId': '1702139', 'name': 'J. Leskovec'}]\n",
            "Venue The Web Conference\n",
            "year 2014\n",
            "Abstract In online social media systems users are not only posting, consuming, and resharing content, but also creating new and destroying existing connections in the underlying social network. While each of these two types of dynamics has individually been studied in the past, much less is known about the connection between the two. How does user information posting and seeking behavior interact with the evolution of the underlying social network structure? Here, we study ways in which network structure reacts to users posting and sharing content. We examine the complete dynamics of the Twitter information network, where users post and reshare information while they also create and destroy connections. We find that the dynamics of network structure can be characterized by steady rates of change, interrupted by sudden bursts. Information diffusion in the form of cascades of post re-sharing often creates such sudden bursts of new connections, which significantly change users' local network structure. We also explore the effect of the information content on the dynamics of the network and find evidence that the appearance of new topics and real-world events can lead to significant changes in edge creations and deletions. Lastly, we develop a model that quantifies the dynamics of the network and the occurrence of these bursts as a function of the information spreading through the network. The model can successfully predict which information diffusion events will lead to bursts in network dynamics.\n",
            "------------------------------------\n",
            "Title How can i improve my app? Classifying user reviews for software maintenance and evolution\n",
            "Author [{'authorId': '3117169', 'name': 'Sebastiano Panichella'}, {'authorId': '3144783', 'name': 'Andrea Di Sorbo'}, {'authorId': '144540463', 'name': 'Emitza Guzman'}, {'authorId': '1717023', 'name': 'C. A. Visaggio'}, {'authorId': '1711200', 'name': 'G. Canfora'}, {'authorId': '50355692', 'name': 'H. Gall'}]\n",
            "Venue IEEE International Conference on Software Maintenance and Evolution\n",
            "year 2015\n",
            "Abstract App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings. These platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. Previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. In this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) Natural Language Processing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify app reviews into the proposed categories. We show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).\n",
            "------------------------------------\n",
            "Title Thermodynamics with Continuous Information Flow\n",
            "Author [{'authorId': '34708126', 'name': 'J. Horowitz'}, {'authorId': '40660219', 'name': 'M. Esposito'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract We provide a unified thermodynamic formalism describing information transfers in autonomous as well as nonautonomous systems described by stochastic thermodynamics. We demonstrate how information is continuously generated in an auxiliary system and then transferred to a relevant system that can utilize it to fuel otherwise impossible processes. Indeed, while the joint system satisfies the second law, the entropy balance for the relevant system is modified by an information term related to the mutual information rate between the two systems. We show that many important results previously derived for nonautonomous Maxwell demons can be recovered from our formalism and use a cycle decomposition to analyze the continuous information flow in autonomous systems operating at steady-state. A model system is used to illustrate our findings.\n",
            "------------------------------------\n",
            "Title Global priorities for an effective information basis of biodiversity distributions\n",
            "Author [{'authorId': '39326465', 'name': 'Carsten Meyer'}, {'authorId': '2871866', 'name': 'H. Kreft'}, {'authorId': '145634039', 'name': 'R. Guralnick'}, {'authorId': '3799786', 'name': 'W. Jetz'}]\n",
            "Venue Nature Communications\n",
            "year 2015\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title AppIntent: analyzing sensitive data transmission in android for privacy leakage detection\n",
            "Author [{'authorId': '2133673', 'name': 'Zhemin Yang'}, {'authorId': '2110950734', 'name': 'Min Yang'}, {'authorId': None, 'name': 'Yuan Zhang'}, {'authorId': '3969047', 'name': 'G. Gu'}, {'authorId': '1756489', 'name': 'P. Ning'}, {'authorId': '2118774785', 'name': 'X. Wang'}]\n",
            "Venue Conference on Computer and Communications Security\n",
            "year 2013\n",
            "Abstract Android phones often carry personal information, attracting malicious developers to embed code in Android applications to steal sensitive data. With known techniques in the literature, one may easily determine if sensitive data is being transmitted out of an Android phone. However, transmission of sensitive data in itself does not necessarily indicate privacy leakage; a better indicator may be whether the transmission is by user intention or not. When transmission is not intended by the user, it is more likely a privacy leakage. The problem is how to determine if transmission is user intended. As a first solution in this space, we present a new analysis framework called AppIntent. For each data transmission, AppIntent can efficiently provide a sequence of GUI manipulations corresponding to the sequence of events that lead to the data transmission, thus helping an analyst to determine if the data transmission is user intended or not. The basic idea is to use symbolic execution to generate the aforementioned event sequence, but straightforward symbolic execution proves to be too time-consuming to be practical. A major innovation in AppIntent is to leverage the unique Android execution model to reduce the search space without sacrificing code coverage. We also present an evaluation of AppIntent with a set of 750 malicious apps, as well as 1,000 top free apps from Google Play. The results show that AppIntent can effectively help separate the apps that truly leak user privacy from those that do not.\n",
            "------------------------------------\n",
            "Title Understanding Employee Responses to Stressful Information Security Requirements: A Coping Perspective\n",
            "Author [{'authorId': '144257789', 'name': \"J. D'Arcy\"}, {'authorId': '1827881', 'name': 'Tejaswini C. Herath'}, {'authorId': '2227214', 'name': 'Mindy K. Shoss'}]\n",
            "Venue Journal of Management Information Systems\n",
            "year 2014\n",
            "Abstract We use coping theory to explore an underlying relationship between employee stress caused by burdensome, complex, and ambiguous information security requirements (termed \"security-related stress\" or SRS) and deliberate information security policy (ISP) violations. Results from a survey of 539 employee users suggest that SRS engenders an emotion-focused coping response in the form of moral disengagement from ISP violations, which in turn increases one's susceptibility to this behavior. Our multidimensional view of SRS—comprised of security-related overload, complexity, and uncertainty—offers a new perspective on the workplace environment factors that foster noncompliant user behavior and inspire cognitive rationalizations of such behavior. The study extends technostress research to the information systems security domain and provides a theoretical framework for the influence of SRS on user behavior. For practitioners, the results highlight the incidence of SRS in organizations and suggest potential mechanisms to counter the stressful effects of information security requirements.\n",
            "------------------------------------\n",
            "Title Geo-indistinguishability: differential privacy for location-based systems\n",
            "Author [{'authorId': '2827623', 'name': 'M. Andrés'}, {'authorId': '3444176', 'name': 'N. E. Bordenabe'}, {'authorId': '3472832', 'name': 'K. Chatzikokolakis'}, {'authorId': '1722055', 'name': 'C. Palamidessi'}]\n",
            "Venue Conference on Computer and Communications Security\n",
            "year 2012\n",
            "Abstract The growing popularity of location-based systems, allowing unknown/untrusted servers to easily collect huge amounts of information regarding users' location, has recently started raising serious privacy concerns. In this paper we introduce geoind, a formal notion of privacy for location-based systems that protects the user's exact location, while allowing approximate information -- typically needed to obtain a certain desired service -- to be released. This privacy definition formalizes the intuitive notion of protecting the user's location within a radius $r$ with a level of privacy that depends on r, and corresponds to a generalized version of the well-known concept of differential privacy. Furthermore, we present a mechanism for achieving geoind by adding controlled random noise to the user's location. We describe how to use our mechanism to enhance LBS applications with geo-indistinguishability guarantees without compromising the quality of the application results. Finally, we compare state-of-the-art mechanisms from the literature with ours. It turns out that, among all mechanisms independent of the prior, our mechanism offers the best privacy guarantees.\n",
            "------------------------------------\n",
            "Title Analyst Information Discovery and Interpretation Roles: A Topic Modeling Approach\n",
            "Author [{'authorId': '30839759', 'name': 'Allen H. Huang'}, {'authorId': '46248953', 'name': 'Reuven Lehavy'}, {'authorId': '46205335', 'name': 'Amy Y. Zang'}, {'authorId': '2054764800', 'name': 'Rong Zheng'}]\n",
            "Venue Management Sciences\n",
            "year 2016\n",
            "Abstract This study examines analyst information intermediary roles using a textual analysis of analyst reports and corporate disclosures. We employ a topic modeling methodology from computational linguistic research to compare the thematic content of a large sample of analyst reports issued promptly after earnings conference calls with the content of the calls themselves. We show that analysts discuss exclusive topics beyond those from conference calls and interpret topics from conference calls. In addition, we find that investors place a greater value on new information in analyst reports when managers face greater incentives to withhold value-relevant information. Analyst interpretation is particularly valuable when the processing costs of conference call information increase. Finally, we document that investors react to analyst report content that simply confirms managers’ conference call discussions. Overall, our study shows that analysts play the information intermediary roles by discovering information beyond corporate disclosures and by clarifying and confirming corporate disclosures.\n",
            "------------------------------------\n",
            "Title Evaluating Behaviorally-Motivated Policy: Experimental Evidence from the Lightbulb Market\n",
            "Author [{'authorId': '6112526', 'name': 'H. Allcott'}, {'authorId': '145946385', 'name': 'Dmitry Taubinsky'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract Imperfect information and inattention to energy costs are important potential motivations for energy efficiency standards and subsidies. We evaluate these motivations in the lightbulb market using a theoretical model and two randomized experiments. We derive welfare effects as functions of reduced-form sufficient statistics capturing economic and psychological parameters, which we estimate using a novel within-subject information disclosure experiment. The main results suggest that moderate subsidies for energy-efficient lightbulbs may increase welfare, but informational and attentional biases alone do not justify a ban on incandescent lightbulbs. Our results and techniques generate broader methodological insights into welfare analysis with misoptimizing consumers. (JEL D12, D83, H21, H31, L67, Q41, Q48)\n",
            "------------------------------------\n",
            "Title Conditional Adversarial Domain Adaptation\n",
            "Author [{'authorId': '35776445', 'name': 'Mingsheng Long'}, {'authorId': '3451430', 'name': 'Zhangjie Cao'}, {'authorId': '2144499343', 'name': 'Jianmin Wang'}, {'authorId': '1694621', 'name': 'Michael I. Jordan'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2017\n",
            "Abstract Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may struggle to align different domains of multimodal distributions that are native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. Experiments testify that the proposed approach exceeds the state-of-the-art results on five benchmark datasets.\n",
            "------------------------------------\n",
            "Title Inoculating the Public against Misinformation about Climate Change\n",
            "Author [{'authorId': '35958880', 'name': 'S. van der Linden'}, {'authorId': '46826196', 'name': 'A. Leiserowitz'}, {'authorId': '47755941', 'name': 'S. Rosenthal'}, {'authorId': '144141937', 'name': 'E. Maibach'}]\n",
            "Venue Global Challenges\n",
            "year 2017\n",
            "Abstract Effectively addressing climate change requires significant changes in individual and collective human behavior and decision‐making. Yet, in light of the increasing politicization of (climate) science, and the attempts of vested‐interest groups to undermine the scientific consensus on climate change through organized “disinformation campaigns,” identifying ways to effectively engage with the public about the issue across the political spectrum has proven difficult. A growing body of research suggests that one promising way to counteract the politicization of science is to convey the high level of normative agreement (“consensus”) among experts about the reality of human‐caused climate change. Yet, much prior research examining public opinion dynamics in the context of climate change has done so under conditions with limited external validity. Moreover, no research to date has examined how to protect the public from the spread of influential misinformation about climate change. The current research bridges this divide by exploring how people evaluate and process consensus cues in a polarized information environment. Furthermore, evidence is provided that it is possible to pre‐emptively protect (“inoculate”) public attitudes about climate change against real‐world misinformation.\n",
            "------------------------------------\n",
            "Title Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks\n",
            "Author [{'authorId': '2143649323', 'name': 'Jin Huang'}, {'authorId': '2542603', 'name': 'Wayne Xin Zhao'}, {'authorId': '20768777', 'name': 'Hongjian Dou'}, {'authorId': '153693432', 'name': 'Ji-rong Wen'}, {'authorId': '152536227', 'name': 'Edward Y. Chang'}]\n",
            "Venue Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "year 2018\n",
            "Abstract With the revival of neural networks, many studies try to adapt powerful sequential neural models, ıe Recurrent Neural Networks (RNN), to sequential recommendation. RNN-based networks encode historical interaction records into a hidden state vector. Although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. It is difficult to capture fine-grained user preference from the interaction sequence. Furthermore, the latent vector representation is usually hard to understand and explain. To address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. Our model integrates the RNN-based networks with Key-Value Memory Network (KV-MN). We further incorporate knowledge base (KB) information to enhance the semantic representation of KV-MN. RNN-based models are good at capturing sequential user preference, while knowledge-enhanced KV-MNs are good at capturing attribute-level user preference. By using a hybrid of RNNs and KV-MNs, it is expected to be endowed with both benefits from these two components. The sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. With the incorporation of KB information, our model is also highly interpretable. To our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale KB information.\n",
            "------------------------------------\n",
            "Title Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!\n",
            "Author [{'authorId': '1779119', 'name': 'Laura Chiticariu'}, {'authorId': '1718694', 'name': 'Yunyao Li'}, {'authorId': '47265115', 'name': 'Frederick Reiss'}]\n",
            "Venue Conference on Empirical Methods in Natural Language Processing\n",
            "year 2013\n",
            "Abstract The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape of IE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.\n",
            "------------------------------------\n",
            "Title Comprehending and Learning From Internet Sources: Processing Patterns of Better and Poorer Learners\n",
            "Author [{'authorId': '39221711', 'name': 'S. Goldman'}, {'authorId': '29401868', 'name': 'Jason L. G. Braasch'}, {'authorId': '33951735', 'name': 'J. Wiley'}, {'authorId': '1769251', 'name': 'A. Graesser'}, {'authorId': '71062897', 'name': 'Kamila Brodowinska'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract Readers increasingly attempt to understand and learn from information sources they find on the Internet. Doing so highlights the crucial role that evaluative processes play in selecting and making sense of the information. In a prior study, Wiley et al. (2009, Experiment 1) asked undergraduates to perform a web-based inquiry task about volcanoes using multiple Internet sources. A major finding established a clear link between learning outcomes, source evaluations, and reading behaviors. The present study used think-aloud protocol methodology to better understand the processing that learners engaged in during this task: 10 better learners were contrasted with 11 poorer learners. Results indicate that better learners engaged in more sense-making, self-explanation, and comprehension-monitoring processes on reliable sites as compared with unreliable sites, and did so by a larger margin than did poorer learners. Better learners also engaged in more goal-directed navigation than poorer learners. Case studies of two better and two poorer learners further illustrate how evaluation processes contributed to navigation decisions. Findings suggest that multiple-source comprehension is a dynamic process that involves interplay among sense-making, monitoring, and evaluation processes, all of which promote strategic reading. \n",
            " \n",
            " \n",
            " \n",
            "阅读者日益想要弄明白及学习他们从互联网上各种来源所找到的信息资料。他们这样做突显出在选择和弄明白这些信息时评价过程所起的重要作用。威立等人在以前一项研究(2009,实验1)中,参与研究的大学生要利用互联网多种资源来完成一项关于火山的網路探究式学习任务。该研究的一个主要结果是建立了学习成果、信息来源评价与阅读行为之间的明确联系。本研究则使用有声思维研究方法,以深入考查学习者在参与同一个学习任务时他们处理信息的过程,并以10名表现较好的与11名表现较差的学习者作比对。结果显示,对于可靠网站上的资料,表现较好的学习者较多致力于弄明白自我解释的过程和理解监控的过程,而对于不可靠网站上的资料,这种行为则较少;他们这种行为亦远多于表现较差的学习者。此外,表现较好的学习者比表现较差的学习者较多致力于有目标的网上浏览。两个表现较好及两个表现较差的学习者的案例研究,进一步说明评价过程如何有助于在网上浏览时所作的决定。本研究结果显示,理解多种来源的信息是一个动态的过程,其中涉及弄明白、监控和评价过程之间的相互作用,而这些过程均能促进策略性阅读。 \n",
            " \n",
            " \n",
            " \n",
            "Es cada vez mas comun que lectores intenten entender y aprender de fuentes de informacion del Internet. Esto demuestra el rol crucial que los procesos de evaluacion tienen en seleccionar y sacar sentido de la informacion recibida. En un estudio anterior, Wiley et al. (2009, Experiment 1) les pidieron a subgraduados que hicieran una busqueda en la red sobre volcanes usando multiples fuentes del Internet. Un resultado clave establecio una conexion clara entre los resultados del aprendizaje, la evaluacion de las fuentes, y la manera de leer. El presente estudio uso la metodologia del protocolo de pensar en voz alta para mejor entender los procesos usados por los aprendices al cumplir dicha tarea: se compararon 10 aprendices mejores con 11 aprendices pobres. Los resultados senalan que los mejores aprendices buscaban sus propias explicaciones que hicieran sentido y procesos de monitoreo de comprension en sitios confiables comparados con los sitios que no eran confiables, y lo hacian con un margen mayor que los aprendices pobres. Un estudio de casos de dos mejores y dos pobres aprendices ilustran aun mas como los procesos de evaluacion contribuian al proceso de navegacion. Los resultados sugieren que la comprension de multiples fuentes es un proceso dinamico que requiere interaccion entre los procesos de hacer sentido, monitoreo, y evaluacion, todos de los cuales promulgan la lectura estrategica. \n",
            " \n",
            " \n",
            " \n",
            "يحاول القراء بشكل متزايد الفهم والتعلم من مصادر المعلومات التي يجدونها على شبكة الإنترنيت؛ وبذلك فهذا يسلط الضوء على الدور الحاسم الذي تلعبه عمليات التقييم في اختيار وإعطاء معنى للمعلومات. وفي دراسة سابقة طلب “وايلي” وآخرون (التجربة١،٢٠٠٩) من الطلبة الجامعيين إجراء بحث على شبكة الإنترنيت حول البراكين مستخدمين مصادر إنترنيت متعددة.تم التوصل إلى نتيجة رئيسية تقوم على أن هناك صلة واضحة بين التعلم وتقييمات المصدر وسلوكيات القراءة. استخدمت الدراسة الحالية منهجية بروتوكول التفكيير بصوت عال لفهم بشكل أفضل العمليات التي استخدمها المتعلمون أثناء هذه المهمة: تمت مقارنة ١٠من أفضل المتعلمين ب١١من أضعف المتعلمين. تشير النتائج إلى أن أفضل المتعلمين استخدموا عمليات أكثر في إعطاء معنى للتفسير الذاتي ومراقبة الفهم على مواقع موثوق بها بالمقارنة مع مواقع غير موثوق بها وفعلوا ذلك أكثر من أضعف المتعلمين. كما أن أفضل المتعلمين قد قاموا بالبحث على أهدافهم عبر الإنترنيت بصورة مباشرة. وتوضح كذلك دراسة الحالة لأفضل متعلمين وأضعف متعلمين كيف ساهمت عمليات التقييم في قرارات البحث عبر الإنترنيت. تشير النتائج إلى أن فهم المصادر المتعددة عملية فعالة تشمل التفاعل المتبادل بين إعطاء المعنى والمراقبة وعملية التقييم، وكل منها تنمي القراءة الاستراتيجية. \n",
            " \n",
            " \n",
            " \n",
            "Читaющиe люди вce чaщe oбpaщaютcя к интepнeтy кaк к иcтoчникy инфopмaции. Oднaкo, для eeгpaмoтнoгo oтбopa ивocпpиятиякpaйнeвaжнo yмeть oцeнить эти иcтoчники. B paнee пpoвeдeнныx иccлeдoвaнияx (Wiley и дp., 2009, Экcпepимeнт 1) yчeныe пpeдлoжили cтyдeнтaм млaдшиx кypcoв пoиcкaть мaтepиaл o вyлкaнax пo paзличныминтepнeт-caйтaм. B итoгe выявилacь пpямaя cвязь мeждy peзyльтaтaми yчeбнoй дeятeльнocти, yмeниeм oцeнить иcтoчники и caмим пoвeдeниeм cтyдeнтoв-читaтeлeй. B нacтoящeмиccлeдoвaнии, чтoбы лyчшe пoнять, кaк пpoиcxoдит пpoцecc oцeнивaния, иcпoльзoвaлcя мeтoд “paзмышлeниe вcлyx”, и cpaвнивaлиcь paзмышлeния дecяти лyчшиx и дecяти нaибoлee cлaбыx yчaщиxcя. Peзyльтaты пoкaзывaют, чтo cильныe yчaщиecя знaчитeльнo чaщe paбoтaют c нaдeжными caйтaми, бoльшe зaнимaютcя aнaлизoм инфopмaции и кoнтpoлиpyют coбcтвeннoe ocмыcлeниe пpoчитaннoгo. Кpoмe тoгo, caм пpoцecc иx ceтeвoгo пoиcкa бoлee цeлeнaпpaвлeн, чeм дeятeльнocть cлaбыx yчaщиxcя. B кaчecтвe иллюcтpaции oпиcaн пpoцecc oцeнивaния иcтoчникoв и cooтвeтcтвyющaя eмy тpaeктopия пoиcкa для двyx cильныx и двyx cлaбыx yчaщиxcя. Aвтopы пoлaгaют, чтo вocпpиятиe инфopмaции из мнoжecтвa иcтoчникoв – динaмичный пpoцecc, кoтopый coчeтaeт в ceбe вoccoздaниe нoвыx для читaтeля cмыcлoв, a тaкжe мoнитopинг и oцeнивaниe пpoцeccoв пoзнaния, чтo в coвoкyпнocти paзвивaeт нaвыки cтpaтeгичecкoгo чтeния. \n",
            " \n",
            " \n",
            " \n",
            "Les lecteurs essaient de plus en plus de comprendre et d'apprendre au moyen de sources d'information qu'ils trouvent sur Internet. Cette pratique souligne le role crucial que jouent les processus d’evaluation lors de la selection de l'information et du sens qu'on lui donne. Dans une etude precedente, Wiley et al. (2009, premiere experience) ont demande a des etudiants de premier cycle d'effectuer sur la Toile une recherche sur les volcans en utilisant plusieurs sources d'Internet. Des liens sont apparus clairement entre les resultats obtenus, les evaluations des sources et les comportements de lecture. L’etude presentee ici a utilise la methodologie du protocole consistant a penser a haute voix pour mieux comprendre la facon de proceder des lecteurs lors de cette tâche, ceci avec 10 eleves de bon niveau contrastes a 11 eleves de niveau faible. Les resultats montrent que les meilleurs eleves s'engagent dans des processus d'auto-explication de recherche du sens et de pilotage de la comprehension sur des sites plus fiables que d'autres, et qu'ils procedent ainsi plus largement que les moins bons eleves. Les meilleurs eleves sont aussi plus engages dans une navigation avec but que les moins bons eleves. L’etude de cas de deux bons eleves et de deux faibles permettant de mieux illustrer encore comment les processus d’evaluation contribuent aux decisions de navigation. Les resultats suggerent que la comprehension de sources multiples est un processus dynamique qui implique des interactions entre l'attribution de sens, le pilotage, et les processus d’evaluation, tous ces elements contribuant a une lecture strategique.\n",
            "------------------------------------\n",
            "Title Context-Dependent Sentiment Analysis in User-Generated Videos\n",
            "Author [{'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '144802290', 'name': 'Amir Zadeh'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2017\n",
            "Abstract Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.\n",
            "------------------------------------\n",
            "Title A classification of location privacy attacks and approaches\n",
            "Author [{'authorId': '1926764', 'name': 'Marius Wernke'}, {'authorId': '145454897', 'name': 'P. Skvortsov'}, {'authorId': '145046960', 'name': 'Frank Dürr'}, {'authorId': '1700118', 'name': 'K. Rothermel'}]\n",
            "Venue Personal and Ubiquitous Computing\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title RefSeq: an update on mammalian reference sequences\n",
            "Author [{'authorId': '1753253', 'name': 'K. Pruitt'}, {'authorId': '49076132', 'name': 'Garth R. Brown'}, {'authorId': '2436763', 'name': 'S. Hiatt'}, {'authorId': '1401199158', 'name': 'F. Thibaud-Nissen'}, {'authorId': '2003891', 'name': 'Alex Astashyn'}, {'authorId': '50654620', 'name': 'O. Ermolaeva'}, {'authorId': '2264606', 'name': 'C. Farrell'}, {'authorId': '144951362', 'name': 'Jennifer Hart'}, {'authorId': '3218124', 'name': 'M. Landrum'}, {'authorId': '3309511', 'name': 'Kelly M. McGarvey'}, {'authorId': '143690289', 'name': 'M. R. Murphy'}, {'authorId': '1398781025', 'name': \"N. O'Leary\"}, {'authorId': '144143833', 'name': 'S. Pujar'}, {'authorId': '47202114', 'name': 'B. Rajput'}, {'authorId': '47330346', 'name': 'S. H. Rangwala'}, {'authorId': '31863769', 'name': 'Lillian D. Riddick'}, {'authorId': '3199404', 'name': 'Andrei Shkeda'}, {'authorId': '2912118', 'name': 'Hanzhen Sun'}, {'authorId': '2901686', 'name': 'P. Tamez'}, {'authorId': '36967624', 'name': 'R. E. Tully'}, {'authorId': '2430219', 'name': 'Craig Wallin'}, {'authorId': '2055948707', 'name': 'David Webb'}, {'authorId': '32805351', 'name': 'Janet Weber'}, {'authorId': '30707576', 'name': 'Wendy Wu'}, {'authorId': '2041192', 'name': 'Michael DiCuccio'}, {'authorId': '50617031', 'name': 'P. Kitts'}, {'authorId': '1758049', 'name': 'D. Maglott'}, {'authorId': '144308320', 'name': 'Terence D. Murphy'}, {'authorId': '1968560', 'name': 'J. Ostell'}]\n",
            "Venue Nucleic Acids Res.\n",
            "year 2013\n",
            "Abstract The National Center for Biotechnology Information (NCBI) Reference Sequence (RefSeq) database is a collection of annotated genomic, transcript and protein sequence records derived from data in public sequence archives and from computation, curation and collaboration (http://www.ncbi.nlm.nih.gov/refseq/). We report here on growth of the mammalian and human subsets, changes to NCBI’s eukaryotic annotation pipeline and modifications affecting transcript and protein records. Recent changes to NCBI’s eukaryotic genome annotation pipeline provide higher throughput, and the addition of RNAseq data to the pipeline results in a significant expansion of the number of transcripts and novel exons annotated on mammalian RefSeq genomes. Recent annotation changes include reporting supporting evidence for transcript records, modification of exon feature annotation and the addition of a structured report of gene and sequence attributes of biological interest. We also describe a revised protein annotation policy for alternatively spliced transcripts with more divergent predicted proteins and we summarize the current status of the RefSeqGene project.\n",
            "------------------------------------\n",
            "Title Robust chemical preservation of digital information on DNA in silica with error-correcting codes.\n",
            "Author [{'authorId': '48560944', 'name': 'R. Grass'}, {'authorId': '145639495', 'name': 'Reinhard Heckel'}, {'authorId': '31450590', 'name': 'M. Puddu'}, {'authorId': '38186808', 'name': 'D. Paunescu'}, {'authorId': '32073567', 'name': 'W. Stark'}]\n",
            "Venue Angewandte Chemie\n",
            "year 2015\n",
            "Abstract Information, such as text printed on paper or images projected onto microfilm, can survive for over 500 years. However, the storage of digital information for time frames exceeding 50 years is challenging. Here we show that digital information can be stored on DNA and recovered without errors for considerably longer time frames. To allow for the perfect recovery of the information, we encapsulate the DNA in an inorganic matrix, and employ error-correcting codes to correct storage-related errors. Specifically, we translated 83 kB of information to 4991 DNA segments, each 158 nucleotides long, which were encapsulated in silica. Accelerated aging experiments were performed to measure DNA decay kinetics, which show that data can be archived on DNA for millennia under a wide range of conditions. The original information could be recovered error free, even after treating the DNA in silica at 70 °C for one week. This is thermally equivalent to storing information on DNA in central Europe for 2000 years.\n",
            "------------------------------------\n",
            "Title A Survey of the State-of-the-Art Localization Techniques and Their Potentials for Autonomous Vehicle Applications\n",
            "Author [{'authorId': '40907031', 'name': 'Sampo Kuutti'}, {'authorId': '34929667', 'name': 'Saber Fallah'}, {'authorId': '8940287', 'name': 'K. Katsaros'}, {'authorId': '1953808', 'name': 'M. Dianati'}, {'authorId': '144087518', 'name': 'F. Mccullough'}, {'authorId': '144235212', 'name': 'A. Mouzakitis'}]\n",
            "Venue IEEE Internet of Things Journal\n",
            "year 2018\n",
            "Abstract For an autonomous vehicle to operate safely and effectively, an accurate and robust localization system is essential. While there are a variety of vehicle localization techniques in literature, there is a lack of effort in comparing these techniques and identifying their potentials and limitations for autonomous vehicle applications. Hence, this paper evaluates the state-of-the-art vehicle localization techniques and investigates their applicability on autonomous vehicles. The analysis starts with discussing the techniques which merely use the information obtained from on-board vehicle sensors. It is shown that although some techniques can achieve the accuracy required for autonomous driving but suffer from the high cost of the sensors and also sensor performance limitations in different driving scenarios (e.g., cornering and intersections) and different environmental conditions (e.g., darkness and snow). This paper continues the analysis with considering the techniques which benefit from off-board information obtained from V2X communication channels, in addition to vehicle sensory information. The analysis shows that augmenting off-board information to sensory information has potential to design low-cost localization systems with high accuracy and robustness, however, their performance depends on penetration rate of nearby connected vehicles or infrastructure and the quality of network service.\n",
            "------------------------------------\n",
            "Title Blissfully ignorant: the effects of general privacy concerns, general institutional trust, and affect in the privacy calculus\n",
            "Author [{'authorId': '3035002', 'name': 'F. Kehr'}, {'authorId': '1793743', 'name': 'T. Kowatsch'}, {'authorId': '145775736', 'name': 'D. Wentzel'}, {'authorId': '2801545', 'name': 'E. Fleisch'}]\n",
            "Venue Information Systems Journal\n",
            "year 2015\n",
            "Abstract Existing research on information privacy has mostly relied on the privacy calculus model, which views privacy‐related decision‐making as a rational process where individuals weigh the anticipated risks of disclosing personal data against the potential benefits. In this research, we develop an extension to the privacy calculus model, arguing that the situation‐specific assessment of risks and benefits is bounded by (1) pre‐existing attitudes or dispositions, such as general privacy concerns or general institutional trust, and (2) limited cognitive resources and heuristic thinking. An experimental study, employing two samples from the USA and Switzerland, examined consumer responses to a new smartphone application that collects driving behavior data and provided converging support for these predictions. Specifically, the results revealed that a situation‐specific assessment of risks and benefits fully mediates the effect of dispositional factors on information disclosure. In addition, the results showed that privacy assessment is influenced by momentary affective states, indicating that consumers underestimate the risks of information disclosure when confronted with a user interface that elicits positive affect.\n",
            "------------------------------------\n",
            "Title How Much Position Information Do Convolutional Neural Networks Encode?\n",
            "Author [{'authorId': '3240989', 'name': 'Md. Amirul Islam'}, {'authorId': '1805367', 'name': 'Sen Jia'}, {'authorId': '2866780', 'name': 'Neil D. B. Bruce'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2020\n",
            "Abstract In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.\n",
            "------------------------------------\n",
            "Title Information provision for stroke patients and their caregivers.\n",
            "Author [{'authorId': '144233450', 'name': 'A. Forster'}, {'authorId': '49860772', 'name': 'L. Brown'}, {'authorId': '2119123984', 'name': 'Jane Smith'}, {'authorId': '144253717', 'name': 'A. House'}, {'authorId': '145532176', 'name': 'P. Knapp'}, {'authorId': '49095222', 'name': 'John Wright'}, {'authorId': '1695918', 'name': 'John B. Young'}]\n",
            "Venue Cochrane Database of Systematic Reviews\n",
            "year 2012\n",
            "Abstract BACKGROUND\n",
            "Research shows that stroke patients and their families are dissatisfied with the information provided and have a poor understanding of stroke and associated issues.\n",
            "\n",
            "\n",
            "OBJECTIVES\n",
            "To assess the effectiveness of information provision strategies in improving the outcome for stroke patients or their identified caregivers, or both.\n",
            "\n",
            "\n",
            "SEARCH METHODS\n",
            "For this update we searched the Cochrane Stroke Group Trials Register (June 2012), the Cochrane Central Register of Controlled trials (CENTRAL), the Cochrane Database of Systematic Reviews (CDSR), the Database of Abstracts of Reviews of Effects (DARE), the NHS Economic Evaluation Database (EED), and the Health Technology Assessment (HTA) Database (The Cochrane Library June, 2012), MEDLINE (1966 to June 2012), EMBASE (1980 to June 2012), CINAHL (1982 to June 2012) and PsycINFO (1974 to June 2012). We also searched ongoing trials registers, scanned bibliographies of relevant articles and books and contacted researchers.\n",
            "\n",
            "\n",
            "SELECTION CRITERIA\n",
            "Randomised trials involving patients or carers of patients with a clinical diagnosis of stroke or transient ischaemic attack (TIA) where an information intervention was compared with standard care, or where information and another therapy were compared with the other therapy alone.\n",
            "\n",
            "\n",
            "DATA COLLECTION AND ANALYSIS\n",
            "Two review authors independently assessed trial eligibility and methodological quality and extracted data. Primary outcomes were knowledge about stroke and stroke services, and impact on mood.\n",
            "\n",
            "\n",
            "MAIN RESULTS\n",
            "We have added four new trials to this update. This review now includes 21 trials involving 2289 patient and 1290 carer participants. Nine trials evaluated a passive and 12 trials an active information intervention. Meta-analyses showed a significant effect in favour of the intervention on patient knowledge (standardised mean difference (SMD) 0.29, 95% confidence interval (CI) 0.12 to 0.46, P < 0.001), carer knowledge (SMD 0.74, 95% CI 0.06 to 1.43, P = 0.03), one aspect of patient satisfaction (odds ratio (OR) 2.07, 95% CI 1.33 to 3.23, P = 0.001), and patient depression scores (mean difference (MD) -0.52, 95% CI -0.93 to -0.10, P = 0.01). There was no significant effect (P > 0.05) on number of cases of anxiety or depression in patients, carer mood or satisfaction, or death. Qualitative analyses found no strong evidence of an effect on other outcomes. Post-hoc subgroup analyses showed that active information had a significantly greater effect than passive information on patient mood but not on other outcomes.\n",
            "\n",
            "\n",
            "AUTHORS' CONCLUSIONS\n",
            "There is evidence that information improves patient and carer knowledge of stroke, aspects of patient satisfaction, and reduces patient depression scores. However, the reduction in depression scores was small and may not be clinically significant. Although the best way to provide information is still unclear there is some evidence that strategies that actively involve patients and carers and include planned follow-up for clarification and reinforcement have a greater effect on patient mood.\n",
            "------------------------------------\n",
            "Title Pathology imaging informatics for quantitative analysis of whole-slide images\n",
            "Author [{'authorId': '37749491', 'name': 'S. Kothari'}, {'authorId': '1736789', 'name': 'J. Phan'}, {'authorId': '2246285', 'name': 'T. Stokes'}, {'authorId': '152176821', 'name': 'May D. Wang'}]\n",
            "Venue JAMIA Journal of the American Medical Informatics Association\n",
            "year 2013\n",
            "Abstract Objectives With the objective of bringing clinical decision support systems to reality, this article reviews histopathological whole-slide imaging informatics methods, associated challenges, and future research opportunities. Target audience This review targets pathologists and informaticians who have a limited understanding of the key aspects of whole-slide image (WSI) analysis and/or a limited knowledge of state-of-the-art technologies and analysis methods. Scope First, we discuss the importance of imaging informatics in pathology and highlight the challenges posed by histopathological WSI. Next, we provide a thorough review of current methods for: quality control of histopathological images; feature extraction that captures image properties at the pixel, object, and semantic levels; predictive modeling that utilizes image features for diagnostic or prognostic applications; and data and information visualization that explores WSI for de novo discovery. In addition, we highlight future research directions and discuss the impact of large public repositories of histopathological data, such as the Cancer Genome Atlas, on the field of pathology informatics. Following the review, we present a case study to illustrate a clinical decision support system that begins with quality control and ends with predictive modeling for several cancer endpoints. Currently, state-of-the-art software tools only provide limited image processing capabilities instead of complete data analysis for clinical decision-making. We aim to inspire researchers to conduct more research in pathology imaging informatics so that clinical decision support can become a reality.\n",
            "------------------------------------\n",
            "Title DNA Fountain enables a robust and efficient storage architecture\n",
            "Author [{'authorId': '2422788', 'name': 'Yaniv Erlich'}, {'authorId': '1815791', 'name': 'Dina Zielinski'}]\n",
            "Venue Science\n",
            "year 2016\n",
            "Abstract A reliable and efficient DNA storage architecture DNA has the potential to provide large-capacity information storage. However, current methods have only been able to use a fraction of the theoretical maximum. Erlich and Zielinski present a method, DNA Fountain, which approaches the theoretical maximum for information stored per nucleotide. They demonstrated efficient encoding of information—including a full computer operating system—into DNA that could be retrieved at scale after multiple rounds of polymerase chain reaction. Science, this issue p. 950 A resilient DNA storage strategy enables near-maximal information content per nucleotide. DNA is an attractive medium to store digital information. Here we report a storage strategy, called DNA Fountain, that is highly robust and approaches the information capacity per nucleotide. Using our approach, we stored a full computer operating system, movie, and other files with a total of 2.14 × 106 bytes in DNA oligonucleotides and perfectly retrieved the information from a sequencing coverage equivalent to a single tile of Illumina sequencing. We also tested a process that can allow 2.18 × 1015 retrievals using the original DNA sample and were able to perfectly decode the data. Finally, we explored the limit of our architecture in terms of bytes per molecule and obtained a perfect retrieval from a density of 215 petabytes per gram of DNA, orders of magnitude higher than previous reports.\n",
            "------------------------------------\n",
            "Title Can Twitter Help Predict Firm-Level Earnings and Stock Returns?\n",
            "Author [{'authorId': '50534165', 'name': 'Eli Bartov'}, {'authorId': '83279718', 'name': 'Lucile Faurel'}, {'authorId': '3428581', 'name': 'Partha Mohanram'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract ABSTRACT: Prior research has examined how companies exploit Twitter in communicating with investors, and whether Twitter activity predicts the stock market as a whole. We test whether opinions of individuals tweeted just prior to a firm's earnings announcement predict its earnings and announcement returns. Using a broad sample from 2009 to 2012, we find that the aggregate opinion from individual tweets successfully predicts a firm's forthcoming quarterly earnings and announcement returns. These results hold for tweets that convey original information, as well as tweets that disseminate existing information, and are stronger for tweets providing information directly related to firm fundamentals and stock trading. Importantly, our results hold even after controlling for concurrent information or opinion from traditional media sources, and are stronger for firms in weaker information environments. Our findings highlight the importance of considering the aggregate opinion from individual tweets when assessing...\n",
            "------------------------------------\n",
            "Title Attention Augmented Convolutional Networks\n",
            "Author [{'authorId': '4689792', 'name': 'Irwan Bello'}, {'authorId': '2368067', 'name': 'Barret Zoph'}, {'authorId': '40348417', 'name': 'Ashish Vaswani'}, {'authorId': '1789737', 'name': 'Jonathon Shlens'}, {'authorId': '2827616', 'name': 'Quoc V. Le'}]\n",
            "Venue IEEE International Conference on Computer Vision\n",
            "year 2019\n",
            "Abstract Convolutional networks have enjoyed much success in many computer vision applications. The convolution operation however has a significant weakness in that it only operates on a local neighbourhood, thus missing global information. Self-attention, on the other hand, has emerged as a recent advance to capture long range interactions, but has mostly been applied to sequence modeling and generative modeling tasks. In this paper, we propose to augment convolutional networks with self-attention by concatenating convolutional feature maps with a set of feature maps produced via a novel relative self-attention mechanism. In particular, we extend previous work on relative self-attention over sequences to images and discuss a memory efficient implementation. Unlike Squeeze-and-Excitation, which performs attention over the channels and ignores spatial information, our self-attention mechanism attends jointly to both features and spatial locations while preserving translation equivariance. We find that Attention Augmentation leads to consistent improvements in image classification on ImageNet and object detection on COCO across many different models and scales, including ResNets and a state-of-the art mobile constrained network, while keeping the number of parameters similar. In particular, our method achieves a 1.3% top-1 accuracy improvement on ImageNet classification over a ResNet50 baseline and outperforms other attention mechanisms for images such as Squeeze-and-Excitation. It also achieves an improvement of 1.4 AP in COCO Object Detection on top of a RetinaNet baseline.\n",
            "------------------------------------\n",
            "Title Knowing when to doubt: developing a critical stance when learning from others.\n",
            "Author [{'authorId': '7560415', 'name': 'Candice M. Mills'}]\n",
            "Venue Developmental Psychology\n",
            "year 2013\n",
            "Abstract Children may be biased toward accepting information as true, but the fact remains that children are exposed to misinformation from many sources, and mastering the intricacies of doubt is necessary. The current article examines this issue, focusing on understanding developmental changes and consistencies in children's ability to take a critical stance toward information. Research reviewed includes studies of children's ability to detect ignorance, inaccuracy, incompetence, deception, and distortion. Particular emphasis is placed on what this research indicates about how children are reasoning about when to trust and when to doubt. The remainder of the article proposes a framework to evaluate preexisting research and encourage further research, closing with a discussion of several other overarching questions that should be considered to develop a model to explain developmental, individual, and situational differences in children's ability to evaluate information.\n",
            "------------------------------------\n",
            "Title Anxious politics : democratic citizenship in a threatening world\n",
            "Author [{'authorId': '50483051', 'name': 'B. Albertson'}, {'authorId': '13901928', 'name': 'S. Gadarian'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract 1. Anxiety in public life 2. What's your worry? Finding and creating anxiety in the American public 3. Anxiety, immigration, and the search for information 4. Don't worry, be trusting? The effect of anxiety on political trust 5. The politics of anxiety: anxiety's role on public opinion 6. Anxiety and democratic citizenship.\n",
            "------------------------------------\n",
            "Title International Society of Neuropathology‐Haarlem Consensus Guidelines for Nervous System Tumor Classification and Grading\n",
            "Author [{'authorId': '2975248', 'name': 'D. Louis'}, {'authorId': '144144978', 'name': 'A. Perry'}, {'authorId': '2052294765', 'name': 'P. Burger'}, {'authorId': '145839173', 'name': 'D. Ellison'}, {'authorId': '4995271', 'name': 'G. Reifenberger'}, {'authorId': '133681468', 'name': 'A. von Deimling'}, {'authorId': '50138848', 'name': 'K. Aldape'}, {'authorId': '2614122', 'name': 'D. Brat'}, {'authorId': '2058016674', 'name': 'V. Collins'}, {'authorId': '3134228', 'name': 'C. Eberhart'}, {'authorId': '48731743', 'name': 'D. Figarella-Branger'}, {'authorId': '2780693', 'name': 'G. Fuller'}, {'authorId': '3918072', 'name': 'F. Giangaspero'}, {'authorId': '3555781', 'name': 'C. Giannini'}, {'authorId': '2144089', 'name': 'C. Hawkins'}, {'authorId': '3889509', 'name': 'P. Kleihues'}, {'authorId': '145083277', 'name': 'A. Korshunov'}, {'authorId': '2988332', 'name': 'J. Kros'}, {'authorId': '4345259', 'name': 'M. Beatriz Lopes'}, {'authorId': '145958455', 'name': 'H. Ng'}, {'authorId': '3548878', 'name': 'H. Ohgaki'}, {'authorId': '144869687', 'name': 'W. Paulus'}, {'authorId': '144208043', 'name': 'T. Pietsch'}, {'authorId': '34762158', 'name': 'M. Rosenblum'}, {'authorId': '4147674', 'name': 'E. Rushing'}, {'authorId': '4401459', 'name': 'F. Soylemezoğlu'}, {'authorId': '5295422', 'name': 'O. Wiestler'}, {'authorId': '3053722', 'name': 'P. Wesseling'}]\n",
            "Venue Brain Pathology\n",
            "year 2014\n",
            "Abstract Major discoveries in the biology of nervous system tumors have raised the question of how non‐histological data such as molecular information can be incorporated into the next World Health Organization (WHO) classification of central nervous system tumors. To address this question, a meeting of neuropathologists with expertise in molecular diagnosis was held in Haarlem, the Netherlands, under the sponsorship of the International Society of Neuropathology (ISN). Prior to the meeting, participants solicited input from clinical colleagues in diverse neuro‐oncological specialties. The present “white paper” catalogs the recommendations of the meeting, at which a consensus was reached that incorporation of molecular information into the next WHO classification should follow a set of provided “ISN‐Haarlem” guidelines. Salient recommendations include that (i) diagnostic entities should be defined as narrowly as possible to optimize interobserver reproducibility, clinicopathological predictions and therapeutic planning; (ii) diagnoses should be “layered” with histologic classification, WHO grade and molecular information listed below an “integrated diagnosis”; (iii) determinations should be made for each tumor entity as to whether molecular information is required, suggested or not needed for its definition; (iv) some pediatric entities should be separated from their adult counterparts; (v) input for guiding decisions regarding tumor classification should be solicited from experts in complementary disciplines of neuro‐oncology; and (iv) entity‐specific molecular testing and reporting formats should be followed in diagnostic reports. It is hoped that these guidelines will facilitate the forthcoming update of the fourth edition of the WHO classification of central nervous system tumors.\n",
            "------------------------------------\n",
            "Title Incentives for Information Production in Markets Where Prices Affect Real Investment\n",
            "Author [{'authorId': '145604903', 'name': 'James Dow'}, {'authorId': '3073437', 'name': 'Itay Goldstein'}, {'authorId': '1922840', 'name': 'A. Guembel'}]\n",
            "Venue \n",
            "year 2016\n",
            "Abstract We analyze information production incentives for traders in financial markets, when firms condition investment decisions on information revealed through stock prices. We show that traders’ private value of information about a firm’s investment project increases with the ex ante likelihood the project will be undertaken. This generates an informational amplification effect of shocks to firm value. Information production by traders may exhibit strategic complementarities for projects that would not be undertaken in the absence of positive news from the stock market. A small decline in fundamentals can lead to a market breakdown where information production ceases, and investment and firm value collapse. Our theory sheds light on how productivity shocks are amplified over the business cycle.\n",
            "------------------------------------\n",
            "Title Censoring Representations with an Adversary\n",
            "Author [{'authorId': '144632352', 'name': 'Harrison Edwards'}, {'authorId': '1728216', 'name': 'A. Storkey'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2015\n",
            "Abstract In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model.\n",
            "------------------------------------\n",
            "Title Information metamaterials and metasurfaces\n",
            "Author [{'authorId': '1911485', 'name': 'T. Cui'}, {'authorId': '2108061115', 'name': 'Shuo Liu'}, {'authorId': '2152828670', 'name': 'Lei Zhang'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract Traditionally, “metamaterials” have been described by effective medium parameters due to the subwavelength nature of unit particles. The continuous nature of medium parameters makes traditional metamaterials behave as analog metamaterials. Recently, the concept of coding metamaterials or “metasurfaces” has been proposed, in which metamaterials are characterized by digital coding particles of “0” and “1” with opposite phase responses. It has been demonstrated that electromagnetic waves can be manipulated by changing the coding sequences of “0” and “1”. The coding particles provide a link between the physical world and digital world, leading to digital metamaterials and even field programmable metamaterials, which can be used to control electromagnetic waves in real time. The digital coding representation of metamaterials or metasurfaces can also allow the concepts and signal processing methods in information science to be introduced to physical metamaterials, thereby realizing extreme control of electromagnetic waves. Such studies have set the foundation of information metamaterials and metasurfaces. In this review article, the coding, digital, and field programmable metamaterials and metasurfaces are systematically summarized and analyzed with particular emphases on the information and digital convolution aspects. The future trend of information metamaterial/metasurface is predicted, including software-defined metamaterials/metasurfaces and cognitive metamaterials/metasurfaces.\n",
            "------------------------------------\n",
            "Title Determinants of patient choice of healthcare providers: a scoping review\n",
            "Author [{'authorId': '2079720131', 'name': 'A. Victoor'}, {'authorId': '3712735', 'name': 'D. Delnoij'}, {'authorId': '153747669', 'name': 'R. Friele'}, {'authorId': '40540180', 'name': 'J. Rademakers'}]\n",
            "Venue BMC Health Services Research\n",
            "year 2012\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title Pileup per particle identification\n",
            "Author [{'authorId': '94923404', 'name': 'D. Bertolini'}, {'authorId': '144326960', 'name': 'P. Harris'}, {'authorId': '49398324', 'name': 'M. Low'}, {'authorId': '151698976', 'name': 'N. Tran'}]\n",
            "Venue \n",
            "year 2014\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A Glorious and Not-So-Short History of the Information Systems Field\n",
            "Author [{'authorId': '1719444', 'name': 'R. Hirschheim'}, {'authorId': '1716864', 'name': 'H. Klein'}]\n",
            "Venue Journal of the AIS\n",
            "year 2012\n",
            "Abstract Research Article\n",
            "------------------------------------\n",
            "Title Link Prediction Based on Graph Neural Networks\n",
            "Author [{'authorId': '3098251', 'name': 'Muhan Zhang'}, {'authorId': '9527255', 'name': 'Yixin Chen'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2018\n",
            "Abstract Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\\gamma$-decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the $\\gamma$-decaying theory, we propose a new algorithm to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems.\n",
            "------------------------------------\n",
            "Title Improving understanding in the research informed consent process: a systematic review of 54 interventions tested in randomized control trials\n",
            "Author [{'authorId': '2457911', 'name': 'Adam A. Nishimura'}, {'authorId': '40513845', 'name': 'Jantey Carey'}, {'authorId': '4194065', 'name': 'P. Erwin'}, {'authorId': '6971536', 'name': 'J. Tilburt'}, {'authorId': '46194969', 'name': 'M. Murad'}, {'authorId': '40120359', 'name': 'Jennifer B. McCormick'}]\n",
            "Venue BMC Medical Ethics\n",
            "year 2013\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title GSDS 2.0: an upgraded gene feature visualization server\n",
            "Author [{'authorId': '2143657223', 'name': 'B. Hu'}, {'authorId': '2436328', 'name': 'Jinpu Jin'}, {'authorId': '36328688', 'name': 'Anyuan Guo'}, {'authorId': '2153526647', 'name': 'He Zhang'}, {'authorId': '8277897', 'name': 'Jingchu Luo'}, {'authorId': '144398798', 'name': 'G. Gao'}]\n",
            "Venue Bioinform.\n",
            "year 2014\n",
            "Abstract Summary: Visualizing genes’ structure and annotated features helps biologists to investigate their function and evolution intuitively. The Gene Structure Display Server (GSDS) has been widely used by more than 60 000 users since its first publication in 2007. Here, we reported the upgraded GSDS 2.0 with a newly designed interface, supports for more types of annotation features and formats, as well as an integrated visual editor for editing the generated figure. Moreover, a user-specified phylogenetic tree can be added to facilitate further evolutionary analysis. The full source code is also available for downloading. Availability and implementation: Web server and source code are freely available at http://gsds.cbi.pku.edu.cn. Contact: gaog@mail.cbi.pku.edu.cn or gsds@mail.cbi.pku.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "------------------------------------\n",
            "Title Variational Lossy Autoencoder\n",
            "Author [{'authorId': '41192764', 'name': 'Xi Chen'}, {'authorId': '1726807', 'name': 'Diederik P. Kingma'}, {'authorId': '2887364', 'name': 'Tim Salimans'}, {'authorId': '144581158', 'name': 'Yan Duan'}, {'authorId': '6515819', 'name': 'Prafulla Dhariwal'}, {'authorId': '47971768', 'name': 'J. Schulman'}, {'authorId': '1701686', 'name': 'Ilya Sutskever'}, {'authorId': '1689992', 'name': 'P. Abbeel'}]\n",
            "Venue International Conference on Learning Representations\n",
            "year 2016\n",
            "Abstract Representation learning seeks to expose certain aspects of observed data in a learned representation that's amenable to downstream tasks like classification. For instance, a good representation for 2D images might be one that describes only global structure and discards information about detailed texture. In this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE model allows us to have control over what the global latent code can learn and , by designing the architecture accordingly, we can force the global latent code to discard irrelevant information such as texture in 2D images, and hence the VAE only \"autoencodes\" data in a lossy fashion. In addition, by leveraging autoregressive models as both prior distribution $p(z)$ and decoding distribution $p(x|z)$, we can greatly improve generative modeling performance of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and Caltech-101 Silhouettes density estimation tasks.\n",
            "------------------------------------\n",
            "Title The Evolving Disclosure Landscape: How Changes in Technology, the Media, and Capital Markets Are Affecting Disclosure\n",
            "Author [{'authorId': '144405514', 'name': 'Gregory S. Miller'}, {'authorId': '46187645', 'name': 'Douglas J. Skinner'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract Recent changes in technology and the media are causing significant changes in how capital markets assimilate and respond to information. We identify important themes in the disclosure literature and use this as a framework to discuss the conference papers that appear in this volume. These papers examine how managers’ disclosure practices are being affected by changes in technology, the media, and capital markets. While this work makes important progress, we discuss how continuing technological change and the emergence of new forms of media offer further opportunities for research on the role of disclosure in capital markets.\n",
            "------------------------------------\n",
            "Title Enhancing wireless information and power transfer by exploiting multi-antenna techniques\n",
            "Author [{'authorId': '46772727', 'name': 'Xiaoming Chen'}, {'authorId': '1732114', 'name': 'Zhaoyang Zhang'}, {'authorId': '145244246', 'name': 'Hsiao-Hwa Chen'}, {'authorId': '2111008678', 'name': 'Huazi Zhang'}]\n",
            "Venue IEEE Communications Magazine\n",
            "year 2015\n",
            "Abstract This article reviews an emerging wireless information and power transfer (WIPT) technique with an emphasis on its performance enhancement employing multi-antenna techniques. Compared to traditional wireless information transmission, WIPT faces numerous challenges. First, it is more susceptible to channel fading and path loss, resulting in a much shorter power transfer distance. Second, it gives rise to the issue of how to balance spectral efficiency for information transmission and energy efficiency for power transfer in order to obtain an optimal tradeoff. Third, there exists a security issue for information transmission in order to improve power transfer efficiency. In this context, multi-antenna techniques, e.g. energy beamforming, are introduced to solve these problems by exploiting spatial degree of freedom. This article provides a tutorial on various aspects of multi-antenna based WIPT techniques, with a focus on tackling the challenges by parameter optimization and protocol design. In particular, we investigate the WIPT tradeoffs based on two typical multi-antenna techniques: the limited feedback multi-antenna technique for short-distance transfer; and the large-scale multiple-input multiple-output (LS-MIMO, also known as massive MIMO) technique for long-distance transfer. Finally, simulation results validate the effectiveness of the proposed schemes.\n",
            "------------------------------------\n",
            "Title Disclosure Antecedents in an Online Service Context\n",
            "Author [{'authorId': '70856893', 'name': 'David L. Mothersbaugh'}, {'authorId': '118129920', 'name': 'William K. Foxx'}, {'authorId': '39712177', 'name': 'S. Beatty'}, {'authorId': '50695587', 'name': 'Sijun Wang'}]\n",
            "Venue \n",
            "year 2012\n",
            "Abstract The authors propose and find that the mixed results of prior research regarding disclosure antecedents are due in part to a failure to account for information sensitivity. Using prospect theory to examine willingness to disclose in an online service context, the authors propose and find that greater sensitivity of information requested produces weaker effects of customization benefits but stronger effects of information control and online privacy concern. The authors also find that customization benefits can overcome the negative effects of sensitive information requests when concern is lower or control is higher, and that perceived risk and firm trust are mechanisms through which disclosure antecedents operate. For theory, this research suggests that online disclosure models need to include sensitivity of information as a moderator. Moreover, the privacy paradox (consumers voice concerns but still disclose) may result from a failure to account for information sensitivity, since the authors find no effect of privacy concern on overall disclosure but find the predicted negative effect for higher sensitive information. For practice, our research suggests actionable strategies to aid online marketers in matching information requests with the needs and concerns of consumers by providing greater control and customization, enhancing firm trust, and adapting information requests to the situation.\n",
            "------------------------------------\n",
            "Title Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation\n",
            "Author [{'authorId': '12806133', 'name': 'Sandra Wachter'}, {'authorId': '3127701', 'name': 'B. Mittelstadt'}, {'authorId': '1982425', 'name': 'L. Floridi'}]\n",
            "Venue \n",
            "year 2017\n",
            "Abstract Since approval of the EU General Data Protection Regulation (GDPR) in 2016, it has been widely and repeatedly claimed that the GDPR will legally mandate a ‘right to explanation’ of all decisions made by automated or artificially intelligent algorithmic systems. This right to explanation is viewed as an ideal mechanism to enhance the accountability and transparency of automated decision-making. However, there are several reasons to doubt both the legal existence and the feasibility of such a right. In contrast to the right to explanation of specific automated decisions claimed elsewhere, the GDPR only mandates that data subjects receive meaningful, but properly limited, information (Articles 13-15) about the logic involved, as well as the significance and the envisaged consequences of automated decision-making systems, what we term a ‘right to be informed’. Further, the ambiguity and limited scope of the ‘right not to be subject to automated decision-making’ contained in Article 22 (from which the alleged ‘right to explanation’ stems) raises questions over the protection actually afforded to data subjects. These problems show that the GDPR lacks precise language as well as explicit and well-defined rights and safeguards against automated decision-making, and therefore runs the risk of being toothless. We propose a number of legislative and policy steps that, if taken, may improve the transparency and accountability of automated decision-making when the GDPR comes into force in 2018.\n",
            "------------------------------------\n",
            "Title Re-examining the Unified Theory of Acceptance and Use of Technology (UTAUT): Towards a Revised Theoretical Model\n",
            "Author [{'authorId': '1724490', 'name': 'Yogesh Kumar Dwivedi'}, {'authorId': '1688149', 'name': 'N. Rana'}, {'authorId': '1775120', 'name': 'A. Jeyaraj'}, {'authorId': '2054405211', 'name': 'Marc Clement'}, {'authorId': '2116399602', 'name': 'Michael D. Williams'}]\n",
            "Venue Inf. Syst. Frontiers\n",
            "year 2017\n",
            "Abstract None\n",
            "------------------------------------\n",
            "Title A supply chain traceability system for food safety based on HACCP, blockchain & Internet of things\n",
            "Author [{'authorId': '35896328', 'name': 'Feng Tian'}]\n",
            "Venue International Conference on Service Systems and Service Management\n",
            "year 2017\n",
            "Abstract In recent times food safety has drawn upsurge of academic and commercial concerns. In supply chain area, with the rapid growth of internet technologies, a lot of emerging technologies have been applied in traceability systems. However, to date, nearly all of these systems are centralized which are monopolistic, asymmetric and opaque that could result in the trust problem, such as fraud, corruption, tampering and falsifying information. Besides, centralized system is vulnerable to collapse, since a single point of breakdown will lead the whole system to be crashed. Today, a new technology called the blockchain which is a ground-breaking innovation in decentralized information technology presents a whole new approach. However, since this technology is still in its early stages, it has some inherent defects, in which scalability become a primary and urgent one when we face the mass data in the real world. In this paper we will build a food supply chain traceability system for real-time food tracing based on HACCP (Hazard Analysis and Critical Control Points), blockchain and Internet of things, which could provide an information platform for all the supply chain members with openness, transparency, neutrality, reliability and security. Furthermore, we introduce a new concept BigchainDB to fill the gap in the decentralized systems at scale. The paper concludes with a description of a use case and the challenges to adopt blockchain technology in the future food supply chain traceability systems are discussed.\n",
            "------------------------------------\n",
            "Title Processing political misinformation: comprehending the Trump phenomenon\n",
            "Author [{'authorId': '4385936', 'name': 'Briony Swire'}, {'authorId': '4859855', 'name': 'A. Berinsky'}, {'authorId': '2573193', 'name': 'S. Lewandowsky'}, {'authorId': '3139999', 'name': 'Ullrich K. H. Ecker'}]\n",
            "Venue Royal Society Open Science\n",
            "year 2017\n",
            "Abstract This study investigated the cognitive processing of true and false political information. Specifically, it examined the impact of source credibility on the assessment of veracity when information comes from a polarizing source (Experiment 1), and effectiveness of explanations when they come from one's own political party or an opposition party (Experiment 2). These experiments were conducted prior to the 2016 Presidential election. Participants rated their belief in factual and incorrect statements that President Trump made on the campaign trail; facts were subsequently affirmed and misinformation retracted. Participants then re-rated their belief immediately or after a delay. Experiment 1 found that (i) if information was attributed to Trump, Republican supporters of Trump believed it more than if it was presented without attribution, whereas the opposite was true for Democrats and (ii) although Trump supporters reduced their belief in misinformation items following a correction, they did not change their voting preferences. Experiment 2 revealed that the explanation's source had relatively little impact, and belief updating was more influenced by perceived credibility of the individual initially purporting the information. These findings suggest that people use political figures as a heuristic to guide evaluation of what is true or false, yet do not necessarily insist on veracity as a prerequisite for supporting political candidates.\n",
            "------------------------------------\n",
            "Title Enhanced LSTM for Natural Language Inference\n",
            "Author [{'authorId': '47261124', 'name': 'Qian Chen'}, {'authorId': '1854999', 'name': 'Xiao-Dan Zhu'}, {'authorId': '1749989', 'name': 'Zhenhua Ling'}, {'authorId': '144572674', 'name': 'Si Wei'}, {'authorId': '36357862', 'name': 'Hui Jiang'}, {'authorId': '1697366', 'name': 'D. Inkpen'}]\n",
            "Venue Annual Meeting of the Association for Computational Linguistics\n",
            "year 2016\n",
            "Abstract Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result—it further improves the performance even when added to the already very strong model.\n",
            "------------------------------------\n",
            "Title Trust and Involvement in Tourism Social Media and Web-Based Travel Information Sources\n",
            "Author [{'authorId': '12365012', 'name': 'Ana María Munar'}, {'authorId': '104146210', 'name': 'J. K. S. Jacobsen'}]\n",
            "Venue \n",
            "year 2013\n",
            "Abstract While utilisation of electronic social media is increasingly relevant as tourism practices, there is still a deficiency of empirical research on tourists' creation and use of various types of online content. This study maps and explores Scandinavian tourists' perceptions of Web 1.0 and Web 2.0 information sources and scrutinises influence of electronic social media on holidaymakers' information sharing, based on a summer season survey in the mature and well-known destination of Mallorca, Spain. Empirical evidence is presented on perceived trustworthiness of social media platforms and other Internet-based information. The study also examines tourists' involvement in developing and sharing of virtual content. It critically analyses technological mediation through electronic word-of-mouth and involvement factors related to virtual dissemination of travel narratives. Moreover, the paper discusses information intensity, hedonic aspects and utilitarian values of tourist information in relation to interaction aspects of social media, in a context of holiday choices and online booking.\n",
            "------------------------------------\n",
            "Title Learning Attentional Communication for Multi-Agent Cooperation\n",
            "Author [{'authorId': '46179766', 'name': 'Jiechuan Jiang'}, {'authorId': '2265693', 'name': 'Zongqing Lu'}]\n",
            "Venue Neural Information Processing Systems\n",
            "year 2018\n",
            "Abstract Communication could potentially be an effective way for multi-agent cooperation. However, information sharing among all agents or in predefined communication architectures that existing methods adopt can be problematic. When there is a large number of agents, agents cannot differentiate valuable information that helps cooperative decision making from globally shared information. Therefore, communication barely helps, and could even impair the learning of multi-agent cooperation. Predefined communication architectures, on the other hand, restrict communication among agents and thus restrain potential cooperation. To tackle these difficulties, in this paper, we propose an attentional communication model that learns when communication is needed and how to integrate shared information for cooperative decision making. Our model leads to efficient and effective communication for large-scale multi-agent cooperation. Empirically, we show the strength of our model in a variety of cooperative scenarios, where agents are able to develop more coordinated and sophisticated strategies than existing methods.\n",
            "------------------------------------\n",
            "Title Coronavirus-Related Health Literacy: A Cross-Sectional Study in Adults during the COVID-19 Infodemic in Germany\n",
            "Author [{'authorId': '10438169', 'name': 'O. Okan'}, {'authorId': '10423098', 'name': 'T. Bollweg'}, {'authorId': '100596058', 'name': 'E. Berens'}, {'authorId': '48102709', 'name': 'K. Hurrelmann'}, {'authorId': '48500018', 'name': 'U. Bauer'}, {'authorId': '123589864', 'name': 'D. Schaeffer'}]\n",
            "Venue International Journal of Environmental Research and Public Health\n",
            "year 2020\n",
            "Abstract There is an “infodemic” associated with the COVID-19 pandemic—an overabundance of valid and invalid information. Health literacy is the ability to access, understand, appraise, and apply health information, making it crucial for navigating coronavirus and COVID-19 information environments. A cross-sectional representative study of participants ≥ 16 years in Germany was conducted using an online survey. A coronavirus-related health literacy measure was developed (HLS-COVID-Q22). Internal consistency was very high (α = 0.940; ρ = 0.891) and construct validity suggests a sufficient model fit, making HLS-COVID-Q22 a feasible tool for assessing coronavirus-related health literacy in population surveys. While 49.9% of our sample had sufficient levels of coronavirus-related health literacy, 50.1% had “problematic” (15.2%) or “inadequate” (34.9%) levels. Although the overall level of health literacy is high, a vast number of participants report difficulties dealing with coronavirus and COVID-19 information. The participants felt well informed about coronavirus, but 47.8% reported having difficulties judging whether they could trust media information on COVID-19. Confusion about coronavirus information was significantly higher among those who had lower health literacy. This calls for targeted public information campaigns and promotion of population-based health literacy for better navigation of information environments during the infodemic, identification of disinformation, and decision-making based on reliable and trustworthy information.\n",
            "------------------------------------\n",
            "Title Existing data sources for clinical epidemiology: The Danish National Database of Reimbursed Prescriptions\n",
            "Author [{'authorId': '5948118', 'name': 'S. A. Jóhannesdóttir'}, {'authorId': '1382495689', 'name': 'E. Horváth-Puhó'}, {'authorId': '4384657', 'name': 'V. Ehrenstein'}, {'authorId': '31820923', 'name': 'M. Schmidt'}, {'authorId': '145982639', 'name': 'L. Pedersen'}, {'authorId': '34432960', 'name': 'H. Sørensen'}]\n",
            "Venue Clinical Epidemiology\n",
            "year 2012\n",
            "Abstract The Danish health care system provides partial reimbursement of most prescription medications in Denmark. The dispensation of prescription medications is registered in administrative databases. Each time a prescription is redeemed at a pharmacy, an electronic record is generated with information related to the user, prescriber, the pharmacy, and the dispensed drug. The National Health Service gathers this information for administration of the drug reimbursement plan. Recently, this information became the basis for the establishment of a new research database, the Danish National Database of Reimbursed Prescriptions (DNDRP). In this paper, we review the content, coverage, quality, linkage, access, and research possibilities of this new database. The database encompasses the reimbursement records of all reimbursed drugs sold in community pharmacies and hospital-based outpatient pharmacies in Denmark since 2004. On average, approximately 3.5 million users are recorded in the database each year. During the coverage period, the number of annual prescription redemptions increased by 15%. Most dispensed prescriptions are in the categories “alimentary tract and metabolism”, “cardiovascular system”, “nervous system”, and “respiratory system”. Individuals are identified by the unique central personal registration (CPR) number assigned to all persons born in or immigrating to Denmark. The new database fully complies with Denmark’s Act on Processing of Personal Data, while avoiding additional restrictions imposed on data use at the Danish National Prescription Registry, administered by Statistics Denmark. Most importantly, CPR numbers are reversibly encrypted, which allows re-identification of drug users; furthermore, the data access is possible outside the servers of Statistics Denmark. These features open additional opportunities for international collaboration, validation studies, studies on adverse drug effects requiring review of medical records, studies involving contact to general practitioners, and linkage of prescription data to other clinical and research databases. The DNDRP thus is a valuable data source for pharmacoepidemiological research.\n",
            "------------------------------------\n",
            "Title FPGA based Real time 'secure' body temperature monitoring suitable for WBSN 2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing\n",
            "Author [{'authorId': '39570475', 'name': 'M. Rao'}, {'authorId': '1812777', 'name': 'T. Newe'}, {'authorId': '1678424', 'name': 'I. Grout'}, {'authorId': '25668050', 'name': 'E. Lewis'}, {'authorId': '3058510', 'name': 'Avijit Mathur'}]\n",
            "Venue \n",
            "year 2015\n",
            "Abstract In wireless body sensor networks (WBSNs), sensors continuously monitor human physiological activities using medical sensors, for example; blood pressure, body temperature and electrocardiography (ECG). A WBSN can be used to develop a patient monitoring system. The traditional body sensor networks (BSNs) have limited hardware resources in terms of computational capabilities, data processing speed, memory and battery life. Also these BSNs are generally not suitable for the implementation of security mechanisms, reason is that, implementation of security mechanisms require relatively more hardware resources because of the complexity of their algorithms. To get rid of these limitations a Field Programmable Gate Array (FPGA) device is suitable because of its flexible architecture and high performance features. In this paper an FPGA based experimental framework is investigated to implement real time body temperature monitoring with reliable data transmission, using data integrity verification. This data integrity check is very important for patient monitoring systems as unreliable data could lead the healthcare professionals to make an incorrect diagnosis concerning patients health. The data integrity verification is achieved using newly selected cryptographic hash function called, SHA-3 (Secure Hash Algorithm-3). To the best of authors knowledge, all previously published FPGA based WBSNs implementations did not implemented any security mechanisms to secure physiological data, so this work is the first contribution regarding it.\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import requests\n",
        "import json\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "articleDictionary={\n",
        "    \"title\":[],\n",
        "    \"author\":[],\n",
        "    \"journal\":[],\n",
        "    \"year\":[],\n",
        "    \"Abstract\":[]\n",
        "\n",
        "}\n",
        "\n",
        "# request = requests.post('https://api.semanticscholar.org/graph/v1/paper/search?query=information+retrival&year=2012-2023&fields=authors,venue,year,abstract,title&offset=0&limit=99', json=data).json()\n",
        "from semanticscholar import SemanticScholar\n",
        "sch = SemanticScholar()\n",
        "resultsFromSemantic = []\n",
        "results = sch.search_paper('Information Retrival',year=\"2012-2023\")\n",
        "\n",
        "for item in results:\n",
        "  print(\"Title\",item.title)\n",
        "  print(\"Author\",item.authors)\n",
        "  print(\"Venue\",item.venue)\n",
        "  print(\"year\",item.year)\n",
        "  print(\"Abstract\",item.abstract)\n",
        "  print(36*\"-\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ3V7Cguwql_"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGhxVMz_wqmA"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}